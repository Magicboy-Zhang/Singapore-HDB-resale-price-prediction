{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>minPrimary_transitTime</th>\n",
       "      <th>min_dis</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Improved</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>Type S2</th>\n",
       "      <th>...</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>CHOA CHU KANG</th>\n",
       "      <th>CLEMENTI</th>\n",
       "      <th>JURONG WEST</th>\n",
       "      <th>KALLANG/WHAMPOA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "      <th>YISHUN</th>\n",
       "      <th>resale_price_per_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.377567</td>\n",
       "      <td>759.0</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>93.166667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6410.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.371036</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5186.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.430421</td>\n",
       "      <td>964.0</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>71.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5335.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.352865</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>94.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6691.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.371233</td>\n",
       "      <td>454.0</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5476.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>1.341138</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>48.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4908.045977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>1.329478</td>\n",
       "      <td>868.0</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>57.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5176.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>1.389799</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>91.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6246.107527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>1.338132</td>\n",
       "      <td>397.0</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>76.416667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5709.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>1.390053</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6145.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13811 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat  minPrimary_transitTime   min_dis  remaining_lease   DBSS  \\\n",
       "0      1.377567                   759.0  0.001040        93.166667  False   \n",
       "1      1.371036                   368.0  0.018341        60.833333  False   \n",
       "2      1.430421                   964.0  0.005845        71.083333  False   \n",
       "3      1.352865                   448.0  0.009913        94.833333  False   \n",
       "4      1.371233                   454.0  0.005618        61.000000  False   \n",
       "...         ...                     ...       ...              ...    ...   \n",
       "13806  1.341138                   514.0  0.003085        48.833333  False   \n",
       "13807  1.329478                   868.0  0.006544        57.083333  False   \n",
       "13808  1.389799                   254.0  0.002423        91.833333  False   \n",
       "13809  1.338132                   397.0  0.004211        76.416667  False   \n",
       "13810  1.390053                   353.0  0.002005        88.916667  False   \n",
       "\n",
       "       Improved  Model A  New Generation  Type S1  Type S2  ...  BUKIT MERAH  \\\n",
       "0          True    False           False    False    False  ...        False   \n",
       "1         False    False            True    False    False  ...        False   \n",
       "2         False    False           False    False    False  ...        False   \n",
       "3         False     True           False    False    False  ...        False   \n",
       "4         False    False           False    False    False  ...        False   \n",
       "...         ...      ...             ...      ...      ...  ...          ...   \n",
       "13806      True    False           False    False    False  ...        False   \n",
       "13807     False    False            True    False    False  ...        False   \n",
       "13808     False     True           False    False    False  ...        False   \n",
       "13809      True    False           False    False    False  ...        False   \n",
       "13810     False    False           False    False    False  ...        False   \n",
       "\n",
       "       CENTRAL AREA  CHOA CHU KANG  CLEMENTI  JURONG WEST  KALLANG/WHAMPOA  \\\n",
       "0             False           True     False        False            False   \n",
       "1             False          False     False        False            False   \n",
       "2             False          False     False        False            False   \n",
       "3             False          False     False        False            False   \n",
       "4             False          False     False        False            False   \n",
       "...             ...            ...       ...          ...              ...   \n",
       "13806         False          False     False        False            False   \n",
       "13807         False          False     False        False            False   \n",
       "13808         False          False     False        False            False   \n",
       "13809         False          False     False         True            False   \n",
       "13810         False          False     False        False            False   \n",
       "\n",
       "       QUEENSTOWN  WOODLANDS  YISHUN  resale_price_per_sqm  \n",
       "0           False      False   False           6410.714286  \n",
       "1           False      False   False           5186.813187  \n",
       "2           False       True   False           5335.365854  \n",
       "3           False      False   False           6691.176471  \n",
       "4           False      False   False           5476.190476  \n",
       "...           ...        ...     ...                   ...  \n",
       "13806       False      False   False           4908.045977  \n",
       "13807       False      False   False           5176.470588  \n",
       "13808       False      False   False           6246.107527  \n",
       "13809       False      False   False           5709.090909  \n",
       "13810       False      False   False           6145.833333  \n",
       "\n",
       "[13811 rows x 34 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train34_df = pd.read_csv('full_hdb_perSqm_train_f34.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "test34_df = pd.read_csv('full_hdb_perSqm_test_f34.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "train16_df = pd.read_csv('full_hdb_perSqm_train_f16.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "test16_df = pd.read_csv('full_hdb_perSqm_test_f16.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "train34_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>minPrimary_transitTime</th>\n",
       "      <th>min_dis</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Improved</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>Type S2</th>\n",
       "      <th>...</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>CHOA CHU KANG</th>\n",
       "      <th>CLEMENTI</th>\n",
       "      <th>JURONG WEST</th>\n",
       "      <th>KALLANG/WHAMPOA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "      <th>YISHUN</th>\n",
       "      <th>resale_price_per_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.367908</td>\n",
       "      <td>871.0</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6122.448980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.374001</td>\n",
       "      <td>612.0</td>\n",
       "      <td>0.011506</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.364612</td>\n",
       "      <td>834.0</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9071.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.365588</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>53.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5671.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.365698</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>56.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4775.280899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>1.422602</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>87.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5855.670103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>1.419920</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5978.494624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>1.427238</td>\n",
       "      <td>865.0</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>59.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5879.120879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>1.414291</td>\n",
       "      <td>934.0</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>93.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5619.469027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>1.434633</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>60.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4895.522388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5919 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lat  minPrimary_transitTime   min_dis  remaining_lease   DBSS  \\\n",
       "0     1.367908                   871.0  0.002827        53.500000  False   \n",
       "1     1.374001                   612.0  0.011506        62.083333  False   \n",
       "2     1.364612                   834.0  0.007193        88.750000  False   \n",
       "3     1.365588                  1052.0  0.010096        53.583333  False   \n",
       "4     1.365698                  1347.0  0.010306        56.083333  False   \n",
       "...        ...                     ...       ...              ...    ...   \n",
       "5914  1.422602                   879.0  0.011602        87.833333  False   \n",
       "5915  1.419920                   608.0  0.012480        88.916667  False   \n",
       "5916  1.427238                   865.0  0.002624        59.583333  False   \n",
       "5917  1.414291                   934.0  0.007527        93.583333  False   \n",
       "5918  1.434633                   800.0  0.004970        60.916667  False   \n",
       "\n",
       "      Improved  Model A  New Generation  Type S1  Type S2  ...  BUKIT MERAH  \\\n",
       "0         True    False           False    False    False  ...        False   \n",
       "1         True    False           False    False    False  ...        False   \n",
       "2        False     True           False    False    False  ...        False   \n",
       "3        False    False            True    False    False  ...        False   \n",
       "4        False    False            True    False    False  ...        False   \n",
       "...        ...      ...             ...      ...      ...  ...          ...   \n",
       "5914     False     True           False    False    False  ...        False   \n",
       "5915     False     True           False    False    False  ...        False   \n",
       "5916     False    False            True    False    False  ...        False   \n",
       "5917      True    False           False    False    False  ...        False   \n",
       "5918     False     True           False    False    False  ...        False   \n",
       "\n",
       "      CENTRAL AREA  CHOA CHU KANG  CLEMENTI  JURONG WEST  KALLANG/WHAMPOA  \\\n",
       "0            False          False     False        False            False   \n",
       "1            False          False     False        False            False   \n",
       "2            False          False     False        False            False   \n",
       "3            False          False     False        False            False   \n",
       "4            False          False     False        False            False   \n",
       "...            ...            ...       ...          ...              ...   \n",
       "5914         False          False     False        False            False   \n",
       "5915         False          False     False        False            False   \n",
       "5916         False          False     False        False            False   \n",
       "5917         False          False     False        False            False   \n",
       "5918         False          False     False        False            False   \n",
       "\n",
       "      QUEENSTOWN  WOODLANDS  YISHUN  resale_price_per_sqm  \n",
       "0          False      False   False           6122.448980  \n",
       "1          False      False   False           6440.000000  \n",
       "2          False      False   False           9071.428571  \n",
       "3          False      False   False           5671.641791  \n",
       "4          False      False   False           4775.280899  \n",
       "...          ...        ...     ...                   ...  \n",
       "5914       False      False    True           5855.670103  \n",
       "5915       False      False    True           5978.494624  \n",
       "5916       False      False    True           5879.120879  \n",
       "5917       False      False    True           5619.469027  \n",
       "5918       False      False    True           4895.522388  \n",
       "\n",
       "[5919 rows x 34 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test34_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>01 TO 03</th>\n",
       "      <th>22 TO 24</th>\n",
       "      <th>25 TO 27</th>\n",
       "      <th>28 TO 30</th>\n",
       "      <th>34 TO 36</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "      <th>resale_price_per_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.377567</td>\n",
       "      <td>93.166667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6410.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.371036</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5186.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.430421</td>\n",
       "      <td>71.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5335.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.352865</td>\n",
       "      <td>94.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6691.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.371233</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5476.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>1.341138</td>\n",
       "      <td>48.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4908.045977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>1.329478</td>\n",
       "      <td>57.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5176.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>1.389799</td>\n",
       "      <td>91.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6246.107527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>1.338132</td>\n",
       "      <td>76.416667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5709.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>1.390053</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6145.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13811 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat  remaining_lease   DBSS  Model A  New Generation  Type S1  \\\n",
       "0      1.377567        93.166667  False    False           False    False   \n",
       "1      1.371036        60.833333  False    False            True    False   \n",
       "2      1.430421        71.083333  False    False           False    False   \n",
       "3      1.352865        94.833333  False     True           False    False   \n",
       "4      1.371233        61.000000  False    False           False    False   \n",
       "...         ...              ...    ...      ...             ...      ...   \n",
       "13806  1.341138        48.833333  False    False           False    False   \n",
       "13807  1.329478        57.083333  False    False            True    False   \n",
       "13808  1.389799        91.833333  False     True           False    False   \n",
       "13809  1.338132        76.416667  False    False           False    False   \n",
       "13810  1.390053        88.916667  False    False           False    False   \n",
       "\n",
       "       01 TO 03  22 TO 24  25 TO 27  28 TO 30  34 TO 36  BUKIT MERAH  \\\n",
       "0         False     False     False     False     False        False   \n",
       "1          True     False     False     False     False        False   \n",
       "2         False     False     False     False     False        False   \n",
       "3         False     False     False     False     False        False   \n",
       "4         False     False     False     False     False        False   \n",
       "...         ...       ...       ...       ...       ...          ...   \n",
       "13806      True     False     False     False     False        False   \n",
       "13807     False     False     False     False     False        False   \n",
       "13808     False     False     False     False     False        False   \n",
       "13809     False     False     False     False     False        False   \n",
       "13810     False     False     False     False     False        False   \n",
       "\n",
       "       CENTRAL AREA  QUEENSTOWN  WOODLANDS  resale_price_per_sqm  \n",
       "0             False       False      False           6410.714286  \n",
       "1             False       False      False           5186.813187  \n",
       "2             False       False       True           5335.365854  \n",
       "3             False       False      False           6691.176471  \n",
       "4             False       False      False           5476.190476  \n",
       "...             ...         ...        ...                   ...  \n",
       "13806         False       False      False           4908.045977  \n",
       "13807         False       False      False           5176.470588  \n",
       "13808         False       False      False           6246.107527  \n",
       "13809         False       False      False           5709.090909  \n",
       "13810         False       False      False           6145.833333  \n",
       "\n",
       "[13811 rows x 16 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train16_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>01 TO 03</th>\n",
       "      <th>22 TO 24</th>\n",
       "      <th>25 TO 27</th>\n",
       "      <th>28 TO 30</th>\n",
       "      <th>34 TO 36</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "      <th>resale_price_per_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.367908</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6122.448980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.374001</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.364612</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9071.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.365588</td>\n",
       "      <td>53.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5671.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.365698</td>\n",
       "      <td>56.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4775.280899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>1.422602</td>\n",
       "      <td>87.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5855.670103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>1.419920</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5978.494624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>1.427238</td>\n",
       "      <td>59.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5879.120879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>1.414291</td>\n",
       "      <td>93.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5619.469027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>1.434633</td>\n",
       "      <td>60.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4895.522388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5919 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lat  remaining_lease   DBSS  Model A  New Generation  Type S1  \\\n",
       "0     1.367908        53.500000  False    False           False    False   \n",
       "1     1.374001        62.083333  False    False           False    False   \n",
       "2     1.364612        88.750000  False     True           False    False   \n",
       "3     1.365588        53.583333  False    False            True    False   \n",
       "4     1.365698        56.083333  False    False            True    False   \n",
       "...        ...              ...    ...      ...             ...      ...   \n",
       "5914  1.422602        87.833333  False     True           False    False   \n",
       "5915  1.419920        88.916667  False     True           False    False   \n",
       "5916  1.427238        59.583333  False    False            True    False   \n",
       "5917  1.414291        93.583333  False    False           False    False   \n",
       "5918  1.434633        60.916667  False     True           False    False   \n",
       "\n",
       "      01 TO 03  22 TO 24  25 TO 27  28 TO 30  34 TO 36  BUKIT MERAH  \\\n",
       "0        False     False     False     False     False        False   \n",
       "1         True     False     False     False     False        False   \n",
       "2        False     False      True     False     False        False   \n",
       "3        False     False     False     False     False        False   \n",
       "4        False     False     False     False     False        False   \n",
       "...        ...       ...       ...       ...       ...          ...   \n",
       "5914     False     False     False     False     False        False   \n",
       "5915     False     False     False     False     False        False   \n",
       "5916     False     False     False     False     False        False   \n",
       "5917      True     False     False     False     False        False   \n",
       "5918     False     False     False     False     False        False   \n",
       "\n",
       "      CENTRAL AREA  QUEENSTOWN  WOODLANDS  resale_price_per_sqm  \n",
       "0            False       False      False           6122.448980  \n",
       "1            False       False      False           6440.000000  \n",
       "2            False       False      False           9071.428571  \n",
       "3            False       False      False           5671.641791  \n",
       "4            False       False      False           4775.280899  \n",
       "...            ...         ...        ...                   ...  \n",
       "5914         False       False      False           5855.670103  \n",
       "5915         False       False      False           5978.494624  \n",
       "5916         False       False      False           5879.120879  \n",
       "5917         False       False      False           5619.469027  \n",
       "5918         False       False      False           4895.522388  \n",
       "\n",
       "[5919 rows x 16 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict = {\n",
    "    'hidden_units' : [7, 8, 9],\n",
    "    'batch_size' : [16, 32, 64],\n",
    "    'learning_rate' : [[0.008, 0.01], [0.0008, 0.001]]\n",
    "}\n",
    "\n",
    "def create_model(columns, units = 8, activation = 'relu', loss = 'mae', optimizer = 'SGD', metrics = 'mae'):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(units, input_shape = (len(columns), ), activation = activation),\n",
    "        Dense(1, activation = activation)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = loss,\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5919 entries, 0 to 5918\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   lat                     5919 non-null   float64\n",
      " 1   minPrimary_transitTime  5919 non-null   float64\n",
      " 2   min_dis                 5919 non-null   float64\n",
      " 3   remaining_lease         5919 non-null   float64\n",
      " 4   DBSS                    5919 non-null   bool   \n",
      " 5   Improved                5919 non-null   bool   \n",
      " 6   Model A                 5919 non-null   bool   \n",
      " 7   New Generation          5919 non-null   bool   \n",
      " 8   Type S1                 5919 non-null   bool   \n",
      " 9   Type S2                 5919 non-null   bool   \n",
      " 10  2 ROOM                  5919 non-null   bool   \n",
      " 11  01 TO 03                5919 non-null   bool   \n",
      " 12  04 TO 06                5919 non-null   bool   \n",
      " 13  16 TO 18                5919 non-null   bool   \n",
      " 14  19 TO 21                5919 non-null   bool   \n",
      " 15  22 TO 24                5919 non-null   bool   \n",
      " 16  25 TO 27                5919 non-null   bool   \n",
      " 17  28 TO 30                5919 non-null   bool   \n",
      " 18  31 TO 33                5919 non-null   bool   \n",
      " 19  34 TO 36                5919 non-null   bool   \n",
      " 20  37 TO 39                5919 non-null   bool   \n",
      " 21  40 TO 42                5919 non-null   bool   \n",
      " 22  43 TO 45                5919 non-null   bool   \n",
      " 23  BISHAN                  5919 non-null   bool   \n",
      " 24  BUKIT MERAH             5919 non-null   bool   \n",
      " 25  CENTRAL AREA            5919 non-null   bool   \n",
      " 26  CHOA CHU KANG           5919 non-null   bool   \n",
      " 27  CLEMENTI                5919 non-null   bool   \n",
      " 28  JURONG WEST             5919 non-null   bool   \n",
      " 29  KALLANG/WHAMPOA         5919 non-null   bool   \n",
      " 30  QUEENSTOWN              5919 non-null   bool   \n",
      " 31  WOODLANDS               5919 non-null   bool   \n",
      " 32  YISHUN                  5919 non-null   bool   \n",
      "dtypes: bool(29), float64(4)\n",
      "memory usage: 352.7 KB\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model 34\n",
    "'''\n",
    "\n",
    "# train set\n",
    "y_train = train34_df['resale_price_per_sqm']\n",
    "x_train = train34_df.drop('resale_price_per_sqm', axis = 1)\n",
    "\n",
    "# test set\n",
    "y_test = test34_df[['resale_price_per_sqm']]\n",
    "x_test = test34_df.drop('resale_price_per_sqm', axis = 1)\n",
    "\n",
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>minPrimary_transitTime</th>\n",
       "      <th>min_dis</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Improved</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>Type S2</th>\n",
       "      <th>...</th>\n",
       "      <th>BISHAN</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>CHOA CHU KANG</th>\n",
       "      <th>CLEMENTI</th>\n",
       "      <th>JURONG WEST</th>\n",
       "      <th>KALLANG/WHAMPOA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "      <th>YISHUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156048</td>\n",
       "      <td>-0.026266</td>\n",
       "      <td>-1.299018</td>\n",
       "      <td>1.261190</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.800836</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>4.855382</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007990</td>\n",
       "      <td>-1.229159</td>\n",
       "      <td>3.027768</td>\n",
       "      <td>-0.878525</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>2.772393</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.354411</td>\n",
       "      <td>0.604407</td>\n",
       "      <td>-0.097186</td>\n",
       "      <td>-0.200213</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>3.268705</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.404001</td>\n",
       "      <td>-0.983043</td>\n",
       "      <td>0.920124</td>\n",
       "      <td>1.371485</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>1.225188</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012449</td>\n",
       "      <td>-0.964584</td>\n",
       "      <td>-0.154118</td>\n",
       "      <td>-0.867495</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>-0.669887</td>\n",
       "      <td>-0.779997</td>\n",
       "      <td>-0.787476</td>\n",
       "      <td>-1.672645</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.800836</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>-0.934243</td>\n",
       "      <td>0.309068</td>\n",
       "      <td>0.077641</td>\n",
       "      <td>-1.126687</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>2.772393</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>0.433403</td>\n",
       "      <td>-1.579874</td>\n",
       "      <td>-0.953137</td>\n",
       "      <td>1.172955</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>1.225188</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>-0.738033</td>\n",
       "      <td>-1.139942</td>\n",
       "      <td>-0.505835</td>\n",
       "      <td>0.152730</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.800836</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>3.937080</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>0.439144</td>\n",
       "      <td>-1.275306</td>\n",
       "      <td>-1.057544</td>\n",
       "      <td>0.979939</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13811 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat  minPrimary_transitTime   min_dis  remaining_lease      DBSS  \\\n",
       "0      0.156048               -0.026266 -1.299018         1.261190 -0.113286   \n",
       "1      0.007990               -1.229159  3.027768        -0.878525 -0.113286   \n",
       "2      1.354411                0.604407 -0.097186        -0.200213 -0.113286   \n",
       "3     -0.404001               -0.983043  0.920124         1.371485 -0.113286   \n",
       "4      0.012449               -0.964584 -0.154118        -0.867495 -0.113286   \n",
       "...         ...                     ...       ...              ...       ...   \n",
       "13806 -0.669887               -0.779997 -0.787476        -1.672645 -0.113286   \n",
       "13807 -0.934243                0.309068  0.077641        -1.126687 -0.113286   \n",
       "13808  0.433403               -1.579874 -0.953137         1.172955 -0.113286   \n",
       "13809 -0.738033               -1.139942 -0.505835         0.152730 -0.113286   \n",
       "13810  0.439144               -1.275306 -1.057544         0.979939 -0.113286   \n",
       "\n",
       "       Improved   Model A  New Generation   Type S1   Type S2  ...    BISHAN  \\\n",
       "0      1.800836 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "1     -0.555298 -0.816201        2.772393 -0.039943 -0.022519  ... -0.121219   \n",
       "2     -0.555298 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "3     -0.555298  1.225188       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "4     -0.555298 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "...         ...       ...             ...       ...       ...  ...       ...   \n",
       "13806  1.800836 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "13807 -0.555298 -0.816201        2.772393 -0.039943 -0.022519  ... -0.121219   \n",
       "13808 -0.555298  1.225188       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "13809  1.800836 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "13810 -0.555298 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "\n",
       "       BUKIT MERAH  CENTRAL AREA  CHOA CHU KANG  CLEMENTI  JURONG WEST  \\\n",
       "0        -0.198981     -0.082337       4.855382 -0.145157    -0.253995   \n",
       "1        -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "2        -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "3        -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "4        -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "...            ...           ...            ...       ...          ...   \n",
       "13806    -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "13807    -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "13808    -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "13809    -0.198981     -0.082337      -0.205957 -0.145157     3.937080   \n",
       "13810    -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "\n",
       "       KALLANG/WHAMPOA  QUEENSTOWN  WOODLANDS    YISHUN  \n",
       "0             -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "1             -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "2             -0.18119   -0.159825   3.268705 -0.278484  \n",
       "3             -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "4             -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "...                ...         ...        ...       ...  \n",
       "13806         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "13807         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "13808         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "13809         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "13810         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "\n",
       "[13811 rows x 33 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_scaled_train = scaler.fit_transform(x_train)\n",
    "\n",
    "x_scaled_train = pd.DataFrame(x_scaled_train, columns = x_train.columns)\n",
    "\n",
    "x_scaled_test = scaler.fit_transform(x_test)\n",
    "\n",
    "x_scaled_test = pd.DataFrame(x_scaled_test, columns = x_test.columns)\n",
    "\n",
    "x_scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 2s 2ms/step - loss: 4385.7329 - mae: 4385.7329 - val_loss: 535.1006 - val_mae: 535.1006\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 522.1991 - mae: 522.1991 - val_loss: 553.0164 - val_mae: 553.0164\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 524.3036 - mae: 524.3036 - val_loss: 532.6707 - val_mae: 532.6707\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 512.0093 - mae: 512.0093 - val_loss: 526.1748 - val_mae: 526.1748\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 503.6854 - mae: 503.6854 - val_loss: 491.7916 - val_mae: 491.7916\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 482.8032 - mae: 482.8032 - val_loss: 481.4672 - val_mae: 481.4672\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 460.5576 - mae: 460.5576 - val_loss: 479.0305 - val_mae: 479.0305\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 446.5360 - mae: 446.5360 - val_loss: 462.9540 - val_mae: 462.9540\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441.4243 - mae: 441.4243 - val_loss: 443.1856 - val_mae: 443.1856\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436.0224 - mae: 436.0224 - val_loss: 438.1470 - val_mae: 438.1470\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435.9852 - mae: 435.9852 - val_loss: 442.0859 - val_mae: 442.0859\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432.4687 - mae: 432.4687 - val_loss: 453.2413 - val_mae: 453.2413\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431.4347 - mae: 431.4347 - val_loss: 435.9234 - val_mae: 435.9234\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428.6930 - mae: 428.6930 - val_loss: 428.8548 - val_mae: 428.8548\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427.8684 - mae: 427.8684 - val_loss: 440.9244 - val_mae: 440.9244\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.6437 - mae: 425.6437 - val_loss: 439.4918 - val_mae: 439.4918\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.0558 - mae: 425.0558 - val_loss: 429.4801 - val_mae: 429.4801\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.5088 - mae: 423.5088 - val_loss: 425.1385 - val_mae: 425.1385\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.6601 - mae: 421.6601 - val_loss: 419.5467 - val_mae: 419.5467\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.1076 - mae: 421.1076 - val_loss: 423.7773 - val_mae: 423.7773\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.6145 - mae: 420.6145 - val_loss: 431.0545 - val_mae: 431.0545\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419.3236 - mae: 419.3236 - val_loss: 424.3268 - val_mae: 424.3268\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.2531 - mae: 418.2531 - val_loss: 420.1469 - val_mae: 420.1469\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.6923 - mae: 418.6923 - val_loss: 421.7941 - val_mae: 421.7941\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.9200 - mae: 416.9200 - val_loss: 430.5838 - val_mae: 430.5838\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.8830 - mae: 416.8830 - val_loss: 426.7632 - val_mae: 426.7632\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.1387 - mae: 415.1387 - val_loss: 420.0477 - val_mae: 420.0477\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.6591 - mae: 414.6591 - val_loss: 433.8736 - val_mae: 433.8736\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.0008 - mae: 414.0008 - val_loss: 443.8153 - val_mae: 443.8153\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3300.2986 - mae: 3300.2986 - val_loss: 559.4200 - val_mae: 559.4200\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 517.2319 - mae: 517.2319 - val_loss: 521.3384 - val_mae: 521.3384\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 508.9350 - mae: 508.9350 - val_loss: 531.5696 - val_mae: 531.5696\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 490.2122 - mae: 490.2122 - val_loss: 503.1446 - val_mae: 503.1446\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 470.5964 - mae: 470.5964 - val_loss: 477.1407 - val_mae: 477.1407\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 460.3458 - mae: 460.3458 - val_loss: 471.5953 - val_mae: 471.5953\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 452.5632 - mae: 452.5632 - val_loss: 467.8314 - val_mae: 467.8314\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 449.7644 - mae: 449.7644 - val_loss: 461.0141 - val_mae: 461.0141\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 446.2370 - mae: 446.2370 - val_loss: 468.3112 - val_mae: 468.3112\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441.4909 - mae: 441.4909 - val_loss: 460.3684 - val_mae: 460.3684\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 438.5623 - mae: 438.5623 - val_loss: 433.0979 - val_mae: 433.0979\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433.9020 - mae: 433.9020 - val_loss: 462.0410 - val_mae: 462.0410\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432.4707 - mae: 432.4707 - val_loss: 426.8708 - val_mae: 426.8708\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429.4887 - mae: 429.4887 - val_loss: 430.1899 - val_mae: 430.1899\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427.9706 - mae: 427.9706 - val_loss: 439.1050 - val_mae: 439.1050\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427.3415 - mae: 427.3415 - val_loss: 437.9709 - val_mae: 437.9709\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424.1882 - mae: 424.1882 - val_loss: 456.3336 - val_mae: 456.3336\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.7802 - mae: 425.7802 - val_loss: 438.3718 - val_mae: 438.3718\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.5641 - mae: 425.5641 - val_loss: 434.1182 - val_mae: 434.1182\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.8350 - mae: 423.8350 - val_loss: 422.9026 - val_mae: 422.9026\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.3081 - mae: 423.3081 - val_loss: 430.8603 - val_mae: 430.8603\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.6831 - mae: 421.6831 - val_loss: 444.5199 - val_mae: 444.5199\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.9995 - mae: 420.9995 - val_loss: 425.2103 - val_mae: 425.2103\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.3949 - mae: 421.3949 - val_loss: 432.9951 - val_mae: 432.9951\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.6954 - mae: 421.6954 - val_loss: 484.9840 - val_mae: 484.9840\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.9268 - mae: 421.9268 - val_loss: 425.4763 - val_mae: 425.4763\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.8515 - mae: 420.8515 - val_loss: 421.1025 - val_mae: 421.1025\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422.0738 - mae: 422.0738 - val_loss: 437.3596 - val_mae: 437.3596\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.3483 - mae: 418.3483 - val_loss: 430.0478 - val_mae: 430.0478\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419.5889 - mae: 419.5889 - val_loss: 420.8078 - val_mae: 420.8078\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417.7299 - mae: 417.7299 - val_loss: 420.0794 - val_mae: 420.0794\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417.4819 - mae: 417.4819 - val_loss: 437.8583 - val_mae: 437.8583\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.2879 - mae: 416.2879 - val_loss: 423.3372 - val_mae: 423.3372\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.7096 - mae: 415.7096 - val_loss: 443.6137 - val_mae: 443.6137\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.3629 - mae: 415.3629 - val_loss: 419.6373 - val_mae: 419.6373\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.8002 - mae: 413.8002 - val_loss: 417.1617 - val_mae: 417.1617\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.7890 - mae: 413.7890 - val_loss: 421.0412 - val_mae: 421.0412\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.7268 - mae: 410.7268 - val_loss: 445.3800 - val_mae: 445.3800\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.1621 - mae: 412.1621 - val_loss: 416.7021 - val_mae: 416.7021\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.0046 - mae: 412.0046 - val_loss: 417.6691 - val_mae: 417.6691\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.6749 - mae: 412.6749 - val_loss: 415.6462 - val_mae: 415.6462\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.8576 - mae: 409.8576 - val_loss: 416.6360 - val_mae: 416.6360\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.1312 - mae: 411.1312 - val_loss: 424.5068 - val_mae: 424.5068\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.8183 - mae: 411.8183 - val_loss: 406.2715 - val_mae: 406.2715\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.2932 - mae: 410.2932 - val_loss: 416.6140 - val_mae: 416.6140\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.5317 - mae: 408.5317 - val_loss: 412.1040 - val_mae: 412.1040\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.6860 - mae: 408.6860 - val_loss: 417.3900 - val_mae: 417.3900\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.6782 - mae: 409.6782 - val_loss: 413.9804 - val_mae: 413.9804\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.1265 - mae: 409.1265 - val_loss: 405.5753 - val_mae: 405.5753\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.7058 - mae: 407.7058 - val_loss: 407.6484 - val_mae: 407.6484\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.3133 - mae: 408.3133 - val_loss: 418.3493 - val_mae: 418.3493\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.0594 - mae: 407.0594 - val_loss: 404.2540 - val_mae: 404.2540\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.0983 - mae: 407.0983 - val_loss: 405.4216 - val_mae: 405.4216\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.9952 - mae: 407.9952 - val_loss: 420.7619 - val_mae: 420.7619\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.9495 - mae: 407.9495 - val_loss: 413.7337 - val_mae: 413.7337\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406.4125 - mae: 406.4125 - val_loss: 408.2743 - val_mae: 408.2743\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.1138 - mae: 407.1138 - val_loss: 411.7363 - val_mae: 411.7363\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.5659 - mae: 407.5659 - val_loss: 421.7924 - val_mae: 421.7924\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.3361 - mae: 407.3361 - val_loss: 426.4370 - val_mae: 426.4370\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.0340 - mae: 407.0340 - val_loss: 418.7700 - val_mae: 418.7700\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406.3407 - mae: 406.3407 - val_loss: 432.9092 - val_mae: 432.9092\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406.1046 - mae: 406.1046 - val_loss: 404.4718 - val_mae: 404.4718\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6030.2676 - mae: 6030.2676 - val_loss: 5895.1787 - val_mae: 5895.1787\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2762.7522 - mae: 2762.7522 - val_loss: 502.6948 - val_mae: 502.6948\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 495.7170 - mae: 495.7170 - val_loss: 495.4380 - val_mae: 495.4380\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 491.4652 - mae: 491.4652 - val_loss: 496.6768 - val_mae: 496.6768\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 489.5674 - mae: 489.5674 - val_loss: 492.8778 - val_mae: 492.8778\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 488.1620 - mae: 488.1620 - val_loss: 499.0117 - val_mae: 499.0117\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 484.7305 - mae: 484.7305 - val_loss: 487.2373 - val_mae: 487.2373\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 482.3022 - mae: 482.3022 - val_loss: 480.0801 - val_mae: 480.0801\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 476.8478 - mae: 476.8478 - val_loss: 479.1373 - val_mae: 479.1373\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 468.6211 - mae: 468.6211 - val_loss: 464.5188 - val_mae: 464.5188\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 462.2317 - mae: 462.2317 - val_loss: 467.4297 - val_mae: 467.4297\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 456.4561 - mae: 456.4561 - val_loss: 462.0485 - val_mae: 462.0485\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 450.4639 - mae: 450.4639 - val_loss: 452.4586 - val_mae: 452.4586\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 447.1476 - mae: 447.1476 - val_loss: 457.5958 - val_mae: 457.5958\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442.5168 - mae: 442.5168 - val_loss: 454.0100 - val_mae: 454.0100\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442.2676 - mae: 442.2676 - val_loss: 449.3882 - val_mae: 449.3882\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 441.9623 - mae: 441.9623 - val_loss: 449.8525 - val_mae: 449.8525\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 440.2363 - mae: 440.2363 - val_loss: 443.6157 - val_mae: 443.6157\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439.7119 - mae: 439.7119 - val_loss: 445.4425 - val_mae: 445.4425\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438.0266 - mae: 438.0266 - val_loss: 440.1100 - val_mae: 440.1100\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436.5668 - mae: 436.5668 - val_loss: 446.1442 - val_mae: 446.1442\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437.0771 - mae: 437.0771 - val_loss: 446.0214 - val_mae: 446.0214\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436.4494 - mae: 436.4494 - val_loss: 437.5605 - val_mae: 437.5605\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 434.7462 - mae: 434.7462 - val_loss: 447.4737 - val_mae: 447.4737\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 433.3891 - mae: 433.3891 - val_loss: 441.6456 - val_mae: 441.6456\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 431.0555 - mae: 431.0555 - val_loss: 435.5352 - val_mae: 435.5352\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 430.3330 - mae: 430.3330 - val_loss: 441.6259 - val_mae: 441.6259\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 428.0804 - mae: 428.0804 - val_loss: 430.8113 - val_mae: 430.8113\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 427.8414 - mae: 427.8414 - val_loss: 431.7464 - val_mae: 431.7464\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426.3098 - mae: 426.3098 - val_loss: 427.3177 - val_mae: 427.3177\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425.0562 - mae: 425.0562 - val_loss: 425.1987 - val_mae: 425.1987\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423.4411 - mae: 423.4411 - val_loss: 430.9221 - val_mae: 430.9221\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.3413 - mae: 421.3413 - val_loss: 423.2416 - val_mae: 423.2416\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.3909 - mae: 421.3909 - val_loss: 424.6845 - val_mae: 424.6845\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.3340 - mae: 420.3340 - val_loss: 423.4618 - val_mae: 423.4618\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.9184 - mae: 419.9184 - val_loss: 422.8834 - val_mae: 422.8834\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.0036 - mae: 420.0036 - val_loss: 416.3968 - val_mae: 416.3968\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.5598 - mae: 418.5598 - val_loss: 418.7771 - val_mae: 418.7771\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.6817 - mae: 417.6817 - val_loss: 422.6738 - val_mae: 422.6738\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.3897 - mae: 416.3897 - val_loss: 422.1697 - val_mae: 422.1697\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.7142 - mae: 417.7142 - val_loss: 416.3526 - val_mae: 416.3526\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.2511 - mae: 417.2511 - val_loss: 423.6521 - val_mae: 423.6521\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.7422 - mae: 416.7422 - val_loss: 424.4441 - val_mae: 424.4441\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.6025 - mae: 416.6025 - val_loss: 421.3434 - val_mae: 421.3434\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.1608 - mae: 416.1608 - val_loss: 425.3028 - val_mae: 425.3028\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.9541 - mae: 415.9541 - val_loss: 425.3142 - val_mae: 425.3142\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.8933 - mae: 415.8933 - val_loss: 422.4694 - val_mae: 422.4694\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.3987 - mae: 417.3987 - val_loss: 417.6761 - val_mae: 417.6761\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.5131 - mae: 415.5131 - val_loss: 426.1998 - val_mae: 426.1998\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.3977 - mae: 415.3977 - val_loss: 419.7069 - val_mae: 419.7069\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.6974 - mae: 416.6974 - val_loss: 419.6058 - val_mae: 419.6058\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 5934.3916 - mae: 5934.3916 - val_loss: 5064.3667 - val_mae: 5064.3667\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1222.5299 - mae: 1222.5299 - val_loss: 512.1923 - val_mae: 512.1923\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 498.3502 - mae: 498.3502 - val_loss: 506.0076 - val_mae: 506.0076\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 492.1792 - mae: 492.1792 - val_loss: 499.1270 - val_mae: 499.1270\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 484.1815 - mae: 484.1815 - val_loss: 489.9107 - val_mae: 489.9107\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 474.3162 - mae: 474.3162 - val_loss: 464.8654 - val_mae: 464.8654\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 464.3277 - mae: 464.3277 - val_loss: 460.9989 - val_mae: 460.9989\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 455.5308 - mae: 455.5308 - val_loss: 462.2819 - val_mae: 462.2819\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 452.0426 - mae: 452.0426 - val_loss: 455.5066 - val_mae: 455.5066\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 445.5556 - mae: 445.5556 - val_loss: 452.4514 - val_mae: 452.4514\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 441.3518 - mae: 441.3518 - val_loss: 456.5466 - val_mae: 456.5466\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437.7129 - mae: 437.7129 - val_loss: 447.4362 - val_mae: 447.4362\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 434.8198 - mae: 434.8198 - val_loss: 438.3691 - val_mae: 438.3691\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429.3735 - mae: 429.3735 - val_loss: 437.1707 - val_mae: 437.1707\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 428.2260 - mae: 428.2260 - val_loss: 434.9092 - val_mae: 434.9092\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425.8643 - mae: 425.8643 - val_loss: 426.6750 - val_mae: 426.6750\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.5589 - mae: 422.5589 - val_loss: 427.5297 - val_mae: 427.5297\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.3817 - mae: 422.3817 - val_loss: 423.3700 - val_mae: 423.3700\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.6125 - mae: 420.6125 - val_loss: 432.7229 - val_mae: 432.7229\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.3060 - mae: 421.3060 - val_loss: 425.4493 - val_mae: 425.4493\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.6111 - mae: 419.6111 - val_loss: 422.3763 - val_mae: 422.3763\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.0647 - mae: 419.0647 - val_loss: 420.5878 - val_mae: 420.5878\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.9281 - mae: 417.9281 - val_loss: 427.4150 - val_mae: 427.4150\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.6100 - mae: 417.6100 - val_loss: 418.5259 - val_mae: 418.5259\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.6096 - mae: 417.6096 - val_loss: 419.2520 - val_mae: 419.2520\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.7950 - mae: 415.7950 - val_loss: 422.9975 - val_mae: 422.9975\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.0358 - mae: 415.0358 - val_loss: 431.0649 - val_mae: 431.0649\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.8862 - mae: 414.8862 - val_loss: 418.3163 - val_mae: 418.3163\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.0844 - mae: 414.0844 - val_loss: 416.4106 - val_mae: 416.4106\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.0235 - mae: 414.0235 - val_loss: 415.2236 - val_mae: 415.2236\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.1528 - mae: 412.1528 - val_loss: 420.6192 - val_mae: 420.6192\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.5309 - mae: 412.5309 - val_loss: 422.7787 - val_mae: 422.7787\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.6543 - mae: 412.6543 - val_loss: 420.7272 - val_mae: 420.7272\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.3201 - mae: 411.3201 - val_loss: 417.0850 - val_mae: 417.0850\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.0709 - mae: 410.0709 - val_loss: 415.3139 - val_mae: 415.3139\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.8085 - mae: 409.8085 - val_loss: 409.0919 - val_mae: 409.0919\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.6588 - mae: 409.6588 - val_loss: 418.3127 - val_mae: 418.3127\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.8791 - mae: 408.8791 - val_loss: 413.0887 - val_mae: 413.0887\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.9083 - mae: 406.9083 - val_loss: 419.7314 - val_mae: 419.7314\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.5002 - mae: 407.5002 - val_loss: 408.4922 - val_mae: 408.4922\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.4375 - mae: 407.4375 - val_loss: 407.1180 - val_mae: 407.1180\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.8526 - mae: 405.8526 - val_loss: 407.3570 - val_mae: 407.3570\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.4165 - mae: 405.4165 - val_loss: 408.6562 - val_mae: 408.6562\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.4905 - mae: 405.4905 - val_loss: 409.5757 - val_mae: 409.5757\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.7142 - mae: 404.7142 - val_loss: 413.5114 - val_mae: 413.5114\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1577 - mae: 404.1577 - val_loss: 407.4767 - val_mae: 407.4767\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.7480 - mae: 403.7480 - val_loss: 407.3512 - val_mae: 407.3512\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.2928 - mae: 403.2928 - val_loss: 405.4877 - val_mae: 405.4877\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.3656 - mae: 403.3656 - val_loss: 408.7101 - val_mae: 408.7101\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.9765 - mae: 402.9765 - val_loss: 408.5196 - val_mae: 408.5196\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1631 - mae: 404.1631 - val_loss: 404.4884 - val_mae: 404.4884\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.0715 - mae: 403.0715 - val_loss: 404.9219 - val_mae: 404.9219\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.1356 - mae: 403.1356 - val_loss: 407.8205 - val_mae: 407.8205\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.2343 - mae: 404.2343 - val_loss: 404.0931 - val_mae: 404.0931\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.4673 - mae: 402.4673 - val_loss: 406.7261 - val_mae: 406.7261\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6331 - mae: 402.6331 - val_loss: 405.7617 - val_mae: 405.7617\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.2647 - mae: 402.2647 - val_loss: 411.1661 - val_mae: 411.1661\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.1527 - mae: 402.1527 - val_loss: 405.7998 - val_mae: 405.7998\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.5463 - mae: 401.5463 - val_loss: 407.1998 - val_mae: 407.1998\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.8913 - mae: 400.8913 - val_loss: 400.2404 - val_mae: 400.2404\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.9223 - mae: 400.9223 - val_loss: 405.1096 - val_mae: 405.1096\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.5808 - mae: 400.5808 - val_loss: 403.8657 - val_mae: 403.8657\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.3139 - mae: 401.3139 - val_loss: 406.5515 - val_mae: 406.5515\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.8098 - mae: 400.8098 - val_loss: 401.1420 - val_mae: 401.1420\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.0375 - mae: 400.0375 - val_loss: 404.6606 - val_mae: 404.6606\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.5276 - mae: 400.5276 - val_loss: 401.8476 - val_mae: 401.8476\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.4331 - mae: 400.4331 - val_loss: 403.5728 - val_mae: 403.5728\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.6868 - mae: 399.6868 - val_loss: 402.5142 - val_mae: 402.5142\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.2593 - mae: 398.2593 - val_loss: 401.4171 - val_mae: 401.4171\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.3801 - mae: 398.3801 - val_loss: 406.7398 - val_mae: 406.7398\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6052.2227 - mae: 6052.2227 - val_loss: 6038.4561 - val_mae: 6038.4561\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6007.2759 - mae: 6007.2759 - val_loss: 5889.6934 - val_mae: 5889.6934\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4811.6455 - mae: 4811.6455 - val_loss: 1733.1466 - val_mae: 1733.1466\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 648.5208 - mae: 648.5208 - val_loss: 496.4163 - val_mae: 496.4163\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 490.8018 - mae: 490.8018 - val_loss: 496.9901 - val_mae: 496.9901\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 488.5350 - mae: 488.5350 - val_loss: 496.8273 - val_mae: 496.8273\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 487.4575 - mae: 487.4575 - val_loss: 498.0740 - val_mae: 498.0740\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 487.4968 - mae: 487.4968 - val_loss: 492.6101 - val_mae: 492.6101\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 485.9397 - mae: 485.9397 - val_loss: 490.0009 - val_mae: 490.0009\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 484.7660 - mae: 484.7660 - val_loss: 488.3603 - val_mae: 488.3603\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 484.9265 - mae: 484.9265 - val_loss: 486.6952 - val_mae: 486.6952\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482.9613 - mae: 482.9613 - val_loss: 487.3169 - val_mae: 487.3169\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 481.9973 - mae: 481.9973 - val_loss: 489.1028 - val_mae: 489.1028\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 479.6922 - mae: 479.6922 - val_loss: 479.1184 - val_mae: 479.1184\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 477.8896 - mae: 477.8896 - val_loss: 482.5595 - val_mae: 482.5595\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 475.0999 - mae: 475.0999 - val_loss: 482.3582 - val_mae: 482.3582\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 472.8268 - mae: 472.8268 - val_loss: 477.0284 - val_mae: 477.0284\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 469.1189 - mae: 469.1189 - val_loss: 469.3384 - val_mae: 469.3384\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 465.2277 - mae: 465.2277 - val_loss: 467.6172 - val_mae: 467.6172\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 460.5084 - mae: 460.5084 - val_loss: 462.5674 - val_mae: 462.5674\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 455.4836 - mae: 455.4836 - val_loss: 458.6624 - val_mae: 458.6624\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452.2524 - mae: 452.2524 - val_loss: 452.4147 - val_mae: 452.4147\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 448.0978 - mae: 448.0978 - val_loss: 452.5373 - val_mae: 452.5373\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444.7389 - mae: 444.7389 - val_loss: 446.9166 - val_mae: 446.9166\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441.3010 - mae: 441.3010 - val_loss: 445.4625 - val_mae: 445.4625\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.4613 - mae: 438.4613 - val_loss: 440.7106 - val_mae: 440.7106\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 434.9244 - mae: 434.9244 - val_loss: 441.2824 - val_mae: 441.2824\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 433.7540 - mae: 433.7540 - val_loss: 435.7917 - val_mae: 435.7917\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.9474 - mae: 430.9474 - val_loss: 438.5874 - val_mae: 438.5874\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429.9988 - mae: 429.9988 - val_loss: 434.4827 - val_mae: 434.4827\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.2649 - mae: 428.2649 - val_loss: 431.9174 - val_mae: 431.9174\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426.9191 - mae: 426.9191 - val_loss: 430.4256 - val_mae: 430.4256\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.6322 - mae: 424.6322 - val_loss: 431.9987 - val_mae: 431.9987\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.0178 - mae: 425.0178 - val_loss: 433.1066 - val_mae: 433.1066\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.6476 - mae: 423.6476 - val_loss: 427.7134 - val_mae: 427.7134\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.6537 - mae: 422.6537 - val_loss: 430.8464 - val_mae: 430.8464\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.7116 - mae: 421.7116 - val_loss: 424.5006 - val_mae: 424.5006\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.9742 - mae: 420.9742 - val_loss: 427.0046 - val_mae: 427.0046\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.4812 - mae: 421.4812 - val_loss: 423.6330 - val_mae: 423.6330\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.8175 - mae: 419.8175 - val_loss: 420.5826 - val_mae: 420.5826\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.2343 - mae: 418.2343 - val_loss: 420.9319 - val_mae: 420.9319\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.9006 - mae: 417.9006 - val_loss: 424.2973 - val_mae: 424.2973\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.2688 - mae: 417.2688 - val_loss: 422.6679 - val_mae: 422.6679\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.3550 - mae: 417.3550 - val_loss: 416.8147 - val_mae: 416.8147\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.2864 - mae: 415.2864 - val_loss: 422.4877 - val_mae: 422.4877\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.4508 - mae: 415.4508 - val_loss: 417.3143 - val_mae: 417.3143\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.4477 - mae: 415.4477 - val_loss: 418.5800 - val_mae: 418.5800\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.4763 - mae: 414.4763 - val_loss: 417.3501 - val_mae: 417.3501\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.7288 - mae: 413.7288 - val_loss: 417.1673 - val_mae: 417.1673\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.3223 - mae: 413.3223 - val_loss: 416.5992 - val_mae: 416.5992\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.0794 - mae: 413.0794 - val_loss: 417.3316 - val_mae: 417.3316\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.5247 - mae: 413.5247 - val_loss: 413.5799 - val_mae: 413.5799\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.1393 - mae: 412.1393 - val_loss: 416.5470 - val_mae: 416.5470\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.8766 - mae: 411.8766 - val_loss: 413.8126 - val_mae: 413.8126\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.9870 - mae: 410.9870 - val_loss: 418.2841 - val_mae: 418.2841\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.1135 - mae: 412.1135 - val_loss: 417.1331 - val_mae: 417.1331\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.9973 - mae: 410.9973 - val_loss: 411.2356 - val_mae: 411.2356\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.3472 - mae: 410.3472 - val_loss: 414.1585 - val_mae: 414.1585\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.3736 - mae: 410.3736 - val_loss: 414.9854 - val_mae: 414.9854\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.3624 - mae: 410.3624 - val_loss: 411.8895 - val_mae: 411.8895\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.3804 - mae: 408.3804 - val_loss: 413.3098 - val_mae: 413.3098\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.7802 - mae: 409.7802 - val_loss: 413.9971 - val_mae: 413.9971\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.1638 - mae: 409.1638 - val_loss: 412.8527 - val_mae: 412.8527\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.3274 - mae: 408.3274 - val_loss: 415.0558 - val_mae: 415.0558\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.7709 - mae: 408.7709 - val_loss: 407.8449 - val_mae: 407.8449\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.6297 - mae: 407.6297 - val_loss: 410.3295 - val_mae: 410.3295\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.0105 - mae: 408.0105 - val_loss: 407.0841 - val_mae: 407.0841\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.5027 - mae: 407.5027 - val_loss: 410.9402 - val_mae: 410.9402\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.1106 - mae: 407.1106 - val_loss: 408.3319 - val_mae: 408.3319\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.0626 - mae: 406.0626 - val_loss: 406.8403 - val_mae: 406.8403\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.8017 - mae: 406.8017 - val_loss: 410.6706 - val_mae: 410.6706\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.2914 - mae: 406.2914 - val_loss: 413.3302 - val_mae: 413.3302\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.0421 - mae: 407.0421 - val_loss: 408.5785 - val_mae: 408.5785\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.9115 - mae: 405.9115 - val_loss: 406.8125 - val_mae: 406.8125\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.6723 - mae: 405.6723 - val_loss: 410.1763 - val_mae: 410.1763\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.5348 - mae: 405.5348 - val_loss: 410.6595 - val_mae: 410.6595\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.6757 - mae: 405.6757 - val_loss: 404.4926 - val_mae: 404.4926\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.1891 - mae: 405.1891 - val_loss: 407.5465 - val_mae: 407.5465\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.7911 - mae: 404.7911 - val_loss: 405.6064 - val_mae: 405.6064\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.8172 - mae: 404.8172 - val_loss: 409.0695 - val_mae: 409.0695\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.1606 - mae: 405.1606 - val_loss: 406.8910 - val_mae: 406.8910\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.5714 - mae: 403.5714 - val_loss: 406.7393 - val_mae: 406.7393\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.5523 - mae: 403.5523 - val_loss: 410.5419 - val_mae: 410.5419\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.3363 - mae: 404.3363 - val_loss: 405.6564 - val_mae: 405.6564\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.0111 - mae: 404.0111 - val_loss: 406.9490 - val_mae: 406.9490\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.1883 - mae: 402.1883 - val_loss: 407.9701 - val_mae: 407.9701\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.9041 - mae: 403.9041 - val_loss: 407.4352 - val_mae: 407.4352\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6045.7861 - mae: 6045.7861 - val_loss: 6014.2524 - val_mae: 6014.2524\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5643.1958 - mae: 5643.1958 - val_loss: 4293.3101 - val_mae: 4293.3101\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1307.7084 - mae: 1307.7084 - val_loss: 513.2253 - val_mae: 513.2253\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 502.5746 - mae: 502.5746 - val_loss: 504.1256 - val_mae: 504.1256\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 499.7380 - mae: 499.7380 - val_loss: 505.0936 - val_mae: 505.0936\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 498.0009 - mae: 498.0009 - val_loss: 497.9658 - val_mae: 497.9658\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 492.9921 - mae: 492.9921 - val_loss: 501.8848 - val_mae: 501.8848\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 488.6526 - mae: 488.6526 - val_loss: 493.5858 - val_mae: 493.5858\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 484.3816 - mae: 484.3816 - val_loss: 489.6982 - val_mae: 489.6982\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 479.8588 - mae: 479.8588 - val_loss: 492.5119 - val_mae: 492.5119\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 477.5322 - mae: 477.5322 - val_loss: 478.3428 - val_mae: 478.3428\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 471.8748 - mae: 471.8748 - val_loss: 478.7001 - val_mae: 478.7001\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 465.6931 - mae: 465.6931 - val_loss: 467.5226 - val_mae: 467.5226\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 457.6638 - mae: 457.6638 - val_loss: 458.5659 - val_mae: 458.5659\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 451.6524 - mae: 451.6524 - val_loss: 453.2345 - val_mae: 453.2345\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 445.1843 - mae: 445.1843 - val_loss: 446.9766 - val_mae: 446.9766\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.7201 - mae: 438.7201 - val_loss: 445.0933 - val_mae: 445.0933\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435.4055 - mae: 435.4055 - val_loss: 434.5774 - val_mae: 434.5774\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 432.5733 - mae: 432.5733 - val_loss: 438.8449 - val_mae: 438.8449\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.3708 - mae: 428.3708 - val_loss: 427.8584 - val_mae: 427.8584\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.4965 - mae: 425.4965 - val_loss: 429.5304 - val_mae: 429.5304\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.2245 - mae: 424.2245 - val_loss: 427.1434 - val_mae: 427.1434\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.5272 - mae: 422.5272 - val_loss: 431.1564 - val_mae: 431.1564\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.3933 - mae: 422.3933 - val_loss: 428.2438 - val_mae: 428.2438\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.0302 - mae: 420.0302 - val_loss: 425.6386 - val_mae: 425.6386\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.1833 - mae: 420.1833 - val_loss: 428.2408 - val_mae: 428.2408\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.3684 - mae: 419.3684 - val_loss: 426.1861 - val_mae: 426.1861\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.4740 - mae: 419.4740 - val_loss: 422.3834 - val_mae: 422.3834\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.2923 - mae: 419.2923 - val_loss: 422.2582 - val_mae: 422.2582\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.1448 - mae: 418.1448 - val_loss: 422.1384 - val_mae: 422.1384\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.2409 - mae: 417.2409 - val_loss: 427.6148 - val_mae: 427.6148\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.6462 - mae: 416.6462 - val_loss: 421.2347 - val_mae: 421.2347\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.4879 - mae: 416.4879 - val_loss: 424.8613 - val_mae: 424.8613\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.2805 - mae: 416.2805 - val_loss: 422.7188 - val_mae: 422.7188\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.1882 - mae: 416.1882 - val_loss: 420.3545 - val_mae: 420.3545\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.3426 - mae: 415.3426 - val_loss: 420.4918 - val_mae: 420.4918\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.5080 - mae: 414.5080 - val_loss: 420.8185 - val_mae: 420.8185\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.7003 - mae: 413.7003 - val_loss: 423.4388 - val_mae: 423.4388\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.3119 - mae: 413.3119 - val_loss: 418.9281 - val_mae: 418.9281\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.7355 - mae: 412.7355 - val_loss: 417.8697 - val_mae: 417.8697\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.0769 - mae: 413.0769 - val_loss: 424.7361 - val_mae: 424.7361\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.5247 - mae: 411.5247 - val_loss: 422.4723 - val_mae: 422.4723\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.5052 - mae: 411.5052 - val_loss: 417.2118 - val_mae: 417.2118\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.7743 - mae: 411.7743 - val_loss: 413.6039 - val_mae: 413.6039\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.4143 - mae: 411.4143 - val_loss: 416.2753 - val_mae: 416.2753\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.8776 - mae: 409.8776 - val_loss: 422.3919 - val_mae: 422.3919\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.4796 - mae: 410.4796 - val_loss: 418.7505 - val_mae: 418.7505\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.8739 - mae: 409.8739 - val_loss: 417.7266 - val_mae: 417.7266\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.7878 - mae: 408.7878 - val_loss: 413.5112 - val_mae: 413.5112\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.8448 - mae: 407.8448 - val_loss: 418.3753 - val_mae: 418.3753\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.0544 - mae: 409.0544 - val_loss: 413.8320 - val_mae: 413.8320\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.4118 - mae: 409.4118 - val_loss: 413.7111 - val_mae: 413.7111\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.6943 - mae: 407.6943 - val_loss: 415.3096 - val_mae: 415.3096\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.8084 - mae: 407.8084 - val_loss: 416.7092 - val_mae: 416.7092\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.6132 - mae: 407.6132 - val_loss: 415.5524 - val_mae: 415.5524\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.4694 - mae: 407.4694 - val_loss: 415.6425 - val_mae: 415.6425\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.2344 - mae: 407.2344 - val_loss: 411.9647 - val_mae: 411.9647\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.7238 - mae: 406.7238 - val_loss: 413.9745 - val_mae: 413.9745\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.6189 - mae: 406.6189 - val_loss: 416.5685 - val_mae: 416.5685\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.8195 - mae: 406.8195 - val_loss: 416.1577 - val_mae: 416.1577\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.3398 - mae: 406.3398 - val_loss: 414.6721 - val_mae: 414.6721\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.3482 - mae: 406.3482 - val_loss: 416.5422 - val_mae: 416.5422\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.2458 - mae: 406.2458 - val_loss: 416.6772 - val_mae: 416.6772\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.0510 - mae: 407.0510 - val_loss: 416.2864 - val_mae: 416.2864\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.7147 - mae: 406.7147 - val_loss: 412.8314 - val_mae: 412.8314\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.8808 - mae: 405.8808 - val_loss: 411.8793 - val_mae: 411.8793\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.8333 - mae: 404.8333 - val_loss: 419.1950 - val_mae: 419.1950\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.3108 - mae: 406.3108 - val_loss: 412.0738 - val_mae: 412.0738\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.0409 - mae: 406.0409 - val_loss: 414.1182 - val_mae: 414.1182\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.2588 - mae: 406.2588 - val_loss: 412.3052 - val_mae: 412.3052\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.4199 - mae: 405.4199 - val_loss: 415.0686 - val_mae: 415.0686\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.9658 - mae: 405.9658 - val_loss: 411.9464 - val_mae: 411.9464\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.3824 - mae: 405.3824 - val_loss: 415.8760 - val_mae: 415.8760\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.4631 - mae: 405.4631 - val_loss: 415.0230 - val_mae: 415.0230\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.2978 - mae: 404.2978 - val_loss: 421.4261 - val_mae: 421.4261\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.9707 - mae: 405.9707 - val_loss: 411.9453 - val_mae: 411.9453\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4200.9399 - mae: 4200.9399 - val_loss: 522.8991 - val_mae: 522.8991\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 525.1448 - mae: 525.1448 - val_loss: 533.8840 - val_mae: 533.8840\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 517.6940 - mae: 517.6940 - val_loss: 523.3246 - val_mae: 523.3246\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 511.8185 - mae: 511.8185 - val_loss: 512.3869 - val_mae: 512.3869\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 495.6892 - mae: 495.6892 - val_loss: 490.8558 - val_mae: 490.8558\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 474.0766 - mae: 474.0766 - val_loss: 488.8103 - val_mae: 488.8103\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 461.1525 - mae: 461.1525 - val_loss: 465.3076 - val_mae: 465.3076\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453.3797 - mae: 453.3797 - val_loss: 456.0571 - val_mae: 456.0571\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 447.8735 - mae: 447.8735 - val_loss: 458.3829 - val_mae: 458.3829\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 443.9824 - mae: 443.9824 - val_loss: 456.3452 - val_mae: 456.3452\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441.4489 - mae: 441.4489 - val_loss: 444.7281 - val_mae: 444.7281\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435.8456 - mae: 435.8456 - val_loss: 469.4708 - val_mae: 469.4708\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431.6985 - mae: 431.6985 - val_loss: 441.4353 - val_mae: 441.4353\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429.7349 - mae: 429.7349 - val_loss: 445.6000 - val_mae: 445.6000\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428.4992 - mae: 428.4992 - val_loss: 443.3992 - val_mae: 443.3992\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424.9062 - mae: 424.9062 - val_loss: 445.8299 - val_mae: 445.8299\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424.5417 - mae: 424.5417 - val_loss: 439.7535 - val_mae: 439.7535\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.4211 - mae: 423.4211 - val_loss: 427.9920 - val_mae: 427.9920\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.2236 - mae: 423.2236 - val_loss: 428.9878 - val_mae: 428.9878\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.8845 - mae: 420.8845 - val_loss: 425.3267 - val_mae: 425.3267\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.4296 - mae: 418.4296 - val_loss: 443.8747 - val_mae: 443.8747\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.9326 - mae: 418.9326 - val_loss: 422.7820 - val_mae: 422.7820\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.8600 - mae: 414.8600 - val_loss: 417.6767 - val_mae: 417.6767\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.6320 - mae: 415.6320 - val_loss: 425.0983 - val_mae: 425.0983\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.4290 - mae: 413.4290 - val_loss: 427.2875 - val_mae: 427.2875\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.7942 - mae: 411.7942 - val_loss: 414.7451 - val_mae: 414.7451\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.7099 - mae: 410.7099 - val_loss: 424.6671 - val_mae: 424.6671\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.7914 - mae: 409.7914 - val_loss: 418.4006 - val_mae: 418.4006\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.4274 - mae: 410.4274 - val_loss: 421.5844 - val_mae: 421.5844\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.8820 - mae: 408.8820 - val_loss: 460.3266 - val_mae: 460.3266\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.0752 - mae: 410.0752 - val_loss: 418.7213 - val_mae: 418.7213\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.3420 - mae: 409.3420 - val_loss: 422.2340 - val_mae: 422.2340\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.1223 - mae: 407.1223 - val_loss: 420.9701 - val_mae: 420.9701\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406.6807 - mae: 406.6807 - val_loss: 421.3722 - val_mae: 421.3722\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.0262 - mae: 408.0262 - val_loss: 425.1515 - val_mae: 425.1515\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.0956 - mae: 407.0956 - val_loss: 411.3250 - val_mae: 411.3250\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406.0748 - mae: 406.0748 - val_loss: 414.2480 - val_mae: 414.2480\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.7880 - mae: 405.7880 - val_loss: 408.6117 - val_mae: 408.6117\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.1114 - mae: 405.1114 - val_loss: 424.0786 - val_mae: 424.0786\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.4402 - mae: 405.4402 - val_loss: 417.2080 - val_mae: 417.2080\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 403.9295 - mae: 403.9295 - val_loss: 412.4889 - val_mae: 412.4889\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406.3245 - mae: 406.3245 - val_loss: 405.7155 - val_mae: 405.7155\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.3999 - mae: 404.3999 - val_loss: 417.8382 - val_mae: 417.8382\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.2783 - mae: 405.2783 - val_loss: 411.8590 - val_mae: 411.8590\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.5087 - mae: 404.5087 - val_loss: 410.6133 - val_mae: 410.6133\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 403.4178 - mae: 403.4178 - val_loss: 409.5004 - val_mae: 409.5004\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.4150 - mae: 404.4150 - val_loss: 409.1754 - val_mae: 409.1754\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 403.6885 - mae: 403.6885 - val_loss: 407.6353 - val_mae: 407.6353\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.3482 - mae: 404.3482 - val_loss: 415.0825 - val_mae: 415.0825\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 403.0335 - mae: 403.0335 - val_loss: 412.3256 - val_mae: 412.3256\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 402.8078 - mae: 402.8078 - val_loss: 419.7733 - val_mae: 419.7733\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 402.6992 - mae: 402.6992 - val_loss: 413.0048 - val_mae: 413.0048\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3440.8523 - mae: 3440.8523 - val_loss: 535.4382 - val_mae: 535.4382\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 519.7916 - mae: 519.7916 - val_loss: 531.7152 - val_mae: 531.7152\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 504.8022 - mae: 504.8022 - val_loss: 523.7047 - val_mae: 523.7047\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 485.3620 - mae: 485.3620 - val_loss: 483.4843 - val_mae: 483.4843\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 466.4596 - mae: 466.4596 - val_loss: 465.0474 - val_mae: 465.0474\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453.7590 - mae: 453.7590 - val_loss: 450.3502 - val_mae: 450.3502\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 445.8855 - mae: 445.8855 - val_loss: 472.7970 - val_mae: 472.7970\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441.4926 - mae: 441.4926 - val_loss: 441.6195 - val_mae: 441.6195\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435.8461 - mae: 435.8461 - val_loss: 450.5368 - val_mae: 450.5368\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432.0242 - mae: 432.0242 - val_loss: 453.4858 - val_mae: 453.4858\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429.5539 - mae: 429.5539 - val_loss: 440.7878 - val_mae: 440.7878\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429.8747 - mae: 429.8747 - val_loss: 426.1405 - val_mae: 426.1405\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.9450 - mae: 425.9450 - val_loss: 455.2055 - val_mae: 455.2055\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.6710 - mae: 425.6710 - val_loss: 434.5859 - val_mae: 434.5859\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.5081 - mae: 423.5081 - val_loss: 444.4937 - val_mae: 444.4937\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.8172 - mae: 421.8172 - val_loss: 449.2946 - val_mae: 449.2946\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.1372 - mae: 420.1372 - val_loss: 420.9903 - val_mae: 420.9903\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.9245 - mae: 418.9245 - val_loss: 425.1949 - val_mae: 425.1949\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419.2773 - mae: 419.2773 - val_loss: 438.8416 - val_mae: 438.8416\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.9788 - mae: 418.9788 - val_loss: 424.9003 - val_mae: 424.9003\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417.9869 - mae: 417.9869 - val_loss: 459.0187 - val_mae: 459.0187\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.6994 - mae: 416.6994 - val_loss: 424.6204 - val_mae: 424.6204\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.7944 - mae: 415.7944 - val_loss: 423.7163 - val_mae: 423.7163\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.9551 - mae: 416.9551 - val_loss: 439.4176 - val_mae: 439.4176\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.7872 - mae: 416.7872 - val_loss: 424.3360 - val_mae: 424.3360\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.3426 - mae: 415.3426 - val_loss: 431.4573 - val_mae: 431.4573\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.2589 - mae: 415.2589 - val_loss: 432.9308 - val_mae: 432.9308\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6002.7446 - mae: 6002.7446 - val_loss: 5717.7085 - val_mae: 5717.7085\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2181.1794 - mae: 2181.1794 - val_loss: 529.7974 - val_mae: 529.7974\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 504.7404 - mae: 504.7404 - val_loss: 499.1884 - val_mae: 499.1884\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 488.3790 - mae: 488.3790 - val_loss: 489.6908 - val_mae: 489.6908\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 474.3027 - mae: 474.3027 - val_loss: 464.7600 - val_mae: 464.7600\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 464.3589 - mae: 464.3589 - val_loss: 463.4542 - val_mae: 463.4542\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 456.9481 - mae: 456.9481 - val_loss: 459.1381 - val_mae: 459.1381\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 451.2469 - mae: 451.2469 - val_loss: 450.4891 - val_mae: 450.4891\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 447.0439 - mae: 447.0439 - val_loss: 447.0189 - val_mae: 447.0189\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 443.2785 - mae: 443.2785 - val_loss: 445.9527 - val_mae: 445.9527\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438.2601 - mae: 438.2601 - val_loss: 443.9615 - val_mae: 443.9615\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 433.7104 - mae: 433.7104 - val_loss: 436.8456 - val_mae: 436.8456\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 430.1183 - mae: 430.1183 - val_loss: 432.3753 - val_mae: 432.3753\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 427.2542 - mae: 427.2542 - val_loss: 424.6739 - val_mae: 424.6739\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.7092 - mae: 424.7092 - val_loss: 424.1010 - val_mae: 424.1010\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.0107 - mae: 424.0107 - val_loss: 423.2678 - val_mae: 423.2678\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.4186 - mae: 421.4186 - val_loss: 425.5389 - val_mae: 425.5389\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.6154 - mae: 420.6154 - val_loss: 422.6577 - val_mae: 422.6577\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.2527 - mae: 420.2527 - val_loss: 422.9184 - val_mae: 422.9184\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.6762 - mae: 418.6762 - val_loss: 420.9170 - val_mae: 420.9170\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.1531 - mae: 417.1531 - val_loss: 422.6525 - val_mae: 422.6525\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.3344 - mae: 415.3344 - val_loss: 417.1098 - val_mae: 417.1098\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413.3813 - mae: 413.3813 - val_loss: 420.9032 - val_mae: 420.9032\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.8750 - mae: 411.8750 - val_loss: 418.6627 - val_mae: 418.6627\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.3517 - mae: 411.3517 - val_loss: 421.8997 - val_mae: 421.8997\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.1879 - mae: 410.1879 - val_loss: 415.7047 - val_mae: 415.7047\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.8531 - mae: 409.8531 - val_loss: 411.5268 - val_mae: 411.5268\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.8221 - mae: 408.8221 - val_loss: 411.8456 - val_mae: 411.8456\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.0483 - mae: 408.0483 - val_loss: 408.7185 - val_mae: 408.7185\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.2151 - mae: 406.2151 - val_loss: 412.8031 - val_mae: 412.8031\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.8242 - mae: 406.8242 - val_loss: 414.2501 - val_mae: 414.2501\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.8066 - mae: 406.8066 - val_loss: 408.0858 - val_mae: 408.0858\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.6895 - mae: 405.6895 - val_loss: 408.1805 - val_mae: 408.1805\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.0045 - mae: 406.0045 - val_loss: 410.3586 - val_mae: 410.3586\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.2077 - mae: 406.2077 - val_loss: 407.8894 - val_mae: 407.8894\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.3975 - mae: 404.3975 - val_loss: 405.9113 - val_mae: 405.9113\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.6996 - mae: 405.6996 - val_loss: 416.6483 - val_mae: 416.6483\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.9476 - mae: 404.9476 - val_loss: 405.4647 - val_mae: 405.4647\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.3633 - mae: 403.3633 - val_loss: 409.8846 - val_mae: 409.8846\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.2734 - mae: 404.2734 - val_loss: 406.8193 - val_mae: 406.8193\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.1819 - mae: 403.1819 - val_loss: 410.5748 - val_mae: 410.5748\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.2750 - mae: 403.2750 - val_loss: 406.8613 - val_mae: 406.8613\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.8610 - mae: 402.8610 - val_loss: 406.2867 - val_mae: 406.2867\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.7983 - mae: 403.7983 - val_loss: 404.9737 - val_mae: 404.9737\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1016 - mae: 404.1016 - val_loss: 406.0965 - val_mae: 406.0965\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.8202 - mae: 402.8202 - val_loss: 406.6989 - val_mae: 406.6989\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.3164 - mae: 403.3164 - val_loss: 409.9273 - val_mae: 409.9273\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6324 - mae: 402.6324 - val_loss: 402.9581 - val_mae: 402.9581\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6917 - mae: 402.6917 - val_loss: 405.9343 - val_mae: 405.9343\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.9199 - mae: 401.9199 - val_loss: 407.8569 - val_mae: 407.8569\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.1777 - mae: 402.1777 - val_loss: 405.1752 - val_mae: 405.1752\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.8998 - mae: 401.8998 - val_loss: 404.8186 - val_mae: 404.8186\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.9554 - mae: 401.9554 - val_loss: 400.5173 - val_mae: 400.5173\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.6144 - mae: 401.6144 - val_loss: 406.2838 - val_mae: 406.2838\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.4612 - mae: 401.4612 - val_loss: 405.7155 - val_mae: 405.7155\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.1073 - mae: 401.1073 - val_loss: 406.0473 - val_mae: 406.0473\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.0890 - mae: 401.0890 - val_loss: 402.2540 - val_mae: 402.2540\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.7226 - mae: 400.7226 - val_loss: 418.3199 - val_mae: 418.3199\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.6808 - mae: 399.6808 - val_loss: 401.0204 - val_mae: 401.0204\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.8304 - mae: 400.8304 - val_loss: 405.6362 - val_mae: 405.6362\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.7394 - mae: 399.7394 - val_loss: 418.5727 - val_mae: 418.5727\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.1103 - mae: 400.1103 - val_loss: 406.6433 - val_mae: 406.6433\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.5984 - mae: 399.5984 - val_loss: 404.1638 - val_mae: 404.1638\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6023.3691 - mae: 6023.3691 - val_loss: 5798.2139 - val_mae: 5798.2139\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1986.0623 - mae: 1986.0623 - val_loss: 506.6454 - val_mae: 506.6454\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 502.1465 - mae: 502.1465 - val_loss: 503.7340 - val_mae: 503.7340\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 494.9232 - mae: 494.9232 - val_loss: 499.6826 - val_mae: 499.6826\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 491.6275 - mae: 491.6275 - val_loss: 493.0739 - val_mae: 493.0739\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 486.4310 - mae: 486.4310 - val_loss: 489.7644 - val_mae: 489.7644\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 478.9912 - mae: 478.9912 - val_loss: 478.7948 - val_mae: 478.7948\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 471.2983 - mae: 471.2983 - val_loss: 488.4452 - val_mae: 488.4452\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 462.1830 - mae: 462.1830 - val_loss: 473.8737 - val_mae: 473.8737\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 454.0206 - mae: 454.0206 - val_loss: 458.2496 - val_mae: 458.2496\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 446.8280 - mae: 446.8280 - val_loss: 453.5615 - val_mae: 453.5615\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 440.3694 - mae: 440.3694 - val_loss: 444.8496 - val_mae: 444.8496\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 435.0729 - mae: 435.0729 - val_loss: 443.9552 - val_mae: 443.9552\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432.0203 - mae: 432.0203 - val_loss: 436.0106 - val_mae: 436.0106\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 427.7328 - mae: 427.7328 - val_loss: 434.1466 - val_mae: 434.1466\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.6045 - mae: 424.6045 - val_loss: 427.1085 - val_mae: 427.1085\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423.6153 - mae: 423.6153 - val_loss: 428.1092 - val_mae: 428.1092\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.7658 - mae: 422.7658 - val_loss: 426.2395 - val_mae: 426.2395\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.3467 - mae: 421.3467 - val_loss: 419.5362 - val_mae: 419.5362\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.7720 - mae: 419.7720 - val_loss: 428.7326 - val_mae: 428.7326\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.1498 - mae: 420.1498 - val_loss: 427.0878 - val_mae: 427.0878\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.3939 - mae: 418.3939 - val_loss: 417.4439 - val_mae: 417.4439\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.0693 - mae: 418.0693 - val_loss: 422.8143 - val_mae: 422.8143\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.8043 - mae: 415.8043 - val_loss: 428.0150 - val_mae: 428.0150\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.8434 - mae: 415.8434 - val_loss: 414.1162 - val_mae: 414.1162\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.7031 - mae: 414.7031 - val_loss: 418.3700 - val_mae: 418.3700\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413.7687 - mae: 413.7687 - val_loss: 413.7024 - val_mae: 413.7024\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.9683 - mae: 412.9683 - val_loss: 423.6685 - val_mae: 423.6685\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.4084 - mae: 411.4084 - val_loss: 414.3595 - val_mae: 414.3595\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.1171 - mae: 411.1171 - val_loss: 414.1978 - val_mae: 414.1978\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.6279 - mae: 410.6279 - val_loss: 414.5439 - val_mae: 414.5439\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.4936 - mae: 410.4936 - val_loss: 419.8999 - val_mae: 419.8999\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.3167 - mae: 408.3167 - val_loss: 419.9652 - val_mae: 419.9652\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.1052 - mae: 409.1052 - val_loss: 412.7907 - val_mae: 412.7907\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.3464 - mae: 407.3464 - val_loss: 414.5805 - val_mae: 414.5805\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.9096 - mae: 407.9096 - val_loss: 407.6753 - val_mae: 407.6753\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.6172 - mae: 405.6172 - val_loss: 422.7716 - val_mae: 422.7716\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.9431 - mae: 406.9431 - val_loss: 416.3491 - val_mae: 416.3491\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.9362 - mae: 405.9362 - val_loss: 420.1852 - val_mae: 420.1852\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.1162 - mae: 406.1162 - val_loss: 413.2796 - val_mae: 413.2796\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.1162 - mae: 405.1162 - val_loss: 407.4769 - val_mae: 407.4769\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.7159 - mae: 405.7159 - val_loss: 410.1004 - val_mae: 410.1004\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.6696 - mae: 405.6696 - val_loss: 406.6061 - val_mae: 406.6061\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.1465 - mae: 405.1465 - val_loss: 408.1404 - val_mae: 408.1404\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.8747 - mae: 403.8747 - val_loss: 404.4734 - val_mae: 404.4734\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.8568 - mae: 403.8568 - val_loss: 408.7871 - val_mae: 408.7871\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.5102 - mae: 404.5102 - val_loss: 408.1379 - val_mae: 408.1379\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.0104 - mae: 404.0104 - val_loss: 417.1335 - val_mae: 417.1335\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.5066 - mae: 403.5066 - val_loss: 406.3453 - val_mae: 406.3453\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.8292 - mae: 403.8292 - val_loss: 411.2581 - val_mae: 411.2581\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.9421 - mae: 402.9421 - val_loss: 405.6872 - val_mae: 405.6872\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.8733 - mae: 403.8733 - val_loss: 411.0606 - val_mae: 411.0606\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.9610 - mae: 402.9610 - val_loss: 409.2968 - val_mae: 409.2968\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.6895 - mae: 401.6895 - val_loss: 415.3067 - val_mae: 415.3067\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.3684 - mae: 402.3684 - val_loss: 414.3103 - val_mae: 414.3103\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6048.5879 - mae: 6048.5879 - val_loss: 6028.8071 - val_mae: 6028.8071\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5944.3057 - mae: 5944.3057 - val_loss: 5677.2515 - val_mae: 5677.2515\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3599.4324 - mae: 3599.4324 - val_loss: 571.8716 - val_mae: 571.8716\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 518.5781 - mae: 518.5781 - val_loss: 510.3748 - val_mae: 510.3748\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 504.0735 - mae: 504.0735 - val_loss: 505.4901 - val_mae: 505.4901\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 500.3727 - mae: 500.3727 - val_loss: 503.9563 - val_mae: 503.9563\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 498.8913 - mae: 498.8913 - val_loss: 505.8286 - val_mae: 505.8286\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 497.2042 - mae: 497.2042 - val_loss: 506.6971 - val_mae: 506.6971\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 496.6238 - mae: 496.6238 - val_loss: 502.0266 - val_mae: 502.0266\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 495.4285 - mae: 495.4285 - val_loss: 498.5399 - val_mae: 498.5399\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 493.4007 - mae: 493.4007 - val_loss: 497.1913 - val_mae: 497.1913\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 491.8558 - mae: 491.8558 - val_loss: 494.1653 - val_mae: 494.1653\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 487.2471 - mae: 487.2471 - val_loss: 491.8844 - val_mae: 491.8844\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482.6636 - mae: 482.6636 - val_loss: 487.9297 - val_mae: 487.9297\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 480.1914 - mae: 480.1914 - val_loss: 481.4656 - val_mae: 481.4656\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 478.7887 - mae: 478.7887 - val_loss: 483.1939 - val_mae: 483.1939\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 475.7516 - mae: 475.7516 - val_loss: 484.9508 - val_mae: 484.9508\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 474.3077 - mae: 474.3077 - val_loss: 480.9968 - val_mae: 480.9968\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 471.7447 - mae: 471.7447 - val_loss: 471.8750 - val_mae: 471.8750\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 468.5258 - mae: 468.5258 - val_loss: 477.3848 - val_mae: 477.3848\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 465.9247 - mae: 465.9247 - val_loss: 472.6958 - val_mae: 472.6958\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 463.8944 - mae: 463.8944 - val_loss: 467.1190 - val_mae: 467.1190\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 460.6053 - mae: 460.6053 - val_loss: 468.3360 - val_mae: 468.3360\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 457.1064 - mae: 457.1064 - val_loss: 462.3883 - val_mae: 462.3883\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 453.0332 - mae: 453.0332 - val_loss: 455.7902 - val_mae: 455.7902\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 450.8587 - mae: 450.8587 - val_loss: 454.5899 - val_mae: 454.5899\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 448.3414 - mae: 448.3414 - val_loss: 452.2054 - val_mae: 452.2054\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 445.3725 - mae: 445.3725 - val_loss: 451.7928 - val_mae: 451.7928\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 442.1039 - mae: 442.1039 - val_loss: 447.8213 - val_mae: 447.8213\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440.5252 - mae: 440.5252 - val_loss: 445.0624 - val_mae: 445.0624\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 437.0346 - mae: 437.0346 - val_loss: 447.5964 - val_mae: 447.5964\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435.6974 - mae: 435.6974 - val_loss: 443.6122 - val_mae: 443.6122\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 433.2566 - mae: 433.2566 - val_loss: 440.3688 - val_mae: 440.3688\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431.7954 - mae: 431.7954 - val_loss: 439.0120 - val_mae: 439.0120\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.7685 - mae: 430.7685 - val_loss: 438.1320 - val_mae: 438.1320\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.8118 - mae: 428.8118 - val_loss: 434.8190 - val_mae: 434.8190\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.3566 - mae: 427.3566 - val_loss: 436.0303 - val_mae: 436.0303\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426.3111 - mae: 426.3111 - val_loss: 436.0665 - val_mae: 436.0665\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.3008 - mae: 425.3008 - val_loss: 433.2212 - val_mae: 433.2212\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.2940 - mae: 423.2940 - val_loss: 434.7701 - val_mae: 434.7701\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.9732 - mae: 421.9732 - val_loss: 432.4565 - val_mae: 432.4565\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.8851 - mae: 419.8851 - val_loss: 431.8460 - val_mae: 431.8460\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.0567 - mae: 419.0567 - val_loss: 427.4721 - val_mae: 427.4721\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.9518 - mae: 416.9518 - val_loss: 427.4420 - val_mae: 427.4420\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.6073 - mae: 415.6073 - val_loss: 429.4827 - val_mae: 429.4827\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.4034 - mae: 415.4034 - val_loss: 425.8252 - val_mae: 425.8252\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.6082 - mae: 413.6082 - val_loss: 422.4182 - val_mae: 422.4182\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.1418 - mae: 414.1418 - val_loss: 421.3012 - val_mae: 421.3012\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.6580 - mae: 412.6580 - val_loss: 422.2050 - val_mae: 422.2050\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.2614 - mae: 412.2614 - val_loss: 422.6677 - val_mae: 422.6677\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.1567 - mae: 411.1567 - val_loss: 418.7720 - val_mae: 418.7720\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.7243 - mae: 410.7243 - val_loss: 417.8650 - val_mae: 417.8650\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.7163 - mae: 410.7163 - val_loss: 422.6486 - val_mae: 422.6486\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.3748 - mae: 410.3748 - val_loss: 417.0185 - val_mae: 417.0185\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.2789 - mae: 409.2789 - val_loss: 416.4530 - val_mae: 416.4530\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.8222 - mae: 408.8222 - val_loss: 415.7801 - val_mae: 415.7801\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.1667 - mae: 409.1667 - val_loss: 416.4519 - val_mae: 416.4519\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.0738 - mae: 409.0738 - val_loss: 416.7937 - val_mae: 416.7937\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.6755 - mae: 407.6755 - val_loss: 417.8433 - val_mae: 417.8433\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.8861 - mae: 407.8861 - val_loss: 411.6502 - val_mae: 411.6502\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.3050 - mae: 407.3050 - val_loss: 416.3819 - val_mae: 416.3819\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.8646 - mae: 406.8646 - val_loss: 413.2745 - val_mae: 413.2745\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.6827 - mae: 406.6827 - val_loss: 412.9157 - val_mae: 412.9157\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.1405 - mae: 406.1405 - val_loss: 414.8956 - val_mae: 414.8956\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.2466 - mae: 405.2466 - val_loss: 410.6733 - val_mae: 410.6733\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.9960 - mae: 404.9960 - val_loss: 410.8741 - val_mae: 410.8741\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.0735 - mae: 405.0735 - val_loss: 411.3608 - val_mae: 411.3608\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.0587 - mae: 404.0587 - val_loss: 413.0264 - val_mae: 413.0264\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.9854 - mae: 403.9854 - val_loss: 409.9573 - val_mae: 409.9573\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.0786 - mae: 404.0786 - val_loss: 412.4547 - val_mae: 412.4547\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.8763 - mae: 403.8763 - val_loss: 408.4628 - val_mae: 408.4628\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.7122 - mae: 403.7122 - val_loss: 409.3793 - val_mae: 409.3793\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.2268 - mae: 403.2268 - val_loss: 411.1901 - val_mae: 411.1901\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.0348 - mae: 403.0348 - val_loss: 409.9417 - val_mae: 409.9417\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.7679 - mae: 402.7679 - val_loss: 409.2354 - val_mae: 409.2354\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.5600 - mae: 402.5600 - val_loss: 408.7401 - val_mae: 408.7401\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.0949 - mae: 402.0949 - val_loss: 410.2513 - val_mae: 410.2513\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.8698 - mae: 401.8698 - val_loss: 408.9418 - val_mae: 408.9418\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.4532 - mae: 402.4532 - val_loss: 411.0506 - val_mae: 411.0506\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.7141 - mae: 402.7141 - val_loss: 409.6976 - val_mae: 409.6976\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.2028 - mae: 402.2028 - val_loss: 407.4668 - val_mae: 407.4668\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.7283 - mae: 401.7283 - val_loss: 410.6650 - val_mae: 410.6650\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.7825 - mae: 400.7825 - val_loss: 406.4999 - val_mae: 406.4999\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.3296 - mae: 402.3296 - val_loss: 408.3425 - val_mae: 408.3425\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.4625 - mae: 401.4625 - val_loss: 407.6888 - val_mae: 407.6888\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.5823 - mae: 401.5823 - val_loss: 408.4405 - val_mae: 408.4405\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.0604 - mae: 401.0604 - val_loss: 406.1964 - val_mae: 406.1964\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.5678 - mae: 400.5678 - val_loss: 410.3804 - val_mae: 410.3804\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.0886 - mae: 401.0886 - val_loss: 406.9111 - val_mae: 406.9111\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.2124 - mae: 400.2124 - val_loss: 408.3459 - val_mae: 408.3459\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.7166 - mae: 400.7166 - val_loss: 407.1004 - val_mae: 407.1004\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.7910 - mae: 400.7910 - val_loss: 411.7331 - val_mae: 411.7331\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.8827 - mae: 400.8827 - val_loss: 406.3049 - val_mae: 406.3049\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.6181 - mae: 400.6181 - val_loss: 409.2878 - val_mae: 409.2878\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.1719 - mae: 400.1719 - val_loss: 407.2901 - val_mae: 407.2901\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.9149 - mae: 400.9149 - val_loss: 409.2096 - val_mae: 409.2096\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399.3204 - mae: 399.3204 - val_loss: 410.2824 - val_mae: 410.2824\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6047.6748 - mae: 6047.6748 - val_loss: 6021.5571 - val_mae: 6021.5571\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5749.9912 - mae: 5749.9912 - val_loss: 4747.3579 - val_mae: 4747.3579\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1509.1248 - mae: 1509.1248 - val_loss: 509.5011 - val_mae: 509.5011\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 495.4556 - mae: 495.4556 - val_loss: 492.7289 - val_mae: 492.7289\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 485.2559 - mae: 485.2559 - val_loss: 491.5360 - val_mae: 491.5360\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 477.1352 - mae: 477.1352 - val_loss: 479.9594 - val_mae: 479.9594\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 471.5225 - mae: 471.5225 - val_loss: 475.0344 - val_mae: 475.0344\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 467.3795 - mae: 467.3795 - val_loss: 471.7484 - val_mae: 471.7484\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 463.3806 - mae: 463.3806 - val_loss: 465.7866 - val_mae: 465.7866\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 460.3301 - mae: 460.3301 - val_loss: 460.0288 - val_mae: 460.0288\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 455.0033 - mae: 455.0033 - val_loss: 459.7395 - val_mae: 459.7395\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452.1428 - mae: 452.1428 - val_loss: 455.9527 - val_mae: 455.9527\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 448.2905 - mae: 448.2905 - val_loss: 451.8110 - val_mae: 451.8110\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444.5368 - mae: 444.5368 - val_loss: 451.8214 - val_mae: 451.8214\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441.9328 - mae: 441.9328 - val_loss: 445.2649 - val_mae: 445.2649\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.4145 - mae: 438.4145 - val_loss: 443.8027 - val_mae: 443.8027\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435.4024 - mae: 435.4024 - val_loss: 440.5848 - val_mae: 440.5848\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431.4575 - mae: 431.4575 - val_loss: 441.3872 - val_mae: 441.3872\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429.9474 - mae: 429.9474 - val_loss: 432.9400 - val_mae: 432.9400\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.0749 - mae: 428.0749 - val_loss: 428.9742 - val_mae: 428.9742\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.3356 - mae: 425.3356 - val_loss: 428.0043 - val_mae: 428.0043\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.0072 - mae: 424.0072 - val_loss: 428.8360 - val_mae: 428.8360\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.2960 - mae: 422.2960 - val_loss: 426.7460 - val_mae: 426.7460\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.1270 - mae: 421.1270 - val_loss: 423.6300 - val_mae: 423.6300\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.8040 - mae: 419.8040 - val_loss: 424.8095 - val_mae: 424.8095\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.2509 - mae: 418.2509 - val_loss: 429.1889 - val_mae: 429.1889\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.6973 - mae: 417.6973 - val_loss: 422.5701 - val_mae: 422.5701\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.2414 - mae: 417.2414 - val_loss: 421.7614 - val_mae: 421.7614\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.3630 - mae: 415.3630 - val_loss: 419.5157 - val_mae: 419.5157\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.1496 - mae: 415.1496 - val_loss: 422.1590 - val_mae: 422.1590\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.3197 - mae: 415.3197 - val_loss: 420.7202 - val_mae: 420.7202\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.9913 - mae: 413.9913 - val_loss: 419.2436 - val_mae: 419.2436\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.9223 - mae: 412.9223 - val_loss: 421.0970 - val_mae: 421.0970\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.6786 - mae: 411.6786 - val_loss: 419.2527 - val_mae: 419.2527\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.5867 - mae: 411.5867 - val_loss: 418.9393 - val_mae: 418.9393\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.7331 - mae: 410.7331 - val_loss: 416.1142 - val_mae: 416.1142\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.1137 - mae: 410.1137 - val_loss: 417.3119 - val_mae: 417.3119\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.1283 - mae: 410.1283 - val_loss: 418.5830 - val_mae: 418.5830\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.3544 - mae: 409.3544 - val_loss: 415.9975 - val_mae: 415.9975\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.2275 - mae: 408.2275 - val_loss: 414.4976 - val_mae: 414.4976\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.6430 - mae: 407.6430 - val_loss: 414.3224 - val_mae: 414.3224\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.9943 - mae: 406.9943 - val_loss: 414.7857 - val_mae: 414.7857\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.7451 - mae: 406.7451 - val_loss: 412.7053 - val_mae: 412.7053\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.0286 - mae: 406.0286 - val_loss: 416.2093 - val_mae: 416.2093\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.4952 - mae: 404.4952 - val_loss: 410.6144 - val_mae: 410.6144\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.3578 - mae: 404.3578 - val_loss: 410.8294 - val_mae: 410.8294\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.9401 - mae: 403.9401 - val_loss: 412.0016 - val_mae: 412.0016\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.2892 - mae: 403.2892 - val_loss: 408.2710 - val_mae: 408.2710\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.8354 - mae: 402.8354 - val_loss: 410.6456 - val_mae: 410.6456\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.8269 - mae: 402.8269 - val_loss: 413.6767 - val_mae: 413.6767\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.5668 - mae: 402.5668 - val_loss: 409.8015 - val_mae: 409.8015\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.4243 - mae: 401.4243 - val_loss: 411.9849 - val_mae: 411.9849\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.8541 - mae: 401.8541 - val_loss: 407.4088 - val_mae: 407.4088\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.1471 - mae: 400.1471 - val_loss: 412.1525 - val_mae: 412.1525\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.9195 - mae: 400.9195 - val_loss: 411.1725 - val_mae: 411.1725\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.3810 - mae: 400.3810 - val_loss: 411.3343 - val_mae: 411.3343\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399.9598 - mae: 399.9598 - val_loss: 407.3514 - val_mae: 407.3514\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399.4215 - mae: 399.4215 - val_loss: 404.8345 - val_mae: 404.8345\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399.3206 - mae: 399.3206 - val_loss: 409.1414 - val_mae: 409.1414\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.2361 - mae: 400.2361 - val_loss: 411.3156 - val_mae: 411.3156\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.8583 - mae: 398.8583 - val_loss: 408.1533 - val_mae: 408.1533\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.5122 - mae: 398.5122 - val_loss: 405.5876 - val_mae: 405.5876\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.3594 - mae: 398.3594 - val_loss: 407.0237 - val_mae: 407.0237\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.1512 - mae: 398.1512 - val_loss: 409.3416 - val_mae: 409.3416\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.3352 - mae: 398.3352 - val_loss: 403.7924 - val_mae: 403.7924\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397.4679 - mae: 397.4679 - val_loss: 410.5704 - val_mae: 410.5704\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397.9401 - mae: 397.9401 - val_loss: 403.0250 - val_mae: 403.0250\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397.4449 - mae: 397.4449 - val_loss: 407.2999 - val_mae: 407.2999\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396.0427 - mae: 396.0427 - val_loss: 401.2725 - val_mae: 401.2725\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396.1966 - mae: 396.1966 - val_loss: 403.3859 - val_mae: 403.3859\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396.3982 - mae: 396.3982 - val_loss: 402.2033 - val_mae: 402.2033\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396.2966 - mae: 396.2966 - val_loss: 402.1397 - val_mae: 402.1397\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.6273 - mae: 395.6273 - val_loss: 403.8761 - val_mae: 403.8761\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.1291 - mae: 395.1291 - val_loss: 405.5903 - val_mae: 405.5903\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396.5602 - mae: 396.5602 - val_loss: 400.2112 - val_mae: 400.2112\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.2572 - mae: 395.2572 - val_loss: 400.4931 - val_mae: 400.4931\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394.9290 - mae: 394.9290 - val_loss: 399.6451 - val_mae: 399.6451\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394.8357 - mae: 394.8357 - val_loss: 404.3398 - val_mae: 404.3398\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394.4477 - mae: 394.4477 - val_loss: 400.1852 - val_mae: 400.1852\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.5266 - mae: 395.5266 - val_loss: 402.0800 - val_mae: 402.0800\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.4512 - mae: 395.4512 - val_loss: 404.2109 - val_mae: 404.2109\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.2758 - mae: 395.2758 - val_loss: 405.2419 - val_mae: 405.2419\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394.5618 - mae: 394.5618 - val_loss: 401.0029 - val_mae: 401.0029\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394.6024 - mae: 394.6024 - val_loss: 404.0431 - val_mae: 404.0431\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394.4907 - mae: 394.4907 - val_loss: 400.9306 - val_mae: 400.9306\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394.1775 - mae: 394.1775 - val_loss: 400.0148 - val_mae: 400.0148\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393.1771 - mae: 393.1771 - val_loss: 402.9583 - val_mae: 402.9583\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4200.7266 - mae: 4200.7266 - val_loss: 557.2780 - val_mae: 557.2780\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 511.4071 - mae: 511.4071 - val_loss: 496.6104 - val_mae: 496.6104\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 489.7103 - mae: 489.7103 - val_loss: 489.7343 - val_mae: 489.7343\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 471.0803 - mae: 471.0803 - val_loss: 475.8448 - val_mae: 475.8448\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 458.8853 - mae: 458.8853 - val_loss: 472.1882 - val_mae: 472.1882\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 451.3366 - mae: 451.3366 - val_loss: 448.2506 - val_mae: 448.2506\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 446.2013 - mae: 446.2013 - val_loss: 454.0553 - val_mae: 454.0553\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 440.4171 - mae: 440.4171 - val_loss: 452.8236 - val_mae: 452.8236\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437.1183 - mae: 437.1183 - val_loss: 460.2462 - val_mae: 460.2462\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432.7958 - mae: 432.7958 - val_loss: 439.5695 - val_mae: 439.5695\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432.1417 - mae: 432.1417 - val_loss: 462.1767 - val_mae: 462.1767\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428.8784 - mae: 428.8784 - val_loss: 428.2228 - val_mae: 428.2228\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428.1200 - mae: 428.1200 - val_loss: 434.1282 - val_mae: 434.1282\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.7850 - mae: 423.7850 - val_loss: 427.3536 - val_mae: 427.3536\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.9682 - mae: 423.9682 - val_loss: 424.0939 - val_mae: 424.0939\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.1267 - mae: 423.1267 - val_loss: 458.1332 - val_mae: 458.1332\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422.6143 - mae: 422.6143 - val_loss: 443.7841 - val_mae: 443.7841\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.4221 - mae: 421.4221 - val_loss: 435.7592 - val_mae: 435.7592\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.8763 - mae: 418.8763 - val_loss: 423.2478 - val_mae: 423.2478\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417.3195 - mae: 417.3195 - val_loss: 434.7777 - val_mae: 434.7777\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.1956 - mae: 418.1956 - val_loss: 418.9626 - val_mae: 418.9626\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.3280 - mae: 416.3280 - val_loss: 424.6129 - val_mae: 424.6129\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.0039 - mae: 415.0039 - val_loss: 426.3914 - val_mae: 426.3914\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.1562 - mae: 414.1562 - val_loss: 417.2524 - val_mae: 417.2524\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.5021 - mae: 414.5021 - val_loss: 415.7993 - val_mae: 415.7993\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.4758 - mae: 413.4758 - val_loss: 407.6341 - val_mae: 407.6341\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.7257 - mae: 411.7257 - val_loss: 431.1538 - val_mae: 431.1538\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.1378 - mae: 410.1378 - val_loss: 418.8712 - val_mae: 418.8712\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.5518 - mae: 412.5518 - val_loss: 421.0987 - val_mae: 421.0987\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.1819 - mae: 412.1819 - val_loss: 446.8548 - val_mae: 446.8548\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.9049 - mae: 410.9049 - val_loss: 426.0462 - val_mae: 426.0462\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.2085 - mae: 408.2085 - val_loss: 415.4323 - val_mae: 415.4323\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.5091 - mae: 407.5091 - val_loss: 416.2306 - val_mae: 416.2306\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.5416 - mae: 407.5416 - val_loss: 411.4949 - val_mae: 411.4949\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.3381 - mae: 407.3381 - val_loss: 422.2731 - val_mae: 422.2731\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.9191 - mae: 405.9191 - val_loss: 413.6672 - val_mae: 413.6672\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3344.8982 - mae: 3344.8982 - val_loss: 542.6804 - val_mae: 542.6804\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 520.3526 - mae: 520.3526 - val_loss: 524.1517 - val_mae: 524.1517\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 509.4341 - mae: 509.4341 - val_loss: 519.7477 - val_mae: 519.7477\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 494.9023 - mae: 494.9023 - val_loss: 519.0112 - val_mae: 519.0112\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 477.4847 - mae: 477.4847 - val_loss: 475.1799 - val_mae: 475.1799\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 461.3611 - mae: 461.3611 - val_loss: 495.8169 - val_mae: 495.8169\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453.4619 - mae: 453.4619 - val_loss: 463.1452 - val_mae: 463.1452\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 445.1343 - mae: 445.1343 - val_loss: 453.2780 - val_mae: 453.2780\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437.7375 - mae: 437.7375 - val_loss: 440.2990 - val_mae: 440.2990\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434.5536 - mae: 434.5536 - val_loss: 440.8124 - val_mae: 440.8124\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430.9576 - mae: 430.9576 - val_loss: 439.2060 - val_mae: 439.2060\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429.8733 - mae: 429.8733 - val_loss: 442.7712 - val_mae: 442.7712\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426.5790 - mae: 426.5790 - val_loss: 428.8595 - val_mae: 428.8595\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424.3471 - mae: 424.3471 - val_loss: 443.0653 - val_mae: 443.0653\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.1228 - mae: 423.1228 - val_loss: 440.2182 - val_mae: 440.2182\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.1711 - mae: 421.1711 - val_loss: 435.6310 - val_mae: 435.6310\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.5789 - mae: 418.5789 - val_loss: 425.1621 - val_mae: 425.1621\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417.4268 - mae: 417.4268 - val_loss: 443.0184 - val_mae: 443.0184\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.4037 - mae: 415.4037 - val_loss: 425.5234 - val_mae: 425.5234\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.3770 - mae: 416.3770 - val_loss: 433.4590 - val_mae: 433.4590\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.7570 - mae: 414.7570 - val_loss: 416.5909 - val_mae: 416.5909\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.5565 - mae: 414.5565 - val_loss: 409.0796 - val_mae: 409.0796\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.6961 - mae: 412.6961 - val_loss: 413.5080 - val_mae: 413.5080\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.4350 - mae: 411.4350 - val_loss: 446.7971 - val_mae: 446.7971\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.7876 - mae: 412.7876 - val_loss: 418.1496 - val_mae: 418.1496\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.4332 - mae: 411.4332 - val_loss: 439.2848 - val_mae: 439.2848\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.8692 - mae: 411.8692 - val_loss: 425.3335 - val_mae: 425.3335\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.1084 - mae: 409.1084 - val_loss: 423.8187 - val_mae: 423.8187\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.8709 - mae: 410.8709 - val_loss: 471.3577 - val_mae: 471.3577\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.8946 - mae: 409.8946 - val_loss: 423.8910 - val_mae: 423.8910\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.3315 - mae: 409.3315 - val_loss: 407.4518 - val_mae: 407.4518\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.7930 - mae: 409.7930 - val_loss: 423.3429 - val_mae: 423.3429\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.4610 - mae: 408.4610 - val_loss: 414.0637 - val_mae: 414.0637\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.8852 - mae: 408.8852 - val_loss: 423.1070 - val_mae: 423.1070\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.2832 - mae: 407.2832 - val_loss: 413.4565 - val_mae: 413.4565\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.7119 - mae: 408.7119 - val_loss: 429.2985 - val_mae: 429.2985\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.8198 - mae: 407.8198 - val_loss: 421.8081 - val_mae: 421.8081\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.4736 - mae: 408.4736 - val_loss: 426.6097 - val_mae: 426.6097\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.0397 - mae: 408.0397 - val_loss: 410.8209 - val_mae: 410.8209\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.2303 - mae: 407.2303 - val_loss: 418.5926 - val_mae: 418.5926\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406.2113 - mae: 406.2113 - val_loss: 409.6589 - val_mae: 409.6589\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6021.3784 - mae: 6021.3784 - val_loss: 5835.7026 - val_mae: 5835.7026\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2503.8215 - mae: 2503.8215 - val_loss: 519.5330 - val_mae: 519.5330\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 508.5205 - mae: 508.5205 - val_loss: 504.4604 - val_mae: 504.4604\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 506.0092 - mae: 506.0092 - val_loss: 506.0686 - val_mae: 506.0686\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 504.0006 - mae: 504.0006 - val_loss: 504.9144 - val_mae: 504.9144\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 497.0135 - mae: 497.0135 - val_loss: 501.6162 - val_mae: 501.6162\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 489.6703 - mae: 489.6703 - val_loss: 484.0265 - val_mae: 484.0265\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 478.1039 - mae: 478.1039 - val_loss: 474.6430 - val_mae: 474.6430\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 465.4029 - mae: 465.4029 - val_loss: 479.1621 - val_mae: 479.1621\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 457.3853 - mae: 457.3853 - val_loss: 460.2165 - val_mae: 460.2165\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 452.7127 - mae: 452.7127 - val_loss: 446.8986 - val_mae: 446.8986\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 446.4351 - mae: 446.4351 - val_loss: 452.5525 - val_mae: 452.5525\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 444.6182 - mae: 444.6182 - val_loss: 448.4312 - val_mae: 448.4312\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 440.7374 - mae: 440.7374 - val_loss: 448.5702 - val_mae: 448.5702\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439.2385 - mae: 439.2385 - val_loss: 440.0793 - val_mae: 440.0793\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437.2320 - mae: 437.2320 - val_loss: 441.6791 - val_mae: 441.6791\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 434.2647 - mae: 434.2647 - val_loss: 449.3678 - val_mae: 449.3678\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 433.7418 - mae: 433.7418 - val_loss: 447.8236 - val_mae: 447.8236\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432.7610 - mae: 432.7610 - val_loss: 437.0088 - val_mae: 437.0088\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 431.2512 - mae: 431.2512 - val_loss: 437.9121 - val_mae: 437.9121\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429.8553 - mae: 429.8553 - val_loss: 435.3796 - val_mae: 435.3796\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 428.3964 - mae: 428.3964 - val_loss: 435.9295 - val_mae: 435.9295\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 427.8458 - mae: 427.8458 - val_loss: 431.4462 - val_mae: 431.4462\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426.0596 - mae: 426.0596 - val_loss: 426.9295 - val_mae: 426.9295\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.4383 - mae: 424.4383 - val_loss: 432.7453 - val_mae: 432.7453\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.2359 - mae: 422.2359 - val_loss: 427.9362 - val_mae: 427.9362\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.7711 - mae: 420.7711 - val_loss: 420.4584 - val_mae: 420.4584\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.0609 - mae: 418.0609 - val_loss: 425.0652 - val_mae: 425.0652\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.9062 - mae: 416.9062 - val_loss: 423.1358 - val_mae: 423.1358\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.6491 - mae: 415.6491 - val_loss: 421.1277 - val_mae: 421.1277\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.8318 - mae: 414.8318 - val_loss: 414.7004 - val_mae: 414.7004\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.5901 - mae: 412.5901 - val_loss: 418.9895 - val_mae: 418.9895\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413.4268 - mae: 413.4268 - val_loss: 417.3306 - val_mae: 417.3306\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.3292 - mae: 412.3292 - val_loss: 422.8057 - val_mae: 422.8057\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.4328 - mae: 412.4328 - val_loss: 417.7722 - val_mae: 417.7722\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.1623 - mae: 411.1623 - val_loss: 418.9298 - val_mae: 418.9298\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.0472 - mae: 411.0472 - val_loss: 411.1640 - val_mae: 411.1640\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.5169 - mae: 408.5169 - val_loss: 417.8685 - val_mae: 417.8685\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.5612 - mae: 409.5612 - val_loss: 414.1972 - val_mae: 414.1972\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.0995 - mae: 409.0995 - val_loss: 413.2057 - val_mae: 413.2057\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.9599 - mae: 407.9599 - val_loss: 419.9220 - val_mae: 419.9220\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.3535 - mae: 408.3535 - val_loss: 412.1787 - val_mae: 412.1787\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.8671 - mae: 406.8671 - val_loss: 418.4792 - val_mae: 418.4792\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.4178 - mae: 406.4178 - val_loss: 417.4976 - val_mae: 417.4976\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.0183 - mae: 406.0183 - val_loss: 409.6655 - val_mae: 409.6655\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.7162 - mae: 405.7162 - val_loss: 412.6030 - val_mae: 412.6030\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.9090 - mae: 406.9090 - val_loss: 414.2916 - val_mae: 414.2916\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.6731 - mae: 405.6731 - val_loss: 419.6196 - val_mae: 419.6196\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.4659 - mae: 405.4659 - val_loss: 411.6735 - val_mae: 411.6735\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.6894 - mae: 404.6894 - val_loss: 411.4125 - val_mae: 411.4125\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.3418 - mae: 403.3418 - val_loss: 414.5557 - val_mae: 414.5557\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.9111 - mae: 403.9111 - val_loss: 411.9941 - val_mae: 411.9941\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.7517 - mae: 403.7517 - val_loss: 417.3284 - val_mae: 417.3284\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.0728 - mae: 403.0728 - val_loss: 407.4740 - val_mae: 407.4740\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.0960 - mae: 404.0960 - val_loss: 409.3616 - val_mae: 409.3616\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.4784 - mae: 402.4784 - val_loss: 410.8775 - val_mae: 410.8775\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.1049 - mae: 403.1049 - val_loss: 409.7214 - val_mae: 409.7214\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.1421 - mae: 402.1421 - val_loss: 409.7100 - val_mae: 409.7100\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.9736 - mae: 401.9736 - val_loss: 413.7179 - val_mae: 413.7179\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.9702 - mae: 400.9702 - val_loss: 406.0639 - val_mae: 406.0639\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.6915 - mae: 401.6915 - val_loss: 411.7266 - val_mae: 411.7266\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.0857 - mae: 401.0857 - val_loss: 409.2384 - val_mae: 409.2384\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.1127 - mae: 401.1127 - val_loss: 407.4243 - val_mae: 407.4243\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.5272 - mae: 399.5272 - val_loss: 405.2951 - val_mae: 405.2951\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.6071 - mae: 399.6071 - val_loss: 406.7278 - val_mae: 406.7278\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.3922 - mae: 399.3922 - val_loss: 404.9653 - val_mae: 404.9653\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.0381 - mae: 399.0381 - val_loss: 407.2554 - val_mae: 407.2554\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.5003 - mae: 399.5003 - val_loss: 402.3660 - val_mae: 402.3660\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.8957 - mae: 398.8957 - val_loss: 401.1286 - val_mae: 401.1286\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.6043 - mae: 398.6043 - val_loss: 409.1556 - val_mae: 409.1556\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.1158 - mae: 398.1158 - val_loss: 411.0176 - val_mae: 411.0176\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.9067 - mae: 397.9067 - val_loss: 405.1450 - val_mae: 405.1450\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.0020 - mae: 398.0020 - val_loss: 409.1631 - val_mae: 409.1631\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.9085 - mae: 397.9085 - val_loss: 403.1889 - val_mae: 403.1889\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.9196 - mae: 397.9196 - val_loss: 409.4663 - val_mae: 409.4663\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.4233 - mae: 397.4233 - val_loss: 409.0112 - val_mae: 409.0112\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.3390 - mae: 397.3390 - val_loss: 403.5413 - val_mae: 403.5413\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.2812 - mae: 397.2812 - val_loss: 405.7830 - val_mae: 405.7830\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.3623 - mae: 396.3623 - val_loss: 402.5257 - val_mae: 402.5257\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6009.6938 - mae: 6009.6938 - val_loss: 5691.0942 - val_mae: 5691.0942\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1822.2928 - mae: 1822.2928 - val_loss: 509.5474 - val_mae: 509.5474\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 509.3684 - mae: 509.3684 - val_loss: 515.6711 - val_mae: 515.6711\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 501.0406 - mae: 501.0406 - val_loss: 494.3291 - val_mae: 494.3291\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 491.8876 - mae: 491.8876 - val_loss: 487.9187 - val_mae: 487.9187\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 482.3536 - mae: 482.3536 - val_loss: 480.1386 - val_mae: 480.1386\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 473.6372 - mae: 473.6372 - val_loss: 474.3905 - val_mae: 474.3905\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 469.3055 - mae: 469.3055 - val_loss: 469.6304 - val_mae: 469.6304\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 462.6625 - mae: 462.6625 - val_loss: 473.6668 - val_mae: 473.6668\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 458.8918 - mae: 458.8918 - val_loss: 457.5047 - val_mae: 457.5047\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 453.3321 - mae: 453.3321 - val_loss: 453.0123 - val_mae: 453.0123\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 447.9285 - mae: 447.9285 - val_loss: 442.2617 - val_mae: 442.2617\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 443.4871 - mae: 443.4871 - val_loss: 447.3505 - val_mae: 447.3505\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439.8819 - mae: 439.8819 - val_loss: 436.7441 - val_mae: 436.7441\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436.8727 - mae: 436.8727 - val_loss: 445.1522 - val_mae: 445.1522\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432.8003 - mae: 432.8003 - val_loss: 436.7908 - val_mae: 436.7908\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 431.5999 - mae: 431.5999 - val_loss: 438.2014 - val_mae: 438.2014\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429.8188 - mae: 429.8188 - val_loss: 434.5660 - val_mae: 434.5660\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 427.9974 - mae: 427.9974 - val_loss: 430.2454 - val_mae: 430.2454\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425.9499 - mae: 425.9499 - val_loss: 430.2104 - val_mae: 430.2104\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.1242 - mae: 424.1242 - val_loss: 432.1788 - val_mae: 432.1788\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.8062 - mae: 422.8062 - val_loss: 431.6859 - val_mae: 431.6859\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423.3226 - mae: 423.3226 - val_loss: 433.4001 - val_mae: 433.4001\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.3214 - mae: 421.3214 - val_loss: 419.9885 - val_mae: 419.9885\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.0232 - mae: 422.0232 - val_loss: 425.0628 - val_mae: 425.0628\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.6900 - mae: 420.6900 - val_loss: 426.0628 - val_mae: 426.0628\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.1571 - mae: 421.1571 - val_loss: 428.4527 - val_mae: 428.4527\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.7916 - mae: 419.7916 - val_loss: 425.4896 - val_mae: 425.4896\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.7690 - mae: 419.7690 - val_loss: 422.5128 - val_mae: 422.5128\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.7802 - mae: 417.7802 - val_loss: 437.6147 - val_mae: 437.6147\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.9939 - mae: 416.9939 - val_loss: 422.8479 - val_mae: 422.8479\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.1259 - mae: 417.1259 - val_loss: 425.4000 - val_mae: 425.4000\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.7213 - mae: 415.7213 - val_loss: 420.3544 - val_mae: 420.3544\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.2742 - mae: 414.2742 - val_loss: 425.6333 - val_mae: 425.6333\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6049.6328 - mae: 6049.6328 - val_loss: 6032.1250 - val_mae: 6032.1250\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5969.7471 - mae: 5969.7471 - val_loss: 5764.3638 - val_mae: 5764.3638\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4017.6780 - mae: 4017.6780 - val_loss: 892.3179 - val_mae: 892.3179\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 568.8211 - mae: 568.8211 - val_loss: 501.8329 - val_mae: 501.8329\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 491.5758 - mae: 491.5758 - val_loss: 490.3661 - val_mae: 490.3661\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482.8809 - mae: 482.8809 - val_loss: 483.0647 - val_mae: 483.0647\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 475.0490 - mae: 475.0490 - val_loss: 474.1827 - val_mae: 474.1827\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 466.5407 - mae: 466.5407 - val_loss: 468.7565 - val_mae: 468.7565\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 461.4874 - mae: 461.4874 - val_loss: 463.0515 - val_mae: 463.0515\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 456.5233 - mae: 456.5233 - val_loss: 458.6956 - val_mae: 458.6956\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 453.2442 - mae: 453.2442 - val_loss: 460.7419 - val_mae: 460.7419\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 450.5647 - mae: 450.5647 - val_loss: 450.8844 - val_mae: 450.8844\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 446.8473 - mae: 446.8473 - val_loss: 453.3050 - val_mae: 453.3050\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 443.9284 - mae: 443.9284 - val_loss: 445.4185 - val_mae: 445.4185\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441.2325 - mae: 441.2325 - val_loss: 442.8317 - val_mae: 442.8317\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.2682 - mae: 438.2682 - val_loss: 444.3338 - val_mae: 444.3338\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435.4240 - mae: 435.4240 - val_loss: 436.9359 - val_mae: 436.9359\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 432.5082 - mae: 432.5082 - val_loss: 435.8608 - val_mae: 435.8608\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.3963 - mae: 430.3963 - val_loss: 436.0538 - val_mae: 436.0538\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.4114 - mae: 428.4114 - val_loss: 433.1399 - val_mae: 433.1399\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426.1682 - mae: 426.1682 - val_loss: 427.0530 - val_mae: 427.0530\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.6190 - mae: 423.6190 - val_loss: 430.1656 - val_mae: 430.1656\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.7946 - mae: 422.7946 - val_loss: 425.6442 - val_mae: 425.6442\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.8546 - mae: 421.8546 - val_loss: 424.9812 - val_mae: 424.9812\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.2986 - mae: 420.2986 - val_loss: 426.0942 - val_mae: 426.0942\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.4893 - mae: 419.4893 - val_loss: 421.7613 - val_mae: 421.7613\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.9901 - mae: 417.9901 - val_loss: 426.6332 - val_mae: 426.6332\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.5233 - mae: 416.5233 - val_loss: 420.0945 - val_mae: 420.0945\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.6895 - mae: 416.6895 - val_loss: 422.2438 - val_mae: 422.2438\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.1507 - mae: 416.1507 - val_loss: 419.9078 - val_mae: 419.9078\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.2151 - mae: 414.2151 - val_loss: 427.2226 - val_mae: 427.2226\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.7335 - mae: 414.7335 - val_loss: 417.5775 - val_mae: 417.5775\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.7031 - mae: 413.7031 - val_loss: 419.1527 - val_mae: 419.1527\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.7802 - mae: 413.7802 - val_loss: 417.6793 - val_mae: 417.6793\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.2359 - mae: 413.2359 - val_loss: 416.4930 - val_mae: 416.4930\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.3448 - mae: 413.3448 - val_loss: 417.8007 - val_mae: 417.8007\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.6766 - mae: 412.6766 - val_loss: 420.0423 - val_mae: 420.0423\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.9850 - mae: 411.9850 - val_loss: 420.8365 - val_mae: 420.8365\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.8168 - mae: 411.8168 - val_loss: 422.4716 - val_mae: 422.4716\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.8289 - mae: 412.8289 - val_loss: 419.4915 - val_mae: 419.4915\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.4650 - mae: 411.4650 - val_loss: 417.3169 - val_mae: 417.3169\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.0160 - mae: 412.0160 - val_loss: 414.0641 - val_mae: 414.0641\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.0605 - mae: 411.0605 - val_loss: 423.3483 - val_mae: 423.3483\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.0420 - mae: 411.0420 - val_loss: 419.0728 - val_mae: 419.0728\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.5233 - mae: 411.5233 - val_loss: 419.2116 - val_mae: 419.2116\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.5311 - mae: 410.5311 - val_loss: 414.6985 - val_mae: 414.6985\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.7767 - mae: 410.7767 - val_loss: 421.9433 - val_mae: 421.9433\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.1939 - mae: 411.1939 - val_loss: 414.2516 - val_mae: 414.2516\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.0797 - mae: 410.0797 - val_loss: 417.3918 - val_mae: 417.3918\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.6584 - mae: 410.6584 - val_loss: 416.2559 - val_mae: 416.2559\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.9273 - mae: 409.9273 - val_loss: 416.9955 - val_mae: 416.9955\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.6777 - mae: 410.6777 - val_loss: 417.5999 - val_mae: 417.5999\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6047.8599 - mae: 6047.8599 - val_loss: 6021.4922 - val_mae: 6021.4922\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5762.7837 - mae: 5762.7837 - val_loss: 4826.6885 - val_mae: 4826.6885\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1622.0955 - mae: 1622.0955 - val_loss: 531.3964 - val_mae: 531.3964\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 515.2278 - mae: 515.2278 - val_loss: 509.0160 - val_mae: 509.0160\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 503.3744 - mae: 503.3744 - val_loss: 504.5924 - val_mae: 504.5924\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 499.1397 - mae: 499.1397 - val_loss: 495.7534 - val_mae: 495.7534\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 494.6879 - mae: 494.6879 - val_loss: 493.9792 - val_mae: 493.9792\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 491.7865 - mae: 491.7865 - val_loss: 491.6898 - val_mae: 491.6898\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 486.7134 - mae: 486.7134 - val_loss: 491.2420 - val_mae: 491.2420\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 483.7753 - mae: 483.7753 - val_loss: 487.5578 - val_mae: 487.5578\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 478.1753 - mae: 478.1753 - val_loss: 481.7795 - val_mae: 481.7795\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 470.1053 - mae: 470.1053 - val_loss: 475.1285 - val_mae: 475.1285\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 464.6891 - mae: 464.6891 - val_loss: 467.5887 - val_mae: 467.5887\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 460.6780 - mae: 460.6780 - val_loss: 469.2935 - val_mae: 469.2935\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 457.2249 - mae: 457.2249 - val_loss: 462.5942 - val_mae: 462.5942\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 450.9435 - mae: 450.9435 - val_loss: 462.9621 - val_mae: 462.9621\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 447.1606 - mae: 447.1606 - val_loss: 455.9010 - val_mae: 455.9010\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444.7177 - mae: 444.7177 - val_loss: 452.1689 - val_mae: 452.1689\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441.9523 - mae: 441.9523 - val_loss: 446.5364 - val_mae: 446.5364\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.2680 - mae: 439.2680 - val_loss: 445.4644 - val_mae: 445.4644\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.0032 - mae: 438.0032 - val_loss: 442.2352 - val_mae: 442.2352\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 437.0307 - mae: 437.0307 - val_loss: 447.9011 - val_mae: 447.9011\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 434.8691 - mae: 434.8691 - val_loss: 444.1672 - val_mae: 444.1672\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 433.9583 - mae: 433.9583 - val_loss: 441.4367 - val_mae: 441.4367\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431.8257 - mae: 431.8257 - val_loss: 439.4556 - val_mae: 439.4556\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.4087 - mae: 430.4087 - val_loss: 441.8274 - val_mae: 441.8274\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429.4293 - mae: 429.4293 - val_loss: 438.9971 - val_mae: 438.9971\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.9714 - mae: 427.9714 - val_loss: 432.8647 - val_mae: 432.8647\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.9416 - mae: 427.9416 - val_loss: 432.7413 - val_mae: 432.7413\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426.6577 - mae: 426.6577 - val_loss: 432.9085 - val_mae: 432.9085\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.5858 - mae: 427.5858 - val_loss: 430.9200 - val_mae: 430.9200\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426.8339 - mae: 426.8339 - val_loss: 429.8542 - val_mae: 429.8542\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.9194 - mae: 424.9194 - val_loss: 430.2287 - val_mae: 430.2287\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.3638 - mae: 424.3638 - val_loss: 433.0082 - val_mae: 433.0082\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.2023 - mae: 424.2023 - val_loss: 428.7740 - val_mae: 428.7740\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.9196 - mae: 422.9196 - val_loss: 432.9276 - val_mae: 432.9276\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.4331 - mae: 422.4331 - val_loss: 428.2880 - val_mae: 428.2880\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.5315 - mae: 422.5315 - val_loss: 432.4773 - val_mae: 432.4773\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.4427 - mae: 421.4427 - val_loss: 432.3927 - val_mae: 432.3927\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.1113 - mae: 421.1113 - val_loss: 432.1270 - val_mae: 432.1270\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.8470 - mae: 419.8470 - val_loss: 428.9711 - val_mae: 428.9711\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.1106 - mae: 419.1106 - val_loss: 424.0511 - val_mae: 424.0511\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.8258 - mae: 418.8258 - val_loss: 423.5252 - val_mae: 423.5252\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.5053 - mae: 417.5053 - val_loss: 425.0356 - val_mae: 425.0356\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.2137 - mae: 417.2137 - val_loss: 425.0081 - val_mae: 425.0081\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.3202 - mae: 416.3202 - val_loss: 423.1456 - val_mae: 423.1456\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.3212 - mae: 416.3212 - val_loss: 427.2072 - val_mae: 427.2072\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.8584 - mae: 415.8584 - val_loss: 423.2955 - val_mae: 423.2955\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.7925 - mae: 414.7925 - val_loss: 421.9120 - val_mae: 421.9120\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.6846 - mae: 414.6846 - val_loss: 420.4492 - val_mae: 420.4492\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.8525 - mae: 413.8525 - val_loss: 420.5078 - val_mae: 420.5078\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.0710 - mae: 414.0710 - val_loss: 422.9600 - val_mae: 422.9600\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.1015 - mae: 413.1015 - val_loss: 420.4961 - val_mae: 420.4961\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.7699 - mae: 413.7699 - val_loss: 418.2268 - val_mae: 418.2268\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.1430 - mae: 413.1430 - val_loss: 419.6767 - val_mae: 419.6767\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.0707 - mae: 413.0707 - val_loss: 418.4548 - val_mae: 418.4548\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.1374 - mae: 412.1374 - val_loss: 418.6378 - val_mae: 418.6378\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.0316 - mae: 412.0316 - val_loss: 419.7030 - val_mae: 419.7030\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.3094 - mae: 411.3094 - val_loss: 420.1672 - val_mae: 420.1672\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.2684 - mae: 411.2684 - val_loss: 419.5412 - val_mae: 419.5412\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.8829 - mae: 410.8829 - val_loss: 417.8077 - val_mae: 417.8077\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.3735 - mae: 411.3735 - val_loss: 419.1847 - val_mae: 419.1847\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.0276 - mae: 411.0276 - val_loss: 415.8228 - val_mae: 415.8228\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.8412 - mae: 410.8412 - val_loss: 415.6297 - val_mae: 415.6297\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.2946 - mae: 410.2946 - val_loss: 415.6855 - val_mae: 415.6855\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.2548 - mae: 410.2548 - val_loss: 411.9005 - val_mae: 411.9005\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.8023 - mae: 408.8023 - val_loss: 417.9850 - val_mae: 417.9850\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.2733 - mae: 409.2733 - val_loss: 410.3134 - val_mae: 410.3134\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.8174 - mae: 407.8174 - val_loss: 412.9423 - val_mae: 412.9423\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.3000 - mae: 408.3000 - val_loss: 411.1992 - val_mae: 411.1992\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.8646 - mae: 406.8646 - val_loss: 412.4055 - val_mae: 412.4055\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.4377 - mae: 406.4377 - val_loss: 411.4822 - val_mae: 411.4822\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.1181 - mae: 406.1181 - val_loss: 409.3806 - val_mae: 409.3806\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.3669 - mae: 405.3669 - val_loss: 408.1817 - val_mae: 408.1817\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.9436 - mae: 403.9436 - val_loss: 409.0707 - val_mae: 409.0707\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.1978 - mae: 404.1978 - val_loss: 407.2866 - val_mae: 407.2866\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.5851 - mae: 403.5851 - val_loss: 408.6697 - val_mae: 408.6697\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.2863 - mae: 402.2863 - val_loss: 410.1847 - val_mae: 410.1847\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.3449 - mae: 402.3449 - val_loss: 403.3067 - val_mae: 403.3067\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.7878 - mae: 402.7878 - val_loss: 406.5947 - val_mae: 406.5947\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.5383 - mae: 401.5383 - val_loss: 407.3518 - val_mae: 407.3518\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.0769 - mae: 401.0769 - val_loss: 402.4612 - val_mae: 402.4612\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.0100 - mae: 402.0100 - val_loss: 408.0974 - val_mae: 408.0974\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.1554 - mae: 401.1554 - val_loss: 400.9156 - val_mae: 400.9156\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.6152 - mae: 400.6152 - val_loss: 405.6376 - val_mae: 405.6376\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.4478 - mae: 400.4478 - val_loss: 402.3292 - val_mae: 402.3292\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400.5935 - mae: 400.5935 - val_loss: 403.7306 - val_mae: 403.7306\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399.9514 - mae: 399.9514 - val_loss: 402.0337 - val_mae: 402.0337\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399.5579 - mae: 399.5579 - val_loss: 401.8235 - val_mae: 401.8235\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399.3669 - mae: 399.3669 - val_loss: 406.9323 - val_mae: 406.9323\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.6391 - mae: 398.6391 - val_loss: 408.2412 - val_mae: 408.2412\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.8465 - mae: 398.8465 - val_loss: 402.9368 - val_mae: 402.9368\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.6149 - mae: 398.6149 - val_loss: 400.4268 - val_mae: 400.4268\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.8269 - mae: 398.8269 - val_loss: 402.0642 - val_mae: 402.0642\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.2057 - mae: 398.2057 - val_loss: 399.2017 - val_mae: 399.2017\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397.2003 - mae: 397.2003 - val_loss: 404.1257 - val_mae: 404.1257\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.3164 - mae: 398.3164 - val_loss: 405.8424 - val_mae: 405.8424\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.0900 - mae: 398.0900 - val_loss: 402.5324 - val_mae: 402.5324\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396.7896 - mae: 396.7896 - val_loss: 399.4843 - val_mae: 399.4843\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396.9555 - mae: 396.9555 - val_loss: 401.2138 - val_mae: 401.2138\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397.4940 - mae: 397.4940 - val_loss: 399.6971 - val_mae: 399.6971\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396.4028 - mae: 396.4028 - val_loss: 401.1447 - val_mae: 401.1447\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.6786 - mae: 395.6786 - val_loss: 401.4731 - val_mae: 401.4731\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.4126 - mae: 395.4126 - val_loss: 399.3707 - val_mae: 399.3707\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395.7347 - mae: 395.7347 - val_loss: 402.2602 - val_mae: 402.2602\n"
     ]
    }
   ],
   "source": [
    "# 用梯度下降 - 小批量随机梯度下降（MBGD）- mae + sgd\n",
    "\n",
    "result34_dict = {\n",
    "    'units': [],\n",
    "    'batch_size': [],\n",
    "    'learning_rate': [],\n",
    "    'minimum_mae_error': []\n",
    "}\n",
    "\n",
    "for units in para_dict['hidden_units']:\n",
    "    for b_size in para_dict['batch_size']:\n",
    "        for rate in para_dict['learning_rate'][0]:\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "            optimizer = SGD(learning_rate = rate)\n",
    "\n",
    "            model = create_model(columns = x_train.columns, units = units, optimizer = optimizer)\n",
    "\n",
    "            best_model = model.fit(\n",
    "                x_scaled_train, y_train,\n",
    "                validation_data = (x_scaled_test, y_test),\n",
    "                batch_size = b_size,\n",
    "                epochs = 250,\n",
    "                callbacks = [early_stopping]\n",
    "            )\n",
    "\n",
    "            min_mae = early_stopping.best\n",
    "\n",
    "            result34_dict['units'].append(units)\n",
    "            result34_dict['batch_size'].append(b_size)\n",
    "            result34_dict['learning_rate'].append(rate)\n",
    "            result34_dict['minimum_mae_error'].append(min_mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>minimum_mae_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>419.546722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>404.253998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>416.352631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>400.240417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>404.492615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>411.879272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>405.715485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>420.990295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>400.517303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>404.473358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>406.196442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>399.645111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>407.634094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>407.451752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>401.128571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>419.988525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>414.064117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>399.201691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  batch_size  learning_rate  minimum_mae_error\n",
       "0       7          16          0.008         419.546722\n",
       "1       7          16          0.010         404.253998\n",
       "2       7          32          0.008         416.352631\n",
       "3       7          32          0.010         400.240417\n",
       "4       7          64          0.008         404.492615\n",
       "5       7          64          0.010         411.879272\n",
       "6       8          16          0.008         405.715485\n",
       "7       8          16          0.010         420.990295\n",
       "8       8          32          0.008         400.517303\n",
       "9       8          32          0.010         404.473358\n",
       "10      8          64          0.008         406.196442\n",
       "11      8          64          0.010         399.645111\n",
       "12      9          16          0.008         407.634094\n",
       "13      9          16          0.010         407.451752\n",
       "14      9          32          0.008         401.128571\n",
       "15      9          32          0.010         419.988525\n",
       "16      9          64          0.008         414.064117\n",
       "17      9          64          0.010         399.201691"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result34_sgd_df = pd.DataFrame(result34_dict)\n",
    "\n",
    "result34_sgd_df.to_csv('result34_sgd.csv')\n",
    "\n",
    "result34_sgd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 32984368.0000 - mae: 5573.8271 - val_loss: 22238200.0000 - val_mae: 4583.3091\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 11565702.0000 - mae: 3122.6870 - val_loss: 4104294.7500 - val_mae: 1752.9337\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1949318.6250 - mae: 1068.1791 - val_loss: 1073955.3750 - val_mae: 771.2946\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 818598.3125 - mae: 674.0406 - val_loss: 715207.3125 - val_mae: 632.5662\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610014.0000 - mae: 577.7812 - val_loss: 595390.6250 - val_mae: 569.1544\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536474.7500 - mae: 537.9304 - val_loss: 545388.8750 - val_mae: 539.3376\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 499802.7500 - mae: 518.1223 - val_loss: 518640.3125 - val_mae: 523.5753\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 478347.2812 - mae: 508.2948 - val_loss: 502071.7188 - val_mae: 512.0799\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 463553.0000 - mae: 500.5312 - val_loss: 491360.8750 - val_mae: 506.0389\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 451623.5625 - mae: 494.1630 - val_loss: 483228.6250 - val_mae: 501.4374\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 443661.2500 - mae: 489.6577 - val_loss: 475683.0312 - val_mae: 497.5264\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437035.0000 - mae: 485.6414 - val_loss: 470895.6875 - val_mae: 494.6207\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430433.0312 - mae: 482.5723 - val_loss: 468963.8125 - val_mae: 491.6039\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425312.2500 - mae: 478.3358 - val_loss: 466212.0312 - val_mae: 490.3487\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420406.0625 - mae: 476.4057 - val_loss: 456985.8125 - val_mae: 485.8433\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417207.9688 - mae: 473.4126 - val_loss: 454266.8438 - val_mae: 484.2284\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414069.3750 - mae: 471.6888 - val_loss: 452839.5938 - val_mae: 481.3962\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410884.0938 - mae: 469.1349 - val_loss: 449395.0938 - val_mae: 480.8119\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407795.5312 - mae: 467.8416 - val_loss: 445889.7500 - val_mae: 477.5156\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404758.8125 - mae: 465.0718 - val_loss: 448433.3750 - val_mae: 479.7249\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 402489.5000 - mae: 463.8845 - val_loss: 444598.1562 - val_mae: 476.1730\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 400089.8438 - mae: 461.9938 - val_loss: 442153.6562 - val_mae: 476.0702\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 398168.3125 - mae: 461.3489 - val_loss: 443639.3438 - val_mae: 473.1523\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 395654.6250 - mae: 459.2560 - val_loss: 442259.5312 - val_mae: 473.5411\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 394509.4062 - mae: 458.5418 - val_loss: 437354.4375 - val_mae: 471.4937\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 392938.5312 - mae: 457.0687 - val_loss: 435783.1562 - val_mae: 472.5824\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 391904.7188 - mae: 457.0743 - val_loss: 435563.3438 - val_mae: 470.7523\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 390524.3438 - mae: 456.3966 - val_loss: 431855.4375 - val_mae: 470.6934\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 389559.2188 - mae: 455.8130 - val_loss: 431428.8125 - val_mae: 470.8372\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 388739.5312 - mae: 455.0752 - val_loss: 429722.6250 - val_mae: 468.9382\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 387896.3438 - mae: 454.9807 - val_loss: 430423.0938 - val_mae: 468.2785\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 386922.7188 - mae: 454.6773 - val_loss: 426935.5625 - val_mae: 467.4653\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 385341.4375 - mae: 453.7614 - val_loss: 427665.6562 - val_mae: 466.8268\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 384846.0938 - mae: 452.9077 - val_loss: 430364.1875 - val_mae: 469.1810\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 383957.5625 - mae: 452.4969 - val_loss: 430858.7188 - val_mae: 467.8719\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 383049.0000 - mae: 452.0705 - val_loss: 427206.7812 - val_mae: 467.4994\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 381845.1562 - mae: 451.4121 - val_loss: 429348.1250 - val_mae: 467.6717\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 381558.2500 - mae: 450.9167 - val_loss: 424687.2188 - val_mae: 466.9266\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 381290.7812 - mae: 451.0884 - val_loss: 423164.1562 - val_mae: 464.6321\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 379516.5312 - mae: 449.5831 - val_loss: 422360.7188 - val_mae: 465.8668\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 379075.4062 - mae: 449.9101 - val_loss: 426964.6250 - val_mae: 462.5831\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 378305.0938 - mae: 448.8592 - val_loss: 425701.5625 - val_mae: 464.8178\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 377885.8438 - mae: 449.0252 - val_loss: 425771.2188 - val_mae: 462.3259\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 377152.0938 - mae: 447.9112 - val_loss: 418480.9688 - val_mae: 461.9272\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 376906.0000 - mae: 448.4881 - val_loss: 420831.7500 - val_mae: 461.6015\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 375521.9062 - mae: 446.9619 - val_loss: 423204.7188 - val_mae: 462.9580\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 374661.2188 - mae: 447.0107 - val_loss: 422621.4062 - val_mae: 461.3594\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 375282.9062 - mae: 446.4460 - val_loss: 420246.7812 - val_mae: 461.5141\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 374187.2188 - mae: 445.4684 - val_loss: 418122.2188 - val_mae: 460.3880\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 373738.2812 - mae: 445.3544 - val_loss: 418191.8438 - val_mae: 460.5431\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 372694.1875 - mae: 444.4728 - val_loss: 420235.6562 - val_mae: 461.2815\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 372929.9375 - mae: 445.1228 - val_loss: 421595.5000 - val_mae: 459.8724\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 371825.9375 - mae: 443.5859 - val_loss: 419673.8750 - val_mae: 460.0212\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 371777.0312 - mae: 443.5886 - val_loss: 418660.6875 - val_mae: 459.2127\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 371469.0000 - mae: 443.1307 - val_loss: 418782.4062 - val_mae: 459.3460\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 371267.0000 - mae: 442.8383 - val_loss: 419716.0000 - val_mae: 459.0146\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 370470.0312 - mae: 443.1761 - val_loss: 420042.6875 - val_mae: 459.4858\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 370632.3125 - mae: 442.2844 - val_loss: 419514.2812 - val_mae: 460.1255\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 369745.5938 - mae: 441.6854 - val_loss: 416891.2188 - val_mae: 459.8752\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 370023.3438 - mae: 441.9382 - val_loss: 416697.0312 - val_mae: 458.4507\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 369578.1875 - mae: 442.2220 - val_loss: 417075.9375 - val_mae: 457.8540\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 369345.8750 - mae: 440.7142 - val_loss: 416752.5938 - val_mae: 460.4954\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 368996.1250 - mae: 441.0059 - val_loss: 415473.1250 - val_mae: 458.8708\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 368446.4062 - mae: 440.8246 - val_loss: 417883.2188 - val_mae: 458.2700\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 368749.5938 - mae: 441.1329 - val_loss: 416492.5938 - val_mae: 455.5548\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 368352.0625 - mae: 440.1231 - val_loss: 416902.8438 - val_mae: 456.8742\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 367768.8750 - mae: 440.2461 - val_loss: 415528.3438 - val_mae: 455.3711\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 367866.5312 - mae: 440.2028 - val_loss: 417185.6562 - val_mae: 458.6725\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 367736.2188 - mae: 440.2573 - val_loss: 416453.9688 - val_mae: 458.6394\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 367576.5312 - mae: 440.1740 - val_loss: 415591.6562 - val_mae: 456.8348\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 367455.0938 - mae: 440.3191 - val_loss: 415166.7500 - val_mae: 455.4842\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 366901.8125 - mae: 439.9811 - val_loss: 416829.0625 - val_mae: 455.2345\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 366568.8438 - mae: 439.7896 - val_loss: 417674.7500 - val_mae: 456.2640\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 366570.9062 - mae: 438.7270 - val_loss: 412997.7500 - val_mae: 457.0000\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 366290.1250 - mae: 439.6053 - val_loss: 414287.0625 - val_mae: 455.2116\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365931.5000 - mae: 439.3197 - val_loss: 411810.7188 - val_mae: 453.9528\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 366398.3438 - mae: 438.7154 - val_loss: 412771.9062 - val_mae: 456.6171\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 366292.3125 - mae: 438.9306 - val_loss: 415223.3438 - val_mae: 456.1342\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365809.7188 - mae: 439.3704 - val_loss: 410501.8125 - val_mae: 455.9990\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365290.2500 - mae: 438.4157 - val_loss: 410887.5312 - val_mae: 455.7872\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365761.0000 - mae: 438.8276 - val_loss: 410263.8125 - val_mae: 453.6073\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365497.8750 - mae: 438.7118 - val_loss: 414158.2500 - val_mae: 457.2115\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365446.1875 - mae: 438.9056 - val_loss: 411759.1562 - val_mae: 456.0908\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 364923.6875 - mae: 438.4280 - val_loss: 414911.5938 - val_mae: 455.6464\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 364586.6250 - mae: 438.2430 - val_loss: 412265.5312 - val_mae: 456.7004\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 364906.5938 - mae: 438.3134 - val_loss: 409425.1875 - val_mae: 453.9569\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 364555.5938 - mae: 438.1942 - val_loss: 410425.3438 - val_mae: 454.5488\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363859.1250 - mae: 437.4974 - val_loss: 408229.1875 - val_mae: 456.9590\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 364086.8750 - mae: 438.4429 - val_loss: 408876.0312 - val_mae: 454.3780\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363863.8438 - mae: 437.8979 - val_loss: 409277.2188 - val_mae: 454.7629\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363775.4688 - mae: 437.7447 - val_loss: 409905.2188 - val_mae: 453.4357\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363338.9688 - mae: 437.1498 - val_loss: 409141.4062 - val_mae: 454.1062\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363132.7812 - mae: 437.1766 - val_loss: 409045.3125 - val_mae: 453.2115\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 362298.0312 - mae: 436.3910 - val_loss: 410023.2812 - val_mae: 455.1018\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 362140.0000 - mae: 436.4214 - val_loss: 406752.8750 - val_mae: 451.9535\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 362223.1250 - mae: 436.8342 - val_loss: 405835.2500 - val_mae: 452.4706\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 361791.4375 - mae: 435.9629 - val_loss: 407375.6250 - val_mae: 452.3008\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 361431.4062 - mae: 435.4391 - val_loss: 404785.6562 - val_mae: 452.9603\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 361152.9688 - mae: 435.7899 - val_loss: 405028.5000 - val_mae: 452.1668\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 360783.0625 - mae: 435.3850 - val_loss: 408172.0312 - val_mae: 453.5874\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 361104.5312 - mae: 435.8442 - val_loss: 405466.2812 - val_mae: 451.2932\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 360435.2188 - mae: 435.3099 - val_loss: 405824.1875 - val_mae: 450.8336\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359551.8750 - mae: 434.6351 - val_loss: 408354.6562 - val_mae: 452.8033\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 360345.9688 - mae: 435.3658 - val_loss: 405915.4062 - val_mae: 450.1792\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359915.7188 - mae: 434.5938 - val_loss: 407756.3438 - val_mae: 452.2180\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359636.3438 - mae: 434.8906 - val_loss: 404067.3125 - val_mae: 451.1746\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359726.7188 - mae: 434.7130 - val_loss: 405989.4062 - val_mae: 450.7806\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359140.0938 - mae: 434.4605 - val_loss: 404482.7812 - val_mae: 450.8746\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358779.1250 - mae: 434.5563 - val_loss: 408849.3125 - val_mae: 451.2627\n",
      "Epoch 110/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358820.0000 - mae: 434.4922 - val_loss: 403884.3438 - val_mae: 450.1704\n",
      "Epoch 111/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358176.3125 - mae: 433.6465 - val_loss: 401018.1875 - val_mae: 450.2289\n",
      "Epoch 112/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358110.9062 - mae: 433.8323 - val_loss: 399032.9375 - val_mae: 447.7892\n",
      "Epoch 113/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358029.1250 - mae: 433.5390 - val_loss: 401352.5000 - val_mae: 449.6970\n",
      "Epoch 114/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 357927.6250 - mae: 433.2903 - val_loss: 399645.9375 - val_mae: 449.3593\n",
      "Epoch 115/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 356745.0625 - mae: 432.8073 - val_loss: 399774.5625 - val_mae: 447.2964\n",
      "Epoch 116/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 356336.8125 - mae: 432.0688 - val_loss: 398660.5000 - val_mae: 448.6353\n",
      "Epoch 117/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 356073.8125 - mae: 432.2253 - val_loss: 399581.3438 - val_mae: 447.9990\n",
      "Epoch 118/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 355330.2500 - mae: 431.8503 - val_loss: 398645.2500 - val_mae: 449.2415\n",
      "Epoch 119/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 355203.5000 - mae: 430.8601 - val_loss: 398259.2812 - val_mae: 448.5758\n",
      "Epoch 120/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 354746.3750 - mae: 431.3332 - val_loss: 397288.6875 - val_mae: 445.8460\n",
      "Epoch 121/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353761.4062 - mae: 431.0037 - val_loss: 396316.9062 - val_mae: 444.8524\n",
      "Epoch 122/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353019.9688 - mae: 430.3455 - val_loss: 398155.5000 - val_mae: 445.4146\n",
      "Epoch 123/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353202.3125 - mae: 430.1916 - val_loss: 394126.1562 - val_mae: 444.5331\n",
      "Epoch 124/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 352458.8438 - mae: 429.4364 - val_loss: 393897.0312 - val_mae: 444.4177\n",
      "Epoch 125/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 352049.0000 - mae: 429.4946 - val_loss: 393155.1875 - val_mae: 444.5847\n",
      "Epoch 126/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 351406.3438 - mae: 429.0814 - val_loss: 392039.0938 - val_mae: 443.8869\n",
      "Epoch 127/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 351343.7500 - mae: 428.9531 - val_loss: 389301.0312 - val_mae: 442.5667\n",
      "Epoch 128/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 350523.0000 - mae: 427.8810 - val_loss: 390235.7812 - val_mae: 444.1216\n",
      "Epoch 129/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 350602.4062 - mae: 428.5132 - val_loss: 390660.0625 - val_mae: 442.9316\n",
      "Epoch 130/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 349669.3438 - mae: 427.8747 - val_loss: 392371.1875 - val_mae: 445.9704\n",
      "Epoch 131/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 349905.6875 - mae: 427.8932 - val_loss: 388872.0000 - val_mae: 442.0009\n",
      "Epoch 132/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 349897.9688 - mae: 427.5131 - val_loss: 390479.4375 - val_mae: 441.7017\n",
      "Epoch 133/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 349266.8438 - mae: 427.8579 - val_loss: 390255.1875 - val_mae: 443.3345\n",
      "Epoch 134/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348751.6562 - mae: 427.4658 - val_loss: 391521.4375 - val_mae: 441.0138\n",
      "Epoch 135/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348088.9375 - mae: 425.9986 - val_loss: 391858.0938 - val_mae: 443.7453\n",
      "Epoch 136/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348538.6562 - mae: 426.7647 - val_loss: 389779.1250 - val_mae: 442.6498\n",
      "Epoch 137/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347947.8438 - mae: 426.5720 - val_loss: 391432.2500 - val_mae: 441.5231\n",
      "Epoch 138/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347640.6875 - mae: 425.9314 - val_loss: 388259.3438 - val_mae: 442.9022\n",
      "Epoch 139/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348228.2188 - mae: 426.5816 - val_loss: 389146.9062 - val_mae: 439.9500\n",
      "Epoch 140/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347360.8750 - mae: 425.6619 - val_loss: 388133.0312 - val_mae: 438.6422\n",
      "Epoch 141/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347565.5938 - mae: 426.2384 - val_loss: 387230.5625 - val_mae: 440.6436\n",
      "Epoch 142/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347512.0312 - mae: 425.9979 - val_loss: 389979.5312 - val_mae: 440.7669\n",
      "Epoch 143/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347061.0625 - mae: 425.7656 - val_loss: 390271.6875 - val_mae: 440.8025\n",
      "Epoch 144/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347732.7812 - mae: 425.5497 - val_loss: 385554.7188 - val_mae: 439.7681\n",
      "Epoch 145/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 346814.7812 - mae: 425.4687 - val_loss: 387742.0938 - val_mae: 439.8553\n",
      "Epoch 146/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 346421.1562 - mae: 425.1786 - val_loss: 390264.8125 - val_mae: 440.4039\n",
      "Epoch 147/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 346679.8750 - mae: 425.0307 - val_loss: 388128.7500 - val_mae: 441.2533\n",
      "Epoch 148/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 346777.4688 - mae: 425.0817 - val_loss: 385117.2812 - val_mae: 439.3753\n",
      "Epoch 149/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 345774.8750 - mae: 424.4385 - val_loss: 387914.5938 - val_mae: 442.8866\n",
      "Epoch 150/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347008.9688 - mae: 425.4094 - val_loss: 386485.8125 - val_mae: 440.7304\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 31437410.0000 - mae: 5426.2705 - val_loss: 17357674.0000 - val_mae: 4032.8208\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 8444314.0000 - mae: 2437.0652 - val_loss: 4054284.0000 - val_mae: 1396.6201\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3421510.2500 - mae: 1138.6843 - val_loss: 2976873.0000 - val_mae: 1018.8132\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 2167231.7500 - mae: 909.0145 - val_loss: 1518620.8750 - val_mae: 809.5027\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1207635.7500 - mae: 733.3441 - val_loss: 1020567.8125 - val_mae: 690.5263\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 906387.5000 - mae: 639.2113 - val_loss: 826474.9375 - val_mae: 622.7074\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 767583.1875 - mae: 584.8157 - val_loss: 707823.1875 - val_mae: 575.7457\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 684000.0000 - mae: 552.2523 - val_loss: 636743.8125 - val_mae: 549.8495\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 635268.7500 - mae: 534.7020 - val_loss: 593109.2500 - val_mae: 532.3742\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 601275.5000 - mae: 520.9634 - val_loss: 570646.7500 - val_mae: 523.2027\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579156.3750 - mae: 510.9362 - val_loss: 551450.0625 - val_mae: 514.0569\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 564661.5000 - mae: 504.4484 - val_loss: 539718.6875 - val_mae: 506.7158\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553564.1875 - mae: 499.1574 - val_loss: 527725.1875 - val_mae: 502.7454\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545210.6875 - mae: 494.2571 - val_loss: 526081.8125 - val_mae: 503.3545\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537460.6250 - mae: 490.6725 - val_loss: 521739.9688 - val_mae: 498.3188\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530539.9375 - mae: 487.4124 - val_loss: 516691.5625 - val_mae: 493.7119\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 524093.7500 - mae: 483.5560 - val_loss: 508500.7812 - val_mae: 490.3191\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 517155.8750 - mae: 479.8521 - val_loss: 503361.0938 - val_mae: 490.5987\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 512230.2188 - mae: 477.2859 - val_loss: 499772.4688 - val_mae: 484.4380\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 506894.3438 - mae: 474.2970 - val_loss: 490310.0625 - val_mae: 482.5131\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 502238.9375 - mae: 471.9944 - val_loss: 491921.0938 - val_mae: 482.1033\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 497437.1562 - mae: 469.1836 - val_loss: 485655.6875 - val_mae: 478.8781\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 493269.2812 - mae: 467.1504 - val_loss: 479948.5625 - val_mae: 476.6400\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 490389.5312 - mae: 464.9713 - val_loss: 478354.0938 - val_mae: 475.1556\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 487353.0312 - mae: 463.6319 - val_loss: 476564.1875 - val_mae: 474.5374\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 484260.1250 - mae: 462.3958 - val_loss: 470861.3750 - val_mae: 472.6500\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 480876.0312 - mae: 460.7765 - val_loss: 466131.0625 - val_mae: 471.1201\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 478517.9062 - mae: 459.3801 - val_loss: 466741.8438 - val_mae: 470.1320\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 476625.6562 - mae: 458.5674 - val_loss: 461965.5938 - val_mae: 467.1748\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 475084.4375 - mae: 457.9865 - val_loss: 460801.1250 - val_mae: 467.1595\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 472498.7812 - mae: 456.2184 - val_loss: 459141.2500 - val_mae: 466.5392\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 470691.3438 - mae: 455.2717 - val_loss: 458216.4688 - val_mae: 464.6134\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 468930.0938 - mae: 454.8224 - val_loss: 456418.2500 - val_mae: 464.1963\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 467751.9375 - mae: 453.7841 - val_loss: 459473.4688 - val_mae: 466.1848\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 466479.1250 - mae: 453.2969 - val_loss: 454144.6562 - val_mae: 464.6971\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 465592.9375 - mae: 452.2614 - val_loss: 452842.3750 - val_mae: 463.4297\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 463333.0000 - mae: 451.8291 - val_loss: 452271.3750 - val_mae: 461.4527\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 462135.1562 - mae: 450.8873 - val_loss: 450052.3125 - val_mae: 461.0886\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 460850.7812 - mae: 450.3244 - val_loss: 452112.0312 - val_mae: 461.7384\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 459985.9375 - mae: 449.3477 - val_loss: 443428.6250 - val_mae: 457.1428\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 458107.9375 - mae: 448.1417 - val_loss: 442757.3438 - val_mae: 458.7214\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 457456.4062 - mae: 447.3669 - val_loss: 447787.5938 - val_mae: 461.0365\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 456989.7188 - mae: 447.1273 - val_loss: 440864.5625 - val_mae: 456.3727\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 455368.5312 - mae: 445.9152 - val_loss: 440927.0312 - val_mae: 456.3720\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 454906.2500 - mae: 445.6472 - val_loss: 441329.0000 - val_mae: 455.4802\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453526.5625 - mae: 444.8758 - val_loss: 436369.8125 - val_mae: 456.2582\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 452740.3438 - mae: 444.4752 - val_loss: 436749.8125 - val_mae: 455.4794\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 451338.4375 - mae: 444.0492 - val_loss: 436411.5312 - val_mae: 457.2511\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 450857.3125 - mae: 443.2526 - val_loss: 436121.3125 - val_mae: 455.2338\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 450266.8438 - mae: 443.2412 - val_loss: 432595.8750 - val_mae: 455.7009\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 449629.8750 - mae: 443.0867 - val_loss: 430695.6562 - val_mae: 451.2533\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 449359.2500 - mae: 442.3725 - val_loss: 431327.0938 - val_mae: 450.5268\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 448263.2812 - mae: 441.0330 - val_loss: 430871.4062 - val_mae: 452.4507\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 447313.0312 - mae: 440.9812 - val_loss: 430883.7812 - val_mae: 454.0104\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 445959.2812 - mae: 440.2130 - val_loss: 430597.1875 - val_mae: 450.1221\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 445067.4688 - mae: 439.5692 - val_loss: 426298.3750 - val_mae: 448.2544\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 443885.0312 - mae: 439.0387 - val_loss: 428759.0938 - val_mae: 448.4731\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 444174.0000 - mae: 438.5124 - val_loss: 425416.0000 - val_mae: 448.1475\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442926.5312 - mae: 437.7883 - val_loss: 423776.7812 - val_mae: 447.5282\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442032.1250 - mae: 437.0623 - val_loss: 422045.0000 - val_mae: 445.8780\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441484.5625 - mae: 436.8768 - val_loss: 420801.4688 - val_mae: 445.0645\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441070.8438 - mae: 436.6957 - val_loss: 418998.7188 - val_mae: 445.2646\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 440347.1875 - mae: 435.9683 - val_loss: 420583.6562 - val_mae: 446.1129\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439973.6250 - mae: 435.7031 - val_loss: 414275.1562 - val_mae: 442.5708\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439315.1250 - mae: 435.5472 - val_loss: 416280.4062 - val_mae: 444.7846\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439117.3750 - mae: 434.9866 - val_loss: 417323.4375 - val_mae: 444.6825\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 438674.6875 - mae: 435.1574 - val_loss: 417712.9375 - val_mae: 442.9659\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 438008.5938 - mae: 434.0804 - val_loss: 414304.6250 - val_mae: 444.1024\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437910.4062 - mae: 434.1953 - val_loss: 414982.7812 - val_mae: 444.1949\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437595.3750 - mae: 434.2456 - val_loss: 411457.0938 - val_mae: 441.1357\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436624.3438 - mae: 433.5955 - val_loss: 416360.8750 - val_mae: 443.8704\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436596.5625 - mae: 433.4038 - val_loss: 409525.8750 - val_mae: 440.4224\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435975.2500 - mae: 433.1406 - val_loss: 411567.9375 - val_mae: 441.9233\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435791.5938 - mae: 432.9423 - val_loss: 413094.2500 - val_mae: 440.9631\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435177.6562 - mae: 432.3315 - val_loss: 414861.4688 - val_mae: 444.0258\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434289.4062 - mae: 431.8713 - val_loss: 406609.0938 - val_mae: 439.5485\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434568.8125 - mae: 432.1050 - val_loss: 408775.7812 - val_mae: 440.4811\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434206.0312 - mae: 431.9096 - val_loss: 409950.1562 - val_mae: 440.8167\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433431.7812 - mae: 431.5096 - val_loss: 410739.3125 - val_mae: 439.5408\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433843.3125 - mae: 431.8245 - val_loss: 409352.5312 - val_mae: 439.2955\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433512.2500 - mae: 430.9521 - val_loss: 402247.4375 - val_mae: 439.6942\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433252.6250 - mae: 431.4337 - val_loss: 404436.6562 - val_mae: 438.0808\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432810.3750 - mae: 431.5736 - val_loss: 405477.8438 - val_mae: 438.6706\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432811.5625 - mae: 431.2196 - val_loss: 404949.6250 - val_mae: 436.9570\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432369.9688 - mae: 430.6547 - val_loss: 405258.0000 - val_mae: 437.5721\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432121.5938 - mae: 430.8154 - val_loss: 405045.2812 - val_mae: 437.8041\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431223.3125 - mae: 429.6798 - val_loss: 409575.2500 - val_mae: 441.2586\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431632.9062 - mae: 430.7577 - val_loss: 405182.2500 - val_mae: 438.6735\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431559.4688 - mae: 430.2165 - val_loss: 403028.9062 - val_mae: 439.8808\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431018.9688 - mae: 430.2190 - val_loss: 404327.0938 - val_mae: 437.6617\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430809.2500 - mae: 430.2835 - val_loss: 400835.7812 - val_mae: 436.8134\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430671.3750 - mae: 430.1670 - val_loss: 400184.0938 - val_mae: 437.6985\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430414.6250 - mae: 429.8646 - val_loss: 401500.6562 - val_mae: 436.7972\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429433.3438 - mae: 429.3503 - val_loss: 399859.8125 - val_mae: 435.4980\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429596.4375 - mae: 429.7225 - val_loss: 402406.2188 - val_mae: 435.5316\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428408.0312 - mae: 428.4097 - val_loss: 404066.4688 - val_mae: 437.9630\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428959.2500 - mae: 428.9503 - val_loss: 399995.0625 - val_mae: 435.8456\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428281.9062 - mae: 429.1347 - val_loss: 405413.6562 - val_mae: 436.6540\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428280.8125 - mae: 428.1772 - val_loss: 403883.5000 - val_mae: 435.8164\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427175.3438 - mae: 428.2135 - val_loss: 402488.8750 - val_mae: 436.7103\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427167.8125 - mae: 427.8762 - val_loss: 399598.3125 - val_mae: 435.1588\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426900.6875 - mae: 428.2191 - val_loss: 398787.7812 - val_mae: 435.8732\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426837.8125 - mae: 428.4034 - val_loss: 398649.2500 - val_mae: 433.9359\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426523.8438 - mae: 427.8204 - val_loss: 394775.6875 - val_mae: 432.5751\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425495.9062 - mae: 427.2332 - val_loss: 396624.6562 - val_mae: 432.7001\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425310.8125 - mae: 426.5506 - val_loss: 395728.7812 - val_mae: 435.9265\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424660.2812 - mae: 426.8860 - val_loss: 397997.3438 - val_mae: 432.8013\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423597.4688 - mae: 425.8508 - val_loss: 397466.7500 - val_mae: 432.5933\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423663.0312 - mae: 425.9856 - val_loss: 393815.0625 - val_mae: 433.2735\n",
      "Epoch 110/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422386.3438 - mae: 426.0864 - val_loss: 396175.8438 - val_mae: 432.1619\n",
      "Epoch 111/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422140.7812 - mae: 426.1068 - val_loss: 393151.6875 - val_mae: 431.3352\n",
      "Epoch 112/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420915.5625 - mae: 425.1554 - val_loss: 394085.4688 - val_mae: 429.6916\n",
      "Epoch 113/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420753.9062 - mae: 424.7776 - val_loss: 394114.5000 - val_mae: 429.6818\n",
      "Epoch 114/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419826.6875 - mae: 423.8077 - val_loss: 390383.6562 - val_mae: 430.9097\n",
      "Epoch 115/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419835.4375 - mae: 424.0949 - val_loss: 389595.0312 - val_mae: 430.5537\n",
      "Epoch 116/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418889.8438 - mae: 423.8948 - val_loss: 391521.1562 - val_mae: 430.3636\n",
      "Epoch 117/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418741.7500 - mae: 423.6790 - val_loss: 390898.0312 - val_mae: 429.8073\n",
      "Epoch 118/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418830.7188 - mae: 423.4375 - val_loss: 387206.6250 - val_mae: 428.2244\n",
      "Epoch 119/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417771.5312 - mae: 423.3781 - val_loss: 390609.5938 - val_mae: 428.5594\n",
      "Epoch 120/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417579.1250 - mae: 423.2002 - val_loss: 387468.4688 - val_mae: 428.4698\n",
      "Epoch 121/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417902.2500 - mae: 423.2034 - val_loss: 389795.1562 - val_mae: 428.8429\n",
      "Epoch 122/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416777.6250 - mae: 422.3402 - val_loss: 385858.8125 - val_mae: 427.2785\n",
      "Epoch 123/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416917.4062 - mae: 422.0870 - val_loss: 391124.0625 - val_mae: 428.2021\n",
      "Epoch 124/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416543.4688 - mae: 421.7796 - val_loss: 387020.6250 - val_mae: 427.5732\n",
      "Epoch 125/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416556.1250 - mae: 422.0564 - val_loss: 384230.8438 - val_mae: 426.7909\n",
      "Epoch 126/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415879.0938 - mae: 421.4596 - val_loss: 385454.5938 - val_mae: 428.5731\n",
      "Epoch 127/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415559.9062 - mae: 421.4864 - val_loss: 385740.2188 - val_mae: 427.1942\n",
      "Epoch 128/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414861.4688 - mae: 421.2082 - val_loss: 386116.5000 - val_mae: 426.4243\n",
      "Epoch 129/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414700.1250 - mae: 421.1130 - val_loss: 383729.4688 - val_mae: 424.7165\n",
      "Epoch 130/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414657.0625 - mae: 421.0260 - val_loss: 381228.2500 - val_mae: 424.7693\n",
      "Epoch 131/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412990.1562 - mae: 420.1065 - val_loss: 383827.4688 - val_mae: 425.3211\n",
      "Epoch 132/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413558.3750 - mae: 420.1007 - val_loss: 384614.0000 - val_mae: 426.9710\n",
      "Epoch 133/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413528.2188 - mae: 420.2552 - val_loss: 385487.2188 - val_mae: 426.9644\n",
      "Epoch 134/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412556.3438 - mae: 420.1405 - val_loss: 381597.7812 - val_mae: 425.3082\n",
      "Epoch 135/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412442.1250 - mae: 419.5307 - val_loss: 378680.1250 - val_mae: 424.0126\n",
      "Epoch 136/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410968.9062 - mae: 419.0406 - val_loss: 376667.1250 - val_mae: 422.3811\n",
      "Epoch 137/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410890.8438 - mae: 418.7233 - val_loss: 376410.5625 - val_mae: 423.8470\n",
      "Epoch 138/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410304.4062 - mae: 418.9858 - val_loss: 379770.2188 - val_mae: 424.9331\n",
      "Epoch 139/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409534.5312 - mae: 418.1991 - val_loss: 377246.4375 - val_mae: 422.2241\n",
      "Epoch 140/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409445.1875 - mae: 418.7116 - val_loss: 380022.0312 - val_mae: 423.8049\n",
      "Epoch 141/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409759.4062 - mae: 417.6965 - val_loss: 379464.0625 - val_mae: 422.9111\n",
      "Epoch 142/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408795.7188 - mae: 417.9926 - val_loss: 379849.7500 - val_mae: 424.0572\n",
      "Epoch 143/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409060.3438 - mae: 418.0124 - val_loss: 380011.0000 - val_mae: 422.6708\n",
      "Epoch 144/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408832.3125 - mae: 417.7481 - val_loss: 377664.5312 - val_mae: 421.7687\n",
      "Epoch 145/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408764.1250 - mae: 417.9666 - val_loss: 376122.7188 - val_mae: 424.3850\n",
      "Epoch 146/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408649.8750 - mae: 418.0643 - val_loss: 378860.8438 - val_mae: 422.8855\n",
      "Epoch 147/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408013.0938 - mae: 417.1908 - val_loss: 378830.6562 - val_mae: 425.1292\n",
      "Epoch 148/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407731.0625 - mae: 417.3697 - val_loss: 378567.8125 - val_mae: 424.6283\n",
      "Epoch 149/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407591.9688 - mae: 417.7881 - val_loss: 379285.5625 - val_mae: 422.8255\n",
      "Epoch 150/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407015.9688 - mae: 417.2119 - val_loss: 377580.9688 - val_mae: 423.3502\n",
      "Epoch 151/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407301.2188 - mae: 417.1961 - val_loss: 378982.0312 - val_mae: 423.6354\n",
      "Epoch 152/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407202.1875 - mae: 417.3085 - val_loss: 377496.1562 - val_mae: 423.4192\n",
      "Epoch 153/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406405.5000 - mae: 417.0287 - val_loss: 378284.7500 - val_mae: 423.0126\n",
      "Epoch 154/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406610.2500 - mae: 417.1191 - val_loss: 374804.5938 - val_mae: 422.4028\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 37091292.0000 - mae: 5931.1587 - val_loss: 33968376.0000 - val_mae: 5673.6265\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 29057112.0000 - mae: 5192.4458 - val_loss: 23034622.0000 - val_mae: 4577.7007\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 17497236.0000 - mae: 3844.0183 - val_loss: 12237605.0000 - val_mae: 3110.1963\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 8690818.0000 - mae: 2426.7854 - val_loss: 5635618.0000 - val_mae: 1835.8616\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4094333.7500 - mae: 1404.0986 - val_loss: 2790309.2500 - val_mae: 1089.0059\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2362571.0000 - mae: 925.2222 - val_loss: 1855607.7500 - val_mae: 816.1456\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1753596.1250 - mae: 767.1962 - val_loss: 1493031.7500 - val_mae: 724.3000\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1476204.6250 - mae: 701.2603 - val_loss: 1302826.6250 - val_mae: 679.8494\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1309185.5000 - mae: 665.1242 - val_loss: 1175816.0000 - val_mae: 649.7947\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1185208.1250 - mae: 638.7022 - val_loss: 1073483.2500 - val_mae: 628.3599\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1078456.7500 - mae: 617.7920 - val_loss: 985744.8750 - val_mae: 610.4204\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 994009.1250 - mae: 600.8431 - val_loss: 917530.3125 - val_mae: 595.1733\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 926695.5625 - mae: 586.6418 - val_loss: 861246.8750 - val_mae: 581.6791\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 872441.2500 - mae: 574.0389 - val_loss: 816043.3125 - val_mae: 569.2680\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 828568.8125 - mae: 562.0225 - val_loss: 783232.5625 - val_mae: 561.5297\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 793562.1875 - mae: 552.6683 - val_loss: 756723.6875 - val_mae: 554.2640\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 765964.2500 - mae: 544.5558 - val_loss: 738515.6875 - val_mae: 546.2477\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 744266.0625 - mae: 536.8847 - val_loss: 723071.6250 - val_mae: 540.2405\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 726765.1250 - mae: 530.8753 - val_loss: 709608.5000 - val_mae: 535.8991\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 713041.1875 - mae: 525.3878 - val_loss: 703654.3125 - val_mae: 532.1445\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 702135.1875 - mae: 520.8489 - val_loss: 696926.9375 - val_mae: 527.6983\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 692657.1250 - mae: 516.8266 - val_loss: 689578.4375 - val_mae: 524.5593\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 684698.1250 - mae: 512.7818 - val_loss: 681324.8125 - val_mae: 523.5537\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 677559.7500 - mae: 509.8806 - val_loss: 680194.6250 - val_mae: 520.2633\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 671533.3125 - mae: 506.7628 - val_loss: 672895.5625 - val_mae: 516.6589\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 665613.9375 - mae: 504.0508 - val_loss: 666069.0000 - val_mae: 516.3196\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 660216.0625 - mae: 502.5802 - val_loss: 660489.2500 - val_mae: 511.4395\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 655733.6250 - mae: 499.7485 - val_loss: 660254.9375 - val_mae: 511.3575\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 651216.1250 - mae: 497.9455 - val_loss: 656340.9375 - val_mae: 509.9967\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 647129.1250 - mae: 496.1661 - val_loss: 648924.8750 - val_mae: 507.2978\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 642938.3125 - mae: 494.6593 - val_loss: 647060.8125 - val_mae: 505.7596\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 639141.8750 - mae: 493.3684 - val_loss: 648968.5625 - val_mae: 503.4439\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 636152.2500 - mae: 490.8104 - val_loss: 643433.5625 - val_mae: 502.2652\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 632450.8750 - mae: 489.1735 - val_loss: 637165.7500 - val_mae: 501.1060\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 629316.6250 - mae: 488.1632 - val_loss: 636143.1875 - val_mae: 499.4404\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 626011.8125 - mae: 486.4145 - val_loss: 633175.4375 - val_mae: 496.8405\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 623406.5000 - mae: 484.9242 - val_loss: 630562.8750 - val_mae: 496.9448\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 620673.8125 - mae: 483.3497 - val_loss: 624020.3750 - val_mae: 494.8439\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618102.8750 - mae: 482.8396 - val_loss: 623048.8750 - val_mae: 494.0240\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615423.2500 - mae: 481.3638 - val_loss: 621440.2500 - val_mae: 492.8891\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613421.5625 - mae: 480.4755 - val_loss: 617859.2500 - val_mae: 491.2739\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611410.3750 - mae: 478.8182 - val_loss: 614516.8750 - val_mae: 490.7838\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609410.4375 - mae: 478.1218 - val_loss: 614933.3125 - val_mae: 488.7829\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607288.3750 - mae: 476.9884 - val_loss: 612923.3125 - val_mae: 489.1075\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605472.0625 - mae: 475.8638 - val_loss: 609621.3125 - val_mae: 488.1325\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603943.6875 - mae: 475.2781 - val_loss: 609247.1875 - val_mae: 487.5355\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602085.5000 - mae: 474.5915 - val_loss: 610700.1250 - val_mae: 485.8152\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600640.6875 - mae: 473.1818 - val_loss: 607115.8750 - val_mae: 484.5836\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598996.5625 - mae: 471.9266 - val_loss: 604711.5000 - val_mae: 483.0962\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597834.0000 - mae: 471.3507 - val_loss: 604109.8125 - val_mae: 483.2434\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596346.3125 - mae: 470.9827 - val_loss: 603175.8125 - val_mae: 483.2616\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595057.0625 - mae: 470.2295 - val_loss: 600072.3125 - val_mae: 480.6082\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593872.2500 - mae: 469.3492 - val_loss: 599047.6875 - val_mae: 480.2369\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593043.3750 - mae: 468.8002 - val_loss: 595998.6875 - val_mae: 480.0716\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591611.5625 - mae: 468.1753 - val_loss: 594923.1250 - val_mae: 479.2925\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589325.0000 - mae: 467.3578 - val_loss: 590218.9375 - val_mae: 479.4012\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586910.0625 - mae: 466.9990 - val_loss: 590003.9375 - val_mae: 478.2859\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584742.2500 - mae: 465.7114 - val_loss: 585217.5000 - val_mae: 477.2679\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582558.6250 - mae: 465.6182 - val_loss: 584644.4375 - val_mae: 476.8459\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579873.5625 - mae: 464.8033 - val_loss: 580186.0625 - val_mae: 474.7178\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 577288.4375 - mae: 463.9518 - val_loss: 581145.4375 - val_mae: 475.2851\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574631.9375 - mae: 463.3105 - val_loss: 580611.1250 - val_mae: 475.0062\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572618.3125 - mae: 462.8496 - val_loss: 572772.1250 - val_mae: 473.3465\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570339.6875 - mae: 462.2917 - val_loss: 573725.1250 - val_mae: 474.8448\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568325.8750 - mae: 461.9507 - val_loss: 573814.1250 - val_mae: 474.3156\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566423.3125 - mae: 461.5480 - val_loss: 572405.1250 - val_mae: 473.3800\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564435.2500 - mae: 460.6367 - val_loss: 569813.3125 - val_mae: 472.7618\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562432.0625 - mae: 459.4999 - val_loss: 565827.2500 - val_mae: 472.2106\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561148.5625 - mae: 460.0400 - val_loss: 564505.6250 - val_mae: 470.8519\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558993.1250 - mae: 458.6885 - val_loss: 560747.3750 - val_mae: 469.6566\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557203.1250 - mae: 458.4449 - val_loss: 565451.9375 - val_mae: 470.2996\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555815.5000 - mae: 457.4516 - val_loss: 560807.1875 - val_mae: 470.7358\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554289.0625 - mae: 457.4240 - val_loss: 563057.9375 - val_mae: 470.8080\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553397.3125 - mae: 456.9020 - val_loss: 557306.8750 - val_mae: 468.8132\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552161.1250 - mae: 456.7510 - val_loss: 550271.8750 - val_mae: 466.7740\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550588.5625 - mae: 456.0987 - val_loss: 547065.3125 - val_mae: 465.9182\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549183.1250 - mae: 455.5204 - val_loss: 544294.5625 - val_mae: 465.5557\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548139.7500 - mae: 454.6956 - val_loss: 543251.8750 - val_mae: 466.1316\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546604.2500 - mae: 454.5828 - val_loss: 539773.7500 - val_mae: 464.6361\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545679.1875 - mae: 453.8753 - val_loss: 537679.5625 - val_mae: 464.1797\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544531.5000 - mae: 453.3440 - val_loss: 533481.7500 - val_mae: 465.0373\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543464.9375 - mae: 453.4625 - val_loss: 533468.6250 - val_mae: 464.0113\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542631.0000 - mae: 452.7286 - val_loss: 530493.5625 - val_mae: 463.9619\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541317.0000 - mae: 452.0414 - val_loss: 528532.2500 - val_mae: 463.7515\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540269.7500 - mae: 452.0196 - val_loss: 527162.9375 - val_mae: 463.1772\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539172.2500 - mae: 451.0820 - val_loss: 524795.4375 - val_mae: 462.5934\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538482.5625 - mae: 450.9676 - val_loss: 523470.5312 - val_mae: 461.3806\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537337.3125 - mae: 450.6294 - val_loss: 521931.1562 - val_mae: 460.5338\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536789.3750 - mae: 450.4672 - val_loss: 519967.8438 - val_mae: 459.9880\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536300.2500 - mae: 449.1345 - val_loss: 516105.0312 - val_mae: 459.6788\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535523.8125 - mae: 449.2737 - val_loss: 513788.5312 - val_mae: 458.5111\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534395.3750 - mae: 449.0476 - val_loss: 513367.8438 - val_mae: 458.4393\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533818.2500 - mae: 448.3972 - val_loss: 508940.5938 - val_mae: 457.8084\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531726.1250 - mae: 448.8150 - val_loss: 505461.1562 - val_mae: 457.6373\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524491.3125 - mae: 447.9903 - val_loss: 502067.4688 - val_mae: 456.6498\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 519102.7188 - mae: 447.5463 - val_loss: 499805.9688 - val_mae: 457.6237\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 514705.0625 - mae: 447.5291 - val_loss: 497295.1875 - val_mae: 457.4453\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 511731.5938 - mae: 446.9403 - val_loss: 494996.2188 - val_mae: 456.0964\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 508531.2188 - mae: 446.4654 - val_loss: 492629.3438 - val_mae: 456.2367\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 505666.7500 - mae: 446.4679 - val_loss: 492116.0000 - val_mae: 456.5498\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 502789.5000 - mae: 446.0017 - val_loss: 489843.0000 - val_mae: 454.6303\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 500432.9688 - mae: 445.7275 - val_loss: 487056.4062 - val_mae: 454.6572\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 498554.3125 - mae: 445.8094 - val_loss: 486670.6250 - val_mae: 454.5859\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 496219.5625 - mae: 445.6416 - val_loss: 489129.1250 - val_mae: 453.5757\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 494368.9375 - mae: 444.9328 - val_loss: 485635.5000 - val_mae: 454.2731\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 492350.3125 - mae: 444.7719 - val_loss: 485016.7188 - val_mae: 452.6059\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 490726.3750 - mae: 443.9716 - val_loss: 481442.0625 - val_mae: 453.8801\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 489423.7188 - mae: 444.0192 - val_loss: 479221.0938 - val_mae: 453.4685\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 487875.9375 - mae: 444.2369 - val_loss: 475685.9688 - val_mae: 451.6652\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 486602.7812 - mae: 443.6105 - val_loss: 474179.5000 - val_mae: 452.4223\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 485249.5625 - mae: 443.5309 - val_loss: 473049.0000 - val_mae: 452.1073\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 483622.6562 - mae: 443.1288 - val_loss: 473997.6875 - val_mae: 452.1129\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 482832.7500 - mae: 442.6739 - val_loss: 468709.0000 - val_mae: 451.7831\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 481435.0000 - mae: 442.6994 - val_loss: 469017.9375 - val_mae: 451.4195\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 480624.7188 - mae: 442.1291 - val_loss: 461922.4375 - val_mae: 451.6048\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 479692.0000 - mae: 442.6602 - val_loss: 460300.6875 - val_mae: 449.6104\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 478684.9062 - mae: 441.8321 - val_loss: 458864.6250 - val_mae: 450.6717\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 477324.2500 - mae: 441.9225 - val_loss: 462027.4062 - val_mae: 451.0616\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 476786.4688 - mae: 441.5495 - val_loss: 456512.5000 - val_mae: 449.2921\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 475891.5938 - mae: 441.1245 - val_loss: 455304.1875 - val_mae: 451.1843\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 474068.5000 - mae: 441.4883 - val_loss: 454190.8438 - val_mae: 449.9199\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 470264.7188 - mae: 440.6397 - val_loss: 452940.5625 - val_mae: 449.9095\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 467208.1875 - mae: 440.3218 - val_loss: 451604.9375 - val_mae: 449.8210\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 465162.0312 - mae: 439.5790 - val_loss: 451215.7188 - val_mae: 451.7947\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 463224.4688 - mae: 439.9602 - val_loss: 447204.8438 - val_mae: 448.9592\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 461275.3125 - mae: 439.7544 - val_loss: 444705.4688 - val_mae: 447.8229\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 459328.6562 - mae: 439.2055 - val_loss: 444985.8125 - val_mae: 448.0413\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 457450.6875 - mae: 439.0197 - val_loss: 445500.9062 - val_mae: 448.3224\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 456123.4062 - mae: 438.7290 - val_loss: 441740.4375 - val_mae: 447.7985\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 454271.4062 - mae: 438.2570 - val_loss: 439642.0938 - val_mae: 447.6857\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 453254.3125 - mae: 438.7263 - val_loss: 435647.9062 - val_mae: 445.8914\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 452020.7188 - mae: 438.0929 - val_loss: 436878.0625 - val_mae: 447.2431\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 450767.8125 - mae: 437.6220 - val_loss: 433728.6562 - val_mae: 447.4050\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 449828.9062 - mae: 438.2776 - val_loss: 434378.2500 - val_mae: 447.1188\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 448667.8125 - mae: 437.7721 - val_loss: 433959.1875 - val_mae: 445.7946\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 447710.6562 - mae: 437.4592 - val_loss: 430719.1875 - val_mae: 445.3260\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 446634.7188 - mae: 437.3997 - val_loss: 431843.8750 - val_mae: 447.2470\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 445827.4062 - mae: 437.2333 - val_loss: 430693.5938 - val_mae: 445.7070\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 445027.3750 - mae: 436.7546 - val_loss: 430485.3125 - val_mae: 445.5281\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 443745.1250 - mae: 436.1910 - val_loss: 427192.9375 - val_mae: 444.7529\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442746.6250 - mae: 436.8259 - val_loss: 429751.7188 - val_mae: 444.8010\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442003.0312 - mae: 435.8541 - val_loss: 429763.5000 - val_mae: 445.3299\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 441461.5625 - mae: 435.8538 - val_loss: 426324.3438 - val_mae: 444.6062\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 440814.5625 - mae: 435.7812 - val_loss: 427522.2812 - val_mae: 445.5341\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439870.6250 - mae: 435.9081 - val_loss: 433104.0000 - val_mae: 445.9363\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439362.4375 - mae: 434.7890 - val_loss: 430179.8125 - val_mae: 445.6614\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438796.5000 - mae: 434.8511 - val_loss: 429735.8125 - val_mae: 445.6262\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438508.0000 - mae: 434.7822 - val_loss: 428956.3438 - val_mae: 445.4500\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438307.6875 - mae: 435.0660 - val_loss: 428131.6875 - val_mae: 444.6742\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437753.3125 - mae: 434.5754 - val_loss: 429405.8438 - val_mae: 445.5761\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437427.6562 - mae: 434.7177 - val_loss: 430593.7188 - val_mae: 445.3098\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437327.2500 - mae: 434.6945 - val_loss: 430998.2812 - val_mae: 444.6800\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436786.1250 - mae: 434.2454 - val_loss: 429925.0312 - val_mae: 445.2137\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 36307112.0000 - mae: 5875.8154 - val_loss: 30892506.0000 - val_mae: 5446.9717\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 23257336.0000 - mae: 4673.6475 - val_loss: 16086410.0000 - val_mae: 3825.6707\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 11429698.0000 - mae: 3026.5144 - val_loss: 7947314.5000 - val_mae: 2340.4890\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 5939914.0000 - mae: 1860.1990 - val_loss: 4500886.0000 - val_mae: 1511.8495\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3548253.0000 - mae: 1290.2728 - val_loss: 2730328.5000 - val_mae: 1113.6309\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2235917.2500 - mae: 1001.9861 - val_loss: 1828071.0000 - val_mae: 909.7948\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1566335.5000 - mae: 853.3852 - val_loss: 1315441.8750 - val_mae: 798.4189\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1131285.3750 - mae: 759.5558 - val_loss: 954769.3750 - val_mae: 711.8948\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 832451.6250 - mae: 674.9550 - val_loss: 739845.4375 - val_mae: 638.7971\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 671504.7500 - mae: 609.5250 - val_loss: 628958.1875 - val_mae: 587.7272\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584673.8750 - mae: 565.8027 - val_loss: 566281.6250 - val_mae: 552.1153\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537013.0625 - mae: 539.6854 - val_loss: 532917.3125 - val_mae: 533.3499\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 507933.8438 - mae: 523.8525 - val_loss: 509755.7812 - val_mae: 520.5766\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 486789.7812 - mae: 513.4033 - val_loss: 488779.2500 - val_mae: 509.0647\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 469627.6250 - mae: 504.5435 - val_loss: 476397.3438 - val_mae: 503.1429\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 455205.1875 - mae: 496.2100 - val_loss: 465603.5312 - val_mae: 497.6364\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 443927.7188 - mae: 490.8658 - val_loss: 459721.2812 - val_mae: 490.7016\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 433953.2500 - mae: 484.3925 - val_loss: 449782.6875 - val_mae: 485.1374\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426514.4688 - mae: 480.1323 - val_loss: 446757.8438 - val_mae: 482.1750\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421031.2188 - mae: 476.4583 - val_loss: 439915.1250 - val_mae: 478.4979\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416553.1562 - mae: 474.1194 - val_loss: 436561.1875 - val_mae: 475.6773\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412234.3750 - mae: 471.5716 - val_loss: 432615.1250 - val_mae: 473.8555\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408256.4688 - mae: 468.2623 - val_loss: 428827.9375 - val_mae: 473.3231\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405276.4375 - mae: 466.6757 - val_loss: 430495.2188 - val_mae: 471.9267\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402679.6250 - mae: 464.6450 - val_loss: 421832.7188 - val_mae: 468.4550\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400054.1250 - mae: 463.0257 - val_loss: 421768.2812 - val_mae: 467.8642\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397731.5000 - mae: 461.4865 - val_loss: 418345.6875 - val_mae: 466.8520\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395232.7812 - mae: 459.8085 - val_loss: 416564.6250 - val_mae: 464.7218\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394029.3438 - mae: 458.7230 - val_loss: 420007.6875 - val_mae: 465.4655\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391840.7500 - mae: 457.4868 - val_loss: 415607.6250 - val_mae: 464.4675\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390043.5938 - mae: 456.2887 - val_loss: 413898.7188 - val_mae: 462.1628\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388044.3125 - mae: 455.0064 - val_loss: 415558.5938 - val_mae: 463.0061\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386478.8125 - mae: 453.6412 - val_loss: 409778.0938 - val_mae: 461.2187\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 384583.6562 - mae: 452.8394 - val_loss: 412978.7812 - val_mae: 462.4387\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 383523.1562 - mae: 452.3799 - val_loss: 407511.7188 - val_mae: 459.4859\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 381822.9375 - mae: 451.3826 - val_loss: 409006.7812 - val_mae: 459.1101\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 380602.4375 - mae: 450.2340 - val_loss: 405632.5000 - val_mae: 458.2426\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 379378.1875 - mae: 449.7660 - val_loss: 408276.1875 - val_mae: 458.5687\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 378395.8125 - mae: 449.1930 - val_loss: 406552.1250 - val_mae: 458.4991\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377330.4375 - mae: 448.6913 - val_loss: 401406.6562 - val_mae: 457.0701\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 375889.1562 - mae: 447.9199 - val_loss: 405186.8438 - val_mae: 455.8427\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 375125.9375 - mae: 446.8696 - val_loss: 402353.9375 - val_mae: 456.2211\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373995.7812 - mae: 446.8265 - val_loss: 399011.0625 - val_mae: 454.9908\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373003.5625 - mae: 446.1000 - val_loss: 399799.1562 - val_mae: 454.3195\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 372114.6250 - mae: 445.6879 - val_loss: 402948.4688 - val_mae: 454.4526\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371008.5312 - mae: 444.8276 - val_loss: 395822.0312 - val_mae: 453.3459\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370478.4688 - mae: 444.6287 - val_loss: 397315.6250 - val_mae: 453.9770\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369480.3125 - mae: 444.2499 - val_loss: 396248.2188 - val_mae: 454.6340\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368647.9688 - mae: 443.9205 - val_loss: 396595.0938 - val_mae: 452.1240\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367780.3750 - mae: 442.9245 - val_loss: 394312.6250 - val_mae: 452.5436\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366588.9375 - mae: 442.5130 - val_loss: 396570.3750 - val_mae: 452.1191\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366122.9688 - mae: 442.2450 - val_loss: 401388.8750 - val_mae: 453.6434\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365371.6562 - mae: 441.7649 - val_loss: 392638.1875 - val_mae: 450.8885\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364850.4688 - mae: 441.7194 - val_loss: 393250.0312 - val_mae: 451.9326\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363498.5625 - mae: 441.1635 - val_loss: 395100.7188 - val_mae: 451.4622\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363289.4375 - mae: 440.7718 - val_loss: 392538.0000 - val_mae: 450.6853\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361677.1250 - mae: 439.8910 - val_loss: 388191.9688 - val_mae: 450.6472\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361097.7188 - mae: 439.7388 - val_loss: 389680.1875 - val_mae: 448.9561\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360279.3125 - mae: 439.0794 - val_loss: 388232.5938 - val_mae: 451.6465\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359436.2812 - mae: 438.9099 - val_loss: 388025.3438 - val_mae: 448.9875\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358738.9375 - mae: 438.9849 - val_loss: 389861.3125 - val_mae: 449.7342\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357826.6875 - mae: 437.7048 - val_loss: 386984.5625 - val_mae: 449.4154\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356982.6250 - mae: 437.9951 - val_loss: 390366.0938 - val_mae: 449.9215\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356590.0000 - mae: 437.4450 - val_loss: 388729.0625 - val_mae: 448.8931\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356260.7188 - mae: 437.0637 - val_loss: 384605.5938 - val_mae: 446.7679\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354477.5000 - mae: 436.5280 - val_loss: 388388.6250 - val_mae: 449.3195\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354409.2500 - mae: 436.8177 - val_loss: 387905.9688 - val_mae: 449.1085\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353640.5312 - mae: 436.0125 - val_loss: 387608.0625 - val_mae: 447.8981\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353597.9375 - mae: 435.6827 - val_loss: 385451.9062 - val_mae: 446.6465\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352617.9688 - mae: 435.5044 - val_loss: 384757.7500 - val_mae: 445.7285\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351831.5000 - mae: 434.7590 - val_loss: 383421.7500 - val_mae: 446.2039\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351365.6875 - mae: 434.7622 - val_loss: 382570.5312 - val_mae: 446.3117\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350719.7812 - mae: 434.6447 - val_loss: 384528.2500 - val_mae: 446.0282\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349807.9688 - mae: 434.0089 - val_loss: 380792.8438 - val_mae: 444.0333\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349627.3750 - mae: 433.6850 - val_loss: 380141.3125 - val_mae: 446.0331\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348918.2188 - mae: 433.5612 - val_loss: 382717.8438 - val_mae: 445.5328\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348408.5000 - mae: 433.0952 - val_loss: 379664.4688 - val_mae: 442.9749\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347827.8750 - mae: 433.1922 - val_loss: 382521.4688 - val_mae: 443.1415\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346937.4062 - mae: 432.4258 - val_loss: 380483.6875 - val_mae: 442.7962\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346548.5625 - mae: 432.2576 - val_loss: 381312.3750 - val_mae: 442.6945\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346014.0938 - mae: 431.3697 - val_loss: 376254.6562 - val_mae: 441.4131\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345742.6562 - mae: 431.2549 - val_loss: 376746.1562 - val_mae: 443.4435\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345067.8750 - mae: 430.7713 - val_loss: 374400.6562 - val_mae: 440.5308\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344375.7812 - mae: 430.7180 - val_loss: 380554.3125 - val_mae: 443.1947\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344105.5938 - mae: 430.5002 - val_loss: 381314.1562 - val_mae: 441.6106\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343417.0938 - mae: 429.7647 - val_loss: 378069.5000 - val_mae: 439.7126\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342817.4062 - mae: 429.3858 - val_loss: 377021.6875 - val_mae: 440.8538\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342488.5625 - mae: 428.7108 - val_loss: 375438.2500 - val_mae: 438.2820\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341447.5000 - mae: 427.8448 - val_loss: 372782.6562 - val_mae: 439.3792\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341066.1562 - mae: 428.0398 - val_loss: 375128.1562 - val_mae: 440.3691\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340173.9688 - mae: 427.2335 - val_loss: 376657.5312 - val_mae: 438.4269\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339105.1562 - mae: 426.6497 - val_loss: 372782.6250 - val_mae: 436.4025\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339930.7188 - mae: 426.6626 - val_loss: 376776.2812 - val_mae: 436.4091\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339035.5625 - mae: 425.9127 - val_loss: 372023.1875 - val_mae: 435.1183\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338393.3750 - mae: 425.5429 - val_loss: 370811.0625 - val_mae: 435.5381\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338205.5625 - mae: 425.7318 - val_loss: 371284.7812 - val_mae: 434.3600\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337805.1562 - mae: 424.9338 - val_loss: 373093.6875 - val_mae: 435.3780\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337121.0938 - mae: 424.5128 - val_loss: 373932.9062 - val_mae: 435.7059\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336916.4375 - mae: 424.4897 - val_loss: 372651.1875 - val_mae: 434.2261\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336818.4375 - mae: 424.3032 - val_loss: 375383.5000 - val_mae: 435.2537\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336397.5938 - mae: 424.2549 - val_loss: 373260.6250 - val_mae: 434.4965\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336897.5938 - mae: 423.7791 - val_loss: 372698.4062 - val_mae: 433.0916\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336044.5938 - mae: 423.2276 - val_loss: 372264.0000 - val_mae: 434.2115\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335392.6250 - mae: 423.1327 - val_loss: 369744.5312 - val_mae: 434.8690\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335590.0938 - mae: 423.2089 - val_loss: 366826.1250 - val_mae: 432.7314\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335336.5000 - mae: 423.4513 - val_loss: 369514.6562 - val_mae: 434.0450\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334941.8750 - mae: 423.0028 - val_loss: 373444.8438 - val_mae: 432.7302\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334730.0000 - mae: 422.4955 - val_loss: 373632.3125 - val_mae: 433.9840\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334739.1875 - mae: 422.4954 - val_loss: 369237.4062 - val_mae: 432.5803\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334471.0938 - mae: 422.1416 - val_loss: 371037.9062 - val_mae: 433.6534\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334299.8438 - mae: 422.4170 - val_loss: 367736.8750 - val_mae: 431.4448\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333944.0312 - mae: 422.1859 - val_loss: 370786.5312 - val_mae: 431.8972\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334073.0000 - mae: 421.7085 - val_loss: 366793.6250 - val_mae: 430.6119\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333883.6562 - mae: 421.7951 - val_loss: 365643.6562 - val_mae: 431.0806\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333982.4375 - mae: 421.9281 - val_loss: 368276.1875 - val_mae: 431.8308\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333059.5625 - mae: 421.1300 - val_loss: 367417.4062 - val_mae: 431.4579\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333384.4062 - mae: 422.0867 - val_loss: 368115.1562 - val_mae: 431.8274\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333091.4375 - mae: 421.4271 - val_loss: 366524.4062 - val_mae: 430.8390\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333494.2188 - mae: 421.7548 - val_loss: 365768.2500 - val_mae: 430.6061\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333083.3125 - mae: 421.2429 - val_loss: 367146.4688 - val_mae: 431.5028\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333043.4062 - mae: 421.0124 - val_loss: 367909.7500 - val_mae: 431.9756\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332826.6562 - mae: 421.0902 - val_loss: 368008.2812 - val_mae: 430.4153\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332772.5938 - mae: 421.3938 - val_loss: 367387.3750 - val_mae: 430.2454\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332661.3438 - mae: 420.7835 - val_loss: 362716.4688 - val_mae: 430.2952\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332722.0625 - mae: 420.8658 - val_loss: 363484.8438 - val_mae: 429.4557\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332166.1875 - mae: 421.0593 - val_loss: 367188.0000 - val_mae: 431.7224\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332417.2812 - mae: 420.4300 - val_loss: 364861.4688 - val_mae: 430.5908\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332135.5625 - mae: 420.7679 - val_loss: 366185.2188 - val_mae: 429.7204\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331924.5938 - mae: 420.6944 - val_loss: 367165.8438 - val_mae: 429.6170\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331862.0938 - mae: 420.2048 - val_loss: 364132.0000 - val_mae: 429.1165\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331925.6875 - mae: 420.2775 - val_loss: 364067.2188 - val_mae: 429.0331\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332108.2812 - mae: 420.5450 - val_loss: 364450.6250 - val_mae: 428.8173\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331685.3125 - mae: 419.9608 - val_loss: 361225.5312 - val_mae: 428.2252\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331755.5000 - mae: 420.1275 - val_loss: 367215.7188 - val_mae: 430.7129\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331470.1875 - mae: 419.7913 - val_loss: 361294.5312 - val_mae: 429.1727\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331618.2188 - mae: 420.4396 - val_loss: 366124.6250 - val_mae: 430.1546\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331221.2500 - mae: 419.7729 - val_loss: 363903.9062 - val_mae: 429.2655\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331422.2500 - mae: 419.6600 - val_loss: 361320.7812 - val_mae: 427.6542\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331414.2188 - mae: 420.0438 - val_loss: 366373.5312 - val_mae: 429.7171\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330768.5000 - mae: 419.9238 - val_loss: 366455.6875 - val_mae: 429.4580\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331014.7188 - mae: 419.6240 - val_loss: 364679.1562 - val_mae: 428.6288\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330897.5312 - mae: 419.5040 - val_loss: 362759.4688 - val_mae: 428.2387\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330469.2812 - mae: 419.4553 - val_loss: 361897.7188 - val_mae: 428.0783\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330919.4062 - mae: 419.9301 - val_loss: 363491.0312 - val_mae: 428.8554\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330900.5938 - mae: 419.5375 - val_loss: 364290.2188 - val_mae: 428.8995\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331125.2812 - mae: 419.6182 - val_loss: 363116.9375 - val_mae: 428.6152\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330600.1562 - mae: 419.3518 - val_loss: 363048.2812 - val_mae: 427.7919\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330661.1250 - mae: 419.4686 - val_loss: 365415.2500 - val_mae: 428.1552\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38186720.0000 - mae: 6023.1245 - val_loss: 37112668.0000 - val_mae: 5944.2920\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 35267920.0000 - mae: 5791.9370 - val_loss: 32677062.0000 - val_mae: 5584.8320\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 29712678.0000 - mae: 5320.6191 - val_loss: 26354350.0000 - val_mae: 5017.5254\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 23010120.0000 - mae: 4672.7285 - val_loss: 19627992.0000 - val_mae: 4308.2427\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 16531524.0000 - mae: 3918.2896 - val_loss: 13680499.0000 - val_mae: 3533.7361\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 11181338.0000 - mae: 3137.9978 - val_loss: 9060364.0000 - val_mae: 2770.6997\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 7246477.0000 - mae: 2412.9521 - val_loss: 5816140.0000 - val_mae: 2110.6306\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4578155.5000 - mae: 1823.5825 - val_loss: 3690152.0000 - val_mae: 1610.2939\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2889255.0000 - mae: 1394.0342 - val_loss: 2384527.2500 - val_mae: 1252.5797\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1894729.3750 - mae: 1091.0476 - val_loss: 1643153.6250 - val_mae: 1005.7426\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1363980.1250 - mae: 894.0997 - val_loss: 1262678.8750 - val_mae: 857.6343\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1098336.6250 - mae: 785.2512 - val_loss: 1068488.2500 - val_mae: 775.7616\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 961792.0000 - mae: 727.6841 - val_loss: 960855.4375 - val_mae: 730.1628\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 881527.0625 - mae: 694.6398 - val_loss: 890211.6875 - val_mae: 700.5333\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 824806.6875 - mae: 669.9056 - val_loss: 836710.8750 - val_mae: 678.0465\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 779068.1875 - mae: 650.9937 - val_loss: 792512.0000 - val_mae: 659.3962\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 740665.3125 - mae: 634.3884 - val_loss: 753875.5000 - val_mae: 642.3480\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 707501.1250 - mae: 619.2055 - val_loss: 720168.9375 - val_mae: 627.3067\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 678207.1250 - mae: 606.3962 - val_loss: 690936.7500 - val_mae: 613.5845\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 652092.3125 - mae: 593.7808 - val_loss: 664630.8125 - val_mae: 600.6705\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 629645.3750 - mae: 582.9103 - val_loss: 642686.1875 - val_mae: 589.2529\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610088.7500 - mae: 572.6948 - val_loss: 623894.0625 - val_mae: 579.6468\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592977.4375 - mae: 564.8985 - val_loss: 607577.1250 - val_mae: 569.9150\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578484.7500 - mae: 556.5361 - val_loss: 592902.9375 - val_mae: 562.4190\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 565632.8125 - mae: 550.6064 - val_loss: 581141.1250 - val_mae: 555.7325\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553846.0625 - mae: 543.9832 - val_loss: 570403.6250 - val_mae: 550.8765\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543228.5000 - mae: 539.2346 - val_loss: 559708.2500 - val_mae: 544.6728\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534299.5000 - mae: 534.2442 - val_loss: 552325.5000 - val_mae: 540.5999\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 525779.9375 - mae: 530.6656 - val_loss: 545551.6875 - val_mae: 536.8058\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 518695.2188 - mae: 526.3630 - val_loss: 537223.3125 - val_mae: 533.1611\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 511941.7188 - mae: 523.6070 - val_loss: 531224.3125 - val_mae: 529.3707\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 506334.8125 - mae: 520.2556 - val_loss: 526638.7500 - val_mae: 526.5009\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 500326.4375 - mae: 517.0620 - val_loss: 520056.5938 - val_mae: 524.6909\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 495233.0000 - mae: 514.8302 - val_loss: 515631.5000 - val_mae: 522.8474\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 490101.4062 - mae: 513.0024 - val_loss: 512343.1562 - val_mae: 519.9634\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 485298.4062 - mae: 510.2533 - val_loss: 508411.5000 - val_mae: 516.8135\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 481018.3438 - mae: 507.4983 - val_loss: 502956.5312 - val_mae: 514.4636\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 476401.7812 - mae: 505.1344 - val_loss: 499932.2188 - val_mae: 513.3798\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 471840.0938 - mae: 503.3276 - val_loss: 495529.1562 - val_mae: 510.9897\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 467264.0000 - mae: 500.9838 - val_loss: 490971.5312 - val_mae: 507.8481\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 463093.5312 - mae: 498.5996 - val_loss: 484722.7812 - val_mae: 505.9181\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 458721.3750 - mae: 496.7558 - val_loss: 483354.4375 - val_mae: 504.2276\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 454209.9375 - mae: 494.0703 - val_loss: 479993.7188 - val_mae: 504.9534\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 450763.5312 - mae: 492.8779 - val_loss: 475336.3438 - val_mae: 500.9814\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 446537.5938 - mae: 490.3523 - val_loss: 473071.1250 - val_mae: 498.7162\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 443069.0625 - mae: 488.5594 - val_loss: 468445.3438 - val_mae: 497.0351\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439595.0312 - mae: 486.8674 - val_loss: 465408.5938 - val_mae: 494.9128\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436385.2188 - mae: 484.4267 - val_loss: 462328.6875 - val_mae: 494.0039\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 433420.0938 - mae: 483.2762 - val_loss: 459122.6875 - val_mae: 492.2280\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430815.0312 - mae: 481.3132 - val_loss: 457682.6875 - val_mae: 490.8672\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427859.6562 - mae: 480.0987 - val_loss: 456276.0312 - val_mae: 488.5886\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425572.6875 - mae: 477.9655 - val_loss: 451598.0000 - val_mae: 487.5438\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422972.5000 - mae: 477.0759 - val_loss: 450095.4375 - val_mae: 486.5466\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420672.5312 - mae: 475.8838 - val_loss: 448414.1562 - val_mae: 484.5834\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418426.7500 - mae: 474.0891 - val_loss: 445601.7500 - val_mae: 482.6360\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416341.1562 - mae: 472.6747 - val_loss: 443594.6250 - val_mae: 482.8310\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414525.6250 - mae: 471.7509 - val_loss: 442196.1562 - val_mae: 481.3705\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413040.6875 - mae: 470.7312 - val_loss: 440475.8438 - val_mae: 481.0909\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411157.9375 - mae: 469.5009 - val_loss: 440253.0000 - val_mae: 479.1389\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409809.9688 - mae: 468.7077 - val_loss: 438483.1562 - val_mae: 478.7060\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408572.1562 - mae: 467.5469 - val_loss: 436702.6562 - val_mae: 478.4371\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407159.2500 - mae: 467.2012 - val_loss: 435527.4062 - val_mae: 477.7562\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405913.1250 - mae: 465.4683 - val_loss: 434158.0000 - val_mae: 477.5533\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404607.9688 - mae: 465.6702 - val_loss: 433614.1250 - val_mae: 478.0455\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403702.1562 - mae: 464.6125 - val_loss: 432007.5625 - val_mae: 476.0962\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402847.5625 - mae: 464.3398 - val_loss: 431766.4688 - val_mae: 475.6631\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401784.4688 - mae: 464.0928 - val_loss: 430065.0938 - val_mae: 475.8961\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401081.7812 - mae: 463.5848 - val_loss: 430228.4688 - val_mae: 474.8236\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400260.5625 - mae: 462.4298 - val_loss: 428475.6250 - val_mae: 473.8554\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399392.5938 - mae: 462.7091 - val_loss: 428754.6875 - val_mae: 472.5758\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398334.2812 - mae: 461.6673 - val_loss: 427900.4688 - val_mae: 472.1503\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397885.8438 - mae: 461.2822 - val_loss: 426984.1562 - val_mae: 472.8646\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396847.9688 - mae: 460.9194 - val_loss: 426390.4375 - val_mae: 471.4998\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396188.2812 - mae: 460.7575 - val_loss: 425048.2812 - val_mae: 470.4046\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395402.2812 - mae: 460.1369 - val_loss: 424564.7812 - val_mae: 471.0985\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394517.6562 - mae: 459.1913 - val_loss: 422767.7500 - val_mae: 471.0840\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394073.2500 - mae: 459.7827 - val_loss: 422484.5938 - val_mae: 469.0042\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393091.9688 - mae: 458.4049 - val_loss: 421529.6250 - val_mae: 469.3921\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 392559.5625 - mae: 458.6438 - val_loss: 422886.7500 - val_mae: 469.2114\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391705.5938 - mae: 457.6958 - val_loss: 421484.3750 - val_mae: 468.8642\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391161.2188 - mae: 457.4466 - val_loss: 419736.1250 - val_mae: 468.0332\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390574.0625 - mae: 457.1248 - val_loss: 419925.3750 - val_mae: 468.2788\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389636.1250 - mae: 456.6929 - val_loss: 420260.3125 - val_mae: 468.7286\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389323.3438 - mae: 456.4846 - val_loss: 418639.3125 - val_mae: 467.4750\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388314.8125 - mae: 455.5833 - val_loss: 418182.1562 - val_mae: 467.4160\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387763.6875 - mae: 455.2805 - val_loss: 417764.5938 - val_mae: 466.5453\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387288.8750 - mae: 455.4318 - val_loss: 417342.9375 - val_mae: 466.1076\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386736.5312 - mae: 454.5032 - val_loss: 416683.5312 - val_mae: 466.2274\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386290.8438 - mae: 454.5227 - val_loss: 416460.6562 - val_mae: 466.9802\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385507.4062 - mae: 454.4660 - val_loss: 416744.9375 - val_mae: 465.1531\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384693.6875 - mae: 453.7570 - val_loss: 416557.0312 - val_mae: 464.6622\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384299.0000 - mae: 452.8356 - val_loss: 415079.2812 - val_mae: 466.2299\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383539.9375 - mae: 453.2586 - val_loss: 414847.2500 - val_mae: 465.6017\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383287.3750 - mae: 452.8911 - val_loss: 414738.9375 - val_mae: 464.0977\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382642.8750 - mae: 452.6942 - val_loss: 413847.4062 - val_mae: 463.4330\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382302.7500 - mae: 452.2384 - val_loss: 414949.1875 - val_mae: 464.3950\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381496.6875 - mae: 451.5641 - val_loss: 413142.1250 - val_mae: 463.1790\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381199.5625 - mae: 451.3926 - val_loss: 411698.3750 - val_mae: 462.8868\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380356.0312 - mae: 450.9956 - val_loss: 412225.9688 - val_mae: 463.6031\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379986.5625 - mae: 451.2477 - val_loss: 412069.4688 - val_mae: 462.1443\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379381.9062 - mae: 450.3315 - val_loss: 410015.2812 - val_mae: 462.6469\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378922.4062 - mae: 450.2070 - val_loss: 410075.0938 - val_mae: 463.0408\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378146.0938 - mae: 449.9855 - val_loss: 410725.2188 - val_mae: 461.9638\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377747.3438 - mae: 449.9185 - val_loss: 409518.5625 - val_mae: 460.9496\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377007.5312 - mae: 448.9588 - val_loss: 408554.5000 - val_mae: 462.4803\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376660.5312 - mae: 448.9202 - val_loss: 408329.5625 - val_mae: 461.8517\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375761.8750 - mae: 449.0128 - val_loss: 407913.7188 - val_mae: 460.0227\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375245.8750 - mae: 448.4855 - val_loss: 409213.1250 - val_mae: 459.5382\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374627.9688 - mae: 447.7004 - val_loss: 406958.2500 - val_mae: 460.3526\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374123.7188 - mae: 447.7788 - val_loss: 406350.1250 - val_mae: 460.7084\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373700.0625 - mae: 447.5283 - val_loss: 405772.0625 - val_mae: 460.2762\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373156.3125 - mae: 447.4213 - val_loss: 406114.5625 - val_mae: 460.3662\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372871.4688 - mae: 446.9575 - val_loss: 405810.5625 - val_mae: 459.8519\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371942.6250 - mae: 446.3810 - val_loss: 405210.6250 - val_mae: 460.1019\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371757.3438 - mae: 446.7372 - val_loss: 404929.5000 - val_mae: 458.2549\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371388.0938 - mae: 446.3723 - val_loss: 405168.2500 - val_mae: 458.3022\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371066.0312 - mae: 445.6873 - val_loss: 404981.7188 - val_mae: 459.8684\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370367.8438 - mae: 445.9780 - val_loss: 403437.2812 - val_mae: 457.6987\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369919.2812 - mae: 445.1573 - val_loss: 403868.5312 - val_mae: 458.8003\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369276.9062 - mae: 444.6309 - val_loss: 403435.1875 - val_mae: 460.6706\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369130.7500 - mae: 445.3503 - val_loss: 403401.6250 - val_mae: 458.2338\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368930.0625 - mae: 444.5916 - val_loss: 401283.6250 - val_mae: 456.7624\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368297.7500 - mae: 444.3490 - val_loss: 402366.8750 - val_mae: 456.4136\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368167.4375 - mae: 443.9786 - val_loss: 402446.5625 - val_mae: 456.1217\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367696.5312 - mae: 443.3203 - val_loss: 401906.3438 - val_mae: 458.1067\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367131.5312 - mae: 443.7134 - val_loss: 401204.1562 - val_mae: 456.6104\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366951.9375 - mae: 442.9383 - val_loss: 401253.2812 - val_mae: 456.5629\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366599.9375 - mae: 442.4712 - val_loss: 400491.7812 - val_mae: 456.8788\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365992.7812 - mae: 442.3821 - val_loss: 399427.6562 - val_mae: 457.4253\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365795.7812 - mae: 442.7811 - val_loss: 399562.0312 - val_mae: 455.9276\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365225.2812 - mae: 442.1199 - val_loss: 398738.5625 - val_mae: 455.2013\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364540.4062 - mae: 441.3844 - val_loss: 397691.3438 - val_mae: 455.4466\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364010.6875 - mae: 441.0970 - val_loss: 396487.3125 - val_mae: 453.1241\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363333.6250 - mae: 440.4968 - val_loss: 395303.9062 - val_mae: 454.0645\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362785.8125 - mae: 440.3314 - val_loss: 395845.2500 - val_mae: 451.9287\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362279.3750 - mae: 439.4105 - val_loss: 394535.1875 - val_mae: 451.7721\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361652.6875 - mae: 439.2614 - val_loss: 394929.9688 - val_mae: 451.2068\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361146.6562 - mae: 439.0165 - val_loss: 395840.1250 - val_mae: 450.7977\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360681.8125 - mae: 438.5486 - val_loss: 393983.7500 - val_mae: 451.4391\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360197.0000 - mae: 437.8426 - val_loss: 392612.8750 - val_mae: 450.9821\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359595.5312 - mae: 438.0399 - val_loss: 391988.5625 - val_mae: 449.6233\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359250.0625 - mae: 437.6866 - val_loss: 392183.2500 - val_mae: 450.2157\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358788.6562 - mae: 436.6976 - val_loss: 392222.4375 - val_mae: 451.4225\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358715.3438 - mae: 437.2101 - val_loss: 393005.1562 - val_mae: 451.2370\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358503.4062 - mae: 436.9400 - val_loss: 390795.9688 - val_mae: 449.9234\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357969.2188 - mae: 436.2220 - val_loss: 389741.7188 - val_mae: 449.2711\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357624.5938 - mae: 436.1635 - val_loss: 390543.9375 - val_mae: 448.5904\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357086.0625 - mae: 435.8119 - val_loss: 389177.6250 - val_mae: 448.5221\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356886.7188 - mae: 435.8079 - val_loss: 388250.5000 - val_mae: 448.5728\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356561.1250 - mae: 435.4351 - val_loss: 388641.9375 - val_mae: 448.5616\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356161.4375 - mae: 435.1339 - val_loss: 388804.5312 - val_mae: 447.8232\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355693.0625 - mae: 434.9383 - val_loss: 388958.5000 - val_mae: 447.3528\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355563.0312 - mae: 434.4422 - val_loss: 387786.6875 - val_mae: 446.2944\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354828.9688 - mae: 433.9294 - val_loss: 386891.4688 - val_mae: 446.1945\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354348.1250 - mae: 433.8134 - val_loss: 386816.9062 - val_mae: 445.7308\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354203.1562 - mae: 433.6558 - val_loss: 386577.7188 - val_mae: 446.4699\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353741.8125 - mae: 433.6734 - val_loss: 386775.1250 - val_mae: 445.9688\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353487.5625 - mae: 432.8366 - val_loss: 386148.6875 - val_mae: 445.9025\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352978.2812 - mae: 432.7020 - val_loss: 385170.7500 - val_mae: 444.6167\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352506.5000 - mae: 432.4760 - val_loss: 385034.9062 - val_mae: 444.3745\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352275.0625 - mae: 431.9782 - val_loss: 384693.4375 - val_mae: 445.2230\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352060.2188 - mae: 431.9969 - val_loss: 383560.7188 - val_mae: 444.5537\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351451.9375 - mae: 431.8121 - val_loss: 383915.4375 - val_mae: 444.0287\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351290.3750 - mae: 431.2739 - val_loss: 382753.4375 - val_mae: 444.3774\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351297.8125 - mae: 431.2990 - val_loss: 381498.5938 - val_mae: 443.1890\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350553.3125 - mae: 430.9859 - val_loss: 381802.2812 - val_mae: 442.8465\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350428.6562 - mae: 430.7369 - val_loss: 382388.7500 - val_mae: 443.3892\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350298.3750 - mae: 430.8021 - val_loss: 381089.9688 - val_mae: 441.7384\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349681.8125 - mae: 430.4024 - val_loss: 380944.0000 - val_mae: 442.7133\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349350.0938 - mae: 429.8423 - val_loss: 380347.4375 - val_mae: 442.7442\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348946.7812 - mae: 429.8027 - val_loss: 380626.3750 - val_mae: 442.3794\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348751.6562 - mae: 429.5469 - val_loss: 379388.5312 - val_mae: 441.4161\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348478.7812 - mae: 429.4134 - val_loss: 380477.9688 - val_mae: 442.1080\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348164.5625 - mae: 428.7024 - val_loss: 379481.0625 - val_mae: 442.1790\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347790.8438 - mae: 429.2535 - val_loss: 379563.5000 - val_mae: 440.6645\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347663.6562 - mae: 428.3510 - val_loss: 378113.4688 - val_mae: 440.9714\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347309.6562 - mae: 428.4123 - val_loss: 378354.3750 - val_mae: 440.7650\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346885.3438 - mae: 427.9627 - val_loss: 378370.0000 - val_mae: 439.2270\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346666.9062 - mae: 427.9521 - val_loss: 378068.7500 - val_mae: 440.0609\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346692.6875 - mae: 427.8603 - val_loss: 376896.6562 - val_mae: 440.3387\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346109.1875 - mae: 427.5912 - val_loss: 376201.3125 - val_mae: 439.4686\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345834.8125 - mae: 427.4155 - val_loss: 377781.0000 - val_mae: 438.4836\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345703.0000 - mae: 426.8011 - val_loss: 376328.7812 - val_mae: 439.7223\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345479.8125 - mae: 427.1077 - val_loss: 375481.8438 - val_mae: 438.6254\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345182.2500 - mae: 426.8122 - val_loss: 374870.0625 - val_mae: 438.3563\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344979.3438 - mae: 426.6447 - val_loss: 375411.6562 - val_mae: 438.2724\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344417.2188 - mae: 426.3781 - val_loss: 375648.4062 - val_mae: 438.5805\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344497.5625 - mae: 426.3688 - val_loss: 375061.6250 - val_mae: 437.8273\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344407.5938 - mae: 425.8068 - val_loss: 374424.2500 - val_mae: 438.3496\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343949.4062 - mae: 425.9367 - val_loss: 373860.2500 - val_mae: 438.2620\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343637.1250 - mae: 426.0709 - val_loss: 375004.6250 - val_mae: 437.5878\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343227.2500 - mae: 425.2850 - val_loss: 374452.7812 - val_mae: 437.7146\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343039.8125 - mae: 425.4518 - val_loss: 374793.0000 - val_mae: 437.8484\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342750.9375 - mae: 425.2599 - val_loss: 373287.7188 - val_mae: 436.5719\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342848.8125 - mae: 424.8785 - val_loss: 373119.1250 - val_mae: 436.6944\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342526.1562 - mae: 424.7614 - val_loss: 372809.6250 - val_mae: 437.3193\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342193.3750 - mae: 424.6907 - val_loss: 372698.4062 - val_mae: 435.7529\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341998.9062 - mae: 424.4814 - val_loss: 372182.7500 - val_mae: 435.8604\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341571.6562 - mae: 424.4032 - val_loss: 373489.2500 - val_mae: 436.4011\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340957.1250 - mae: 423.7737 - val_loss: 372236.7188 - val_mae: 435.4353\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340904.0625 - mae: 423.7114 - val_loss: 371764.9062 - val_mae: 435.2411\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340348.8750 - mae: 423.3771 - val_loss: 371211.1875 - val_mae: 434.6183\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340115.0000 - mae: 423.1548 - val_loss: 371053.9062 - val_mae: 435.0750\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339641.4062 - mae: 422.6671 - val_loss: 371495.6562 - val_mae: 436.1309\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339514.5312 - mae: 422.9514 - val_loss: 370877.2188 - val_mae: 434.6249\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339100.5625 - mae: 422.3073 - val_loss: 370587.1250 - val_mae: 435.0753\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338838.5625 - mae: 422.7822 - val_loss: 370172.5938 - val_mae: 433.3776\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338566.1250 - mae: 421.9253 - val_loss: 370435.6250 - val_mae: 433.0877\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338565.0938 - mae: 422.5449 - val_loss: 369638.7500 - val_mae: 431.9371\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338201.3750 - mae: 421.8282 - val_loss: 369999.5000 - val_mae: 432.6638\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337794.6562 - mae: 421.2903 - val_loss: 369713.9688 - val_mae: 434.7831\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338044.1875 - mae: 421.9423 - val_loss: 369039.1562 - val_mae: 433.3549\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337562.0938 - mae: 421.2584 - val_loss: 369197.8125 - val_mae: 433.0977\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337366.8750 - mae: 421.7909 - val_loss: 368639.6562 - val_mae: 432.3378\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337218.5625 - mae: 421.2205 - val_loss: 368427.6250 - val_mae: 432.5334\n",
      "Epoch 216/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336841.2500 - mae: 420.9341 - val_loss: 368299.9688 - val_mae: 432.2336\n",
      "Epoch 217/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336661.1875 - mae: 420.6293 - val_loss: 367710.8438 - val_mae: 433.3476\n",
      "Epoch 218/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336620.0000 - mae: 421.0779 - val_loss: 369091.8750 - val_mae: 434.2307\n",
      "Epoch 219/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336621.3125 - mae: 420.8846 - val_loss: 368147.5000 - val_mae: 433.2640\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38144836.0000 - mae: 6020.0898 - val_loss: 37071504.0000 - val_mae: 5941.2705\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 34486904.0000 - mae: 5728.4707 - val_loss: 30745286.0000 - val_mae: 5424.5938\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 26575380.0000 - mae: 5032.9053 - val_loss: 22105382.0000 - val_mae: 4596.0610\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 18096742.0000 - mae: 4119.0293 - val_loss: 14296550.0000 - val_mae: 3633.6514\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 11240212.0000 - mae: 3150.6072 - val_loss: 8595276.0000 - val_mae: 2700.9014\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6562899.0000 - mae: 2286.1677 - val_loss: 4959226.5000 - val_mae: 1939.6312\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3723339.0000 - mae: 1626.9257 - val_loss: 2873434.2500 - val_mae: 1403.7961\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2197558.5000 - mae: 1187.7052 - val_loss: 1824622.6250 - val_mae: 1065.3221\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1472214.8750 - mae: 933.7844 - val_loss: 1345781.0000 - val_mae: 888.7311\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1145989.1250 - mae: 812.4758 - val_loss: 1118142.8750 - val_mae: 802.5335\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 982916.8750 - mae: 753.0286 - val_loss: 989642.5625 - val_mae: 753.2961\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 882959.3750 - mae: 713.6169 - val_loss: 900066.0000 - val_mae: 717.0205\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 812741.3125 - mae: 683.3128 - val_loss: 836130.8750 - val_mae: 688.5162\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 760209.8750 - mae: 658.1820 - val_loss: 787321.0000 - val_mae: 665.0434\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 719078.9375 - mae: 637.4305 - val_loss: 747932.4375 - val_mae: 645.4926\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 686043.6250 - mae: 620.8821 - val_loss: 714627.8125 - val_mae: 628.3446\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 657974.7500 - mae: 607.0931 - val_loss: 687869.0000 - val_mae: 614.4147\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 633969.9375 - mae: 595.2827 - val_loss: 663817.4375 - val_mae: 601.6265\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612733.0625 - mae: 585.5350 - val_loss: 642095.2500 - val_mae: 590.4547\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593371.6250 - mae: 575.6717 - val_loss: 623799.8125 - val_mae: 580.8102\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 576112.6875 - mae: 567.3742 - val_loss: 608493.1875 - val_mae: 571.5927\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560601.3125 - mae: 559.4581 - val_loss: 592821.8125 - val_mae: 562.6429\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546469.5000 - mae: 551.1572 - val_loss: 580244.3750 - val_mae: 556.1252\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533444.6250 - mae: 544.4510 - val_loss: 569205.4375 - val_mae: 550.0269\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 522672.8125 - mae: 538.7369 - val_loss: 558990.6875 - val_mae: 543.5407\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 512554.7812 - mae: 532.8304 - val_loss: 548821.8125 - val_mae: 537.4894\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 502904.3750 - mae: 527.1254 - val_loss: 540457.6250 - val_mae: 532.9205\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 494830.9375 - mae: 522.4434 - val_loss: 532597.2500 - val_mae: 528.9266\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 487373.5938 - mae: 518.2476 - val_loss: 525724.8125 - val_mae: 524.6266\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 480285.6875 - mae: 513.4507 - val_loss: 519856.3438 - val_mae: 521.6522\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 474179.1250 - mae: 510.2819 - val_loss: 516662.8125 - val_mae: 518.5577\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 468872.0000 - mae: 506.3773 - val_loss: 511909.3125 - val_mae: 515.7327\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 464368.6875 - mae: 503.9104 - val_loss: 508084.7812 - val_mae: 512.6739\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 460028.4688 - mae: 501.2964 - val_loss: 503545.4688 - val_mae: 510.5157\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 455670.2812 - mae: 498.1873 - val_loss: 499886.1562 - val_mae: 508.7877\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452111.5312 - mae: 495.9923 - val_loss: 497504.8750 - val_mae: 507.4549\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 448120.9062 - mae: 494.1877 - val_loss: 493536.3438 - val_mae: 503.8079\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 445242.1875 - mae: 491.5170 - val_loss: 490219.4062 - val_mae: 503.2442\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 442536.5000 - mae: 490.5334 - val_loss: 488735.2812 - val_mae: 500.8289\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439273.3125 - mae: 488.1209 - val_loss: 487521.3125 - val_mae: 499.4067\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436894.7500 - mae: 486.9064 - val_loss: 485740.0000 - val_mae: 498.4909\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 434210.4375 - mae: 484.2860 - val_loss: 480623.6875 - val_mae: 498.4803\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431834.5000 - mae: 484.2928 - val_loss: 480060.0000 - val_mae: 496.0305\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430200.7500 - mae: 482.4103 - val_loss: 477380.4062 - val_mae: 494.5528\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427944.9688 - mae: 480.5863 - val_loss: 475297.6250 - val_mae: 494.7286\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426465.4062 - mae: 480.0294 - val_loss: 474053.7500 - val_mae: 493.2964\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424463.5938 - mae: 478.6405 - val_loss: 468879.5625 - val_mae: 491.8081\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422987.3750 - mae: 478.5831 - val_loss: 469697.9062 - val_mae: 490.8378\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421247.3125 - mae: 477.1290 - val_loss: 467368.0312 - val_mae: 490.2234\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419723.3438 - mae: 476.1092 - val_loss: 465686.5000 - val_mae: 489.3618\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418326.0625 - mae: 475.3369 - val_loss: 463767.4062 - val_mae: 487.8814\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416489.2500 - mae: 474.1677 - val_loss: 460055.4062 - val_mae: 487.2662\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415207.6562 - mae: 473.3314 - val_loss: 459939.2188 - val_mae: 486.5548\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413733.0625 - mae: 472.3359 - val_loss: 456846.8438 - val_mae: 486.2333\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412113.6875 - mae: 471.4810 - val_loss: 456909.8750 - val_mae: 485.1043\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410886.6562 - mae: 470.4263 - val_loss: 455466.8750 - val_mae: 485.8453\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409382.6562 - mae: 469.9182 - val_loss: 452632.1875 - val_mae: 482.5686\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408011.0312 - mae: 468.3179 - val_loss: 450525.1250 - val_mae: 482.4557\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406864.6875 - mae: 468.4726 - val_loss: 448604.3438 - val_mae: 480.7625\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405727.9062 - mae: 466.8976 - val_loss: 447944.3750 - val_mae: 480.1278\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404363.5938 - mae: 466.3549 - val_loss: 447288.6250 - val_mae: 479.5887\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403219.2188 - mae: 465.4867 - val_loss: 443903.6875 - val_mae: 478.8765\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402266.4062 - mae: 464.7075 - val_loss: 445077.7812 - val_mae: 478.8169\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401543.2812 - mae: 464.4576 - val_loss: 442836.2812 - val_mae: 478.3316\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401024.9062 - mae: 464.2870 - val_loss: 440661.0625 - val_mae: 477.2531\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400392.6250 - mae: 463.8189 - val_loss: 441624.1250 - val_mae: 477.0693\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400112.4375 - mae: 463.3978 - val_loss: 440960.0938 - val_mae: 477.2773\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399423.8438 - mae: 463.2361 - val_loss: 439720.7500 - val_mae: 475.9485\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398621.2812 - mae: 462.6298 - val_loss: 436607.0625 - val_mae: 474.9770\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398380.3750 - mae: 462.4054 - val_loss: 437202.0312 - val_mae: 476.6519\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397774.0312 - mae: 462.0958 - val_loss: 438052.0625 - val_mae: 474.7557\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397065.6875 - mae: 461.5084 - val_loss: 436799.1875 - val_mae: 474.6460\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396474.1250 - mae: 460.8066 - val_loss: 434374.6875 - val_mae: 474.5485\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395884.6562 - mae: 460.9448 - val_loss: 434016.0625 - val_mae: 473.3462\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395744.2188 - mae: 460.5985 - val_loss: 432433.7500 - val_mae: 472.8272\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395271.9062 - mae: 460.2948 - val_loss: 432407.2812 - val_mae: 472.6900\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394679.8438 - mae: 460.1179 - val_loss: 432077.0000 - val_mae: 472.8657\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394193.1875 - mae: 459.3066 - val_loss: 431633.8750 - val_mae: 472.6405\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393815.3750 - mae: 459.9884 - val_loss: 433511.8438 - val_mae: 472.1946\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 392991.9688 - mae: 458.7322 - val_loss: 431582.4375 - val_mae: 471.6287\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 392560.1250 - mae: 458.5124 - val_loss: 429156.8125 - val_mae: 471.6681\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 392397.7188 - mae: 458.6815 - val_loss: 429056.5625 - val_mae: 471.4608\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391691.0938 - mae: 458.6553 - val_loss: 430284.2188 - val_mae: 470.9667\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391427.8125 - mae: 457.4178 - val_loss: 427966.9375 - val_mae: 470.5166\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390368.4688 - mae: 457.7549 - val_loss: 427425.0312 - val_mae: 469.9792\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390404.0625 - mae: 457.3129 - val_loss: 428791.9688 - val_mae: 471.0965\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389805.1250 - mae: 457.2350 - val_loss: 426632.4062 - val_mae: 470.1699\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389572.5000 - mae: 457.0785 - val_loss: 425842.0000 - val_mae: 469.6353\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388972.5938 - mae: 456.8533 - val_loss: 424416.8750 - val_mae: 468.7838\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388579.1250 - mae: 455.9658 - val_loss: 424257.7812 - val_mae: 468.5880\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387735.6250 - mae: 455.3766 - val_loss: 422596.3125 - val_mae: 469.4301\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388042.5000 - mae: 456.2940 - val_loss: 424513.7812 - val_mae: 468.5549\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387316.7500 - mae: 455.4894 - val_loss: 420970.7812 - val_mae: 467.5461\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387050.7500 - mae: 455.0789 - val_loss: 423092.5312 - val_mae: 467.5304\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386509.6875 - mae: 455.0950 - val_loss: 423428.5000 - val_mae: 467.2485\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386364.0312 - mae: 455.0460 - val_loss: 422108.2812 - val_mae: 466.0391\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386032.0000 - mae: 454.3200 - val_loss: 422235.1875 - val_mae: 466.7894\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385650.2188 - mae: 454.1259 - val_loss: 421539.9062 - val_mae: 466.8732\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385428.7188 - mae: 453.9336 - val_loss: 420593.6875 - val_mae: 466.6893\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384914.6875 - mae: 453.9380 - val_loss: 419350.4375 - val_mae: 465.7937\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384573.6875 - mae: 453.6447 - val_loss: 418784.3438 - val_mae: 465.6094\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384135.8750 - mae: 453.2568 - val_loss: 417428.5625 - val_mae: 464.8253\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383487.5938 - mae: 452.6264 - val_loss: 417917.1250 - val_mae: 465.1636\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383553.7188 - mae: 453.1904 - val_loss: 418139.5312 - val_mae: 463.2617\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382962.2812 - mae: 452.0329 - val_loss: 417415.0000 - val_mae: 463.7608\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382610.4062 - mae: 451.9505 - val_loss: 417381.4375 - val_mae: 463.5953\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382201.4688 - mae: 451.7469 - val_loss: 415554.2500 - val_mae: 462.6233\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382296.7188 - mae: 451.4360 - val_loss: 413825.5000 - val_mae: 463.1148\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381438.2812 - mae: 451.7339 - val_loss: 415372.5625 - val_mae: 461.4518\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381025.2500 - mae: 450.4411 - val_loss: 415038.7500 - val_mae: 462.6163\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380399.4688 - mae: 450.1027 - val_loss: 413059.1875 - val_mae: 461.6983\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379885.8750 - mae: 450.0690 - val_loss: 413798.0625 - val_mae: 459.9955\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379426.5625 - mae: 449.0932 - val_loss: 411599.2188 - val_mae: 461.1353\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378996.3438 - mae: 449.3222 - val_loss: 411293.6875 - val_mae: 459.7519\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378393.5312 - mae: 448.5306 - val_loss: 412395.6250 - val_mae: 460.2141\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378189.4375 - mae: 448.5258 - val_loss: 411512.8750 - val_mae: 459.2242\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377109.0625 - mae: 447.8748 - val_loss: 411428.9062 - val_mae: 458.9438\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377027.8750 - mae: 447.3789 - val_loss: 410808.5938 - val_mae: 459.3772\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376490.9688 - mae: 447.0746 - val_loss: 410870.1250 - val_mae: 459.1056\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376034.4375 - mae: 446.8694 - val_loss: 410320.8125 - val_mae: 459.2681\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375854.5312 - mae: 446.5665 - val_loss: 408798.6562 - val_mae: 458.1817\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374623.0625 - mae: 445.9206 - val_loss: 409366.4375 - val_mae: 457.2301\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374836.7188 - mae: 446.0247 - val_loss: 408999.7188 - val_mae: 457.2078\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374502.8438 - mae: 445.1526 - val_loss: 406619.0000 - val_mae: 456.6715\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373787.1875 - mae: 444.9050 - val_loss: 406717.8750 - val_mae: 456.5573\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373548.4062 - mae: 444.7095 - val_loss: 406285.0938 - val_mae: 455.2383\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372890.0625 - mae: 443.8315 - val_loss: 405483.2500 - val_mae: 456.0078\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372717.3750 - mae: 444.4645 - val_loss: 406638.6250 - val_mae: 455.7971\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372031.5000 - mae: 443.1324 - val_loss: 405978.3438 - val_mae: 455.9314\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371802.1875 - mae: 443.4714 - val_loss: 404983.0000 - val_mae: 454.6857\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371359.3438 - mae: 442.9666 - val_loss: 405191.3438 - val_mae: 454.8397\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371147.0312 - mae: 443.0912 - val_loss: 403850.9688 - val_mae: 453.6356\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371346.5312 - mae: 442.3499 - val_loss: 404366.9062 - val_mae: 454.1222\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370609.1562 - mae: 442.4335 - val_loss: 403398.0938 - val_mae: 453.7098\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370732.5625 - mae: 442.6457 - val_loss: 404903.1250 - val_mae: 453.9569\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369936.7812 - mae: 441.6560 - val_loss: 403906.1562 - val_mae: 455.3188\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369894.8750 - mae: 441.6159 - val_loss: 403558.1562 - val_mae: 453.5977\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369695.4375 - mae: 442.0486 - val_loss: 403578.0625 - val_mae: 452.1786\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369360.2812 - mae: 441.3992 - val_loss: 402270.3438 - val_mae: 452.2279\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369236.1250 - mae: 440.5146 - val_loss: 401238.2500 - val_mae: 452.8011\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369014.8750 - mae: 441.3673 - val_loss: 402998.9688 - val_mae: 452.3380\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368732.4688 - mae: 440.6824 - val_loss: 404077.8438 - val_mae: 453.2519\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368606.8438 - mae: 441.0202 - val_loss: 401420.4062 - val_mae: 452.8799\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368624.8125 - mae: 440.6543 - val_loss: 402155.2812 - val_mae: 452.3920\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368395.5938 - mae: 440.5818 - val_loss: 399783.0312 - val_mae: 452.5197\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367890.0000 - mae: 440.4497 - val_loss: 402775.6250 - val_mae: 452.1500\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367986.3125 - mae: 440.0971 - val_loss: 400934.6562 - val_mae: 453.0836\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367377.7812 - mae: 440.1751 - val_loss: 401495.0312 - val_mae: 450.7828\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367277.6875 - mae: 439.6970 - val_loss: 400082.9688 - val_mae: 451.3292\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367184.4375 - mae: 439.5008 - val_loss: 399736.0938 - val_mae: 451.5965\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366784.7812 - mae: 439.4800 - val_loss: 399180.5938 - val_mae: 450.7987\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366543.8438 - mae: 439.3165 - val_loss: 399312.3750 - val_mae: 450.8233\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366340.0312 - mae: 439.2338 - val_loss: 399228.6875 - val_mae: 450.1522\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366153.8438 - mae: 439.4666 - val_loss: 399201.8438 - val_mae: 449.4474\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365937.7500 - mae: 438.5905 - val_loss: 399061.8750 - val_mae: 449.1631\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365405.2188 - mae: 438.2162 - val_loss: 398705.3750 - val_mae: 450.6663\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365271.1562 - mae: 438.5513 - val_loss: 397873.8750 - val_mae: 449.2408\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364854.6562 - mae: 437.9579 - val_loss: 397427.7812 - val_mae: 448.9089\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364523.2500 - mae: 437.9696 - val_loss: 398208.3750 - val_mae: 449.1103\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364150.4375 - mae: 437.7361 - val_loss: 398067.3125 - val_mae: 449.1772\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364540.9375 - mae: 437.8696 - val_loss: 398032.0000 - val_mae: 449.2510\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363992.2500 - mae: 437.6043 - val_loss: 396854.9375 - val_mae: 448.9183\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363710.6875 - mae: 437.0375 - val_loss: 396163.1250 - val_mae: 448.7398\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363500.9375 - mae: 437.4280 - val_loss: 397941.9062 - val_mae: 447.6891\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363774.2500 - mae: 437.4134 - val_loss: 395187.1562 - val_mae: 447.2596\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363409.7500 - mae: 436.8374 - val_loss: 396887.7188 - val_mae: 448.3227\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363044.7500 - mae: 436.7302 - val_loss: 397439.6250 - val_mae: 448.1646\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362855.9375 - mae: 436.4650 - val_loss: 396455.8438 - val_mae: 448.8591\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362833.8125 - mae: 437.2117 - val_loss: 396817.5938 - val_mae: 448.4886\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362688.9688 - mae: 436.6875 - val_loss: 397113.1250 - val_mae: 448.4992\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362558.8438 - mae: 436.6401 - val_loss: 397140.5000 - val_mae: 448.3615\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361970.0625 - mae: 436.1090 - val_loss: 396577.3125 - val_mae: 448.4993\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361932.0312 - mae: 436.5032 - val_loss: 399584.4688 - val_mae: 448.6302\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361855.6250 - mae: 435.6286 - val_loss: 394881.1562 - val_mae: 447.1815\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361788.3125 - mae: 435.6516 - val_loss: 396157.9375 - val_mae: 447.0921\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361357.3438 - mae: 435.7692 - val_loss: 395193.3750 - val_mae: 446.8775\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360972.4688 - mae: 435.3516 - val_loss: 394644.4688 - val_mae: 446.9132\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360891.5938 - mae: 435.0880 - val_loss: 393938.7500 - val_mae: 446.1714\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360861.5000 - mae: 435.2431 - val_loss: 395082.0938 - val_mae: 446.4767\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360575.5625 - mae: 435.1927 - val_loss: 393075.0000 - val_mae: 447.1850\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360315.2188 - mae: 434.7740 - val_loss: 394920.7188 - val_mae: 446.5053\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360235.2812 - mae: 434.7171 - val_loss: 394126.2188 - val_mae: 446.8736\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360152.9375 - mae: 434.5743 - val_loss: 395207.1250 - val_mae: 447.6549\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360066.4688 - mae: 434.4548 - val_loss: 393317.5938 - val_mae: 447.5642\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359934.1875 - mae: 434.5186 - val_loss: 393977.5938 - val_mae: 446.9336\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359527.5938 - mae: 434.5728 - val_loss: 393433.7188 - val_mae: 445.1843\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359192.8125 - mae: 433.4522 - val_loss: 393381.2500 - val_mae: 445.4657\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359366.3750 - mae: 433.8481 - val_loss: 393538.0000 - val_mae: 445.9929\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359177.7188 - mae: 433.4651 - val_loss: 395049.9062 - val_mae: 446.6715\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358778.8125 - mae: 433.1668 - val_loss: 392930.6250 - val_mae: 447.8260\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358796.3438 - mae: 433.6748 - val_loss: 393958.9688 - val_mae: 445.8259\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358547.2188 - mae: 433.2545 - val_loss: 393653.7812 - val_mae: 445.8595\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358307.5312 - mae: 432.7751 - val_loss: 392498.9062 - val_mae: 445.5273\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358047.9688 - mae: 432.5972 - val_loss: 391161.1562 - val_mae: 446.0889\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357862.5938 - mae: 433.3677 - val_loss: 391774.9375 - val_mae: 444.8023\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357876.7188 - mae: 432.5070 - val_loss: 391011.1250 - val_mae: 444.0156\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357601.0312 - mae: 432.5243 - val_loss: 391500.1250 - val_mae: 443.7761\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357458.2188 - mae: 432.4382 - val_loss: 391422.4062 - val_mae: 443.8805\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356909.5625 - mae: 432.1821 - val_loss: 390219.5625 - val_mae: 443.1505\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356726.2812 - mae: 432.0390 - val_loss: 390067.1875 - val_mae: 444.7555\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356124.9375 - mae: 431.8359 - val_loss: 388373.7188 - val_mae: 442.2050\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355867.9062 - mae: 431.6929 - val_loss: 388495.1875 - val_mae: 441.8314\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355621.8750 - mae: 431.1471 - val_loss: 388430.4062 - val_mae: 442.6673\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355162.0312 - mae: 430.8780 - val_loss: 389750.6250 - val_mae: 442.8927\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355004.5000 - mae: 430.9949 - val_loss: 387541.3125 - val_mae: 442.7158\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354679.0312 - mae: 430.9927 - val_loss: 388383.6875 - val_mae: 442.4157\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354274.9062 - mae: 430.4785 - val_loss: 387844.1875 - val_mae: 440.6111\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353736.5000 - mae: 430.0733 - val_loss: 386193.3750 - val_mae: 442.0203\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353857.5000 - mae: 430.2303 - val_loss: 387300.6250 - val_mae: 441.4167\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353583.8750 - mae: 430.0252 - val_loss: 386060.4062 - val_mae: 441.0278\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353412.3125 - mae: 430.1231 - val_loss: 386449.5000 - val_mae: 440.4589\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352937.3750 - mae: 429.5377 - val_loss: 385915.5312 - val_mae: 441.6794\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352586.8750 - mae: 428.9676 - val_loss: 384269.5000 - val_mae: 441.3206\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352687.0000 - mae: 429.5997 - val_loss: 384474.5312 - val_mae: 441.1734\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352334.4375 - mae: 429.5923 - val_loss: 384638.3438 - val_mae: 439.5542\n",
      "Epoch 216/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351881.3750 - mae: 428.8240 - val_loss: 383929.9062 - val_mae: 439.0140\n",
      "Epoch 217/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352046.9375 - mae: 428.9872 - val_loss: 385267.9688 - val_mae: 438.9340\n",
      "Epoch 218/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351936.0000 - mae: 428.4014 - val_loss: 384628.3750 - val_mae: 440.7633\n",
      "Epoch 219/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351623.3750 - mae: 428.2766 - val_loss: 382632.1562 - val_mae: 440.0310\n",
      "Epoch 220/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351468.8750 - mae: 428.9412 - val_loss: 383026.1250 - val_mae: 438.6750\n",
      "Epoch 221/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351406.8438 - mae: 428.2039 - val_loss: 383578.4375 - val_mae: 439.5511\n",
      "Epoch 222/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351234.5938 - mae: 428.6240 - val_loss: 383780.7188 - val_mae: 439.1821\n",
      "Epoch 223/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350991.7500 - mae: 428.0814 - val_loss: 383178.3125 - val_mae: 438.6162\n",
      "Epoch 224/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350912.8438 - mae: 428.1479 - val_loss: 384470.8125 - val_mae: 439.1271\n",
      "Epoch 225/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350570.3750 - mae: 427.8568 - val_loss: 383696.0000 - val_mae: 438.2532\n",
      "Epoch 226/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350257.3125 - mae: 427.6527 - val_loss: 381976.2500 - val_mae: 438.2950\n",
      "Epoch 227/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349942.0938 - mae: 427.3770 - val_loss: 382176.5625 - val_mae: 439.1887\n",
      "Epoch 228/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350101.8125 - mae: 427.5840 - val_loss: 383406.0000 - val_mae: 438.4103\n",
      "Epoch 229/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349657.1562 - mae: 427.0449 - val_loss: 383147.4062 - val_mae: 439.5659\n",
      "Epoch 230/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349902.5625 - mae: 427.6908 - val_loss: 381050.6875 - val_mae: 437.7208\n",
      "Epoch 231/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349370.0938 - mae: 426.9549 - val_loss: 380414.0000 - val_mae: 438.1279\n",
      "Epoch 232/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349610.5625 - mae: 426.9619 - val_loss: 381431.5625 - val_mae: 437.8833\n",
      "Epoch 233/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349423.3750 - mae: 427.1196 - val_loss: 380786.5312 - val_mae: 438.5017\n",
      "Epoch 234/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349141.6250 - mae: 426.5804 - val_loss: 382368.9688 - val_mae: 439.2387\n",
      "Epoch 235/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349240.3750 - mae: 426.8082 - val_loss: 380915.6875 - val_mae: 438.4146\n",
      "Epoch 236/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349047.8750 - mae: 427.1910 - val_loss: 381106.1875 - val_mae: 438.9979\n",
      "Epoch 237/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348713.5625 - mae: 426.8877 - val_loss: 380139.5938 - val_mae: 437.6630\n",
      "Epoch 238/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348675.9688 - mae: 426.5039 - val_loss: 380226.3750 - val_mae: 437.4512\n",
      "Epoch 239/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348101.6250 - mae: 426.5273 - val_loss: 379930.5938 - val_mae: 437.9265\n",
      "Epoch 240/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347977.1875 - mae: 426.1069 - val_loss: 378205.6250 - val_mae: 438.0574\n",
      "Epoch 241/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348531.1562 - mae: 426.7827 - val_loss: 379288.9062 - val_mae: 437.7095\n",
      "Epoch 242/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347989.1875 - mae: 425.8361 - val_loss: 378889.0312 - val_mae: 437.0743\n",
      "Epoch 243/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347696.7812 - mae: 425.8906 - val_loss: 378447.5312 - val_mae: 438.1099\n",
      "Epoch 244/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347573.0625 - mae: 426.0796 - val_loss: 380120.8125 - val_mae: 437.7143\n",
      "Epoch 245/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347234.4688 - mae: 425.5724 - val_loss: 381230.2500 - val_mae: 439.0698\n",
      "Epoch 246/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347489.1250 - mae: 425.9735 - val_loss: 379083.5312 - val_mae: 438.8066\n",
      "Epoch 247/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347103.5625 - mae: 425.4436 - val_loss: 379503.7188 - val_mae: 438.1004\n",
      "Epoch 248/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347056.5625 - mae: 425.6113 - val_loss: 381473.7500 - val_mae: 438.1057\n",
      "Epoch 249/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346908.9375 - mae: 425.2960 - val_loss: 377009.2812 - val_mae: 438.1464\n",
      "Epoch 250/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347023.2188 - mae: 425.4485 - val_loss: 377620.3750 - val_mae: 436.9910\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 32209834.0000 - mae: 5505.0728 - val_loss: 20599724.0000 - val_mae: 4402.9858\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 10410952.0000 - mae: 2893.7976 - val_loss: 3735985.2500 - val_mae: 1600.8995\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1812529.3750 - mae: 989.6649 - val_loss: 1117800.6250 - val_mae: 724.1351\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 901811.3125 - mae: 645.7399 - val_loss: 835276.6875 - val_mae: 618.4039\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 742725.5000 - mae: 587.4937 - val_loss: 715286.8125 - val_mae: 576.3423\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 666062.6875 - mae: 557.7173 - val_loss: 643864.8125 - val_mae: 552.1173\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 621688.3125 - mae: 539.9094 - val_loss: 605185.6875 - val_mae: 538.1598\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592968.5000 - mae: 528.9683 - val_loss: 572768.0000 - val_mae: 528.3832\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570397.2500 - mae: 520.1735 - val_loss: 550305.5625 - val_mae: 519.7203\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551615.6875 - mae: 512.1165 - val_loss: 534590.0000 - val_mae: 513.5695\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537972.6875 - mae: 505.7782 - val_loss: 513952.7500 - val_mae: 505.2683\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 525872.6875 - mae: 499.6644 - val_loss: 505664.9688 - val_mae: 501.3460\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 517150.0312 - mae: 494.3863 - val_loss: 492614.1875 - val_mae: 495.8773\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 509252.1875 - mae: 489.3404 - val_loss: 485920.0000 - val_mae: 489.9652\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 501838.0312 - mae: 484.2572 - val_loss: 478553.5312 - val_mae: 486.4645\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 495883.8438 - mae: 480.1993 - val_loss: 472424.9688 - val_mae: 482.3946\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 490098.7812 - mae: 476.8295 - val_loss: 468306.5312 - val_mae: 480.0835\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 486161.5625 - mae: 473.5685 - val_loss: 463674.7812 - val_mae: 478.3549\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 482241.0000 - mae: 470.9234 - val_loss: 459790.9062 - val_mae: 472.6973\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 478382.9688 - mae: 467.1670 - val_loss: 457535.7500 - val_mae: 474.3259\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 474298.3125 - mae: 465.4909 - val_loss: 457089.0312 - val_mae: 470.4321\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 471361.9688 - mae: 462.9587 - val_loss: 454919.6875 - val_mae: 470.4081\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 468109.8125 - mae: 460.6382 - val_loss: 449246.4688 - val_mae: 468.0922\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 465625.7188 - mae: 458.7777 - val_loss: 444303.5000 - val_mae: 465.6219\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 463230.8125 - mae: 457.4158 - val_loss: 444069.6562 - val_mae: 463.2369\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 461516.7812 - mae: 455.7131 - val_loss: 442319.8125 - val_mae: 464.9005\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 459061.1875 - mae: 454.6580 - val_loss: 438510.1250 - val_mae: 464.1355\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 457425.0625 - mae: 453.7123 - val_loss: 439776.2188 - val_mae: 463.0645\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 456026.4688 - mae: 452.7314 - val_loss: 436534.8438 - val_mae: 460.9148\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 454085.6250 - mae: 451.3574 - val_loss: 437760.1875 - val_mae: 459.6486\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 452835.4375 - mae: 450.6509 - val_loss: 431501.5625 - val_mae: 457.0759\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 451410.3438 - mae: 449.6040 - val_loss: 433467.2500 - val_mae: 458.1694\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 449891.2500 - mae: 448.6271 - val_loss: 429497.9375 - val_mae: 457.8516\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 448665.0000 - mae: 448.3351 - val_loss: 428261.1875 - val_mae: 456.9752\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 447479.2812 - mae: 447.4414 - val_loss: 429726.3750 - val_mae: 455.6437\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 446170.5000 - mae: 445.8527 - val_loss: 425609.3750 - val_mae: 454.0118\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 444930.0312 - mae: 445.2443 - val_loss: 423895.6875 - val_mae: 453.6248\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 443716.9375 - mae: 444.3393 - val_loss: 424747.1250 - val_mae: 453.1584\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442220.1875 - mae: 443.4447 - val_loss: 423526.8125 - val_mae: 454.6541\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441353.1875 - mae: 442.9948 - val_loss: 420201.1875 - val_mae: 450.0215\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 440001.6250 - mae: 441.7039 - val_loss: 423312.8125 - val_mae: 452.2291\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 438923.6562 - mae: 441.6832 - val_loss: 422383.9062 - val_mae: 448.3033\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437826.5938 - mae: 440.1616 - val_loss: 418551.1250 - val_mae: 448.5226\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436916.6875 - mae: 439.9095 - val_loss: 418799.0938 - val_mae: 447.9856\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435856.9375 - mae: 438.4705 - val_loss: 415825.6250 - val_mae: 447.4140\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435262.8125 - mae: 438.3819 - val_loss: 416582.5938 - val_mae: 447.3763\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434128.4062 - mae: 437.7438 - val_loss: 415957.5000 - val_mae: 446.7447\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434148.5000 - mae: 437.7542 - val_loss: 415829.3750 - val_mae: 446.0459\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433046.5938 - mae: 436.9286 - val_loss: 408783.8125 - val_mae: 443.5854\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433311.0312 - mae: 436.7086 - val_loss: 416383.9062 - val_mae: 444.6266\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432316.3125 - mae: 436.0244 - val_loss: 417158.5625 - val_mae: 446.5337\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431917.4062 - mae: 435.9405 - val_loss: 411201.6875 - val_mae: 441.9147\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431379.0000 - mae: 435.5478 - val_loss: 409357.0312 - val_mae: 443.4699\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431110.0312 - mae: 435.8546 - val_loss: 411114.2500 - val_mae: 442.4316\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430882.5312 - mae: 435.3217 - val_loss: 408704.5938 - val_mae: 443.6930\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429954.8438 - mae: 435.2179 - val_loss: 411029.2500 - val_mae: 444.0713\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429851.5938 - mae: 435.4181 - val_loss: 412966.8750 - val_mae: 442.5638\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429306.3125 - mae: 434.6574 - val_loss: 409078.0000 - val_mae: 441.1695\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428957.7188 - mae: 434.0728 - val_loss: 406630.5000 - val_mae: 440.8041\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428656.2812 - mae: 434.1535 - val_loss: 409983.7188 - val_mae: 442.3673\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428423.0312 - mae: 433.6710 - val_loss: 406541.5938 - val_mae: 442.8533\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428136.5938 - mae: 433.9545 - val_loss: 408420.7188 - val_mae: 439.9493\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427859.1562 - mae: 433.3872 - val_loss: 411580.9062 - val_mae: 443.3609\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427345.6250 - mae: 433.2168 - val_loss: 405678.8750 - val_mae: 440.5717\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427433.8750 - mae: 433.3000 - val_loss: 407229.6562 - val_mae: 439.9053\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426827.6875 - mae: 432.7943 - val_loss: 407838.8438 - val_mae: 440.9840\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426613.1562 - mae: 433.0884 - val_loss: 404288.7500 - val_mae: 439.7038\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426141.7812 - mae: 432.9528 - val_loss: 406242.9688 - val_mae: 440.5253\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426071.7812 - mae: 432.7412 - val_loss: 403720.5938 - val_mae: 441.9448\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425095.4688 - mae: 432.0000 - val_loss: 404934.5938 - val_mae: 439.5952\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425361.2812 - mae: 433.0166 - val_loss: 409738.5000 - val_mae: 438.4115\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420539.8125 - mae: 431.7339 - val_loss: 403951.8125 - val_mae: 440.1367\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413522.8125 - mae: 431.1096 - val_loss: 398974.9062 - val_mae: 436.6370\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408401.6875 - mae: 430.9464 - val_loss: 403902.5938 - val_mae: 438.6433\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404420.5000 - mae: 430.8818 - val_loss: 403594.7188 - val_mae: 438.2923\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 400988.6875 - mae: 430.8291 - val_loss: 402110.3125 - val_mae: 440.1967\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 398009.8125 - mae: 430.6021 - val_loss: 405464.2188 - val_mae: 438.4043\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 395421.4688 - mae: 429.9876 - val_loss: 402550.3750 - val_mae: 436.0863\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 392672.8125 - mae: 429.3557 - val_loss: 402031.4688 - val_mae: 436.9919\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 390476.2500 - mae: 429.1023 - val_loss: 401649.8125 - val_mae: 436.8658\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 387932.0625 - mae: 428.5487 - val_loss: 397402.3125 - val_mae: 437.0275\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 386189.9062 - mae: 428.4315 - val_loss: 396016.9375 - val_mae: 437.1875\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 384407.3125 - mae: 428.3461 - val_loss: 393808.4062 - val_mae: 437.1753\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 382993.6562 - mae: 427.7039 - val_loss: 389991.6562 - val_mae: 436.4162\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 380772.3438 - mae: 427.2411 - val_loss: 385777.1250 - val_mae: 435.1805\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 379112.2188 - mae: 427.0479 - val_loss: 383433.8438 - val_mae: 434.2220\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 378363.2500 - mae: 426.8688 - val_loss: 381902.5938 - val_mae: 434.9142\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 376630.5938 - mae: 426.5541 - val_loss: 379429.3750 - val_mae: 435.1620\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 375693.1562 - mae: 425.9969 - val_loss: 375474.8438 - val_mae: 436.4313\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 374554.4062 - mae: 426.1706 - val_loss: 375748.5000 - val_mae: 432.1631\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 373228.2500 - mae: 424.9387 - val_loss: 377000.0000 - val_mae: 436.1599\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 372436.7188 - mae: 425.1732 - val_loss: 371558.8438 - val_mae: 432.8213\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 371191.6562 - mae: 424.7492 - val_loss: 372113.3750 - val_mae: 433.9316\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 370968.1875 - mae: 424.8111 - val_loss: 376323.5312 - val_mae: 432.8866\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 368785.2812 - mae: 424.0407 - val_loss: 368064.7188 - val_mae: 431.5406\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 364743.4375 - mae: 423.6535 - val_loss: 370407.7812 - val_mae: 432.5125\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 362351.6875 - mae: 422.4890 - val_loss: 366914.5625 - val_mae: 431.6103\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 360240.2500 - mae: 423.4551 - val_loss: 368824.9688 - val_mae: 431.9568\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358282.3750 - mae: 422.2963 - val_loss: 366238.9375 - val_mae: 431.1920\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 356993.9375 - mae: 422.6351 - val_loss: 365160.1562 - val_mae: 432.4173\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 355128.2500 - mae: 422.3093 - val_loss: 366507.7812 - val_mae: 430.2385\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353472.0312 - mae: 422.5128 - val_loss: 369791.7188 - val_mae: 431.5146\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 352471.4688 - mae: 422.0391 - val_loss: 366128.5625 - val_mae: 431.5681\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 351582.8750 - mae: 422.1228 - val_loss: 367224.1562 - val_mae: 432.0764\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 350508.7500 - mae: 421.9351 - val_loss: 367891.8125 - val_mae: 432.5090\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 349492.8750 - mae: 422.0463 - val_loss: 368268.2188 - val_mae: 435.2130\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 349095.2812 - mae: 422.4352 - val_loss: 369240.8750 - val_mae: 431.9908\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348481.8438 - mae: 421.9202 - val_loss: 368672.5312 - val_mae: 431.9499\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347869.4688 - mae: 422.1597 - val_loss: 369135.4375 - val_mae: 430.3679\n",
      "Epoch 110/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347682.1875 - mae: 421.9559 - val_loss: 368956.8125 - val_mae: 432.7080\n",
      "Epoch 111/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 346887.5000 - mae: 421.5515 - val_loss: 368873.7812 - val_mae: 433.2246\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 29423006.0000 - mae: 5222.8608 - val_loss: 14141406.0000 - val_mae: 3623.2759\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 5568561.0000 - mae: 1959.0807 - val_loss: 1636125.3750 - val_mae: 938.3775\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1131777.2500 - mae: 752.1039 - val_loss: 843232.8750 - val_mae: 667.3088\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 750448.6250 - mae: 616.0269 - val_loss: 642753.4375 - val_mae: 587.8680\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 621623.8750 - mae: 560.9773 - val_loss: 559922.2500 - val_mae: 545.9499\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565453.6250 - mae: 528.5773 - val_loss: 522563.7188 - val_mae: 525.6288\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539930.0625 - mae: 512.4494 - val_loss: 502705.6875 - val_mae: 508.4165\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 524579.5000 - mae: 500.7103 - val_loss: 491790.7500 - val_mae: 499.0731\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 513458.3125 - mae: 492.8236 - val_loss: 478390.9375 - val_mae: 492.9283\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 504869.5938 - mae: 486.6252 - val_loss: 470851.7188 - val_mae: 485.9535\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 497497.0000 - mae: 481.3197 - val_loss: 469516.8438 - val_mae: 482.6264\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 490537.0312 - mae: 475.7126 - val_loss: 457790.0938 - val_mae: 476.9150\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 483888.9688 - mae: 471.0682 - val_loss: 452291.3750 - val_mae: 472.7694\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 478131.7500 - mae: 466.9197 - val_loss: 453116.3125 - val_mae: 470.7897\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 473501.7188 - mae: 463.1016 - val_loss: 442369.5000 - val_mae: 468.0674\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 469084.1875 - mae: 460.6488 - val_loss: 445290.7812 - val_mae: 466.6484\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 466079.7188 - mae: 457.8925 - val_loss: 439195.5312 - val_mae: 464.6624\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 463125.9688 - mae: 455.9559 - val_loss: 432423.2812 - val_mae: 462.1490\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 460729.8125 - mae: 453.9874 - val_loss: 432767.7188 - val_mae: 461.0955\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 457832.4688 - mae: 451.4236 - val_loss: 430336.2188 - val_mae: 457.9256\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 454954.2812 - mae: 449.5162 - val_loss: 431099.1875 - val_mae: 458.4562\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453077.2188 - mae: 448.7335 - val_loss: 424792.5000 - val_mae: 452.5546\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 450585.0312 - mae: 445.6309 - val_loss: 421485.8125 - val_mae: 453.0685\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 448119.5312 - mae: 444.7053 - val_loss: 419241.1250 - val_mae: 449.4908\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 446426.7188 - mae: 443.1660 - val_loss: 415313.0000 - val_mae: 446.2336\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 444803.5000 - mae: 441.4886 - val_loss: 417153.6562 - val_mae: 446.2274\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442910.3125 - mae: 439.6164 - val_loss: 411660.1250 - val_mae: 445.0644\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442226.8438 - mae: 439.2078 - val_loss: 414954.0312 - val_mae: 444.6229\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441166.2812 - mae: 438.4936 - val_loss: 411857.0000 - val_mae: 442.6132\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439213.0938 - mae: 437.5532 - val_loss: 414056.8750 - val_mae: 440.9527\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439056.0000 - mae: 436.1671 - val_loss: 412339.8438 - val_mae: 444.6377\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437349.0938 - mae: 436.0288 - val_loss: 410458.6562 - val_mae: 440.1787\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437269.2812 - mae: 435.3656 - val_loss: 410891.7500 - val_mae: 441.2878\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436426.8125 - mae: 433.9066 - val_loss: 407118.8438 - val_mae: 440.3532\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434040.2500 - mae: 433.9003 - val_loss: 405712.5938 - val_mae: 437.7807\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424384.7188 - mae: 433.6474 - val_loss: 404740.3750 - val_mae: 435.9471\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410627.7500 - mae: 432.1929 - val_loss: 398298.9062 - val_mae: 437.6305\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 398116.5625 - mae: 431.8212 - val_loss: 391193.1562 - val_mae: 436.2286\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 387959.3750 - mae: 430.3875 - val_loss: 389127.5625 - val_mae: 436.5104\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 378925.4062 - mae: 429.4116 - val_loss: 382411.4375 - val_mae: 436.3932\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 371397.8438 - mae: 428.6777 - val_loss: 379922.4375 - val_mae: 437.1728\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363956.5938 - mae: 427.5099 - val_loss: 374723.6562 - val_mae: 433.6757\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359555.8750 - mae: 427.0836 - val_loss: 373821.0625 - val_mae: 434.4384\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 354985.9062 - mae: 426.5865 - val_loss: 376351.1250 - val_mae: 431.9344\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 351550.4062 - mae: 425.2619 - val_loss: 373299.8438 - val_mae: 432.8493\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348797.3750 - mae: 425.0285 - val_loss: 375936.0312 - val_mae: 432.3405\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347464.7812 - mae: 424.3041 - val_loss: 376411.2500 - val_mae: 435.2382\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 346760.5000 - mae: 424.4013 - val_loss: 377220.0000 - val_mae: 432.8569\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 345239.5938 - mae: 423.3266 - val_loss: 381030.2500 - val_mae: 432.0547\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 345151.3438 - mae: 423.4881 - val_loss: 381827.0938 - val_mae: 432.9139\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 344775.9688 - mae: 423.0850 - val_loss: 378685.0312 - val_mae: 432.0688\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 344708.9688 - mae: 423.0181 - val_loss: 376009.2500 - val_mae: 430.6561\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 344047.0625 - mae: 422.6556 - val_loss: 378494.1250 - val_mae: 430.7028\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343699.9062 - mae: 422.0398 - val_loss: 378828.0938 - val_mae: 434.0426\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343447.3125 - mae: 422.1630 - val_loss: 375226.8750 - val_mae: 430.9752\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343364.3750 - mae: 422.1688 - val_loss: 372259.0000 - val_mae: 427.9164\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343982.4375 - mae: 422.0932 - val_loss: 375820.3125 - val_mae: 432.4539\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343907.7188 - mae: 422.0879 - val_loss: 374211.2812 - val_mae: 431.9806\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343649.6562 - mae: 422.3723 - val_loss: 371153.9375 - val_mae: 427.2033\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343158.0312 - mae: 421.7656 - val_loss: 373479.8750 - val_mae: 430.6762\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343210.0938 - mae: 421.9413 - val_loss: 372900.4062 - val_mae: 432.2690\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343305.6250 - mae: 421.8438 - val_loss: 374171.2812 - val_mae: 430.2210\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342744.8438 - mae: 421.3838 - val_loss: 373898.5312 - val_mae: 432.0730\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342537.8125 - mae: 421.1684 - val_loss: 375511.3125 - val_mae: 433.0599\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342980.4688 - mae: 421.1936 - val_loss: 377970.4062 - val_mae: 431.7917\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342235.6250 - mae: 421.1057 - val_loss: 375677.2188 - val_mae: 431.4258\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 341622.9688 - mae: 421.1721 - val_loss: 375773.3125 - val_mae: 432.2338\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 341600.5625 - mae: 420.8544 - val_loss: 378033.2500 - val_mae: 432.6096\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342002.4688 - mae: 421.0907 - val_loss: 373691.1562 - val_mae: 430.9230\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 36937968.0000 - mae: 5925.2412 - val_loss: 32875070.0000 - val_mae: 5608.4790\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 26288418.0000 - mae: 4995.6099 - val_loss: 19427934.0000 - val_mae: 4291.6060\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 13968388.0000 - mae: 3512.1482 - val_loss: 9619237.0000 - val_mae: 2790.0002\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6979116.5000 - mae: 2187.8987 - val_loss: 5126443.5000 - val_mae: 1735.8688\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3989841.5000 - mae: 1445.1953 - val_loss: 3146220.0000 - val_mae: 1255.4875\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2593760.7500 - mae: 1122.5284 - val_loss: 2122313.5000 - val_mae: 1024.4193\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1773784.2500 - mae: 940.9620 - val_loss: 1441171.1250 - val_mae: 865.0466\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1204158.6250 - mae: 802.1379 - val_loss: 1001407.6250 - val_mae: 745.3492\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 878287.1250 - mae: 698.0537 - val_loss: 779280.8750 - val_mae: 657.8615\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 716668.6250 - mae: 623.1270 - val_loss: 667847.0000 - val_mae: 601.1487\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 633317.1250 - mae: 580.1932 - val_loss: 611235.0625 - val_mae: 567.8417\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583692.2500 - mae: 553.1958 - val_loss: 571702.0000 - val_mae: 547.0692\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551644.6250 - mae: 536.3511 - val_loss: 546969.8125 - val_mae: 534.4081\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527525.5625 - mae: 525.3531 - val_loss: 529389.1250 - val_mae: 526.2847\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 510435.9375 - mae: 518.1997 - val_loss: 515961.9375 - val_mae: 518.0673\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 495446.6250 - mae: 511.4473 - val_loss: 506972.2812 - val_mae: 513.6257\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 483189.6875 - mae: 505.6888 - val_loss: 497055.0000 - val_mae: 509.1711\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 472231.8125 - mae: 500.3321 - val_loss: 491344.5000 - val_mae: 506.3617\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 462838.6562 - mae: 495.2742 - val_loss: 483209.5938 - val_mae: 502.4302\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 455196.0938 - mae: 491.7570 - val_loss: 478758.8438 - val_mae: 499.6838\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 448769.2812 - mae: 488.3848 - val_loss: 479778.0938 - val_mae: 498.8952\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442929.1875 - mae: 485.5012 - val_loss: 477271.4062 - val_mae: 496.8984\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438157.4375 - mae: 483.2968 - val_loss: 470977.6875 - val_mae: 493.5833\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432982.2188 - mae: 480.5224 - val_loss: 471323.8438 - val_mae: 492.2932\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429255.3125 - mae: 478.8361 - val_loss: 466677.6250 - val_mae: 491.8759\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425997.4062 - mae: 477.2711 - val_loss: 464980.6875 - val_mae: 489.0520\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422919.9688 - mae: 475.5376 - val_loss: 465699.0000 - val_mae: 488.7032\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420061.8125 - mae: 474.1920 - val_loss: 460791.4375 - val_mae: 487.8896\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417750.8438 - mae: 473.0594 - val_loss: 462374.7812 - val_mae: 487.5363\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415644.6562 - mae: 471.5681 - val_loss: 459855.1562 - val_mae: 485.3930\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413300.2500 - mae: 470.8646 - val_loss: 460858.0312 - val_mae: 484.8235\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411718.2188 - mae: 469.6761 - val_loss: 453252.7812 - val_mae: 481.9044\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410053.8750 - mae: 468.5606 - val_loss: 455765.9062 - val_mae: 484.6936\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408330.6875 - mae: 467.8937 - val_loss: 453750.0000 - val_mae: 481.9817\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407187.3750 - mae: 467.0426 - val_loss: 453255.3750 - val_mae: 482.0126\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405469.5938 - mae: 465.9949 - val_loss: 448578.7812 - val_mae: 479.6812\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403731.8750 - mae: 465.0068 - val_loss: 450544.2500 - val_mae: 480.3150\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402766.6875 - mae: 464.8047 - val_loss: 453439.6250 - val_mae: 480.2278\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401699.0938 - mae: 463.7246 - val_loss: 447265.9375 - val_mae: 478.3181\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400190.5625 - mae: 462.7489 - val_loss: 445225.9375 - val_mae: 477.0003\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398741.5625 - mae: 462.5114 - val_loss: 447429.5625 - val_mae: 476.0135\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397313.2500 - mae: 460.8127 - val_loss: 444337.7500 - val_mae: 475.7902\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396163.4688 - mae: 460.4433 - val_loss: 444556.8750 - val_mae: 475.3593\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395135.3750 - mae: 459.4777 - val_loss: 441619.8438 - val_mae: 473.6892\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394139.7812 - mae: 458.8044 - val_loss: 441522.1562 - val_mae: 474.7337\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392956.4688 - mae: 457.8447 - val_loss: 439465.1875 - val_mae: 472.9778\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392101.7812 - mae: 457.2037 - val_loss: 437851.0938 - val_mae: 472.2796\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390834.6250 - mae: 456.7995 - val_loss: 440060.2500 - val_mae: 472.4796\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389503.7812 - mae: 455.9395 - val_loss: 436133.6562 - val_mae: 469.8042\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388642.1875 - mae: 454.8453 - val_loss: 437787.9062 - val_mae: 470.6934\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 387423.2812 - mae: 454.4785 - val_loss: 435165.1875 - val_mae: 469.4765\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386576.0625 - mae: 453.8321 - val_loss: 433645.8750 - val_mae: 468.2078\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 385651.0000 - mae: 453.3157 - val_loss: 433685.2500 - val_mae: 467.3802\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 384521.1875 - mae: 452.8131 - val_loss: 437452.7500 - val_mae: 469.0203\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 384177.6875 - mae: 451.6920 - val_loss: 434365.8125 - val_mae: 468.2156\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382920.0312 - mae: 451.4181 - val_loss: 429999.7812 - val_mae: 467.1250\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382589.1875 - mae: 451.3853 - val_loss: 431755.3125 - val_mae: 467.7148\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 381604.0938 - mae: 450.6386 - val_loss: 429147.6562 - val_mae: 465.9265\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 380806.3750 - mae: 449.7998 - val_loss: 428562.3438 - val_mae: 465.9311\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 380184.8125 - mae: 449.9871 - val_loss: 429610.4688 - val_mae: 465.9461\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 379172.4688 - mae: 448.4042 - val_loss: 424837.1250 - val_mae: 465.4774\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 378619.5625 - mae: 449.3102 - val_loss: 429271.3750 - val_mae: 464.9872\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377986.3438 - mae: 448.0270 - val_loss: 422310.0000 - val_mae: 462.7817\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377168.4688 - mae: 447.8144 - val_loss: 426017.2500 - val_mae: 463.9758\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 376557.2188 - mae: 447.9466 - val_loss: 427912.6250 - val_mae: 463.8989\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 375907.1562 - mae: 447.0326 - val_loss: 426883.4688 - val_mae: 464.3572\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 375401.4062 - mae: 447.1567 - val_loss: 424308.0000 - val_mae: 462.6660\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374624.2188 - mae: 446.6853 - val_loss: 421894.8438 - val_mae: 460.7672\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373907.6875 - mae: 445.9474 - val_loss: 420659.7812 - val_mae: 460.2998\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373206.9375 - mae: 446.0416 - val_loss: 420859.9375 - val_mae: 459.9020\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 372699.1250 - mae: 445.1541 - val_loss: 418653.8125 - val_mae: 460.8332\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 372336.9688 - mae: 445.1562 - val_loss: 419711.9688 - val_mae: 459.5769\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371380.5312 - mae: 444.8471 - val_loss: 421598.0625 - val_mae: 459.8957\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370844.1562 - mae: 443.8378 - val_loss: 416106.2812 - val_mae: 459.8171\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370040.8125 - mae: 444.1245 - val_loss: 414716.0312 - val_mae: 458.1165\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369749.8438 - mae: 444.2387 - val_loss: 417417.6250 - val_mae: 458.4972\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369204.9375 - mae: 442.9757 - val_loss: 413501.5000 - val_mae: 457.2953\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368330.1250 - mae: 442.9982 - val_loss: 414964.1875 - val_mae: 457.9164\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368090.2188 - mae: 442.8273 - val_loss: 415714.5312 - val_mae: 457.6932\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367903.3125 - mae: 442.4333 - val_loss: 413134.1875 - val_mae: 455.9552\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367155.8750 - mae: 442.0161 - val_loss: 414915.3125 - val_mae: 458.0181\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366776.4688 - mae: 442.6827 - val_loss: 416211.7500 - val_mae: 456.7655\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366305.0938 - mae: 441.4160 - val_loss: 412272.5938 - val_mae: 455.9412\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365582.9062 - mae: 441.2289 - val_loss: 412929.4688 - val_mae: 455.6873\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365378.3125 - mae: 441.0128 - val_loss: 411879.8125 - val_mae: 455.7746\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364296.1250 - mae: 440.1896 - val_loss: 412118.0938 - val_mae: 455.6974\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364539.5625 - mae: 440.6938 - val_loss: 412586.1562 - val_mae: 456.0934\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363517.8438 - mae: 440.0111 - val_loss: 408999.2500 - val_mae: 453.0187\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363425.0312 - mae: 439.6276 - val_loss: 409111.1250 - val_mae: 454.1839\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362293.9688 - mae: 438.7449 - val_loss: 408997.0938 - val_mae: 455.2727\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362766.4062 - mae: 439.6069 - val_loss: 409812.2812 - val_mae: 454.4121\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361824.2188 - mae: 438.7484 - val_loss: 407392.1875 - val_mae: 453.0851\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361580.8750 - mae: 438.6421 - val_loss: 409256.4688 - val_mae: 452.8826\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360868.9062 - mae: 438.2989 - val_loss: 410845.8438 - val_mae: 454.0754\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360648.2500 - mae: 437.6257 - val_loss: 406110.9062 - val_mae: 452.5696\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360339.3125 - mae: 437.9730 - val_loss: 406154.5312 - val_mae: 451.7841\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359312.1562 - mae: 436.8172 - val_loss: 406223.1250 - val_mae: 452.3169\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358969.9375 - mae: 436.4536 - val_loss: 405538.3438 - val_mae: 452.3345\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358652.9062 - mae: 436.6818 - val_loss: 404325.6250 - val_mae: 450.8058\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358142.8438 - mae: 436.2452 - val_loss: 403614.7812 - val_mae: 449.6835\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357164.1562 - mae: 435.7903 - val_loss: 408736.7188 - val_mae: 450.9161\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356724.5625 - mae: 435.0841 - val_loss: 403972.9375 - val_mae: 449.4829\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356491.3125 - mae: 434.7832 - val_loss: 401693.5312 - val_mae: 448.7088\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356131.9062 - mae: 434.3759 - val_loss: 400816.2812 - val_mae: 448.3895\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355184.0938 - mae: 434.1715 - val_loss: 404186.4688 - val_mae: 449.4668\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354554.9375 - mae: 433.3145 - val_loss: 401343.9375 - val_mae: 447.6248\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354123.5938 - mae: 432.9433 - val_loss: 401339.9375 - val_mae: 448.0441\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353532.9062 - mae: 432.6221 - val_loss: 401104.8438 - val_mae: 447.4594\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353272.5625 - mae: 432.3712 - val_loss: 402659.7500 - val_mae: 448.1112\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352587.2812 - mae: 431.9188 - val_loss: 398726.5938 - val_mae: 446.7916\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352406.2812 - mae: 431.8639 - val_loss: 400506.0938 - val_mae: 446.7830\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351491.4062 - mae: 431.0789 - val_loss: 399384.1250 - val_mae: 447.3873\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351111.2500 - mae: 431.0361 - val_loss: 398125.6250 - val_mae: 445.9615\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350150.2188 - mae: 430.1964 - val_loss: 395230.8125 - val_mae: 444.0897\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349366.0312 - mae: 429.3160 - val_loss: 393914.3750 - val_mae: 445.2935\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348600.0938 - mae: 429.1388 - val_loss: 393412.0000 - val_mae: 444.6861\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348016.3125 - mae: 429.1031 - val_loss: 394133.8750 - val_mae: 444.2164\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346913.4062 - mae: 428.0343 - val_loss: 393503.5312 - val_mae: 444.5600\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345997.1562 - mae: 427.7615 - val_loss: 393024.6250 - val_mae: 442.4531\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345031.5312 - mae: 427.0963 - val_loss: 394008.0625 - val_mae: 442.3494\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344188.9375 - mae: 426.4632 - val_loss: 390017.1875 - val_mae: 441.7306\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343196.5938 - mae: 426.2206 - val_loss: 392788.0312 - val_mae: 441.2628\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341759.9688 - mae: 425.1540 - val_loss: 390606.4062 - val_mae: 439.0640\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341837.9688 - mae: 425.2143 - val_loss: 388463.2812 - val_mae: 438.7974\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340600.8125 - mae: 424.3570 - val_loss: 388105.5938 - val_mae: 439.6801\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339898.3750 - mae: 423.8136 - val_loss: 386499.5312 - val_mae: 438.9454\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338631.7812 - mae: 423.0114 - val_loss: 386250.4688 - val_mae: 439.0380\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338074.2812 - mae: 422.6267 - val_loss: 384389.6562 - val_mae: 438.1060\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337278.4375 - mae: 422.2457 - val_loss: 385750.2188 - val_mae: 438.0352\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336418.4062 - mae: 421.6844 - val_loss: 382548.8125 - val_mae: 437.7671\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335994.3750 - mae: 421.4591 - val_loss: 381952.4688 - val_mae: 437.2765\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335223.7500 - mae: 421.0023 - val_loss: 386456.5312 - val_mae: 437.7730\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335089.5000 - mae: 420.6106 - val_loss: 383032.5312 - val_mae: 436.8344\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334138.1250 - mae: 420.0923 - val_loss: 379932.0312 - val_mae: 436.1964\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333805.4688 - mae: 420.0610 - val_loss: 377579.9688 - val_mae: 434.6926\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333141.1250 - mae: 419.7493 - val_loss: 380314.3750 - val_mae: 435.0717\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332530.9375 - mae: 419.1537 - val_loss: 380442.4688 - val_mae: 436.0764\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332103.7500 - mae: 418.9586 - val_loss: 381071.2812 - val_mae: 436.4867\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331635.3438 - mae: 418.5225 - val_loss: 377906.5312 - val_mae: 434.5243\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331313.8125 - mae: 418.3612 - val_loss: 378817.4062 - val_mae: 434.4919\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330885.7188 - mae: 417.7642 - val_loss: 375734.0938 - val_mae: 434.7422\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330411.7500 - mae: 417.7120 - val_loss: 377616.4062 - val_mae: 434.2020\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330224.9375 - mae: 417.4337 - val_loss: 375635.2500 - val_mae: 432.8141\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329546.5000 - mae: 416.5827 - val_loss: 377359.2188 - val_mae: 434.8009\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329095.0312 - mae: 416.5976 - val_loss: 374442.6562 - val_mae: 432.9945\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328465.5312 - mae: 416.1745 - val_loss: 374379.3125 - val_mae: 432.5756\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328159.0938 - mae: 415.4786 - val_loss: 372367.4688 - val_mae: 431.4521\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327901.7188 - mae: 415.6800 - val_loss: 370514.0312 - val_mae: 430.8549\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327355.1250 - mae: 414.7756 - val_loss: 371871.1562 - val_mae: 430.9836\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326801.3438 - mae: 414.6829 - val_loss: 371678.6875 - val_mae: 430.4452\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326556.8750 - mae: 414.5338 - val_loss: 371206.7500 - val_mae: 430.3266\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326161.3750 - mae: 414.2741 - val_loss: 371994.0312 - val_mae: 429.9823\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325748.3750 - mae: 413.3931 - val_loss: 370880.4688 - val_mae: 430.0685\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325582.0625 - mae: 413.1606 - val_loss: 368532.9062 - val_mae: 428.8324\n",
      "Epoch 155/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324738.5625 - mae: 413.3021 - val_loss: 371891.4062 - val_mae: 429.0830\n",
      "Epoch 156/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324385.4062 - mae: 412.3066 - val_loss: 368212.0000 - val_mae: 429.5166\n",
      "Epoch 157/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324476.6250 - mae: 412.6596 - val_loss: 368790.5000 - val_mae: 429.0686\n",
      "Epoch 158/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323926.5312 - mae: 412.2071 - val_loss: 369742.2500 - val_mae: 430.2298\n",
      "Epoch 159/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324192.4375 - mae: 412.5605 - val_loss: 369314.7500 - val_mae: 429.4450\n",
      "Epoch 160/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323455.2188 - mae: 412.1183 - val_loss: 370465.6562 - val_mae: 429.4530\n",
      "Epoch 161/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323756.4062 - mae: 412.1788 - val_loss: 367590.8438 - val_mae: 427.6985\n",
      "Epoch 162/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322917.3125 - mae: 411.3199 - val_loss: 365666.2500 - val_mae: 426.4135\n",
      "Epoch 163/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323304.4688 - mae: 411.6400 - val_loss: 365895.8438 - val_mae: 426.7487\n",
      "Epoch 164/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322930.6875 - mae: 410.8225 - val_loss: 366427.3125 - val_mae: 427.2456\n",
      "Epoch 165/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322649.7188 - mae: 411.3733 - val_loss: 365998.4375 - val_mae: 426.0983\n",
      "Epoch 166/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322660.5625 - mae: 411.2164 - val_loss: 363868.6562 - val_mae: 426.2671\n",
      "Epoch 167/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322484.0625 - mae: 411.0024 - val_loss: 364897.5312 - val_mae: 426.8502\n",
      "Epoch 168/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322530.0938 - mae: 411.2352 - val_loss: 365338.6562 - val_mae: 426.3730\n",
      "Epoch 169/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321868.7500 - mae: 410.8437 - val_loss: 365983.9688 - val_mae: 425.3885\n",
      "Epoch 170/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322063.7500 - mae: 410.7025 - val_loss: 366872.9688 - val_mae: 426.7226\n",
      "Epoch 171/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322081.8750 - mae: 410.4745 - val_loss: 363377.8438 - val_mae: 425.8767\n",
      "Epoch 172/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322024.5000 - mae: 410.9695 - val_loss: 365052.0938 - val_mae: 426.0384\n",
      "Epoch 173/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321958.0938 - mae: 410.4236 - val_loss: 363104.2188 - val_mae: 425.5858\n",
      "Epoch 174/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321616.3750 - mae: 410.4143 - val_loss: 364271.0938 - val_mae: 426.3944\n",
      "Epoch 175/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321770.7500 - mae: 410.6990 - val_loss: 366515.0938 - val_mae: 426.4236\n",
      "Epoch 176/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321370.0625 - mae: 410.2148 - val_loss: 367691.1250 - val_mae: 426.8667\n",
      "Epoch 177/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321667.0625 - mae: 410.2237 - val_loss: 362942.4375 - val_mae: 424.5992\n",
      "Epoch 178/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321234.3750 - mae: 409.9042 - val_loss: 366671.3125 - val_mae: 426.8351\n",
      "Epoch 179/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321155.1875 - mae: 410.0725 - val_loss: 364997.3438 - val_mae: 425.8235\n",
      "Epoch 180/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321320.0625 - mae: 410.2191 - val_loss: 363912.7188 - val_mae: 425.8935\n",
      "Epoch 181/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321245.6562 - mae: 410.2910 - val_loss: 365013.6250 - val_mae: 425.1175\n",
      "Epoch 182/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321106.9062 - mae: 409.9238 - val_loss: 363078.7500 - val_mae: 424.1609\n",
      "Epoch 183/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321121.7188 - mae: 409.8957 - val_loss: 364698.9688 - val_mae: 425.7175\n",
      "Epoch 184/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321050.1250 - mae: 409.7347 - val_loss: 365704.9375 - val_mae: 425.9008\n",
      "Epoch 185/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320511.2500 - mae: 409.6497 - val_loss: 363668.4375 - val_mae: 425.1106\n",
      "Epoch 186/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320613.6250 - mae: 409.3774 - val_loss: 363549.1875 - val_mae: 425.0794\n",
      "Epoch 187/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320434.8125 - mae: 409.6290 - val_loss: 363739.2812 - val_mae: 425.2368\n",
      "Epoch 188/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320688.7812 - mae: 409.4279 - val_loss: 365586.6875 - val_mae: 425.6450\n",
      "Epoch 189/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320581.2188 - mae: 409.6716 - val_loss: 364772.1562 - val_mae: 424.7574\n",
      "Epoch 190/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320524.0000 - mae: 409.1374 - val_loss: 362256.9688 - val_mae: 425.1155\n",
      "Epoch 191/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320354.8125 - mae: 409.5178 - val_loss: 363398.4688 - val_mae: 425.4276\n",
      "Epoch 192/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320402.4062 - mae: 409.6009 - val_loss: 362876.8125 - val_mae: 424.6193\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 35849420.0000 - mae: 5838.4570 - val_loss: 29824482.0000 - val_mae: 5347.8140\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 21549450.0000 - mae: 4478.9365 - val_loss: 13698931.0000 - val_mae: 3523.8625\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 8648447.0000 - mae: 2616.4045 - val_loss: 4836432.5000 - val_mae: 1849.5697\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3078154.0000 - mae: 1357.9800 - val_loss: 1897583.1250 - val_mae: 1031.8270\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1456672.2500 - mae: 868.2189 - val_loss: 1114415.8750 - val_mae: 768.0497\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 978000.9375 - mae: 712.5829 - val_loss: 837591.6250 - val_mae: 669.6379\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 763665.9375 - mae: 636.5831 - val_loss: 684394.0000 - val_mae: 610.2450\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 636116.5000 - mae: 584.8168 - val_loss: 591650.5000 - val_mae: 567.4891\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558346.8125 - mae: 549.5632 - val_loss: 538805.5000 - val_mae: 540.0913\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 512917.7500 - mae: 527.3176 - val_loss: 511999.9062 - val_mae: 524.6364\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 486695.7188 - mae: 514.0245 - val_loss: 497995.6875 - val_mae: 514.4031\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 469249.6875 - mae: 504.3603 - val_loss: 489396.2188 - val_mae: 506.8957\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 456812.4062 - mae: 497.1000 - val_loss: 478878.1562 - val_mae: 501.1076\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 446843.9375 - mae: 491.5039 - val_loss: 477475.2188 - val_mae: 497.7705\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439618.8125 - mae: 488.1403 - val_loss: 473310.7500 - val_mae: 493.5008\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432778.2812 - mae: 483.7570 - val_loss: 469327.8750 - val_mae: 491.5308\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426983.4062 - mae: 480.6599 - val_loss: 470338.6875 - val_mae: 488.8261\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421889.3750 - mae: 477.0793 - val_loss: 463972.0000 - val_mae: 486.3905\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417370.8125 - mae: 474.6773 - val_loss: 459858.8750 - val_mae: 483.2541\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414011.9375 - mae: 471.9316 - val_loss: 459144.0312 - val_mae: 482.6310\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410463.4688 - mae: 469.8882 - val_loss: 459119.4688 - val_mae: 481.3672\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407533.9688 - mae: 467.4600 - val_loss: 457902.9062 - val_mae: 479.0023\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404630.0000 - mae: 465.2933 - val_loss: 454134.5625 - val_mae: 477.8981\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401603.3750 - mae: 463.2828 - val_loss: 454735.3750 - val_mae: 476.0836\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399487.4062 - mae: 461.1768 - val_loss: 452094.2812 - val_mae: 475.9769\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396649.3125 - mae: 459.4038 - val_loss: 449949.3750 - val_mae: 472.6472\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394580.5000 - mae: 457.7690 - val_loss: 452904.1875 - val_mae: 472.8969\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392595.5938 - mae: 455.7202 - val_loss: 447250.1562 - val_mae: 470.8517\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390410.3125 - mae: 454.1841 - val_loss: 446189.2188 - val_mae: 470.4750\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389476.8438 - mae: 453.6572 - val_loss: 446165.5000 - val_mae: 469.3484\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 387866.0000 - mae: 452.6631 - val_loss: 442702.7500 - val_mae: 468.4835\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386192.7188 - mae: 451.1731 - val_loss: 441748.1250 - val_mae: 467.6095\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 385209.6875 - mae: 450.4549 - val_loss: 438452.0000 - val_mae: 467.5179\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 383828.8750 - mae: 449.8043 - val_loss: 437465.9375 - val_mae: 466.5552\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382347.0000 - mae: 448.4819 - val_loss: 438138.8750 - val_mae: 466.5660\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 380712.7500 - mae: 447.6511 - val_loss: 438280.9062 - val_mae: 464.1414\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 380014.3750 - mae: 446.8059 - val_loss: 437499.7500 - val_mae: 463.5916\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 378734.1250 - mae: 445.3404 - val_loss: 433401.2188 - val_mae: 462.8539\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377473.3125 - mae: 444.9890 - val_loss: 434712.0000 - val_mae: 462.8417\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377014.7188 - mae: 444.2704 - val_loss: 434957.7500 - val_mae: 462.6915\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374733.0625 - mae: 443.1985 - val_loss: 434810.3438 - val_mae: 462.1169\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374262.4375 - mae: 442.3890 - val_loss: 429834.5938 - val_mae: 460.6587\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373168.5938 - mae: 441.6678 - val_loss: 428015.4688 - val_mae: 459.9040\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 372085.2812 - mae: 441.3016 - val_loss: 429970.3125 - val_mae: 459.1664\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370879.4375 - mae: 440.1350 - val_loss: 427216.2500 - val_mae: 457.9820\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370443.2188 - mae: 439.7046 - val_loss: 428515.2500 - val_mae: 458.3917\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369512.9062 - mae: 439.6343 - val_loss: 427669.5625 - val_mae: 458.3687\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368159.0938 - mae: 438.1811 - val_loss: 425749.9375 - val_mae: 456.5833\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367673.7812 - mae: 438.1369 - val_loss: 427578.3750 - val_mae: 456.3838\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367290.0000 - mae: 437.5709 - val_loss: 423367.6875 - val_mae: 455.9620\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366215.1250 - mae: 436.7135 - val_loss: 423099.4062 - val_mae: 455.3384\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365091.0000 - mae: 436.3654 - val_loss: 422900.6562 - val_mae: 455.0921\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364345.7500 - mae: 435.4669 - val_loss: 418868.5938 - val_mae: 453.2203\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363772.1875 - mae: 435.2591 - val_loss: 420447.2500 - val_mae: 452.5887\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362695.1250 - mae: 434.8845 - val_loss: 420373.6250 - val_mae: 451.8462\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362102.0000 - mae: 434.1391 - val_loss: 419509.1875 - val_mae: 451.1750\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361410.0312 - mae: 433.4360 - val_loss: 417238.7812 - val_mae: 450.7126\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359450.4375 - mae: 432.4036 - val_loss: 416671.0312 - val_mae: 450.9074\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358357.4688 - mae: 431.6034 - val_loss: 416373.1250 - val_mae: 448.2434\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356538.6562 - mae: 430.3072 - val_loss: 415188.5312 - val_mae: 449.3636\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355999.4688 - mae: 430.1343 - val_loss: 414795.2188 - val_mae: 446.8428\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354977.4062 - mae: 429.4396 - val_loss: 414976.1250 - val_mae: 446.0057\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353874.1562 - mae: 428.5215 - val_loss: 412509.4688 - val_mae: 447.8402\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353183.8125 - mae: 428.1731 - val_loss: 408992.8438 - val_mae: 445.8736\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352482.8125 - mae: 427.7837 - val_loss: 408780.6562 - val_mae: 446.1409\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351691.1875 - mae: 427.6630 - val_loss: 412030.4688 - val_mae: 445.4984\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351627.1875 - mae: 426.8099 - val_loss: 409554.5938 - val_mae: 446.2719\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351056.7188 - mae: 426.8464 - val_loss: 412325.3438 - val_mae: 445.0735\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350368.9375 - mae: 426.4548 - val_loss: 407244.0938 - val_mae: 443.5963\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350154.0938 - mae: 426.0653 - val_loss: 405210.1562 - val_mae: 442.7384\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349343.4375 - mae: 425.5495 - val_loss: 404753.8125 - val_mae: 443.0973\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349161.5938 - mae: 425.8358 - val_loss: 409583.8125 - val_mae: 443.0830\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348750.4688 - mae: 425.4002 - val_loss: 410228.3750 - val_mae: 443.4428\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348494.4688 - mae: 425.6159 - val_loss: 404548.9375 - val_mae: 442.4186\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347986.1250 - mae: 425.3903 - val_loss: 408481.0938 - val_mae: 443.6566\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347611.8125 - mae: 424.7897 - val_loss: 402768.3750 - val_mae: 441.9852\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347339.9688 - mae: 424.4720 - val_loss: 403538.5938 - val_mae: 441.0208\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346794.3438 - mae: 423.6392 - val_loss: 402868.6250 - val_mae: 440.8161\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346331.5312 - mae: 423.4456 - val_loss: 401675.5938 - val_mae: 441.0086\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346050.9688 - mae: 423.8890 - val_loss: 403233.4375 - val_mae: 440.6004\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345563.6250 - mae: 423.0607 - val_loss: 403931.1875 - val_mae: 441.0069\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345030.5000 - mae: 422.7237 - val_loss: 402609.1562 - val_mae: 440.6246\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344853.5312 - mae: 422.6023 - val_loss: 403681.2812 - val_mae: 440.0824\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344526.5938 - mae: 422.6667 - val_loss: 407048.1250 - val_mae: 441.2818\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344345.1875 - mae: 422.0557 - val_loss: 400744.6562 - val_mae: 438.7914\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343926.5000 - mae: 422.5109 - val_loss: 401574.3125 - val_mae: 439.8202\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343836.7500 - mae: 421.7323 - val_loss: 398991.4688 - val_mae: 438.1909\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343231.2500 - mae: 421.7293 - val_loss: 397582.7812 - val_mae: 436.7899\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343141.1562 - mae: 421.3988 - val_loss: 396974.3438 - val_mae: 438.2982\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342849.3438 - mae: 421.2646 - val_loss: 400019.4375 - val_mae: 438.0004\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342378.1562 - mae: 421.0172 - val_loss: 399563.6562 - val_mae: 438.1145\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342068.8750 - mae: 420.5978 - val_loss: 394813.0312 - val_mae: 436.4762\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341756.9062 - mae: 420.9186 - val_loss: 397705.3125 - val_mae: 437.5555\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341706.1562 - mae: 420.6143 - val_loss: 394874.6875 - val_mae: 436.2592\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341627.3750 - mae: 420.3077 - val_loss: 398346.4375 - val_mae: 437.2699\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341605.1562 - mae: 420.2390 - val_loss: 395818.0938 - val_mae: 437.3366\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341284.7812 - mae: 420.0910 - val_loss: 393116.2188 - val_mae: 436.2231\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340942.2500 - mae: 420.3006 - val_loss: 399985.8750 - val_mae: 437.3756\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340240.1875 - mae: 419.5354 - val_loss: 393094.5000 - val_mae: 435.9184\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340496.5625 - mae: 419.9633 - val_loss: 395210.8438 - val_mae: 436.2527\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339202.1250 - mae: 419.2983 - val_loss: 397565.1562 - val_mae: 436.2566\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339621.2812 - mae: 419.7432 - val_loss: 397920.5000 - val_mae: 436.8701\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338954.3438 - mae: 418.8982 - val_loss: 392649.0312 - val_mae: 436.5822\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338999.8750 - mae: 419.0519 - val_loss: 393289.5625 - val_mae: 435.1877\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338745.9688 - mae: 418.6537 - val_loss: 393850.4375 - val_mae: 435.9041\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338608.0312 - mae: 418.5345 - val_loss: 392624.3750 - val_mae: 435.6295\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337722.4062 - mae: 418.7993 - val_loss: 391118.0000 - val_mae: 434.1477\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337801.8438 - mae: 418.4818 - val_loss: 393542.5000 - val_mae: 435.8135\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337571.3438 - mae: 418.8069 - val_loss: 391108.5000 - val_mae: 434.6766\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337054.7500 - mae: 417.9520 - val_loss: 390494.5312 - val_mae: 434.2400\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336931.2188 - mae: 418.5237 - val_loss: 392675.9375 - val_mae: 434.4432\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336373.5312 - mae: 418.2929 - val_loss: 389196.2188 - val_mae: 434.4060\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336061.3750 - mae: 417.7606 - val_loss: 389716.5625 - val_mae: 433.2881\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336098.8125 - mae: 417.7575 - val_loss: 386496.0000 - val_mae: 433.4566\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335517.3438 - mae: 417.4679 - val_loss: 387691.1875 - val_mae: 433.8199\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335623.6562 - mae: 417.7285 - val_loss: 388753.8438 - val_mae: 434.3142\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335136.0938 - mae: 417.9204 - val_loss: 392274.9688 - val_mae: 434.2559\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334966.8750 - mae: 417.6769 - val_loss: 391694.0000 - val_mae: 434.8716\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335208.3125 - mae: 417.2787 - val_loss: 388884.9375 - val_mae: 434.8265\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334760.4062 - mae: 416.9404 - val_loss: 388605.0938 - val_mae: 434.3925\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334789.0625 - mae: 417.4288 - val_loss: 386680.5938 - val_mae: 433.1466\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334991.9375 - mae: 417.5782 - val_loss: 387428.3125 - val_mae: 433.7184\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334825.0938 - mae: 417.4180 - val_loss: 386868.9375 - val_mae: 431.9326\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334259.0625 - mae: 417.0577 - val_loss: 389066.3125 - val_mae: 433.6578\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334465.4062 - mae: 416.9176 - val_loss: 389920.9688 - val_mae: 434.7507\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334462.4375 - mae: 417.0039 - val_loss: 386130.5312 - val_mae: 433.6853\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334473.0312 - mae: 417.5592 - val_loss: 387341.9375 - val_mae: 432.0757\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334063.5000 - mae: 416.3836 - val_loss: 391302.1562 - val_mae: 435.1134\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333943.7812 - mae: 417.1557 - val_loss: 386826.0000 - val_mae: 432.0660\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333943.2500 - mae: 416.8050 - val_loss: 387259.6562 - val_mae: 433.0180\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333944.3750 - mae: 416.7969 - val_loss: 384271.4688 - val_mae: 432.8976\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333736.2500 - mae: 416.6649 - val_loss: 384192.9375 - val_mae: 432.5878\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333844.1250 - mae: 417.0321 - val_loss: 386659.8750 - val_mae: 432.0951\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38065284.0000 - mae: 6015.5640 - val_loss: 36807288.0000 - val_mae: 5924.8604\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 34754732.0000 - mae: 5759.0278 - val_loss: 31917472.0000 - val_mae: 5535.0703\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 28786336.0000 - mae: 5253.1763 - val_loss: 25288606.0000 - val_mae: 4931.4458\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 21958978.0000 - mae: 4570.9722 - val_loss: 18644022.0000 - val_mae: 4194.8359\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 15703856.0000 - mae: 3799.4204 - val_loss: 12990717.0000 - val_mae: 3408.8325\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 10629955.0000 - mae: 3015.4634 - val_loss: 8579866.0000 - val_mae: 2653.4253\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6814436.5000 - mae: 2294.5066 - val_loss: 5377438.0000 - val_mae: 1988.9424\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4185777.7500 - mae: 1693.8318 - val_loss: 3289018.7500 - val_mae: 1472.4962\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2575249.5000 - mae: 1259.3417 - val_loss: 2076042.2500 - val_mae: 1120.2648\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1690062.5000 - mae: 989.7632 - val_loss: 1431248.7500 - val_mae: 911.8988\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1229244.6250 - mae: 836.1314 - val_loss: 1090879.2500 - val_mae: 791.0097\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 984444.8750 - mae: 748.1058 - val_loss: 902855.3125 - val_mae: 719.1823\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 844866.8750 - mae: 692.7360 - val_loss: 791776.1875 - val_mae: 671.8613\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 757786.1875 - mae: 653.9255 - val_loss: 720709.8750 - val_mae: 638.7027\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 699565.6250 - mae: 625.9102 - val_loss: 671910.6250 - val_mae: 614.4026\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 656943.5000 - mae: 604.9572 - val_loss: 634546.4375 - val_mae: 595.2042\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 623242.7500 - mae: 588.5018 - val_loss: 607295.4375 - val_mae: 580.2955\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596212.5000 - mae: 575.3761 - val_loss: 586049.3750 - val_mae: 568.7043\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 573787.6250 - mae: 564.7766 - val_loss: 569312.0625 - val_mae: 559.0356\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555174.8125 - mae: 554.9789 - val_loss: 554868.2500 - val_mae: 551.7097\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539298.6250 - mae: 547.8079 - val_loss: 543884.1875 - val_mae: 544.9507\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 526546.2500 - mae: 540.5864 - val_loss: 535020.6875 - val_mae: 539.6410\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 515058.3438 - mae: 535.2533 - val_loss: 527047.1875 - val_mae: 535.6688\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 505637.3438 - mae: 530.7659 - val_loss: 520583.6875 - val_mae: 531.6922\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 497101.8438 - mae: 526.0880 - val_loss: 514679.1250 - val_mae: 528.8986\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 489554.9688 - mae: 522.0967 - val_loss: 510405.1250 - val_mae: 525.3301\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482799.5625 - mae: 518.7318 - val_loss: 506127.1875 - val_mae: 522.2346\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 476507.0625 - mae: 514.6837 - val_loss: 500993.6562 - val_mae: 520.4216\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 470650.5312 - mae: 512.5286 - val_loss: 496584.4688 - val_mae: 517.1931\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 465525.3750 - mae: 509.3815 - val_loss: 493481.6250 - val_mae: 515.0812\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 460434.2812 - mae: 506.6782 - val_loss: 490986.9062 - val_mae: 512.7928\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 455451.5000 - mae: 503.6792 - val_loss: 487040.5938 - val_mae: 510.5244\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 451100.4375 - mae: 501.2115 - val_loss: 482973.0938 - val_mae: 508.1817\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 446785.7812 - mae: 498.6674 - val_loss: 479620.0938 - val_mae: 505.5647\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 442622.1250 - mae: 495.7697 - val_loss: 476092.7500 - val_mae: 504.4716\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438393.4062 - mae: 494.1257 - val_loss: 473657.6875 - val_mae: 502.0866\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 434654.7188 - mae: 490.9934 - val_loss: 470963.5312 - val_mae: 499.8284\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431172.0000 - mae: 489.1550 - val_loss: 469815.9375 - val_mae: 497.7499\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427850.7500 - mae: 486.3708 - val_loss: 465298.1562 - val_mae: 495.6852\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424609.9062 - mae: 484.4399 - val_loss: 464787.4688 - val_mae: 494.1916\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421860.5000 - mae: 482.8027 - val_loss: 461110.1562 - val_mae: 493.1097\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419109.5625 - mae: 481.5251 - val_loss: 458908.4062 - val_mae: 491.2035\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415926.2500 - mae: 479.3628 - val_loss: 457283.0312 - val_mae: 489.8548\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413710.5312 - mae: 478.2048 - val_loss: 454965.0625 - val_mae: 488.5357\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410956.6875 - mae: 476.5506 - val_loss: 452545.2500 - val_mae: 487.9729\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408604.4062 - mae: 475.3401 - val_loss: 452100.6250 - val_mae: 486.7917\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407112.2500 - mae: 474.5234 - val_loss: 451028.6562 - val_mae: 484.8682\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404779.5312 - mae: 472.3927 - val_loss: 449237.9688 - val_mae: 484.8967\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403058.0938 - mae: 471.6527 - val_loss: 447860.2188 - val_mae: 482.8554\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401381.5312 - mae: 470.4556 - val_loss: 445455.6562 - val_mae: 481.9401\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399745.4062 - mae: 469.0299 - val_loss: 444717.6250 - val_mae: 481.4091\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397643.1875 - mae: 467.6476 - val_loss: 443768.5938 - val_mae: 481.0439\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396233.2812 - mae: 466.6664 - val_loss: 441623.5000 - val_mae: 479.3762\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394189.4062 - mae: 465.4884 - val_loss: 438971.8750 - val_mae: 478.6679\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 392381.0000 - mae: 463.8246 - val_loss: 437927.5625 - val_mae: 477.8046\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390974.9375 - mae: 462.9875 - val_loss: 435579.4375 - val_mae: 475.2462\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389487.4062 - mae: 461.8644 - val_loss: 435372.6875 - val_mae: 475.4967\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388341.9062 - mae: 460.6103 - val_loss: 433915.7500 - val_mae: 474.8031\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386941.7188 - mae: 459.9532 - val_loss: 432487.1875 - val_mae: 474.9177\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385714.6250 - mae: 459.2604 - val_loss: 432296.9688 - val_mae: 472.8314\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384122.4375 - mae: 457.6840 - val_loss: 430416.3750 - val_mae: 473.0418\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383127.9062 - mae: 457.0539 - val_loss: 428355.9375 - val_mae: 472.1592\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381469.5938 - mae: 455.9334 - val_loss: 426724.6562 - val_mae: 471.2209\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380423.9688 - mae: 455.0255 - val_loss: 426123.1875 - val_mae: 469.9319\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379158.2500 - mae: 454.0459 - val_loss: 424845.3438 - val_mae: 468.9969\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378084.1875 - mae: 452.8198 - val_loss: 421756.2500 - val_mae: 468.4994\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377149.8438 - mae: 453.1860 - val_loss: 422556.7500 - val_mae: 466.7288\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376430.6250 - mae: 452.2313 - val_loss: 420860.6562 - val_mae: 467.8862\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375369.3438 - mae: 451.8195 - val_loss: 419147.4688 - val_mae: 467.0889\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374525.2500 - mae: 451.2287 - val_loss: 418622.2500 - val_mae: 467.5847\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374313.5625 - mae: 450.8772 - val_loss: 417257.4375 - val_mae: 465.5331\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373126.2812 - mae: 450.5524 - val_loss: 417202.6250 - val_mae: 465.5941\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372419.5625 - mae: 449.7242 - val_loss: 415593.7500 - val_mae: 465.8194\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371996.5000 - mae: 449.7009 - val_loss: 414206.7500 - val_mae: 463.6117\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371419.3125 - mae: 449.1144 - val_loss: 412414.9688 - val_mae: 463.6129\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370573.4062 - mae: 448.8320 - val_loss: 414076.5312 - val_mae: 462.5577\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370151.1875 - mae: 448.3329 - val_loss: 410868.5000 - val_mae: 462.7400\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369385.2188 - mae: 447.7113 - val_loss: 410238.9062 - val_mae: 462.7300\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368547.6562 - mae: 447.4232 - val_loss: 409947.8125 - val_mae: 461.3132\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367871.0938 - mae: 446.4395 - val_loss: 408815.1875 - val_mae: 462.2751\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367234.2812 - mae: 446.4770 - val_loss: 409143.3750 - val_mae: 461.0286\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366628.9375 - mae: 445.7656 - val_loss: 408135.9375 - val_mae: 460.8338\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365637.4688 - mae: 445.5117 - val_loss: 405768.7812 - val_mae: 460.5771\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365092.0625 - mae: 444.4334 - val_loss: 405321.6562 - val_mae: 460.8770\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364436.7500 - mae: 444.4302 - val_loss: 404467.7500 - val_mae: 459.2617\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363857.5312 - mae: 444.4966 - val_loss: 403623.0625 - val_mae: 458.5981\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363139.5000 - mae: 443.5419 - val_loss: 402489.3438 - val_mae: 457.7531\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362627.4062 - mae: 443.3872 - val_loss: 401773.3750 - val_mae: 457.7653\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362110.0938 - mae: 443.2361 - val_loss: 401811.9062 - val_mae: 457.3656\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361260.5312 - mae: 442.5135 - val_loss: 399897.2188 - val_mae: 457.8160\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360480.8438 - mae: 442.3299 - val_loss: 399218.3438 - val_mae: 455.7358\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359506.5938 - mae: 441.4117 - val_loss: 398375.9062 - val_mae: 456.2776\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358704.1875 - mae: 441.2813 - val_loss: 396686.8438 - val_mae: 454.2642\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357979.6562 - mae: 440.8090 - val_loss: 396014.2188 - val_mae: 455.6605\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357411.4375 - mae: 440.6847 - val_loss: 395304.1250 - val_mae: 454.7887\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356751.3125 - mae: 440.0844 - val_loss: 394941.5312 - val_mae: 454.0997\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355953.0312 - mae: 440.0456 - val_loss: 394537.8750 - val_mae: 453.5205\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355430.1250 - mae: 439.1342 - val_loss: 392356.9688 - val_mae: 453.1466\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354335.0000 - mae: 438.6921 - val_loss: 393137.3750 - val_mae: 453.7316\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353680.0000 - mae: 438.6769 - val_loss: 392136.6875 - val_mae: 452.8389\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353047.3438 - mae: 437.9791 - val_loss: 391995.7188 - val_mae: 452.4064\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352287.3750 - mae: 437.7058 - val_loss: 391370.7188 - val_mae: 452.6402\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351704.0625 - mae: 437.6248 - val_loss: 390946.5625 - val_mae: 450.7868\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351003.7812 - mae: 436.9182 - val_loss: 390187.0625 - val_mae: 449.9519\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350832.8750 - mae: 436.4567 - val_loss: 389648.7812 - val_mae: 449.7620\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350035.8125 - mae: 436.2356 - val_loss: 387636.9375 - val_mae: 449.1962\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349224.3438 - mae: 435.5493 - val_loss: 386862.6562 - val_mae: 449.6665\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348675.2188 - mae: 435.2308 - val_loss: 386639.0625 - val_mae: 450.1981\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348403.4375 - mae: 434.7734 - val_loss: 386815.5625 - val_mae: 449.3396\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347764.1562 - mae: 434.6378 - val_loss: 385721.1250 - val_mae: 448.2954\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346920.5312 - mae: 433.7081 - val_loss: 386832.7500 - val_mae: 450.6527\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346493.0000 - mae: 433.6682 - val_loss: 386361.5625 - val_mae: 448.6902\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345936.0938 - mae: 433.5412 - val_loss: 386614.1562 - val_mae: 445.8859\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345743.1562 - mae: 432.5158 - val_loss: 383438.6562 - val_mae: 446.6725\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345163.9688 - mae: 432.4683 - val_loss: 382941.9062 - val_mae: 446.9312\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344801.9688 - mae: 432.2377 - val_loss: 383405.2500 - val_mae: 446.3001\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344315.0938 - mae: 432.4823 - val_loss: 383088.9688 - val_mae: 445.5126\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343944.5625 - mae: 431.2800 - val_loss: 382061.5938 - val_mae: 446.8469\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343176.2812 - mae: 431.2827 - val_loss: 382783.7812 - val_mae: 447.1008\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343254.3125 - mae: 431.3813 - val_loss: 380596.1250 - val_mae: 445.0862\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342624.5938 - mae: 430.7617 - val_loss: 380497.7500 - val_mae: 443.3800\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342806.6562 - mae: 431.1110 - val_loss: 381083.6875 - val_mae: 444.4049\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342003.5312 - mae: 430.1025 - val_loss: 380320.6875 - val_mae: 444.8030\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341697.8125 - mae: 430.2144 - val_loss: 380437.8438 - val_mae: 444.2066\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341652.0312 - mae: 429.8967 - val_loss: 378593.1250 - val_mae: 443.4717\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341466.5938 - mae: 429.6510 - val_loss: 378698.8750 - val_mae: 443.4276\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340905.4062 - mae: 429.3586 - val_loss: 380029.3438 - val_mae: 442.9957\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340314.7812 - mae: 428.8496 - val_loss: 378610.0000 - val_mae: 441.5860\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340436.5938 - mae: 428.8726 - val_loss: 378234.3438 - val_mae: 442.8701\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340200.4688 - mae: 428.8264 - val_loss: 378209.3438 - val_mae: 442.7463\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339915.6250 - mae: 428.6502 - val_loss: 376512.3438 - val_mae: 442.2014\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339508.5312 - mae: 428.1086 - val_loss: 376446.4688 - val_mae: 442.5290\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339138.0938 - mae: 428.2369 - val_loss: 377620.3125 - val_mae: 442.4765\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339030.0000 - mae: 427.7797 - val_loss: 376395.2500 - val_mae: 440.9791\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338419.7812 - mae: 427.4091 - val_loss: 376901.8125 - val_mae: 442.5799\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338548.3438 - mae: 427.5120 - val_loss: 377366.3750 - val_mae: 440.7828\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338297.4062 - mae: 426.9883 - val_loss: 375140.3750 - val_mae: 442.2355\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337965.2188 - mae: 426.8404 - val_loss: 375081.3438 - val_mae: 440.9652\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337620.8438 - mae: 426.6840 - val_loss: 375607.8750 - val_mae: 440.8998\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337594.8750 - mae: 426.8401 - val_loss: 375193.4062 - val_mae: 440.6102\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337355.3438 - mae: 426.7069 - val_loss: 374634.5312 - val_mae: 439.7211\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336815.8125 - mae: 426.0530 - val_loss: 374679.3750 - val_mae: 438.9499\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336667.3750 - mae: 425.7158 - val_loss: 374300.6250 - val_mae: 440.3632\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336399.3438 - mae: 425.6649 - val_loss: 375368.2188 - val_mae: 438.9540\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336286.2188 - mae: 425.4919 - val_loss: 375021.8750 - val_mae: 440.8337\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335915.1875 - mae: 425.4489 - val_loss: 373778.5625 - val_mae: 438.7459\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335766.7500 - mae: 425.0630 - val_loss: 374074.9062 - val_mae: 441.0836\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335760.6875 - mae: 425.4228 - val_loss: 372966.8750 - val_mae: 439.5120\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335373.6875 - mae: 424.9901 - val_loss: 372544.5000 - val_mae: 438.7111\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335012.1875 - mae: 424.9989 - val_loss: 372940.9062 - val_mae: 437.2097\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335125.4375 - mae: 424.3479 - val_loss: 371974.1875 - val_mae: 437.9837\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334709.2812 - mae: 424.4973 - val_loss: 372339.3438 - val_mae: 437.8472\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334523.8438 - mae: 424.3080 - val_loss: 370785.0000 - val_mae: 437.4025\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334496.0625 - mae: 424.0950 - val_loss: 370157.2812 - val_mae: 436.8491\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334065.9688 - mae: 424.1433 - val_loss: 371997.6562 - val_mae: 435.9434\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333989.1875 - mae: 423.7306 - val_loss: 370446.0625 - val_mae: 437.2852\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333665.7500 - mae: 423.9850 - val_loss: 372047.6250 - val_mae: 436.5588\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333352.7812 - mae: 423.6463 - val_loss: 370932.8750 - val_mae: 436.5456\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333157.7188 - mae: 423.5702 - val_loss: 370770.5312 - val_mae: 435.5634\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333231.2812 - mae: 423.6547 - val_loss: 370943.8125 - val_mae: 435.2581\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332700.6562 - mae: 422.6830 - val_loss: 369588.4062 - val_mae: 438.2789\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332462.5312 - mae: 422.9041 - val_loss: 370272.4375 - val_mae: 437.6904\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332550.5000 - mae: 423.3057 - val_loss: 370120.5000 - val_mae: 435.3275\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332341.9688 - mae: 422.5342 - val_loss: 370390.5938 - val_mae: 436.2989\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331882.7812 - mae: 422.8428 - val_loss: 369827.3438 - val_mae: 436.1557\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331844.7188 - mae: 422.4648 - val_loss: 370394.3750 - val_mae: 435.6006\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331713.9062 - mae: 422.1893 - val_loss: 369353.1250 - val_mae: 435.8062\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331468.3125 - mae: 422.3642 - val_loss: 368993.2188 - val_mae: 434.5550\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330935.1250 - mae: 421.6674 - val_loss: 369143.5625 - val_mae: 436.9841\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331131.6562 - mae: 422.6438 - val_loss: 368469.6875 - val_mae: 433.5601\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331086.6250 - mae: 421.6533 - val_loss: 368617.0625 - val_mae: 435.8972\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330724.9375 - mae: 421.8790 - val_loss: 367833.0000 - val_mae: 433.5130\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330506.6562 - mae: 421.4702 - val_loss: 368575.1562 - val_mae: 433.8317\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330590.1875 - mae: 420.9904 - val_loss: 367770.0938 - val_mae: 434.1075\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330028.3438 - mae: 421.0597 - val_loss: 368706.6562 - val_mae: 434.3095\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330173.9062 - mae: 421.1368 - val_loss: 367429.9062 - val_mae: 434.0938\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329479.1250 - mae: 420.9790 - val_loss: 368651.9375 - val_mae: 432.0682\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329467.5625 - mae: 420.4849 - val_loss: 366991.4062 - val_mae: 431.9601\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329345.9375 - mae: 420.2650 - val_loss: 367041.3750 - val_mae: 433.8488\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329161.4375 - mae: 420.3504 - val_loss: 367260.6250 - val_mae: 433.3947\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329081.0625 - mae: 420.2448 - val_loss: 366533.3438 - val_mae: 432.2807\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328941.6562 - mae: 419.9664 - val_loss: 366174.6875 - val_mae: 433.2758\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328590.3125 - mae: 420.2878 - val_loss: 366056.0938 - val_mae: 431.4037\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328632.7500 - mae: 419.8535 - val_loss: 365211.9688 - val_mae: 431.8590\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328423.3750 - mae: 420.0507 - val_loss: 366693.9062 - val_mae: 431.7307\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328289.3750 - mae: 419.2664 - val_loss: 366053.9062 - val_mae: 433.2523\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328125.6875 - mae: 419.6079 - val_loss: 365814.9062 - val_mae: 433.3634\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327954.4062 - mae: 419.4606 - val_loss: 364514.5312 - val_mae: 431.3403\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328065.5938 - mae: 419.3059 - val_loss: 365735.9062 - val_mae: 432.1113\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327570.9062 - mae: 419.3309 - val_loss: 364612.6875 - val_mae: 431.1172\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327569.7812 - mae: 418.8079 - val_loss: 364912.6250 - val_mae: 431.1568\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327433.4375 - mae: 419.0928 - val_loss: 365305.5625 - val_mae: 432.1785\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327296.3750 - mae: 418.9083 - val_loss: 365095.2812 - val_mae: 431.1131\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327025.4688 - mae: 418.3358 - val_loss: 366846.3438 - val_mae: 435.8177\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327047.4375 - mae: 419.1834 - val_loss: 365262.5625 - val_mae: 431.6421\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326755.6562 - mae: 418.6127 - val_loss: 365416.3125 - val_mae: 430.7320\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326868.7500 - mae: 418.3439 - val_loss: 364030.6250 - val_mae: 431.1900\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326615.5938 - mae: 418.4895 - val_loss: 363936.3750 - val_mae: 431.0345\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326667.0938 - mae: 418.4561 - val_loss: 364491.8750 - val_mae: 431.4701\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326396.1562 - mae: 418.3737 - val_loss: 364057.7812 - val_mae: 430.5126\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326450.4688 - mae: 418.0381 - val_loss: 364298.6250 - val_mae: 431.1640\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326234.6562 - mae: 418.0843 - val_loss: 364457.4688 - val_mae: 430.6164\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326198.0938 - mae: 418.0593 - val_loss: 362946.5312 - val_mae: 429.8800\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325779.7188 - mae: 418.0644 - val_loss: 363740.2188 - val_mae: 430.5719\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326126.1250 - mae: 417.8727 - val_loss: 363583.0938 - val_mae: 430.1223\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325697.5000 - mae: 417.5396 - val_loss: 364741.9062 - val_mae: 431.7849\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325657.5312 - mae: 417.9088 - val_loss: 365020.2812 - val_mae: 431.5587\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325450.3438 - mae: 417.7744 - val_loss: 364629.4688 - val_mae: 429.2764\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325382.0000 - mae: 417.4854 - val_loss: 364235.9688 - val_mae: 431.4695\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325718.1875 - mae: 417.7602 - val_loss: 363448.1562 - val_mae: 430.1838\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325221.2500 - mae: 417.3245 - val_loss: 363271.5312 - val_mae: 429.9323\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325155.8750 - mae: 417.1842 - val_loss: 363824.4375 - val_mae: 431.0121\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325162.2188 - mae: 417.2246 - val_loss: 363672.7500 - val_mae: 429.4121\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325116.6250 - mae: 417.3976 - val_loss: 363794.2188 - val_mae: 428.6813\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324807.5625 - mae: 416.4720 - val_loss: 363961.8438 - val_mae: 431.7344\n",
      "Epoch 216/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324996.4375 - mae: 417.2204 - val_loss: 362450.4062 - val_mae: 429.8817\n",
      "Epoch 217/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324611.3438 - mae: 417.2380 - val_loss: 363760.2188 - val_mae: 428.6255\n",
      "Epoch 218/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324641.6562 - mae: 416.8309 - val_loss: 363077.1875 - val_mae: 429.5523\n",
      "Epoch 219/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324790.7188 - mae: 416.9085 - val_loss: 362667.7812 - val_mae: 428.7260\n",
      "Epoch 220/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324479.0625 - mae: 416.8744 - val_loss: 362728.8438 - val_mae: 429.4895\n",
      "Epoch 221/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324217.5938 - mae: 417.2096 - val_loss: 364378.0625 - val_mae: 427.2051\n",
      "Epoch 222/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324265.3438 - mae: 416.1432 - val_loss: 364368.8750 - val_mae: 430.6806\n",
      "Epoch 223/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324191.0000 - mae: 416.6873 - val_loss: 362326.9688 - val_mae: 428.9597\n",
      "Epoch 224/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324317.5000 - mae: 416.6762 - val_loss: 361848.3750 - val_mae: 428.2394\n",
      "Epoch 225/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323770.9688 - mae: 416.1874 - val_loss: 362918.5625 - val_mae: 429.0481\n",
      "Epoch 226/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323880.2188 - mae: 416.4138 - val_loss: 362559.0938 - val_mae: 429.2336\n",
      "Epoch 227/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324032.9688 - mae: 416.1584 - val_loss: 362623.3750 - val_mae: 428.8305\n",
      "Epoch 228/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323806.1875 - mae: 416.6860 - val_loss: 362290.0312 - val_mae: 428.3464\n",
      "Epoch 229/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323818.9688 - mae: 416.0063 - val_loss: 362256.1250 - val_mae: 430.1090\n",
      "Epoch 230/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323582.0000 - mae: 416.4285 - val_loss: 363325.0312 - val_mae: 428.7993\n",
      "Epoch 231/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323811.8125 - mae: 415.9493 - val_loss: 361849.3125 - val_mae: 428.7127\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38012008.0000 - mae: 6009.9067 - val_loss: 36238588.0000 - val_mae: 5879.9175\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 32720816.0000 - mae: 5593.9971 - val_loss: 28296954.0000 - val_mae: 5222.7915\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 23605032.0000 - mae: 4760.1421 - val_loss: 18909838.0000 - val_mae: 4256.2383\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 14832302.0000 - mae: 3717.0430 - val_loss: 11283247.0000 - val_mae: 3197.7581\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 8458936.0000 - mae: 2691.6135 - val_loss: 6258467.0000 - val_mae: 2261.0645\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4567510.0000 - mae: 1854.4789 - val_loss: 3380157.0000 - val_mae: 1557.1738\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2489466.5000 - mae: 1277.3254 - val_loss: 1953370.0000 - val_mae: 1115.1556\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1531001.2500 - mae: 944.1337 - val_loss: 1328505.3750 - val_mae: 873.5448\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1123816.0000 - mae: 777.9338 - val_loss: 1052710.8750 - val_mae: 757.0441\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 941644.7500 - mae: 703.6537 - val_loss: 920576.0000 - val_mae: 701.8098\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 843409.1250 - mae: 664.2676 - val_loss: 841350.6250 - val_mae: 668.9058\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 781456.0625 - mae: 638.0446 - val_loss: 787378.0625 - val_mae: 645.4761\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 736365.6875 - mae: 618.8926 - val_loss: 746664.0625 - val_mae: 627.6425\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 700884.0000 - mae: 603.4977 - val_loss: 713898.0000 - val_mae: 612.8661\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 671392.5000 - mae: 589.7909 - val_loss: 686410.6250 - val_mae: 600.8827\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 646874.1250 - mae: 579.6503 - val_loss: 662671.5000 - val_mae: 589.7488\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 625008.2500 - mae: 569.9031 - val_loss: 642028.4375 - val_mae: 580.3892\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606064.8125 - mae: 561.0500 - val_loss: 624302.5625 - val_mae: 571.4451\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588963.5625 - mae: 553.3196 - val_loss: 608074.0625 - val_mae: 563.9078\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 574666.2500 - mae: 547.0113 - val_loss: 594755.7500 - val_mae: 556.2321\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561761.3125 - mae: 540.8081 - val_loss: 581988.4375 - val_mae: 550.2986\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549894.0625 - mae: 535.0365 - val_loss: 571342.0000 - val_mae: 545.5261\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539442.7500 - mae: 530.1224 - val_loss: 563806.6250 - val_mae: 540.5880\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529957.1250 - mae: 525.8304 - val_loss: 553957.8125 - val_mae: 535.4530\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 521647.1875 - mae: 521.7597 - val_loss: 546247.2500 - val_mae: 531.6534\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 514016.5938 - mae: 518.0844 - val_loss: 540794.8125 - val_mae: 529.4911\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 506887.4062 - mae: 514.6637 - val_loss: 534159.1875 - val_mae: 525.8466\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 500989.0625 - mae: 511.7015 - val_loss: 528651.2500 - val_mae: 524.5261\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 495915.5000 - mae: 509.9707 - val_loss: 525591.5000 - val_mae: 522.1285\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 490153.7500 - mae: 507.5282 - val_loss: 520090.5312 - val_mae: 518.9699\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 485138.9375 - mae: 504.2927 - val_loss: 514365.4688 - val_mae: 517.6888\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 480232.3438 - mae: 502.8142 - val_loss: 509888.5625 - val_mae: 514.1426\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 475999.9688 - mae: 500.3387 - val_loss: 506355.1875 - val_mae: 513.7951\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 472209.9375 - mae: 498.7673 - val_loss: 500183.3125 - val_mae: 512.0279\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 467523.2500 - mae: 496.9325 - val_loss: 495495.1562 - val_mae: 510.1295\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 463640.9375 - mae: 495.0137 - val_loss: 490549.5938 - val_mae: 507.0980\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 458492.3438 - mae: 492.4203 - val_loss: 485449.6562 - val_mae: 503.9089\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 453860.4062 - mae: 489.4300 - val_loss: 480631.6875 - val_mae: 501.5021\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 448958.9375 - mae: 487.0679 - val_loss: 475753.1562 - val_mae: 497.8360\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444623.2188 - mae: 484.3001 - val_loss: 469615.2500 - val_mae: 495.4832\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440743.8125 - mae: 482.2530 - val_loss: 468403.8750 - val_mae: 494.9552\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436723.3125 - mae: 480.5875 - val_loss: 464846.9062 - val_mae: 491.7953\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 433701.7500 - mae: 479.1515 - val_loss: 460475.8438 - val_mae: 489.5630\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430774.8125 - mae: 477.7116 - val_loss: 457793.8125 - val_mae: 488.5063\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427486.1562 - mae: 475.8956 - val_loss: 455235.9375 - val_mae: 488.7168\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424224.2188 - mae: 474.1764 - val_loss: 450197.5312 - val_mae: 488.0087\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420996.9062 - mae: 472.7081 - val_loss: 449879.1562 - val_mae: 484.2068\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418282.5000 - mae: 471.4015 - val_loss: 446728.0312 - val_mae: 483.6393\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415951.1875 - mae: 469.7937 - val_loss: 444034.3438 - val_mae: 483.7600\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413307.8125 - mae: 468.2250 - val_loss: 442097.3750 - val_mae: 484.4645\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410865.7812 - mae: 467.9165 - val_loss: 438895.0312 - val_mae: 480.2797\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408567.2812 - mae: 466.5334 - val_loss: 437614.5000 - val_mae: 479.9067\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406638.0938 - mae: 465.1212 - val_loss: 434767.8438 - val_mae: 479.2258\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404260.5625 - mae: 464.4537 - val_loss: 432348.4375 - val_mae: 477.1462\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401924.0000 - mae: 463.0471 - val_loss: 431151.7188 - val_mae: 478.1664\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400078.7500 - mae: 461.9054 - val_loss: 427771.6875 - val_mae: 475.1463\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397421.6250 - mae: 460.9408 - val_loss: 427819.9375 - val_mae: 474.6714\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396001.0938 - mae: 459.6562 - val_loss: 423919.6562 - val_mae: 473.0660\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393638.8750 - mae: 458.6469 - val_loss: 424180.8438 - val_mae: 472.4298\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 392295.1562 - mae: 457.4679 - val_loss: 421855.5312 - val_mae: 471.7630\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390708.5938 - mae: 457.3455 - val_loss: 420348.5312 - val_mae: 468.8753\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389837.1250 - mae: 455.8488 - val_loss: 419956.8750 - val_mae: 471.0967\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388560.4062 - mae: 456.0037 - val_loss: 417442.6562 - val_mae: 469.0743\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387344.7500 - mae: 454.9620 - val_loss: 416414.0312 - val_mae: 469.6924\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386755.1875 - mae: 455.1105 - val_loss: 414937.2188 - val_mae: 466.3578\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385683.0000 - mae: 454.0717 - val_loss: 413700.5312 - val_mae: 467.9982\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384915.3125 - mae: 453.7344 - val_loss: 413382.5938 - val_mae: 467.5343\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384085.5938 - mae: 453.4433 - val_loss: 411376.2500 - val_mae: 466.0534\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383181.1875 - mae: 453.5388 - val_loss: 410353.0312 - val_mae: 465.6721\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382846.9375 - mae: 452.6700 - val_loss: 411706.4688 - val_mae: 466.5106\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381845.6875 - mae: 452.0552 - val_loss: 410906.8438 - val_mae: 464.7105\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381033.8438 - mae: 451.9171 - val_loss: 409734.8438 - val_mae: 465.6158\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380740.4062 - mae: 451.6740 - val_loss: 407348.9062 - val_mae: 463.6506\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379765.9375 - mae: 451.3271 - val_loss: 408735.5625 - val_mae: 463.8105\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379307.0938 - mae: 451.1452 - val_loss: 405980.5000 - val_mae: 462.8695\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378662.3750 - mae: 450.5054 - val_loss: 404659.5000 - val_mae: 462.7990\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378075.2188 - mae: 450.1509 - val_loss: 404079.9375 - val_mae: 461.7291\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377605.5000 - mae: 449.9944 - val_loss: 404087.1875 - val_mae: 462.6317\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376866.5000 - mae: 449.6135 - val_loss: 404242.0312 - val_mae: 461.3711\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376153.0312 - mae: 448.8731 - val_loss: 402693.7812 - val_mae: 461.0875\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375608.7500 - mae: 448.5214 - val_loss: 400362.0625 - val_mae: 460.3885\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375087.9375 - mae: 448.2897 - val_loss: 402013.9688 - val_mae: 460.3769\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374460.5938 - mae: 447.9883 - val_loss: 399490.8750 - val_mae: 459.3972\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373613.3438 - mae: 447.0727 - val_loss: 398369.0938 - val_mae: 458.8569\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372830.6562 - mae: 446.5343 - val_loss: 398801.7188 - val_mae: 461.5450\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372134.7188 - mae: 446.5984 - val_loss: 396237.1250 - val_mae: 458.4892\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371586.4375 - mae: 446.4110 - val_loss: 399103.4688 - val_mae: 458.5253\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371422.5312 - mae: 445.3997 - val_loss: 395024.2188 - val_mae: 457.2121\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369904.0312 - mae: 444.7832 - val_loss: 395780.5312 - val_mae: 458.0222\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369706.1562 - mae: 444.1786 - val_loss: 395752.0000 - val_mae: 456.9063\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369379.3750 - mae: 444.2204 - val_loss: 393117.0000 - val_mae: 457.1650\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368896.2188 - mae: 443.5996 - val_loss: 393433.6250 - val_mae: 455.6023\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368192.0000 - mae: 443.8035 - val_loss: 393700.0625 - val_mae: 455.3231\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367983.7500 - mae: 443.0421 - val_loss: 392605.8750 - val_mae: 455.2326\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367469.7812 - mae: 442.9882 - val_loss: 391429.0625 - val_mae: 454.8909\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367162.9688 - mae: 442.9078 - val_loss: 390875.5000 - val_mae: 454.9560\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366935.2188 - mae: 442.1522 - val_loss: 390042.7812 - val_mae: 453.8681\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366399.7500 - mae: 442.5027 - val_loss: 390679.5000 - val_mae: 454.5245\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365845.1250 - mae: 441.6552 - val_loss: 390683.6250 - val_mae: 454.1060\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366034.0625 - mae: 441.6051 - val_loss: 388715.4375 - val_mae: 453.5409\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365375.3750 - mae: 441.7158 - val_loss: 388178.7812 - val_mae: 452.6441\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365103.5938 - mae: 441.2133 - val_loss: 389468.2812 - val_mae: 453.6179\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364691.9062 - mae: 441.0559 - val_loss: 389174.6562 - val_mae: 453.5749\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364037.5938 - mae: 440.9386 - val_loss: 387351.8750 - val_mae: 451.3161\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363682.0000 - mae: 440.1386 - val_loss: 388046.7500 - val_mae: 454.1739\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363451.3750 - mae: 440.3292 - val_loss: 386869.1875 - val_mae: 451.6803\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363336.4062 - mae: 440.4102 - val_loss: 387426.5312 - val_mae: 451.3152\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362904.5625 - mae: 439.9700 - val_loss: 387443.2500 - val_mae: 452.7566\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362912.2188 - mae: 440.0356 - val_loss: 385335.0625 - val_mae: 450.5692\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362390.4062 - mae: 439.6889 - val_loss: 385016.8125 - val_mae: 449.1100\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361647.1250 - mae: 438.9746 - val_loss: 385972.6875 - val_mae: 452.1104\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361480.9688 - mae: 439.5581 - val_loss: 383213.6250 - val_mae: 450.7543\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361528.6875 - mae: 439.6476 - val_loss: 385341.1875 - val_mae: 450.3777\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361209.1875 - mae: 439.2816 - val_loss: 382930.2500 - val_mae: 449.7511\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360493.4375 - mae: 438.7930 - val_loss: 385076.1562 - val_mae: 450.8709\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360866.5938 - mae: 439.1054 - val_loss: 382851.6875 - val_mae: 449.8426\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360057.3438 - mae: 438.4338 - val_loss: 381906.4688 - val_mae: 449.6908\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359800.6250 - mae: 438.8978 - val_loss: 382188.2500 - val_mae: 448.4513\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359875.3750 - mae: 438.2617 - val_loss: 380727.6250 - val_mae: 449.9444\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359760.6250 - mae: 438.6177 - val_loss: 380805.6562 - val_mae: 448.0413\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358919.0938 - mae: 437.9948 - val_loss: 379796.4688 - val_mae: 447.9747\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359012.4062 - mae: 437.6751 - val_loss: 380032.5312 - val_mae: 448.7083\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358406.8125 - mae: 437.6766 - val_loss: 378120.8750 - val_mae: 447.4877\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358351.0000 - mae: 437.7603 - val_loss: 379441.8125 - val_mae: 446.1673\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358284.0625 - mae: 437.8744 - val_loss: 377988.5312 - val_mae: 445.8262\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358341.4688 - mae: 437.3189 - val_loss: 378902.7188 - val_mae: 446.1388\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357702.7188 - mae: 437.1187 - val_loss: 379041.1875 - val_mae: 445.8215\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357470.8438 - mae: 437.0378 - val_loss: 376390.5938 - val_mae: 445.7136\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356741.0938 - mae: 436.7630 - val_loss: 376266.4062 - val_mae: 446.6302\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356087.0625 - mae: 436.1991 - val_loss: 377455.7188 - val_mae: 447.1667\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355753.1875 - mae: 436.2347 - val_loss: 378027.5000 - val_mae: 446.1221\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355032.2500 - mae: 435.8014 - val_loss: 374962.5938 - val_mae: 446.7984\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354410.1250 - mae: 435.8226 - val_loss: 374318.5312 - val_mae: 444.6587\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353394.9375 - mae: 434.7926 - val_loss: 373179.5000 - val_mae: 445.3098\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352642.4062 - mae: 434.4067 - val_loss: 371838.3750 - val_mae: 445.6651\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352221.7500 - mae: 434.7332 - val_loss: 372114.0000 - val_mae: 442.9978\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352033.3750 - mae: 433.8691 - val_loss: 369939.7500 - val_mae: 443.5809\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351066.2188 - mae: 434.1815 - val_loss: 369259.0938 - val_mae: 443.5794\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350715.7500 - mae: 433.7849 - val_loss: 370386.2812 - val_mae: 441.0406\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350637.4688 - mae: 433.0370 - val_loss: 369843.5625 - val_mae: 443.1411\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350090.5625 - mae: 433.4916 - val_loss: 367437.4688 - val_mae: 441.4754\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349242.0938 - mae: 433.0019 - val_loss: 368678.1562 - val_mae: 440.9211\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349009.7188 - mae: 432.5208 - val_loss: 367487.5312 - val_mae: 441.2990\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348765.0938 - mae: 432.8134 - val_loss: 367437.8125 - val_mae: 441.6688\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348419.3438 - mae: 432.1753 - val_loss: 368589.8438 - val_mae: 442.9066\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347834.3125 - mae: 432.2058 - val_loss: 367934.4062 - val_mae: 441.4925\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347606.2812 - mae: 431.9678 - val_loss: 366972.2188 - val_mae: 440.1375\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346774.3750 - mae: 431.3199 - val_loss: 366895.9688 - val_mae: 440.8501\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346486.8125 - mae: 431.5358 - val_loss: 365307.6250 - val_mae: 440.7262\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346363.5312 - mae: 431.1609 - val_loss: 366199.3438 - val_mae: 441.7313\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345787.8438 - mae: 430.8494 - val_loss: 365552.3750 - val_mae: 439.0107\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345351.0312 - mae: 430.6181 - val_loss: 364430.0625 - val_mae: 440.6513\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344850.0000 - mae: 430.7361 - val_loss: 363230.5625 - val_mae: 440.1587\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344831.0938 - mae: 430.6825 - val_loss: 363415.8125 - val_mae: 439.0735\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344165.8125 - mae: 430.1046 - val_loss: 362344.0312 - val_mae: 439.0188\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343994.3750 - mae: 430.2271 - val_loss: 364244.0625 - val_mae: 439.0616\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343547.3438 - mae: 429.5758 - val_loss: 363622.6250 - val_mae: 439.6849\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343437.1875 - mae: 429.5881 - val_loss: 362141.9062 - val_mae: 439.0526\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342894.5000 - mae: 429.7240 - val_loss: 363802.4375 - val_mae: 439.8235\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342278.9062 - mae: 429.2170 - val_loss: 361412.6562 - val_mae: 438.3998\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341640.5625 - mae: 429.4731 - val_loss: 363342.0312 - val_mae: 436.5922\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341595.8750 - mae: 428.3625 - val_loss: 361894.0625 - val_mae: 438.2351\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341482.6250 - mae: 428.6273 - val_loss: 361567.6875 - val_mae: 438.9780\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340689.7812 - mae: 428.5654 - val_loss: 361242.5625 - val_mae: 438.5737\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341085.8438 - mae: 428.6813 - val_loss: 360608.0000 - val_mae: 436.4284\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340726.3750 - mae: 428.2845 - val_loss: 360425.5625 - val_mae: 436.2904\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340166.9375 - mae: 427.9460 - val_loss: 360409.5000 - val_mae: 436.4854\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339872.7188 - mae: 427.8600 - val_loss: 359035.5938 - val_mae: 436.5896\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339568.0938 - mae: 427.7916 - val_loss: 356718.5000 - val_mae: 436.1005\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339680.2812 - mae: 427.8655 - val_loss: 359403.4062 - val_mae: 437.2041\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339000.7500 - mae: 427.5769 - val_loss: 357891.2812 - val_mae: 436.7525\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339096.4062 - mae: 427.3612 - val_loss: 358339.2500 - val_mae: 437.3617\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338468.9375 - mae: 427.3166 - val_loss: 358227.9688 - val_mae: 435.7123\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338594.8125 - mae: 427.1169 - val_loss: 357389.9062 - val_mae: 436.4108\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337860.9062 - mae: 426.5087 - val_loss: 356706.8125 - val_mae: 436.3882\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337460.8125 - mae: 426.5523 - val_loss: 358078.6562 - val_mae: 434.9144\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337320.0312 - mae: 425.7438 - val_loss: 355418.6875 - val_mae: 435.2245\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336793.5000 - mae: 425.9075 - val_loss: 355542.8750 - val_mae: 434.4508\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336454.3125 - mae: 425.6449 - val_loss: 356052.9375 - val_mae: 437.1853\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336366.6875 - mae: 425.7480 - val_loss: 354676.0312 - val_mae: 434.2188\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336193.7812 - mae: 425.3615 - val_loss: 355324.5938 - val_mae: 435.9316\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335780.7812 - mae: 424.9356 - val_loss: 355804.0938 - val_mae: 434.4870\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335600.6250 - mae: 424.9209 - val_loss: 354272.7812 - val_mae: 433.6244\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335191.8750 - mae: 424.3332 - val_loss: 354000.3438 - val_mae: 434.1623\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334931.9375 - mae: 424.4959 - val_loss: 354235.0938 - val_mae: 432.0096\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334331.6875 - mae: 423.8037 - val_loss: 351983.0625 - val_mae: 432.4155\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334331.6562 - mae: 423.8463 - val_loss: 354321.9062 - val_mae: 432.1654\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334133.7812 - mae: 423.2900 - val_loss: 353413.5312 - val_mae: 433.6677\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333620.0000 - mae: 422.8149 - val_loss: 354678.5000 - val_mae: 434.8910\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333282.7500 - mae: 423.6607 - val_loss: 353457.5625 - val_mae: 431.7036\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333041.4062 - mae: 422.9061 - val_loss: 350816.7500 - val_mae: 431.6467\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332810.5625 - mae: 422.5948 - val_loss: 351507.6562 - val_mae: 432.3087\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332902.2188 - mae: 422.9722 - val_loss: 351609.0312 - val_mae: 431.4316\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332425.5312 - mae: 422.3839 - val_loss: 349609.7500 - val_mae: 430.9308\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331758.3438 - mae: 422.0617 - val_loss: 351345.0625 - val_mae: 430.5725\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331542.9688 - mae: 421.8675 - val_loss: 350941.8438 - val_mae: 433.7192\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331811.9375 - mae: 422.5523 - val_loss: 351003.5000 - val_mae: 430.8732\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330871.7812 - mae: 421.5233 - val_loss: 349036.0938 - val_mae: 430.7073\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330331.5938 - mae: 421.2619 - val_loss: 349398.6562 - val_mae: 431.1537\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330478.9062 - mae: 421.2445 - val_loss: 347970.3125 - val_mae: 431.2578\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330165.2500 - mae: 420.8803 - val_loss: 348526.8438 - val_mae: 430.7969\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329747.6562 - mae: 420.5486 - val_loss: 348817.9375 - val_mae: 431.5984\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329336.5312 - mae: 420.2099 - val_loss: 347616.0000 - val_mae: 430.0816\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329178.4062 - mae: 420.2134 - val_loss: 346492.6562 - val_mae: 428.2853\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328799.4375 - mae: 419.8063 - val_loss: 347695.4062 - val_mae: 430.0973\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328351.0000 - mae: 419.5220 - val_loss: 347272.8125 - val_mae: 428.9419\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328141.2188 - mae: 418.6100 - val_loss: 349539.2188 - val_mae: 432.6823\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328103.3125 - mae: 419.3239 - val_loss: 346322.7812 - val_mae: 429.9118\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327720.0312 - mae: 418.9391 - val_loss: 345774.7188 - val_mae: 427.7958\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327306.2812 - mae: 418.3301 - val_loss: 345986.1562 - val_mae: 428.9346\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327112.2188 - mae: 418.3779 - val_loss: 346607.4688 - val_mae: 430.8248\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326618.1562 - mae: 418.5646 - val_loss: 345827.8125 - val_mae: 427.5180\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326684.4688 - mae: 418.1751 - val_loss: 344745.2812 - val_mae: 427.2054\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326432.0000 - mae: 418.3570 - val_loss: 345110.8438 - val_mae: 427.0408\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325742.3750 - mae: 418.0273 - val_loss: 346663.4688 - val_mae: 425.9072\n",
      "Epoch 216/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325968.6250 - mae: 417.7318 - val_loss: 344280.0938 - val_mae: 427.0208\n",
      "Epoch 217/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325539.0312 - mae: 417.5215 - val_loss: 344162.6875 - val_mae: 427.1383\n",
      "Epoch 218/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325256.9062 - mae: 417.1150 - val_loss: 344248.1562 - val_mae: 427.1021\n",
      "Epoch 219/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325067.6250 - mae: 416.6067 - val_loss: 344123.5938 - val_mae: 430.6292\n",
      "Epoch 220/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324672.8438 - mae: 417.2589 - val_loss: 343665.0938 - val_mae: 428.0444\n",
      "Epoch 221/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324701.7812 - mae: 417.1589 - val_loss: 342132.7188 - val_mae: 425.7938\n",
      "Epoch 222/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324216.0625 - mae: 416.0842 - val_loss: 342966.6250 - val_mae: 426.3521\n",
      "Epoch 223/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324072.6562 - mae: 416.8495 - val_loss: 343704.7500 - val_mae: 426.5881\n",
      "Epoch 224/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323608.4062 - mae: 415.8972 - val_loss: 342004.4062 - val_mae: 427.2703\n",
      "Epoch 225/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323764.0625 - mae: 416.2038 - val_loss: 344154.5312 - val_mae: 427.7548\n",
      "Epoch 226/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323140.3750 - mae: 415.8245 - val_loss: 341942.1250 - val_mae: 426.3036\n",
      "Epoch 227/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323205.6875 - mae: 415.8381 - val_loss: 341590.5938 - val_mae: 425.4015\n",
      "Epoch 228/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 323126.2812 - mae: 415.8858 - val_loss: 341323.6562 - val_mae: 425.1516\n",
      "Epoch 229/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 322640.1875 - mae: 415.4518 - val_loss: 340791.9062 - val_mae: 424.8816\n",
      "Epoch 230/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 322446.2500 - mae: 415.1242 - val_loss: 341537.5625 - val_mae: 426.1797\n",
      "Epoch 231/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 322516.4062 - mae: 415.2151 - val_loss: 340069.2188 - val_mae: 425.1463\n",
      "Epoch 232/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 322079.1250 - mae: 414.8705 - val_loss: 340688.9688 - val_mae: 425.9175\n",
      "Epoch 233/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 322260.9062 - mae: 414.9912 - val_loss: 341258.3125 - val_mae: 425.5097\n",
      "Epoch 234/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321845.4688 - mae: 414.9790 - val_loss: 340675.7500 - val_mae: 424.5108\n",
      "Epoch 235/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321862.1875 - mae: 414.7086 - val_loss: 340578.8438 - val_mae: 424.4029\n",
      "Epoch 236/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321632.9062 - mae: 414.7171 - val_loss: 341904.8750 - val_mae: 424.0270\n",
      "Epoch 237/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321629.4688 - mae: 414.5534 - val_loss: 339081.5312 - val_mae: 423.6227\n",
      "Epoch 238/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321681.3438 - mae: 414.3274 - val_loss: 339464.2500 - val_mae: 425.5072\n",
      "Epoch 239/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321309.2188 - mae: 414.6684 - val_loss: 338867.7812 - val_mae: 423.8167\n",
      "Epoch 240/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321018.0312 - mae: 414.0301 - val_loss: 338703.9375 - val_mae: 424.3785\n",
      "Epoch 241/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321018.7500 - mae: 414.3341 - val_loss: 341769.5625 - val_mae: 426.8065\n",
      "Epoch 242/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 320706.1875 - mae: 413.7293 - val_loss: 339991.0938 - val_mae: 425.1641\n",
      "Epoch 243/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 320860.3125 - mae: 414.4881 - val_loss: 338847.2500 - val_mae: 423.5005\n",
      "Epoch 244/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 320189.0000 - mae: 413.3122 - val_loss: 339053.6562 - val_mae: 426.7042\n",
      "Epoch 245/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 320157.5625 - mae: 413.6819 - val_loss: 338941.0312 - val_mae: 424.1285\n",
      "Epoch 246/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 319914.8750 - mae: 413.5197 - val_loss: 338671.1562 - val_mae: 423.4169\n",
      "Epoch 247/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 319804.8750 - mae: 413.3475 - val_loss: 338251.1250 - val_mae: 423.7333\n",
      "Epoch 248/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 319624.6250 - mae: 413.3086 - val_loss: 339044.1562 - val_mae: 422.9587\n",
      "Epoch 249/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 319266.9062 - mae: 412.9929 - val_loss: 337395.8750 - val_mae: 422.7796\n",
      "Epoch 250/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 319217.0312 - mae: 413.3999 - val_loss: 337359.5000 - val_mae: 422.6650\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 31640682.0000 - mae: 5454.8394 - val_loss: 19325378.0000 - val_mae: 4271.4209\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 9270134.0000 - mae: 2695.5286 - val_loss: 3033403.2500 - val_mae: 1392.5132\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1624179.5000 - mae: 888.9630 - val_loss: 943019.0000 - val_mae: 675.1002\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 848564.8750 - mae: 622.2138 - val_loss: 663520.5625 - val_mae: 577.3256\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 684985.0625 - mae: 566.6678 - val_loss: 575424.1875 - val_mae: 545.2072\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 621439.5000 - mae: 541.5598 - val_loss: 538472.1250 - val_mae: 528.9376\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 589802.4375 - mae: 527.6575 - val_loss: 521145.4062 - val_mae: 519.0002\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 568963.5000 - mae: 516.5288 - val_loss: 503873.7500 - val_mae: 510.0731\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553000.2500 - mae: 508.7237 - val_loss: 493607.1562 - val_mae: 502.0343\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540090.6250 - mae: 502.1747 - val_loss: 489041.5625 - val_mae: 497.9591\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530274.6250 - mae: 496.7115 - val_loss: 479347.5938 - val_mae: 491.3294\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 520820.4688 - mae: 491.0920 - val_loss: 470804.8125 - val_mae: 486.7997\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 512851.8750 - mae: 486.8297 - val_loss: 464010.5312 - val_mae: 483.5906\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 506060.1562 - mae: 482.9017 - val_loss: 460492.0938 - val_mae: 479.6185\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 499536.0625 - mae: 478.5667 - val_loss: 455732.6250 - val_mae: 476.6105\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 494611.6875 - mae: 475.5927 - val_loss: 448278.9375 - val_mae: 475.0628\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 490102.2188 - mae: 473.4720 - val_loss: 452330.9062 - val_mae: 473.9194\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 486122.8750 - mae: 470.9299 - val_loss: 443935.1250 - val_mae: 471.1844\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 483591.1875 - mae: 468.9953 - val_loss: 441866.3750 - val_mae: 469.9726\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 479635.4688 - mae: 466.3094 - val_loss: 436685.2812 - val_mae: 465.7775\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 476545.8125 - mae: 464.1598 - val_loss: 436537.7500 - val_mae: 466.6863\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 474239.1875 - mae: 462.4701 - val_loss: 431684.5938 - val_mae: 463.4580\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 471306.0000 - mae: 460.2914 - val_loss: 427901.2500 - val_mae: 461.6399\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 469107.8750 - mae: 458.9000 - val_loss: 425692.3125 - val_mae: 459.4518\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 466230.8750 - mae: 456.8139 - val_loss: 426755.0625 - val_mae: 458.6141\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 464121.4062 - mae: 455.6343 - val_loss: 424838.7188 - val_mae: 457.1393\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 462074.7188 - mae: 453.7455 - val_loss: 421486.0312 - val_mae: 456.6026\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 460663.0938 - mae: 452.7853 - val_loss: 421914.3750 - val_mae: 452.2591\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 458163.4062 - mae: 450.3457 - val_loss: 415953.7500 - val_mae: 450.7003\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 456617.6562 - mae: 449.7284 - val_loss: 413239.5625 - val_mae: 450.3489\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453837.9375 - mae: 447.6553 - val_loss: 412992.4375 - val_mae: 449.6566\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 452831.9062 - mae: 447.1294 - val_loss: 411928.9062 - val_mae: 447.2245\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 450587.0312 - mae: 445.3821 - val_loss: 415829.1250 - val_mae: 446.4718\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 448761.7812 - mae: 443.4023 - val_loss: 408115.5938 - val_mae: 445.3307\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 447168.9688 - mae: 442.6060 - val_loss: 409165.9688 - val_mae: 445.1014\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 445485.6250 - mae: 441.3590 - val_loss: 408255.5938 - val_mae: 443.1444\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 443361.5625 - mae: 439.6072 - val_loss: 405226.0000 - val_mae: 442.2971\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442204.8438 - mae: 438.7866 - val_loss: 406448.0625 - val_mae: 441.3669\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 440487.0938 - mae: 438.2322 - val_loss: 409047.7188 - val_mae: 439.6935\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439412.0312 - mae: 436.4332 - val_loss: 403471.9688 - val_mae: 439.6447\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437793.2188 - mae: 435.5919 - val_loss: 398433.8438 - val_mae: 437.2145\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435906.4688 - mae: 434.4433 - val_loss: 397130.0000 - val_mae: 437.8517\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435581.2188 - mae: 434.4423 - val_loss: 399123.5938 - val_mae: 435.5001\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434385.5312 - mae: 433.1846 - val_loss: 396688.1875 - val_mae: 434.9765\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432813.3125 - mae: 432.2868 - val_loss: 395752.3750 - val_mae: 435.0903\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432025.8438 - mae: 431.9447 - val_loss: 394353.7500 - val_mae: 433.2848\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431610.5000 - mae: 431.0960 - val_loss: 394146.9375 - val_mae: 433.9773\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430421.0312 - mae: 430.9958 - val_loss: 396507.0938 - val_mae: 432.5570\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429169.8750 - mae: 429.8627 - val_loss: 391473.5625 - val_mae: 432.8438\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429190.7812 - mae: 430.6191 - val_loss: 395195.6562 - val_mae: 433.2121\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428529.6250 - mae: 429.6168 - val_loss: 393738.5625 - val_mae: 431.8581\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427365.1250 - mae: 428.5934 - val_loss: 393644.1875 - val_mae: 432.2159\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426794.0938 - mae: 428.3484 - val_loss: 392341.1250 - val_mae: 433.1890\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426271.3438 - mae: 428.3591 - val_loss: 391174.8750 - val_mae: 431.8022\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425699.4375 - mae: 427.8857 - val_loss: 389032.9688 - val_mae: 430.5083\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424829.2812 - mae: 427.2534 - val_loss: 392509.1875 - val_mae: 429.9871\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424479.3125 - mae: 426.7408 - val_loss: 391771.3438 - val_mae: 432.8624\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424565.6562 - mae: 427.0913 - val_loss: 387523.8438 - val_mae: 427.5608\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423887.2500 - mae: 426.9167 - val_loss: 385830.4375 - val_mae: 428.4791\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423021.2500 - mae: 426.1356 - val_loss: 388654.0312 - val_mae: 427.4800\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422759.6562 - mae: 425.6474 - val_loss: 385672.4688 - val_mae: 428.4932\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421725.3438 - mae: 425.4953 - val_loss: 388726.8438 - val_mae: 428.7652\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421607.5000 - mae: 425.0880 - val_loss: 386191.3750 - val_mae: 428.6117\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421597.3438 - mae: 425.3116 - val_loss: 387184.8750 - val_mae: 427.6089\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420026.8438 - mae: 424.1447 - val_loss: 384705.3438 - val_mae: 429.1825\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420770.1250 - mae: 424.5394 - val_loss: 385112.9688 - val_mae: 427.7612\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419639.2812 - mae: 423.6375 - val_loss: 386829.9375 - val_mae: 427.9073\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419751.4688 - mae: 424.3698 - val_loss: 385538.3750 - val_mae: 427.5525\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418916.5000 - mae: 423.7983 - val_loss: 384492.3750 - val_mae: 427.2940\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418985.6875 - mae: 423.5822 - val_loss: 382855.1250 - val_mae: 426.0514\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418320.3438 - mae: 423.1529 - val_loss: 384461.6875 - val_mae: 425.2299\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418250.1250 - mae: 423.1426 - val_loss: 380889.5000 - val_mae: 426.5923\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418013.2812 - mae: 423.0109 - val_loss: 382780.4688 - val_mae: 424.8528\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417249.7188 - mae: 422.1774 - val_loss: 381909.1250 - val_mae: 424.7866\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417082.4688 - mae: 422.4698 - val_loss: 384758.9062 - val_mae: 425.6863\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416311.4688 - mae: 422.3864 - val_loss: 380525.3750 - val_mae: 427.3844\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416628.4688 - mae: 422.3288 - val_loss: 378196.5625 - val_mae: 423.5704\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415660.8438 - mae: 421.8883 - val_loss: 377573.7812 - val_mae: 427.0885\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414352.6250 - mae: 422.0211 - val_loss: 377276.5312 - val_mae: 422.9774\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411089.6250 - mae: 421.7023 - val_loss: 382673.4688 - val_mae: 425.5086\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407458.4688 - mae: 421.2493 - val_loss: 380435.2500 - val_mae: 424.9692\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 401346.0625 - mae: 420.9883 - val_loss: 378308.6562 - val_mae: 423.8082\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 390052.3438 - mae: 420.6026 - val_loss: 375353.0625 - val_mae: 423.4803\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 380876.8438 - mae: 419.9312 - val_loss: 368609.9688 - val_mae: 423.7289\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 372611.4688 - mae: 419.0848 - val_loss: 367053.5625 - val_mae: 424.7566\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365873.2500 - mae: 418.8533 - val_loss: 365764.3438 - val_mae: 423.2188\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358500.4062 - mae: 418.4874 - val_loss: 359080.1875 - val_mae: 423.6999\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353793.7188 - mae: 418.2107 - val_loss: 356505.6562 - val_mae: 422.7668\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348767.7500 - mae: 417.5171 - val_loss: 356734.3438 - val_mae: 423.0157\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343926.5625 - mae: 416.9757 - val_loss: 353592.4062 - val_mae: 421.9175\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 340476.4375 - mae: 416.2902 - val_loss: 351842.1250 - val_mae: 423.3752\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 337251.1250 - mae: 415.9909 - val_loss: 353492.0938 - val_mae: 421.6663\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 335046.8438 - mae: 415.7816 - val_loss: 352648.3750 - val_mae: 421.9459\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332952.8750 - mae: 414.9944 - val_loss: 356207.4062 - val_mae: 422.8281\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331617.7500 - mae: 414.5802 - val_loss: 355137.3438 - val_mae: 421.7534\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330264.4375 - mae: 413.7924 - val_loss: 353760.6250 - val_mae: 421.1035\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329877.4688 - mae: 413.8230 - val_loss: 352691.8438 - val_mae: 420.1458\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329664.9375 - mae: 413.8815 - val_loss: 355671.0312 - val_mae: 421.7449\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328614.3125 - mae: 413.1693 - val_loss: 357012.8125 - val_mae: 422.6202\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328410.4375 - mae: 413.1644 - val_loss: 352881.5000 - val_mae: 422.4058\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328318.1250 - mae: 413.6140 - val_loss: 355823.9375 - val_mae: 421.5917\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328640.6875 - mae: 413.0355 - val_loss: 353532.5000 - val_mae: 421.1256\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327949.3125 - mae: 412.5932 - val_loss: 354568.7500 - val_mae: 421.6564\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327749.6562 - mae: 413.0707 - val_loss: 356177.3438 - val_mae: 421.1995\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327574.0000 - mae: 412.4375 - val_loss: 356564.7812 - val_mae: 421.1661\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326868.9062 - mae: 412.8192 - val_loss: 353799.4688 - val_mae: 420.4756\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327057.6875 - mae: 412.4616 - val_loss: 354472.3125 - val_mae: 421.8301\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 28829426.0000 - mae: 5145.7783 - val_loss: 13009724.0000 - val_mae: 3402.5664\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 5045167.0000 - mae: 1743.2384 - val_loss: 1442278.3750 - val_mae: 836.4687\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1144384.8750 - mae: 709.5792 - val_loss: 776438.1875 - val_mae: 606.1904\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 776396.6250 - mae: 586.6544 - val_loss: 627297.2500 - val_mae: 549.2896\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 651647.6875 - mae: 543.2836 - val_loss: 571361.8125 - val_mae: 526.2432\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 597971.5625 - mae: 521.2434 - val_loss: 549168.5625 - val_mae: 513.7878\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570141.0000 - mae: 508.2083 - val_loss: 533389.3750 - val_mae: 506.8733\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552891.0000 - mae: 499.2731 - val_loss: 524410.5000 - val_mae: 498.4735\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539575.2500 - mae: 491.8876 - val_loss: 508392.5625 - val_mae: 494.4485\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529634.9375 - mae: 488.2223 - val_loss: 500454.1250 - val_mae: 487.6933\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 520603.2500 - mae: 482.6231 - val_loss: 498344.1250 - val_mae: 485.8882\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 514277.5938 - mae: 479.1127 - val_loss: 488906.2812 - val_mae: 480.5408\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 508520.6875 - mae: 475.7687 - val_loss: 484911.6562 - val_mae: 477.4667\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 501958.0625 - mae: 471.5872 - val_loss: 475229.0000 - val_mae: 472.5503\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 496260.5625 - mae: 468.0295 - val_loss: 474702.0625 - val_mae: 469.6019\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 491806.9375 - mae: 463.8049 - val_loss: 471232.9062 - val_mae: 466.2772\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 486259.9688 - mae: 460.6100 - val_loss: 458293.6250 - val_mae: 460.2620\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 482145.8125 - mae: 457.4999 - val_loss: 457158.3125 - val_mae: 459.5508\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 477691.5000 - mae: 454.9656 - val_loss: 464368.3438 - val_mae: 460.8813\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 471843.6875 - mae: 452.3259 - val_loss: 453262.3750 - val_mae: 456.2904\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 466866.9688 - mae: 450.1128 - val_loss: 451874.1562 - val_mae: 455.4391\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 462258.0625 - mae: 448.3863 - val_loss: 453234.0625 - val_mae: 452.6063\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 457797.9688 - mae: 446.4445 - val_loss: 449358.2812 - val_mae: 451.8708\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453990.5000 - mae: 444.2380 - val_loss: 449239.3125 - val_mae: 449.9377\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 450954.2500 - mae: 442.9829 - val_loss: 445129.0000 - val_mae: 448.1584\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 447583.0625 - mae: 441.0670 - val_loss: 440064.3750 - val_mae: 447.1198\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 445344.1250 - mae: 439.6384 - val_loss: 435016.6250 - val_mae: 445.0245\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442899.5625 - mae: 438.9092 - val_loss: 429990.6875 - val_mae: 443.2072\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 440304.2500 - mae: 436.9787 - val_loss: 432296.4688 - val_mae: 445.5712\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 438722.9688 - mae: 436.4672 - val_loss: 426925.2500 - val_mae: 443.4439\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436218.8438 - mae: 435.1181 - val_loss: 420600.7812 - val_mae: 440.9976\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 434147.7812 - mae: 434.3055 - val_loss: 420929.3125 - val_mae: 440.6193\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432755.6250 - mae: 433.8393 - val_loss: 419576.4688 - val_mae: 439.8445\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430911.7500 - mae: 432.5242 - val_loss: 416386.8750 - val_mae: 439.3680\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429413.7812 - mae: 432.1734 - val_loss: 418124.5000 - val_mae: 438.7537\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427989.2812 - mae: 431.4637 - val_loss: 411842.3750 - val_mae: 437.0478\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426690.4062 - mae: 430.5930 - val_loss: 410215.6562 - val_mae: 436.0682\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426149.5312 - mae: 430.3411 - val_loss: 409871.6250 - val_mae: 439.2243\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425008.5938 - mae: 429.7692 - val_loss: 408758.5938 - val_mae: 435.7976\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423737.0312 - mae: 429.0045 - val_loss: 407342.0625 - val_mae: 434.7903\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423320.3750 - mae: 429.1704 - val_loss: 409858.9688 - val_mae: 435.6578\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422302.3750 - mae: 428.0125 - val_loss: 408346.9062 - val_mae: 435.2083\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421440.9062 - mae: 428.0723 - val_loss: 402541.8125 - val_mae: 433.5370\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421081.9062 - mae: 427.6883 - val_loss: 405302.3750 - val_mae: 434.5639\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420357.0000 - mae: 426.9333 - val_loss: 402807.0312 - val_mae: 432.5691\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418956.5000 - mae: 426.4653 - val_loss: 405360.7500 - val_mae: 433.3791\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418221.8438 - mae: 425.5413 - val_loss: 402178.8438 - val_mae: 430.9107\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416922.0938 - mae: 424.9705 - val_loss: 406570.4688 - val_mae: 433.2771\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415990.2188 - mae: 424.4225 - val_loss: 404725.5000 - val_mae: 435.4158\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415509.5625 - mae: 424.2734 - val_loss: 400849.4688 - val_mae: 432.6607\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415217.9375 - mae: 423.6239 - val_loss: 402108.6875 - val_mae: 432.4007\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415093.5625 - mae: 423.2038 - val_loss: 402454.2812 - val_mae: 429.9963\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414223.4688 - mae: 423.1396 - val_loss: 399320.8438 - val_mae: 431.2997\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414609.6875 - mae: 423.0349 - val_loss: 403266.4375 - val_mae: 429.0249\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413710.2500 - mae: 422.7146 - val_loss: 403984.8125 - val_mae: 431.5630\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413311.5625 - mae: 422.4513 - val_loss: 405889.6562 - val_mae: 430.2837\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412746.3750 - mae: 421.5148 - val_loss: 401211.4688 - val_mae: 432.5588\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411963.0625 - mae: 421.3217 - val_loss: 400399.8438 - val_mae: 429.8420\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412262.1250 - mae: 421.3552 - val_loss: 398498.6562 - val_mae: 428.7302\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411719.0312 - mae: 420.7687 - val_loss: 398418.7500 - val_mae: 428.2757\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411188.3125 - mae: 420.6526 - val_loss: 403435.7188 - val_mae: 430.6276\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410728.8125 - mae: 420.1611 - val_loss: 400187.5938 - val_mae: 430.4147\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410245.7812 - mae: 419.7187 - val_loss: 400513.8750 - val_mae: 429.0381\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409855.4375 - mae: 419.3132 - val_loss: 401341.9062 - val_mae: 429.3520\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409281.8438 - mae: 418.8232 - val_loss: 398892.5938 - val_mae: 429.7935\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409792.1875 - mae: 419.6172 - val_loss: 403569.0000 - val_mae: 429.7306\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409044.7812 - mae: 418.5498 - val_loss: 402721.6562 - val_mae: 427.9890\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409749.9062 - mae: 419.3501 - val_loss: 400026.8750 - val_mae: 429.1549\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408989.0625 - mae: 418.9833 - val_loss: 403573.6875 - val_mae: 430.8445\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408439.5625 - mae: 418.8000 - val_loss: 398243.0938 - val_mae: 427.7251\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407966.2500 - mae: 418.4817 - val_loss: 398482.5312 - val_mae: 429.5022\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408308.3125 - mae: 417.9266 - val_loss: 397853.2812 - val_mae: 427.9725\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407538.8125 - mae: 418.5480 - val_loss: 400046.1562 - val_mae: 426.7538\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407041.6250 - mae: 418.0375 - val_loss: 400402.8438 - val_mae: 427.6673\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407283.3125 - mae: 418.0898 - val_loss: 398359.8750 - val_mae: 425.9193\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406913.2188 - mae: 417.4989 - val_loss: 393713.2188 - val_mae: 426.5024\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406943.4688 - mae: 417.9055 - val_loss: 396600.9688 - val_mae: 426.7512\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406455.3125 - mae: 417.5616 - val_loss: 399522.7812 - val_mae: 426.6220\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406472.3125 - mae: 417.6410 - val_loss: 397532.5000 - val_mae: 427.9262\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406274.5625 - mae: 417.2264 - val_loss: 395535.3125 - val_mae: 426.2915\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405820.5312 - mae: 417.2771 - val_loss: 400089.8438 - val_mae: 427.9865\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405785.8125 - mae: 417.1458 - val_loss: 398186.6875 - val_mae: 426.6872\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405430.8125 - mae: 417.0721 - val_loss: 402266.2500 - val_mae: 427.5399\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404981.8750 - mae: 416.3837 - val_loss: 401494.7500 - val_mae: 427.7829\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405116.9062 - mae: 416.3332 - val_loss: 395130.4375 - val_mae: 426.4548\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 36568016.0000 - mae: 5892.4668 - val_loss: 32337650.0000 - val_mae: 5551.0049\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 25771836.0000 - mae: 4928.5435 - val_loss: 18711752.0000 - val_mae: 4206.8740\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 12600672.0000 - mae: 3364.2319 - val_loss: 7549603.5000 - val_mae: 2559.9448\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4423884.5000 - mae: 1814.2698 - val_loss: 2252434.0000 - val_mae: 1229.8160\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1406588.1250 - mae: 895.6217 - val_loss: 955093.5625 - val_mae: 736.1328\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 825006.9375 - mae: 662.4463 - val_loss: 726903.5625 - val_mae: 636.7916\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 695701.1875 - mae: 610.1558 - val_loss: 650158.6875 - val_mae: 601.0396\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 632087.9375 - mae: 582.4090 - val_loss: 604954.3125 - val_mae: 578.4688\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588192.3750 - mae: 561.8639 - val_loss: 571761.9375 - val_mae: 561.3976\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554810.6875 - mae: 546.1495 - val_loss: 547104.8750 - val_mae: 547.6857\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529135.5000 - mae: 534.3712 - val_loss: 526544.0625 - val_mae: 535.9051\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 508094.0625 - mae: 524.1907 - val_loss: 511071.8438 - val_mae: 528.2481\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 491446.1875 - mae: 516.8271 - val_loss: 500666.9375 - val_mae: 520.5687\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 478184.9688 - mae: 510.5263 - val_loss: 491518.5000 - val_mae: 514.7519\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 466417.0938 - mae: 504.5435 - val_loss: 482340.9375 - val_mae: 510.3378\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 456828.1562 - mae: 500.5601 - val_loss: 478373.1875 - val_mae: 505.5185\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 447943.7500 - mae: 495.3330 - val_loss: 473272.7812 - val_mae: 503.0325\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 441178.0312 - mae: 491.7862 - val_loss: 468267.0625 - val_mae: 498.9701\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 434426.4688 - mae: 488.5980 - val_loss: 465985.0625 - val_mae: 496.3594\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429082.3438 - mae: 485.4606 - val_loss: 465793.7500 - val_mae: 494.3761\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424650.1250 - mae: 482.3072 - val_loss: 457559.8750 - val_mae: 490.3797\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420431.5312 - mae: 480.0885 - val_loss: 455979.0625 - val_mae: 488.4024\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416772.4375 - mae: 477.6407 - val_loss: 456039.0938 - val_mae: 488.1071\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413286.9062 - mae: 474.9679 - val_loss: 454347.5000 - val_mae: 485.2531\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410140.0938 - mae: 472.9364 - val_loss: 453043.2188 - val_mae: 484.7336\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407247.9062 - mae: 470.9620 - val_loss: 448716.0938 - val_mae: 482.0317\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404757.1875 - mae: 469.1224 - val_loss: 447034.9062 - val_mae: 480.6256\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402298.0000 - mae: 467.2355 - val_loss: 444680.2500 - val_mae: 480.2407\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399924.3750 - mae: 465.9812 - val_loss: 447246.1562 - val_mae: 479.6366\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397838.3438 - mae: 464.3286 - val_loss: 440015.8750 - val_mae: 478.8559\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395882.6875 - mae: 463.4940 - val_loss: 441693.9375 - val_mae: 476.6794\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393714.4062 - mae: 461.2518 - val_loss: 438729.1250 - val_mae: 475.3546\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391546.4375 - mae: 459.9846 - val_loss: 439529.2188 - val_mae: 475.0259\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390217.8125 - mae: 458.7628 - val_loss: 436780.6250 - val_mae: 473.5303\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 387839.5000 - mae: 457.2100 - val_loss: 434977.2500 - val_mae: 473.7628\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386195.9688 - mae: 456.0281 - val_loss: 431508.2500 - val_mae: 470.8716\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 384049.1875 - mae: 454.3989 - val_loss: 429806.4375 - val_mae: 470.0055\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382784.3125 - mae: 453.2076 - val_loss: 429503.7188 - val_mae: 469.5770\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 380410.7812 - mae: 451.7468 - val_loss: 426401.9688 - val_mae: 466.9184\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 378411.2500 - mae: 450.5117 - val_loss: 425083.8750 - val_mae: 465.9002\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 376001.0312 - mae: 448.0225 - val_loss: 424827.6250 - val_mae: 466.8019\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374476.7812 - mae: 447.3463 - val_loss: 422659.9688 - val_mae: 466.1480\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 372741.4375 - mae: 446.5884 - val_loss: 422622.1875 - val_mae: 464.8160\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370865.3750 - mae: 445.0032 - val_loss: 421870.9688 - val_mae: 462.7709\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369632.0000 - mae: 443.4703 - val_loss: 417184.1562 - val_mae: 460.9809\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367513.3750 - mae: 441.9000 - val_loss: 415810.5312 - val_mae: 460.0967\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366281.6562 - mae: 440.6728 - val_loss: 415724.0938 - val_mae: 459.8676\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365248.5000 - mae: 440.1060 - val_loss: 416694.7812 - val_mae: 460.0156\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363173.2188 - mae: 438.7252 - val_loss: 415240.8125 - val_mae: 458.4479\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362796.3438 - mae: 438.0884 - val_loss: 412990.8750 - val_mae: 457.0682\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361324.9375 - mae: 436.5286 - val_loss: 409363.8438 - val_mae: 456.4789\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359845.2188 - mae: 436.3386 - val_loss: 411947.1562 - val_mae: 454.0334\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358894.4375 - mae: 434.8485 - val_loss: 412113.9688 - val_mae: 455.4436\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357951.1562 - mae: 434.2874 - val_loss: 409877.1875 - val_mae: 452.6205\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357014.7188 - mae: 433.1648 - val_loss: 406901.2188 - val_mae: 453.5597\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356203.0938 - mae: 432.7051 - val_loss: 409685.2812 - val_mae: 453.4480\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355238.1875 - mae: 432.1237 - val_loss: 408355.9375 - val_mae: 452.5399\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354500.6562 - mae: 431.6282 - val_loss: 402352.0312 - val_mae: 451.3072\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353736.3438 - mae: 431.4352 - val_loss: 406444.7500 - val_mae: 450.2148\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353003.2500 - mae: 430.0068 - val_loss: 402175.0000 - val_mae: 449.8754\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352134.2188 - mae: 429.7496 - val_loss: 404097.0938 - val_mae: 450.2984\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351735.5000 - mae: 429.2866 - val_loss: 402118.5938 - val_mae: 449.1494\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350880.5625 - mae: 428.5793 - val_loss: 401686.0625 - val_mae: 449.1104\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349999.2188 - mae: 428.1785 - val_loss: 400760.9688 - val_mae: 447.6222\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350200.7188 - mae: 428.4207 - val_loss: 398533.2812 - val_mae: 447.7271\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349043.6875 - mae: 427.6840 - val_loss: 396571.6250 - val_mae: 447.7709\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348709.9688 - mae: 427.4955 - val_loss: 397874.3125 - val_mae: 446.9762\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347709.5312 - mae: 427.4885 - val_loss: 400502.1562 - val_mae: 445.9243\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347849.4062 - mae: 426.6725 - val_loss: 396757.7812 - val_mae: 444.5237\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347210.0000 - mae: 426.0317 - val_loss: 395857.0000 - val_mae: 446.0686\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347017.9688 - mae: 426.4830 - val_loss: 395348.2188 - val_mae: 444.8795\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346221.4688 - mae: 425.7175 - val_loss: 394548.2812 - val_mae: 444.3218\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345708.6250 - mae: 425.3544 - val_loss: 393829.6250 - val_mae: 445.7579\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345838.5938 - mae: 425.7627 - val_loss: 393558.4062 - val_mae: 442.7801\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344738.9375 - mae: 424.9446 - val_loss: 392730.1250 - val_mae: 441.8449\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344708.3750 - mae: 424.5870 - val_loss: 393262.5312 - val_mae: 443.6330\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343751.6562 - mae: 424.1140 - val_loss: 390657.4375 - val_mae: 442.6206\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344216.2500 - mae: 424.4073 - val_loss: 391361.8125 - val_mae: 442.9385\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343419.2188 - mae: 424.1174 - val_loss: 392131.2812 - val_mae: 442.9186\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342732.6250 - mae: 423.4819 - val_loss: 393451.0312 - val_mae: 441.9296\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342673.0625 - mae: 422.9207 - val_loss: 389020.0938 - val_mae: 441.5206\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342231.2812 - mae: 423.3561 - val_loss: 389865.5625 - val_mae: 441.1723\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341890.9062 - mae: 422.9363 - val_loss: 388875.9062 - val_mae: 440.9994\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341477.8125 - mae: 422.6158 - val_loss: 390959.9688 - val_mae: 440.8909\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341153.0312 - mae: 422.4094 - val_loss: 391901.0000 - val_mae: 441.5282\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340562.6562 - mae: 421.7569 - val_loss: 387455.1562 - val_mae: 441.3098\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340662.0625 - mae: 422.3492 - val_loss: 387932.2500 - val_mae: 440.9497\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340231.9375 - mae: 422.3636 - val_loss: 388846.9688 - val_mae: 440.4109\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339980.5312 - mae: 421.6907 - val_loss: 389495.4062 - val_mae: 439.9352\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339726.5000 - mae: 421.5576 - val_loss: 387371.0625 - val_mae: 439.5182\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339286.1250 - mae: 421.5468 - val_loss: 387562.6875 - val_mae: 439.3450\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338665.3750 - mae: 421.1438 - val_loss: 388221.4375 - val_mae: 439.2659\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338961.8750 - mae: 420.7878 - val_loss: 386427.5312 - val_mae: 439.2163\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338328.8438 - mae: 420.6649 - val_loss: 384981.9062 - val_mae: 439.2886\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337917.9375 - mae: 420.9306 - val_loss: 384706.1875 - val_mae: 437.7955\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337587.3438 - mae: 420.2301 - val_loss: 383938.2500 - val_mae: 436.8510\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337470.9062 - mae: 420.0156 - val_loss: 387356.9062 - val_mae: 439.8994\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336907.0000 - mae: 419.7234 - val_loss: 385360.3125 - val_mae: 440.2886\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336692.5000 - mae: 419.7700 - val_loss: 385202.0938 - val_mae: 437.7152\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336259.3750 - mae: 419.5072 - val_loss: 382349.7812 - val_mae: 437.4681\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335504.2500 - mae: 419.2167 - val_loss: 384025.3125 - val_mae: 436.2858\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335460.8750 - mae: 418.9469 - val_loss: 382912.0625 - val_mae: 436.7257\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335085.9688 - mae: 418.3333 - val_loss: 384376.5938 - val_mae: 437.5459\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335044.4688 - mae: 417.9966 - val_loss: 382899.7812 - val_mae: 437.5046\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334693.8125 - mae: 418.4928 - val_loss: 379290.0938 - val_mae: 435.1414\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334063.1562 - mae: 418.1546 - val_loss: 379563.9688 - val_mae: 434.7353\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333195.3750 - mae: 417.1626 - val_loss: 380712.0938 - val_mae: 434.8764\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333146.2188 - mae: 417.7991 - val_loss: 380536.0312 - val_mae: 434.1907\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332637.0938 - mae: 416.9248 - val_loss: 381874.2500 - val_mae: 434.4475\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332452.1562 - mae: 416.7996 - val_loss: 375730.5938 - val_mae: 433.4958\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331668.3125 - mae: 416.5715 - val_loss: 377959.1562 - val_mae: 433.5712\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331350.3125 - mae: 416.7551 - val_loss: 377817.7188 - val_mae: 432.3471\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331380.0000 - mae: 416.0881 - val_loss: 376011.4375 - val_mae: 432.4486\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330992.9375 - mae: 415.9302 - val_loss: 377381.3125 - val_mae: 432.6214\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330377.7500 - mae: 415.6345 - val_loss: 379391.4062 - val_mae: 431.8680\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330798.2188 - mae: 415.5497 - val_loss: 376195.6250 - val_mae: 432.0309\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329780.1875 - mae: 415.5002 - val_loss: 377281.8125 - val_mae: 431.0226\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329433.1250 - mae: 414.7094 - val_loss: 373563.3438 - val_mae: 432.4782\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329123.1250 - mae: 414.7401 - val_loss: 375049.3750 - val_mae: 431.6301\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328583.4375 - mae: 414.4583 - val_loss: 372713.5625 - val_mae: 431.0178\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328949.3125 - mae: 414.9195 - val_loss: 374125.0000 - val_mae: 430.8095\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327886.1562 - mae: 414.5100 - val_loss: 376044.1562 - val_mae: 431.7636\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327884.9688 - mae: 414.0026 - val_loss: 375025.0000 - val_mae: 430.6118\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327753.8750 - mae: 414.1747 - val_loss: 374765.4062 - val_mae: 430.4031\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327232.0938 - mae: 413.6260 - val_loss: 375610.0000 - val_mae: 431.2073\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327302.2812 - mae: 414.1230 - val_loss: 374976.0625 - val_mae: 430.1063\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326869.9062 - mae: 413.7288 - val_loss: 375051.0312 - val_mae: 430.9472\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326552.3438 - mae: 413.2831 - val_loss: 375229.8125 - val_mae: 432.7394\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326436.9688 - mae: 413.5267 - val_loss: 373692.6875 - val_mae: 429.9062\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325936.0938 - mae: 413.0655 - val_loss: 371969.4375 - val_mae: 429.2056\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325967.1250 - mae: 413.2268 - val_loss: 376062.3438 - val_mae: 430.0784\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325602.9062 - mae: 412.7326 - val_loss: 374943.0312 - val_mae: 431.0402\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325368.9375 - mae: 412.6557 - val_loss: 371584.1562 - val_mae: 429.9381\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325223.8750 - mae: 413.2462 - val_loss: 373879.0625 - val_mae: 428.8167\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325123.5938 - mae: 412.5620 - val_loss: 371710.4375 - val_mae: 428.6575\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325154.0938 - mae: 412.7234 - val_loss: 374038.5312 - val_mae: 429.0879\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324497.5312 - mae: 412.1328 - val_loss: 372249.4375 - val_mae: 429.5392\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324411.9688 - mae: 412.4304 - val_loss: 372902.0000 - val_mae: 428.7890\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324696.8125 - mae: 412.3510 - val_loss: 373762.7812 - val_mae: 429.2045\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324271.1562 - mae: 412.1956 - val_loss: 371186.1250 - val_mae: 429.5104\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323938.2812 - mae: 412.0302 - val_loss: 367931.0000 - val_mae: 427.4228\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323781.0312 - mae: 411.7795 - val_loss: 373237.3750 - val_mae: 429.6183\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323699.5625 - mae: 411.6410 - val_loss: 370113.9062 - val_mae: 428.2423\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323390.4062 - mae: 411.5111 - val_loss: 371236.8438 - val_mae: 427.7152\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323344.0625 - mae: 410.7174 - val_loss: 371754.7188 - val_mae: 429.5497\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323086.9688 - mae: 411.0272 - val_loss: 374485.4062 - val_mae: 429.7309\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322951.4688 - mae: 411.2621 - val_loss: 369508.5000 - val_mae: 428.0522\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322519.8125 - mae: 410.7984 - val_loss: 370306.6250 - val_mae: 428.0610\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322405.2500 - mae: 410.4844 - val_loss: 369379.7188 - val_mae: 428.1638\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322120.5000 - mae: 410.7046 - val_loss: 369161.8125 - val_mae: 427.9081\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321880.6875 - mae: 410.6974 - val_loss: 368987.2188 - val_mae: 426.9392\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321388.4688 - mae: 410.2854 - val_loss: 368971.8125 - val_mae: 426.9426\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320825.9688 - mae: 409.9697 - val_loss: 367681.6562 - val_mae: 426.1223\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320664.6250 - mae: 409.8442 - val_loss: 367523.4062 - val_mae: 426.9189\n",
      "Epoch 155/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320083.7500 - mae: 409.0374 - val_loss: 368525.9062 - val_mae: 426.3842\n",
      "Epoch 156/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319908.3125 - mae: 409.6658 - val_loss: 371726.4062 - val_mae: 426.9313\n",
      "Epoch 157/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319342.6562 - mae: 408.8932 - val_loss: 368302.2500 - val_mae: 426.7127\n",
      "Epoch 158/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319511.9062 - mae: 408.9456 - val_loss: 368005.9375 - val_mae: 428.4238\n",
      "Epoch 159/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318843.1250 - mae: 408.9426 - val_loss: 366497.0938 - val_mae: 426.0380\n",
      "Epoch 160/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318788.2812 - mae: 408.8156 - val_loss: 366434.1250 - val_mae: 425.5130\n",
      "Epoch 161/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318512.8750 - mae: 408.7987 - val_loss: 365469.5938 - val_mae: 425.7060\n",
      "Epoch 162/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318199.9062 - mae: 408.4406 - val_loss: 367517.6875 - val_mae: 427.0414\n",
      "Epoch 163/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318416.3750 - mae: 408.4778 - val_loss: 365273.7812 - val_mae: 426.0903\n",
      "Epoch 164/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318146.9375 - mae: 408.1376 - val_loss: 366440.7812 - val_mae: 427.9518\n",
      "Epoch 165/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317826.1562 - mae: 408.7501 - val_loss: 363724.5625 - val_mae: 425.4940\n",
      "Epoch 166/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317284.2188 - mae: 408.3383 - val_loss: 366576.0312 - val_mae: 425.7766\n",
      "Epoch 167/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317513.4062 - mae: 408.3833 - val_loss: 366234.5000 - val_mae: 426.0332\n",
      "Epoch 168/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317414.5000 - mae: 408.1668 - val_loss: 363069.3750 - val_mae: 424.9303\n",
      "Epoch 169/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316906.3750 - mae: 408.0674 - val_loss: 365876.0312 - val_mae: 425.1541\n",
      "Epoch 170/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317045.2500 - mae: 408.2137 - val_loss: 365895.7500 - val_mae: 425.8001\n",
      "Epoch 171/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316779.0312 - mae: 407.6570 - val_loss: 365075.5000 - val_mae: 424.3559\n",
      "Epoch 172/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316442.0938 - mae: 407.5247 - val_loss: 364304.5625 - val_mae: 425.9790\n",
      "Epoch 173/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316852.3438 - mae: 407.8396 - val_loss: 366048.6562 - val_mae: 426.4114\n",
      "Epoch 174/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316534.2812 - mae: 407.7509 - val_loss: 364032.3125 - val_mae: 425.0068\n",
      "Epoch 175/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316319.4688 - mae: 408.0821 - val_loss: 371905.5312 - val_mae: 427.1807\n",
      "Epoch 176/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316272.3125 - mae: 407.2890 - val_loss: 364889.6562 - val_mae: 425.4121\n",
      "Epoch 177/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316190.3125 - mae: 407.3898 - val_loss: 365859.4375 - val_mae: 425.9299\n",
      "Epoch 178/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316150.3438 - mae: 407.5620 - val_loss: 365067.7500 - val_mae: 427.1241\n",
      "Epoch 179/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315894.5312 - mae: 407.4678 - val_loss: 366489.4375 - val_mae: 425.1488\n",
      "Epoch 180/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315785.7188 - mae: 407.7305 - val_loss: 367799.1250 - val_mae: 425.4580\n",
      "Epoch 181/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315808.1562 - mae: 406.7037 - val_loss: 363089.0625 - val_mae: 424.0670\n",
      "Epoch 182/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315739.7812 - mae: 407.2882 - val_loss: 363040.0938 - val_mae: 424.0517\n",
      "Epoch 183/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315831.2500 - mae: 407.3200 - val_loss: 364593.3125 - val_mae: 425.4834\n",
      "Epoch 184/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315410.1562 - mae: 407.0109 - val_loss: 361786.3125 - val_mae: 424.6048\n",
      "Epoch 185/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 314877.7500 - mae: 406.7156 - val_loss: 365280.1562 - val_mae: 425.8638\n",
      "Epoch 186/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315477.8438 - mae: 407.3727 - val_loss: 368085.3125 - val_mae: 425.8237\n",
      "Epoch 187/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315330.6875 - mae: 407.1447 - val_loss: 364274.3750 - val_mae: 424.4043\n",
      "Epoch 188/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315195.2500 - mae: 406.8991 - val_loss: 365719.0625 - val_mae: 425.6316\n",
      "Epoch 189/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315088.6875 - mae: 406.9142 - val_loss: 363867.6875 - val_mae: 424.2081\n",
      "Epoch 190/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315276.5625 - mae: 406.9955 - val_loss: 363922.7188 - val_mae: 424.4118\n",
      "Epoch 191/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 314984.8438 - mae: 406.7342 - val_loss: 363217.8125 - val_mae: 424.3745\n",
      "Epoch 192/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 314559.5000 - mae: 406.8385 - val_loss: 364593.0312 - val_mae: 424.2752\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 35516712.0000 - mae: 5815.7812 - val_loss: 28703948.0000 - val_mae: 5262.1460\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 20080406.0000 - mae: 4314.4062 - val_loss: 12537872.0000 - val_mae: 3315.4077\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 7697605.5000 - mae: 2424.2153 - val_loss: 4231802.0000 - val_mae: 1717.0242\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2516134.5000 - mae: 1224.3981 - val_loss: 1484101.6250 - val_mae: 923.5626\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1091140.2500 - mae: 758.9825 - val_loss: 824575.2500 - val_mae: 669.7542\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 755013.5000 - mae: 616.8450 - val_loss: 657670.2500 - val_mae: 587.0303\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 668339.5625 - mae: 570.5684 - val_loss: 606128.6875 - val_mae: 559.4427\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 632902.3750 - mae: 553.0019 - val_loss: 575829.0625 - val_mae: 544.5508\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608530.9375 - mae: 541.1935 - val_loss: 556267.0000 - val_mae: 533.0934\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589646.1875 - mae: 531.4636 - val_loss: 541209.7500 - val_mae: 525.0217\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573988.8750 - mae: 523.0989 - val_loss: 526122.1875 - val_mae: 517.8385\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560535.5000 - mae: 516.0826 - val_loss: 514580.8438 - val_mae: 512.9258\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548939.0625 - mae: 510.7275 - val_loss: 506375.6562 - val_mae: 507.9402\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539110.6250 - mae: 505.6424 - val_loss: 496125.6250 - val_mae: 503.3689\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531028.0000 - mae: 501.5019 - val_loss: 489927.3125 - val_mae: 499.1802\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 523768.0625 - mae: 497.3029 - val_loss: 484690.9062 - val_mae: 495.9421\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 516836.6562 - mae: 493.9470 - val_loss: 481245.3125 - val_mae: 493.8016\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 510759.3125 - mae: 489.7927 - val_loss: 475165.5312 - val_mae: 491.3322\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 504576.5625 - mae: 485.6090 - val_loss: 469665.3125 - val_mae: 488.3576\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 499179.3750 - mae: 481.7146 - val_loss: 464121.5625 - val_mae: 482.7299\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 494270.0312 - mae: 479.0742 - val_loss: 459938.2812 - val_mae: 479.7870\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 489518.9688 - mae: 475.8476 - val_loss: 457325.7812 - val_mae: 479.7053\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 486538.5312 - mae: 472.7993 - val_loss: 452459.7812 - val_mae: 475.4760\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 483284.1875 - mae: 471.0615 - val_loss: 448490.2812 - val_mae: 471.9066\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 478707.6875 - mae: 467.3725 - val_loss: 449954.9688 - val_mae: 470.8310\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 476030.5312 - mae: 465.1252 - val_loss: 447536.2812 - val_mae: 469.4013\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 472578.1250 - mae: 462.7526 - val_loss: 444387.6562 - val_mae: 466.4449\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 469671.0938 - mae: 460.6692 - val_loss: 441475.7812 - val_mae: 463.9574\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 467197.4375 - mae: 459.0856 - val_loss: 437264.4375 - val_mae: 461.3971\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 465187.9688 - mae: 457.7778 - val_loss: 435215.6875 - val_mae: 461.3264\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 463136.3750 - mae: 456.2116 - val_loss: 435231.0625 - val_mae: 461.7316\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 461027.1250 - mae: 455.0132 - val_loss: 432833.0312 - val_mae: 457.9665\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 459514.3125 - mae: 453.7851 - val_loss: 426447.2500 - val_mae: 456.9093\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 457550.9375 - mae: 452.9305 - val_loss: 429941.1250 - val_mae: 456.6530\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 455943.6562 - mae: 450.8824 - val_loss: 426064.8438 - val_mae: 454.6342\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 454219.8750 - mae: 449.4174 - val_loss: 421800.1250 - val_mae: 453.5654\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 452740.6875 - mae: 449.1686 - val_loss: 419382.5000 - val_mae: 451.8647\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 451496.6250 - mae: 448.1005 - val_loss: 420940.5938 - val_mae: 451.5713\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 450174.1562 - mae: 446.5429 - val_loss: 417784.5312 - val_mae: 451.7235\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 448345.6875 - mae: 445.6818 - val_loss: 417334.3750 - val_mae: 449.3231\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 447568.5938 - mae: 444.3741 - val_loss: 418031.1250 - val_mae: 447.9529\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 446143.8750 - mae: 444.1428 - val_loss: 415928.7812 - val_mae: 447.7909\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 444927.4062 - mae: 443.0496 - val_loss: 414494.6562 - val_mae: 446.9310\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 443394.0625 - mae: 441.6013 - val_loss: 412010.9062 - val_mae: 447.2553\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 441854.2188 - mae: 441.0771 - val_loss: 412710.8438 - val_mae: 446.2520\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 440575.8750 - mae: 439.6435 - val_loss: 409378.0000 - val_mae: 449.3833\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439443.1875 - mae: 439.5154 - val_loss: 410171.0938 - val_mae: 443.3643\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438344.2188 - mae: 438.8673 - val_loss: 406099.6562 - val_mae: 441.8480\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437108.5625 - mae: 437.7785 - val_loss: 406580.6250 - val_mae: 441.8598\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 435771.9688 - mae: 436.6762 - val_loss: 404644.1875 - val_mae: 442.2362\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 434420.4062 - mae: 436.2756 - val_loss: 402031.1250 - val_mae: 439.7376\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 433332.0625 - mae: 435.1033 - val_loss: 400953.0000 - val_mae: 441.1559\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432445.0312 - mae: 434.7519 - val_loss: 398674.8125 - val_mae: 437.7634\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 430629.0312 - mae: 433.7391 - val_loss: 402010.4375 - val_mae: 436.9595\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429232.9375 - mae: 432.5632 - val_loss: 398831.8125 - val_mae: 437.2845\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 427433.9688 - mae: 431.4813 - val_loss: 399091.9375 - val_mae: 436.1619\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425915.0938 - mae: 430.7016 - val_loss: 397764.4062 - val_mae: 435.0650\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424861.9375 - mae: 430.0798 - val_loss: 395417.2500 - val_mae: 435.3734\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423994.4375 - mae: 429.8418 - val_loss: 393678.3125 - val_mae: 433.6993\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422973.2500 - mae: 429.0222 - val_loss: 397379.0000 - val_mae: 433.8499\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421976.8125 - mae: 428.5312 - val_loss: 397043.8438 - val_mae: 433.6948\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421123.4375 - mae: 427.8208 - val_loss: 396633.7812 - val_mae: 432.7274\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419722.1875 - mae: 426.6661 - val_loss: 392319.6250 - val_mae: 434.7595\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419276.0938 - mae: 426.1972 - val_loss: 391331.2188 - val_mae: 433.2361\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418852.4688 - mae: 426.3244 - val_loss: 389094.8438 - val_mae: 431.2675\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417948.6562 - mae: 425.8578 - val_loss: 390480.5312 - val_mae: 432.1807\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417435.0000 - mae: 425.2665 - val_loss: 390751.7188 - val_mae: 430.7598\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416842.5938 - mae: 424.2964 - val_loss: 386769.7500 - val_mae: 431.8002\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416575.1250 - mae: 424.4800 - val_loss: 387236.4375 - val_mae: 430.0969\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415911.9375 - mae: 423.6355 - val_loss: 386992.8438 - val_mae: 431.0486\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415553.7812 - mae: 423.7817 - val_loss: 389821.1875 - val_mae: 429.9774\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415216.0000 - mae: 423.2106 - val_loss: 386933.9375 - val_mae: 431.0541\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414581.1875 - mae: 423.0185 - val_loss: 387609.0312 - val_mae: 431.3527\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414113.5312 - mae: 422.5919 - val_loss: 385427.0000 - val_mae: 429.6900\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413771.6250 - mae: 421.7233 - val_loss: 386410.7500 - val_mae: 429.7142\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413186.0312 - mae: 421.6732 - val_loss: 386327.6562 - val_mae: 430.6330\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413148.0625 - mae: 421.4777 - val_loss: 386158.8438 - val_mae: 428.9118\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412541.2812 - mae: 421.8334 - val_loss: 385361.9688 - val_mae: 426.9823\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412077.4375 - mae: 421.0139 - val_loss: 386437.1250 - val_mae: 429.9098\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411866.3125 - mae: 421.2868 - val_loss: 384363.2500 - val_mae: 427.0174\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411577.2812 - mae: 420.9861 - val_loss: 387236.9688 - val_mae: 429.3172\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411310.1250 - mae: 420.6418 - val_loss: 384908.1250 - val_mae: 427.0147\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410850.2188 - mae: 420.1278 - val_loss: 386955.7500 - val_mae: 429.4490\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411012.5000 - mae: 420.3136 - val_loss: 384126.5938 - val_mae: 427.6769\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410205.3438 - mae: 420.0154 - val_loss: 382149.3125 - val_mae: 427.5766\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407706.6875 - mae: 420.0130 - val_loss: 384872.4062 - val_mae: 427.2645\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404949.5000 - mae: 419.8766 - val_loss: 383570.1875 - val_mae: 428.1172\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401671.0625 - mae: 418.5518 - val_loss: 380719.3125 - val_mae: 428.2242\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38125364.0000 - mae: 6019.7070 - val_loss: 36784164.0000 - val_mae: 5923.4595\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 34393768.0000 - mae: 5731.8252 - val_loss: 31136008.0000 - val_mae: 5473.9043\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 27594352.0000 - mae: 5151.3613 - val_loss: 23703590.0000 - val_mae: 4786.0400\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 20134912.0000 - mae: 4384.2573 - val_loss: 16638525.0000 - val_mae: 3966.7578\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 13692782.0000 - mae: 3539.1548 - val_loss: 11054581.0000 - val_mae: 3129.4956\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 8882053.0000 - mae: 2730.8462 - val_loss: 7089588.5000 - val_mae: 2388.4143\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5591854.0000 - mae: 2064.4844 - val_loss: 4477531.5000 - val_mae: 1807.7329\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3526810.7500 - mae: 1562.0070 - val_loss: 2924752.7500 - val_mae: 1394.0598\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2358192.5000 - mae: 1224.1213 - val_loss: 2080991.5000 - val_mae: 1133.9845\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1741355.3750 - mae: 1022.2922 - val_loss: 1633010.6250 - val_mae: 983.4670\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1404888.8750 - mae: 904.1170 - val_loss: 1372290.2500 - val_mae: 889.4615\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1197478.8750 - mae: 829.6795 - val_loss: 1196574.2500 - val_mae: 827.0856\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1050299.2500 - mae: 776.7728 - val_loss: 1062745.7500 - val_mae: 779.6373\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 935252.2500 - mae: 734.6740 - val_loss: 954165.5625 - val_mae: 739.5778\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 841788.8125 - mae: 698.6790 - val_loss: 864406.9375 - val_mae: 704.8885\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 763697.3125 - mae: 666.1556 - val_loss: 789132.8125 - val_mae: 674.1531\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 698447.6875 - mae: 637.3420 - val_loss: 724299.9375 - val_mae: 645.2215\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 644233.5625 - mae: 611.4710 - val_loss: 670148.1250 - val_mae: 618.6583\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600154.1875 - mae: 587.7950 - val_loss: 626975.7500 - val_mae: 595.9122\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 565149.0000 - mae: 567.7626 - val_loss: 591074.8125 - val_mae: 576.1646\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538347.8750 - mae: 551.4603 - val_loss: 565257.7500 - val_mae: 560.2542\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 518389.7188 - mae: 539.2807 - val_loss: 545635.9375 - val_mae: 547.8302\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 503400.9062 - mae: 529.0205 - val_loss: 530857.4375 - val_mae: 539.0491\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 491860.4375 - mae: 522.0957 - val_loss: 518784.7500 - val_mae: 531.4603\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482656.0625 - mae: 516.8018 - val_loss: 509326.9375 - val_mae: 525.6590\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 475161.1562 - mae: 511.9694 - val_loss: 502212.0000 - val_mae: 521.5803\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 468177.3125 - mae: 507.8066 - val_loss: 494815.5938 - val_mae: 517.7715\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 462210.2500 - mae: 505.1946 - val_loss: 490484.8438 - val_mae: 513.9932\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 456809.8438 - mae: 501.6599 - val_loss: 484238.1562 - val_mae: 511.0925\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 451570.8438 - mae: 498.3084 - val_loss: 477708.9688 - val_mae: 508.5628\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 446329.9062 - mae: 495.8958 - val_loss: 473769.7188 - val_mae: 505.1381\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441633.9375 - mae: 492.5579 - val_loss: 468549.1250 - val_mae: 502.2546\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 437040.2188 - mae: 490.4444 - val_loss: 464657.1562 - val_mae: 499.2184\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 432834.6250 - mae: 487.4827 - val_loss: 459466.3750 - val_mae: 497.2007\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428192.8125 - mae: 484.7473 - val_loss: 454062.3438 - val_mae: 494.1070\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424393.0625 - mae: 482.0175 - val_loss: 450597.7500 - val_mae: 492.9401\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420623.8438 - mae: 480.3259 - val_loss: 446498.7188 - val_mae: 489.3335\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416906.9688 - mae: 477.2495 - val_loss: 443787.6250 - val_mae: 487.7551\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413455.1875 - mae: 475.4347 - val_loss: 439470.0000 - val_mae: 484.4329\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409581.1562 - mae: 472.3288 - val_loss: 434757.7188 - val_mae: 480.8689\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406124.8750 - mae: 470.2459 - val_loss: 431854.4375 - val_mae: 479.1426\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403107.7812 - mae: 467.4465 - val_loss: 428727.6875 - val_mae: 476.5213\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 400486.5312 - mae: 465.9632 - val_loss: 426841.9062 - val_mae: 474.8156\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398273.8438 - mae: 463.9212 - val_loss: 424443.2500 - val_mae: 475.2092\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396295.5000 - mae: 462.4451 - val_loss: 423195.2188 - val_mae: 474.0353\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395107.0625 - mae: 462.3372 - val_loss: 422821.9062 - val_mae: 471.5984\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393080.1250 - mae: 459.7460 - val_loss: 419631.5312 - val_mae: 472.2796\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391710.4688 - mae: 459.5374 - val_loss: 416711.0312 - val_mae: 470.3202\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390567.5938 - mae: 458.5625 - val_loss: 416245.6250 - val_mae: 469.6561\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389394.8750 - mae: 457.7510 - val_loss: 415823.3125 - val_mae: 468.3177\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387930.0000 - mae: 456.7997 - val_loss: 415054.1562 - val_mae: 468.8478\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386870.2500 - mae: 455.9555 - val_loss: 412267.4688 - val_mae: 467.1012\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385621.3125 - mae: 455.1358 - val_loss: 410371.7188 - val_mae: 466.3663\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384794.5000 - mae: 453.9790 - val_loss: 412520.3750 - val_mae: 466.3865\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383315.4375 - mae: 453.4172 - val_loss: 409774.0000 - val_mae: 466.4780\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382631.4688 - mae: 452.7684 - val_loss: 408111.5000 - val_mae: 464.8087\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381404.8125 - mae: 452.1749 - val_loss: 407447.4062 - val_mae: 464.1487\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379976.2188 - mae: 451.3597 - val_loss: 406528.1250 - val_mae: 463.8259\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378902.0938 - mae: 450.1371 - val_loss: 405698.5000 - val_mae: 463.2506\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377886.3750 - mae: 449.9750 - val_loss: 404430.6875 - val_mae: 462.4732\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376972.2188 - mae: 449.0614 - val_loss: 402084.0000 - val_mae: 461.1693\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376013.1250 - mae: 448.7808 - val_loss: 402232.6250 - val_mae: 459.4391\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374966.6250 - mae: 447.5286 - val_loss: 400457.3125 - val_mae: 460.9722\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374232.3438 - mae: 447.2399 - val_loss: 400255.2500 - val_mae: 461.6524\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373329.5625 - mae: 446.7422 - val_loss: 398450.1875 - val_mae: 459.3511\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372734.1875 - mae: 446.4748 - val_loss: 397796.7188 - val_mae: 458.4967\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371700.6875 - mae: 445.5055 - val_loss: 397798.7812 - val_mae: 458.5497\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370925.5312 - mae: 445.5450 - val_loss: 396689.1875 - val_mae: 457.0903\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370024.3438 - mae: 444.3623 - val_loss: 395247.1250 - val_mae: 456.3598\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369439.6562 - mae: 443.8488 - val_loss: 395409.9375 - val_mae: 457.6756\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368573.5625 - mae: 443.5764 - val_loss: 395075.8750 - val_mae: 455.8617\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368055.5625 - mae: 442.7508 - val_loss: 394337.2812 - val_mae: 456.0639\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367483.7500 - mae: 442.5482 - val_loss: 393996.1562 - val_mae: 455.9633\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366590.5312 - mae: 442.1751 - val_loss: 392787.5938 - val_mae: 455.3487\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365816.0625 - mae: 441.5265 - val_loss: 391780.9062 - val_mae: 455.5627\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365344.7188 - mae: 441.1121 - val_loss: 392239.6562 - val_mae: 454.8602\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364484.1250 - mae: 440.7960 - val_loss: 392547.4688 - val_mae: 453.4485\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363735.9062 - mae: 439.8356 - val_loss: 389852.2188 - val_mae: 452.7043\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362478.1562 - mae: 439.3285 - val_loss: 389536.9062 - val_mae: 452.0621\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361765.9375 - mae: 438.5016 - val_loss: 389675.5938 - val_mae: 452.2426\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361011.4062 - mae: 438.0215 - val_loss: 388347.9688 - val_mae: 450.5283\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360006.5938 - mae: 437.2413 - val_loss: 385947.3438 - val_mae: 449.9609\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359060.5625 - mae: 436.9188 - val_loss: 385756.7812 - val_mae: 451.4283\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358533.3750 - mae: 436.1822 - val_loss: 385406.8125 - val_mae: 450.4037\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357836.3125 - mae: 436.1893 - val_loss: 385205.2188 - val_mae: 448.4142\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356958.9688 - mae: 435.5557 - val_loss: 383688.7188 - val_mae: 447.4480\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356486.9375 - mae: 435.0600 - val_loss: 383796.0000 - val_mae: 448.0601\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355821.5625 - mae: 434.8802 - val_loss: 382189.3125 - val_mae: 447.4016\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355436.1250 - mae: 434.0029 - val_loss: 381484.5625 - val_mae: 446.6416\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354613.3750 - mae: 434.1073 - val_loss: 382175.7812 - val_mae: 447.0749\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353957.4375 - mae: 433.2987 - val_loss: 382687.0312 - val_mae: 448.7101\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353298.7812 - mae: 433.2144 - val_loss: 381377.9375 - val_mae: 446.1067\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353026.6875 - mae: 433.0517 - val_loss: 380039.1562 - val_mae: 445.2983\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352292.7500 - mae: 431.9839 - val_loss: 380161.5938 - val_mae: 446.3602\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351528.2188 - mae: 432.0369 - val_loss: 378042.6562 - val_mae: 445.4278\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351118.9062 - mae: 431.7796 - val_loss: 378525.6875 - val_mae: 444.9213\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350884.2188 - mae: 431.4613 - val_loss: 378885.8438 - val_mae: 444.5821\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 350088.4688 - mae: 431.1336 - val_loss: 379100.5625 - val_mae: 445.5549\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349646.2188 - mae: 430.7824 - val_loss: 378226.3125 - val_mae: 444.4580\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349315.5625 - mae: 430.4645 - val_loss: 375357.0312 - val_mae: 443.0903\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 348748.6562 - mae: 430.3890 - val_loss: 375293.1562 - val_mae: 443.5781\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348016.4688 - mae: 429.8525 - val_loss: 375257.4062 - val_mae: 443.0633\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 347427.5312 - mae: 429.3574 - val_loss: 374378.3438 - val_mae: 442.9757\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347046.2812 - mae: 429.2952 - val_loss: 374424.9062 - val_mae: 443.0055\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346094.4375 - mae: 428.5604 - val_loss: 373611.9062 - val_mae: 443.0286\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345955.9688 - mae: 428.5150 - val_loss: 373294.1562 - val_mae: 442.7557\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345326.9375 - mae: 428.5620 - val_loss: 372008.4062 - val_mae: 441.0184\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344968.5625 - mae: 427.6058 - val_loss: 373659.8438 - val_mae: 442.2290\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344730.4062 - mae: 427.9237 - val_loss: 373401.6250 - val_mae: 442.3296\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344288.2812 - mae: 427.3452 - val_loss: 371584.7500 - val_mae: 440.3441\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343947.5625 - mae: 427.2000 - val_loss: 371415.3750 - val_mae: 440.4191\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343556.6562 - mae: 426.9285 - val_loss: 368800.8125 - val_mae: 440.5852\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343415.3438 - mae: 427.0800 - val_loss: 370582.6562 - val_mae: 441.1447\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343047.7812 - mae: 426.6541 - val_loss: 369069.4688 - val_mae: 439.7011\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342398.1875 - mae: 426.1371 - val_loss: 368306.5938 - val_mae: 440.7532\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342164.8125 - mae: 426.2139 - val_loss: 369284.9375 - val_mae: 439.8639\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 342091.8750 - mae: 426.0278 - val_loss: 369171.5000 - val_mae: 439.9992\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341612.5312 - mae: 425.3585 - val_loss: 368242.6875 - val_mae: 439.7994\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341721.0938 - mae: 425.8766 - val_loss: 366821.2812 - val_mae: 438.6594\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341144.0938 - mae: 425.7476 - val_loss: 367542.3438 - val_mae: 438.0827\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341052.2188 - mae: 425.3904 - val_loss: 367434.5625 - val_mae: 438.4623\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340569.1875 - mae: 424.8235 - val_loss: 369082.0625 - val_mae: 441.2172\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 340408.4062 - mae: 424.9643 - val_loss: 366401.9688 - val_mae: 439.9419\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339957.7188 - mae: 425.0016 - val_loss: 366627.1250 - val_mae: 438.7393\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339860.3438 - mae: 424.4983 - val_loss: 366854.6250 - val_mae: 437.9125\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339290.7188 - mae: 423.9375 - val_loss: 365102.8750 - val_mae: 437.9684\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339177.8125 - mae: 424.2773 - val_loss: 365175.9375 - val_mae: 436.5777\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338982.1875 - mae: 424.2089 - val_loss: 364876.2188 - val_mae: 437.7606\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338780.5938 - mae: 424.0463 - val_loss: 364206.4375 - val_mae: 436.0016\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 338332.7812 - mae: 423.5992 - val_loss: 365484.6875 - val_mae: 436.7850\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338203.7188 - mae: 423.4774 - val_loss: 364611.4375 - val_mae: 437.4334\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 337976.5938 - mae: 423.2466 - val_loss: 364192.1250 - val_mae: 437.6355\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337814.0625 - mae: 423.4945 - val_loss: 364434.0000 - val_mae: 435.8950\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337389.9062 - mae: 422.7968 - val_loss: 363689.9688 - val_mae: 436.8807\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337356.0938 - mae: 422.7371 - val_loss: 363794.9375 - val_mae: 437.3169\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337192.3125 - mae: 422.6265 - val_loss: 362006.5000 - val_mae: 436.4215\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336972.5938 - mae: 422.2897 - val_loss: 363522.2188 - val_mae: 437.7413\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336605.2812 - mae: 422.6947 - val_loss: 362429.3438 - val_mae: 436.5478\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336746.5312 - mae: 422.6895 - val_loss: 362639.5625 - val_mae: 435.7253\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336436.4062 - mae: 422.4996 - val_loss: 363700.8750 - val_mae: 434.8320\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335954.1250 - mae: 421.7553 - val_loss: 364082.1250 - val_mae: 437.3593\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336019.1875 - mae: 421.9799 - val_loss: 363259.7188 - val_mae: 436.7449\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335760.9375 - mae: 421.9369 - val_loss: 362089.8438 - val_mae: 435.6244\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335539.6562 - mae: 421.7327 - val_loss: 362815.7812 - val_mae: 437.1161\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335535.7812 - mae: 421.9221 - val_loss: 359351.5625 - val_mae: 434.7028\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335227.8750 - mae: 421.5682 - val_loss: 360653.4062 - val_mae: 434.7512\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 335071.0938 - mae: 421.8490 - val_loss: 362938.1875 - val_mae: 435.2061\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334966.7188 - mae: 420.9991 - val_loss: 362273.1250 - val_mae: 435.2142\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334688.0938 - mae: 421.1450 - val_loss: 362806.8125 - val_mae: 435.6770\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334515.9375 - mae: 421.1292 - val_loss: 362526.8438 - val_mae: 435.4449\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334551.0312 - mae: 421.0815 - val_loss: 362047.4375 - val_mae: 434.5982\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334491.2812 - mae: 421.0315 - val_loss: 360347.8750 - val_mae: 434.4015\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334115.3125 - mae: 420.8247 - val_loss: 361582.4062 - val_mae: 434.3683\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333905.4375 - mae: 420.6691 - val_loss: 359471.7812 - val_mae: 434.0320\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333845.8438 - mae: 420.7556 - val_loss: 360609.1875 - val_mae: 433.6997\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333746.9375 - mae: 420.5406 - val_loss: 359418.9375 - val_mae: 434.1280\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333440.2812 - mae: 420.3582 - val_loss: 361115.7812 - val_mae: 434.2286\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333449.3750 - mae: 420.0918 - val_loss: 360250.0938 - val_mae: 434.0243\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333144.0000 - mae: 420.0586 - val_loss: 359457.6562 - val_mae: 432.9819\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332926.1562 - mae: 419.8219 - val_loss: 359941.7500 - val_mae: 434.8802\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332986.0938 - mae: 419.7678 - val_loss: 360072.5938 - val_mae: 433.5134\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332559.0000 - mae: 419.4949 - val_loss: 358593.2188 - val_mae: 433.3286\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332060.6250 - mae: 419.2555 - val_loss: 358112.4375 - val_mae: 433.1611\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332279.0312 - mae: 419.3364 - val_loss: 358259.4062 - val_mae: 432.0858\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331852.1875 - mae: 419.0201 - val_loss: 358116.7812 - val_mae: 432.2873\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331481.3438 - mae: 418.7900 - val_loss: 359631.4062 - val_mae: 432.6299\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331573.8750 - mae: 418.6939 - val_loss: 357023.7500 - val_mae: 432.2813\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331379.9375 - mae: 418.7296 - val_loss: 357728.3438 - val_mae: 431.5516\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331355.7812 - mae: 418.4007 - val_loss: 356327.3750 - val_mae: 431.9930\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330889.5312 - mae: 418.2816 - val_loss: 357456.4688 - val_mae: 432.4393\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330761.1250 - mae: 417.9633 - val_loss: 356462.5625 - val_mae: 432.1303\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331063.3438 - mae: 418.5933 - val_loss: 357360.4688 - val_mae: 432.0616\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330729.2500 - mae: 417.9427 - val_loss: 357229.4375 - val_mae: 431.4908\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330489.3125 - mae: 418.0970 - val_loss: 356759.1250 - val_mae: 431.7133\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330396.0312 - mae: 418.2330 - val_loss: 356224.7500 - val_mae: 430.9612\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330459.4062 - mae: 418.1115 - val_loss: 357018.5938 - val_mae: 431.7566\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330123.8125 - mae: 417.5222 - val_loss: 356586.4062 - val_mae: 431.7861\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330109.4062 - mae: 417.9033 - val_loss: 356673.5938 - val_mae: 432.0226\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329900.5625 - mae: 417.9409 - val_loss: 356188.6562 - val_mae: 431.3914\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329837.8438 - mae: 417.6156 - val_loss: 355658.7188 - val_mae: 431.3122\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329560.1250 - mae: 417.4040 - val_loss: 357171.2500 - val_mae: 431.0269\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329353.7500 - mae: 417.2280 - val_loss: 354846.0938 - val_mae: 429.9660\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329441.4688 - mae: 417.1840 - val_loss: 355481.6250 - val_mae: 430.5794\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328992.0625 - mae: 417.2987 - val_loss: 355739.4688 - val_mae: 431.0453\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329046.8125 - mae: 416.9289 - val_loss: 355913.3750 - val_mae: 430.2269\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329048.5312 - mae: 417.0177 - val_loss: 354796.0625 - val_mae: 430.4934\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328433.9062 - mae: 416.8665 - val_loss: 355718.3438 - val_mae: 430.5819\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328484.5625 - mae: 416.8545 - val_loss: 355058.4062 - val_mae: 429.3536\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328601.5938 - mae: 416.5721 - val_loss: 354191.6562 - val_mae: 430.1599\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327895.9062 - mae: 416.3956 - val_loss: 353465.4688 - val_mae: 430.4167\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327932.1875 - mae: 416.4483 - val_loss: 354651.7188 - val_mae: 430.5616\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327929.5625 - mae: 416.7883 - val_loss: 355594.0938 - val_mae: 429.6641\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327879.0625 - mae: 416.4065 - val_loss: 354528.9062 - val_mae: 430.0285\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327646.3125 - mae: 416.5878 - val_loss: 354951.8438 - val_mae: 429.3263\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327541.1875 - mae: 416.0213 - val_loss: 353774.4062 - val_mae: 429.0891\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327480.4688 - mae: 415.8515 - val_loss: 354615.0312 - val_mae: 430.4380\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327579.3125 - mae: 416.2924 - val_loss: 353561.5000 - val_mae: 429.9079\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327207.0625 - mae: 415.9518 - val_loss: 354108.5000 - val_mae: 430.1765\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327125.1562 - mae: 415.8083 - val_loss: 354357.9688 - val_mae: 429.5552\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326931.7812 - mae: 416.1085 - val_loss: 354314.9375 - val_mae: 429.9767\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327025.0938 - mae: 415.5774 - val_loss: 352989.3438 - val_mae: 429.6160\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326655.1875 - mae: 415.7160 - val_loss: 352953.2812 - val_mae: 428.6703\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326570.5625 - mae: 415.7034 - val_loss: 353196.6875 - val_mae: 427.7784\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326455.2812 - mae: 415.1102 - val_loss: 353154.1562 - val_mae: 431.4189\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326214.0938 - mae: 416.0911 - val_loss: 353960.6562 - val_mae: 428.1928\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326132.4375 - mae: 415.2342 - val_loss: 352727.8750 - val_mae: 429.0887\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325831.4375 - mae: 415.1539 - val_loss: 353851.9375 - val_mae: 428.5024\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325627.4688 - mae: 414.9916 - val_loss: 352592.1875 - val_mae: 429.2220\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325505.8438 - mae: 414.8509 - val_loss: 353803.2812 - val_mae: 430.0965\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325609.2812 - mae: 415.1946 - val_loss: 352448.3438 - val_mae: 429.2316\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325162.9688 - mae: 414.5865 - val_loss: 353161.0938 - val_mae: 430.1026\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325159.0625 - mae: 415.1983 - val_loss: 352476.5312 - val_mae: 427.7791\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324838.2188 - mae: 414.4242 - val_loss: 354719.0625 - val_mae: 429.5187\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 37849100.0000 - mae: 5994.6187 - val_loss: 35855600.0000 - val_mae: 5839.8569\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 32070924.0000 - mae: 5513.0298 - val_loss: 27330494.0000 - val_mae: 5099.0591\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 22222128.0000 - mae: 4572.0630 - val_loss: 17108796.0000 - val_mae: 4011.3948\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 12670976.0000 - mae: 3391.9834 - val_loss: 8879832.0000 - val_mae: 2807.8767\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6114394.5000 - mae: 2234.5757 - val_loss: 4101061.7500 - val_mae: 1778.7188\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2790421.7500 - mae: 1384.9784 - val_loss: 2022963.5000 - val_mae: 1136.0015\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1506286.2500 - mae: 940.0090 - val_loss: 1299383.1250 - val_mae: 852.3051\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1078161.3750 - mae: 764.9257 - val_loss: 1047262.6250 - val_mae: 745.4545\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 916884.0000 - mae: 696.7997 - val_loss: 933553.5000 - val_mae: 696.4039\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 828595.0625 - mae: 660.0429 - val_loss: 863085.1875 - val_mae: 664.1752\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 767041.1875 - mae: 632.2885 - val_loss: 810609.1250 - val_mae: 639.7228\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 719120.1250 - mae: 610.4008 - val_loss: 767113.1250 - val_mae: 619.4807\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 680677.0625 - mae: 592.5913 - val_loss: 734643.3750 - val_mae: 603.2298\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 649794.9375 - mae: 577.2635 - val_loss: 707071.6250 - val_mae: 589.3405\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 623829.4375 - mae: 565.0539 - val_loss: 682748.7500 - val_mae: 578.7451\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602931.0625 - mae: 555.3575 - val_loss: 664709.7500 - val_mae: 569.9183\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585098.5000 - mae: 546.8749 - val_loss: 648519.0000 - val_mae: 561.9137\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 569746.7500 - mae: 539.7954 - val_loss: 633849.0000 - val_mae: 554.6908\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555814.1250 - mae: 533.0761 - val_loss: 620275.8750 - val_mae: 548.5167\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542968.0000 - mae: 527.1306 - val_loss: 609703.8750 - val_mae: 542.1981\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532818.0000 - mae: 522.1375 - val_loss: 599524.8125 - val_mae: 538.1209\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 523096.4062 - mae: 518.1957 - val_loss: 591181.5625 - val_mae: 533.5848\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 514536.1250 - mae: 514.2644 - val_loss: 583654.9375 - val_mae: 530.2073\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 506769.7500 - mae: 511.0847 - val_loss: 578549.5625 - val_mae: 527.7477\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 499572.8438 - mae: 507.7262 - val_loss: 568918.3750 - val_mae: 523.4131\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 493220.1250 - mae: 504.8863 - val_loss: 562463.2500 - val_mae: 520.5911\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 486838.1250 - mae: 502.4343 - val_loss: 558735.5625 - val_mae: 518.0502\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 481413.7188 - mae: 499.2991 - val_loss: 553257.3750 - val_mae: 514.9746\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 476136.4375 - mae: 497.0204 - val_loss: 544741.6875 - val_mae: 511.9062\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 470478.4688 - mae: 494.0929 - val_loss: 540836.3125 - val_mae: 509.0587\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 465308.0938 - mae: 491.2025 - val_loss: 537681.6250 - val_mae: 506.9867\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 460527.7500 - mae: 489.1678 - val_loss: 531733.1250 - val_mae: 503.6513\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 456263.0312 - mae: 486.3603 - val_loss: 527821.9375 - val_mae: 501.7382\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452397.7188 - mae: 484.7934 - val_loss: 522360.8750 - val_mae: 499.5624\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 449077.7812 - mae: 482.7789 - val_loss: 518309.2500 - val_mae: 498.0112\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 445819.0000 - mae: 481.1938 - val_loss: 514882.8125 - val_mae: 496.7312\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 442365.0938 - mae: 479.8850 - val_loss: 510998.5312 - val_mae: 495.0148\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438843.6875 - mae: 477.7850 - val_loss: 506271.8125 - val_mae: 493.3816\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435906.3438 - mae: 476.8700 - val_loss: 504973.6875 - val_mae: 491.8644\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 432909.3125 - mae: 475.6263 - val_loss: 503548.8750 - val_mae: 490.5674\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430813.2812 - mae: 474.3305 - val_loss: 501152.3750 - val_mae: 488.8325\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428284.1250 - mae: 472.9358 - val_loss: 498029.8438 - val_mae: 488.8119\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425628.3438 - mae: 471.3295 - val_loss: 490858.7812 - val_mae: 486.0778\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423602.6562 - mae: 470.9005 - val_loss: 490366.3438 - val_mae: 485.9512\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421738.2812 - mae: 470.1388 - val_loss: 491603.0312 - val_mae: 485.6291\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419643.3438 - mae: 468.5950 - val_loss: 485056.8125 - val_mae: 484.4191\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417270.9062 - mae: 467.9001 - val_loss: 484601.2188 - val_mae: 482.6057\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414764.5938 - mae: 466.2515 - val_loss: 481169.8750 - val_mae: 481.5498\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412593.1562 - mae: 465.2209 - val_loss: 478423.7812 - val_mae: 480.9547\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411120.9375 - mae: 464.3056 - val_loss: 475340.0625 - val_mae: 479.4469\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408935.6562 - mae: 463.3779 - val_loss: 475379.7500 - val_mae: 478.1047\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406972.8750 - mae: 461.9550 - val_loss: 473338.5938 - val_mae: 477.5157\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405815.0625 - mae: 461.2763 - val_loss: 473592.5625 - val_mae: 476.6029\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404182.1250 - mae: 460.2451 - val_loss: 469568.8438 - val_mae: 476.4236\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402152.1875 - mae: 459.4852 - val_loss: 469340.8438 - val_mae: 475.6626\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401017.3438 - mae: 458.7186 - val_loss: 467511.7500 - val_mae: 475.2423\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399484.0938 - mae: 457.8925 - val_loss: 463617.5625 - val_mae: 472.9138\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398194.2500 - mae: 457.0155 - val_loss: 463570.4688 - val_mae: 473.3570\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396736.5938 - mae: 456.3864 - val_loss: 460685.5625 - val_mae: 472.2499\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395532.6875 - mae: 455.7994 - val_loss: 460188.5312 - val_mae: 470.8419\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394374.2500 - mae: 454.9133 - val_loss: 458258.3438 - val_mae: 470.1132\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393207.6562 - mae: 453.8403 - val_loss: 457528.5625 - val_mae: 470.2969\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 392049.1875 - mae: 453.9025 - val_loss: 455106.8438 - val_mae: 469.2179\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391136.3438 - mae: 453.1082 - val_loss: 454723.3125 - val_mae: 468.8391\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389924.9062 - mae: 452.4327 - val_loss: 454176.3438 - val_mae: 467.8848\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389177.5312 - mae: 451.6436 - val_loss: 455192.7500 - val_mae: 468.7379\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388628.5625 - mae: 451.5761 - val_loss: 451834.3750 - val_mae: 467.3776\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387258.2500 - mae: 450.9642 - val_loss: 451319.4375 - val_mae: 467.5231\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386531.8125 - mae: 450.6438 - val_loss: 451642.1875 - val_mae: 467.0480\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385918.7188 - mae: 450.0071 - val_loss: 450307.0625 - val_mae: 466.2040\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384812.8125 - mae: 449.0462 - val_loss: 447559.8438 - val_mae: 465.6544\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383982.1562 - mae: 449.4341 - val_loss: 447204.7500 - val_mae: 464.7415\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383225.7812 - mae: 448.2853 - val_loss: 446833.9375 - val_mae: 464.4583\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382930.4688 - mae: 448.2446 - val_loss: 446510.7188 - val_mae: 464.7910\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381461.0938 - mae: 447.6152 - val_loss: 448423.6875 - val_mae: 465.2750\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380544.2812 - mae: 447.3804 - val_loss: 444314.4062 - val_mae: 462.1498\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380155.2500 - mae: 446.6737 - val_loss: 444233.8438 - val_mae: 463.5536\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379205.3750 - mae: 446.2810 - val_loss: 443249.1562 - val_mae: 462.7514\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378631.6875 - mae: 445.7122 - val_loss: 442747.4375 - val_mae: 462.3802\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378349.5312 - mae: 445.9214 - val_loss: 439868.9062 - val_mae: 461.2815\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377041.7500 - mae: 445.1715 - val_loss: 442454.4062 - val_mae: 461.3263\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376691.4375 - mae: 444.4169 - val_loss: 439598.6250 - val_mae: 461.5998\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376094.2188 - mae: 444.9649 - val_loss: 440690.9688 - val_mae: 460.4206\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375702.1250 - mae: 444.0295 - val_loss: 434728.6875 - val_mae: 459.1794\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375124.0312 - mae: 444.0735 - val_loss: 434665.6875 - val_mae: 459.4158\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374261.3750 - mae: 444.0859 - val_loss: 437033.8750 - val_mae: 459.2901\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374196.2188 - mae: 443.3168 - val_loss: 434942.4062 - val_mae: 458.7823\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373381.5625 - mae: 443.1939 - val_loss: 433078.5625 - val_mae: 458.4842\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372630.3750 - mae: 443.2461 - val_loss: 434482.4688 - val_mae: 458.1537\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371895.2500 - mae: 442.2922 - val_loss: 436848.7500 - val_mae: 458.9306\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371253.7812 - mae: 441.8206 - val_loss: 433935.0938 - val_mae: 456.9801\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370822.8438 - mae: 441.4536 - val_loss: 430247.8438 - val_mae: 456.5726\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369325.2812 - mae: 440.5191 - val_loss: 430911.4375 - val_mae: 456.6129\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368681.7812 - mae: 440.9440 - val_loss: 431859.8125 - val_mae: 455.9785\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368378.9375 - mae: 439.8466 - val_loss: 429157.5000 - val_mae: 455.7479\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367395.1562 - mae: 439.8521 - val_loss: 428899.5938 - val_mae: 454.8751\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366788.4688 - mae: 438.9097 - val_loss: 427767.0938 - val_mae: 454.3073\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366451.1875 - mae: 438.9960 - val_loss: 426751.3438 - val_mae: 454.2859\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365756.8750 - mae: 438.0542 - val_loss: 423135.6562 - val_mae: 453.9217\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365227.2500 - mae: 438.6011 - val_loss: 424837.0938 - val_mae: 453.2146\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364993.3750 - mae: 437.5773 - val_loss: 422725.3750 - val_mae: 453.9898\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364590.1562 - mae: 438.0627 - val_loss: 421730.3125 - val_mae: 451.7547\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363822.3125 - mae: 436.9624 - val_loss: 424208.3125 - val_mae: 453.3077\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363484.1875 - mae: 436.8819 - val_loss: 421309.1875 - val_mae: 452.7815\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363081.3750 - mae: 437.2593 - val_loss: 421572.0000 - val_mae: 451.3770\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362767.9375 - mae: 436.0929 - val_loss: 420905.7812 - val_mae: 451.9974\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362223.7812 - mae: 436.4858 - val_loss: 417395.9688 - val_mae: 451.2138\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362164.9062 - mae: 436.5339 - val_loss: 418791.1250 - val_mae: 450.5576\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361603.8125 - mae: 435.6949 - val_loss: 419520.5938 - val_mae: 451.1540\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361188.9062 - mae: 435.8913 - val_loss: 417935.5625 - val_mae: 450.3390\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360618.8125 - mae: 435.3260 - val_loss: 415530.1562 - val_mae: 449.2356\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360213.0000 - mae: 435.1596 - val_loss: 418336.6875 - val_mae: 450.2551\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359741.6250 - mae: 435.1096 - val_loss: 417044.4062 - val_mae: 448.7013\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358797.2500 - mae: 434.1143 - val_loss: 414844.4375 - val_mae: 449.2422\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358864.2812 - mae: 434.8339 - val_loss: 416805.0938 - val_mae: 449.7157\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357903.9375 - mae: 433.8886 - val_loss: 412424.5312 - val_mae: 446.9936\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357677.5000 - mae: 434.1221 - val_loss: 413278.6875 - val_mae: 447.3804\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356885.3438 - mae: 432.9505 - val_loss: 413579.7500 - val_mae: 447.5211\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356470.0000 - mae: 433.1244 - val_loss: 411511.1562 - val_mae: 447.0349\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355928.3438 - mae: 432.8044 - val_loss: 411421.9375 - val_mae: 446.5552\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355376.5625 - mae: 432.2165 - val_loss: 412243.1250 - val_mae: 446.5693\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355062.3125 - mae: 432.2374 - val_loss: 412797.7812 - val_mae: 447.2973\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354850.7500 - mae: 432.0733 - val_loss: 410588.2188 - val_mae: 445.9821\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354276.0000 - mae: 431.8357 - val_loss: 408330.3750 - val_mae: 444.6377\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353831.0625 - mae: 431.1512 - val_loss: 409455.1250 - val_mae: 444.7937\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353654.8750 - mae: 431.7284 - val_loss: 411050.2188 - val_mae: 445.8058\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352807.9375 - mae: 431.0266 - val_loss: 405669.0938 - val_mae: 443.7948\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353058.3750 - mae: 430.7297 - val_loss: 408299.9375 - val_mae: 444.5058\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352325.0312 - mae: 430.4553 - val_loss: 408282.5000 - val_mae: 444.7558\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352208.1250 - mae: 430.2689 - val_loss: 405105.7500 - val_mae: 443.0229\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351287.3125 - mae: 429.6814 - val_loss: 406367.8125 - val_mae: 443.2649\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351326.1562 - mae: 430.0190 - val_loss: 405812.5000 - val_mae: 443.5355\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351003.8750 - mae: 429.6630 - val_loss: 407185.4062 - val_mae: 443.5807\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350608.9062 - mae: 428.9162 - val_loss: 404242.3750 - val_mae: 443.3858\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350106.2812 - mae: 429.3072 - val_loss: 403022.8125 - val_mae: 443.6837\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349820.5000 - mae: 429.2957 - val_loss: 404506.8438 - val_mae: 442.3716\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349730.0312 - mae: 428.5808 - val_loss: 401897.0312 - val_mae: 441.5689\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349422.1875 - mae: 428.7818 - val_loss: 404775.7500 - val_mae: 442.6384\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349228.5312 - mae: 428.3418 - val_loss: 401796.1250 - val_mae: 442.7285\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348801.2812 - mae: 429.0365 - val_loss: 403575.1875 - val_mae: 441.1133\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348277.3750 - mae: 427.8957 - val_loss: 403276.7812 - val_mae: 441.8744\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348156.7500 - mae: 427.3774 - val_loss: 401354.1250 - val_mae: 441.1329\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347518.8438 - mae: 427.7997 - val_loss: 402795.1250 - val_mae: 441.8463\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347236.6250 - mae: 427.5917 - val_loss: 401371.8438 - val_mae: 440.9620\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346670.1250 - mae: 427.2910 - val_loss: 401125.7500 - val_mae: 439.9776\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346537.8750 - mae: 427.1371 - val_loss: 401632.0312 - val_mae: 440.2202\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346487.6562 - mae: 426.5457 - val_loss: 399650.6875 - val_mae: 440.5639\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345778.3125 - mae: 426.7562 - val_loss: 402592.3438 - val_mae: 440.7908\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345613.2500 - mae: 425.7340 - val_loss: 399691.9375 - val_mae: 441.8149\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345358.7812 - mae: 426.9677 - val_loss: 398812.5000 - val_mae: 439.5876\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344681.9062 - mae: 426.0398 - val_loss: 399941.9688 - val_mae: 440.7828\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344379.7812 - mae: 425.7472 - val_loss: 398121.0938 - val_mae: 438.7908\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344283.2812 - mae: 425.6084 - val_loss: 397696.6250 - val_mae: 438.7053\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343849.4062 - mae: 425.2845 - val_loss: 399405.8750 - val_mae: 439.2496\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343750.9062 - mae: 425.3669 - val_loss: 396790.1250 - val_mae: 438.2312\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343390.1875 - mae: 425.2377 - val_loss: 398810.0625 - val_mae: 438.8883\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343494.8438 - mae: 424.9263 - val_loss: 397731.7812 - val_mae: 438.9312\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342922.4688 - mae: 424.8124 - val_loss: 399182.5312 - val_mae: 438.8039\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342710.5938 - mae: 424.4895 - val_loss: 397161.2188 - val_mae: 439.2441\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342601.5625 - mae: 424.5025 - val_loss: 394645.8750 - val_mae: 438.2307\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342257.5000 - mae: 424.5804 - val_loss: 394519.9688 - val_mae: 437.8192\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342064.6250 - mae: 424.1364 - val_loss: 394827.5938 - val_mae: 437.6266\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341892.8125 - mae: 424.0210 - val_loss: 395882.8438 - val_mae: 437.9311\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341380.3438 - mae: 424.2137 - val_loss: 393235.4062 - val_mae: 436.6835\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341079.8125 - mae: 423.6183 - val_loss: 395308.9688 - val_mae: 436.3859\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340707.8750 - mae: 422.9901 - val_loss: 394683.1562 - val_mae: 438.2547\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340954.7500 - mae: 423.5847 - val_loss: 394683.2188 - val_mae: 437.8802\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340908.5938 - mae: 423.7245 - val_loss: 392841.4062 - val_mae: 436.1111\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340370.5312 - mae: 423.0262 - val_loss: 392986.3438 - val_mae: 436.1396\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340672.6250 - mae: 423.2517 - val_loss: 390581.2500 - val_mae: 436.7170\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340237.6250 - mae: 423.3402 - val_loss: 392360.8125 - val_mae: 435.9046\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339891.4062 - mae: 422.8583 - val_loss: 390134.6562 - val_mae: 435.1270\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339898.9062 - mae: 423.2249 - val_loss: 390964.8438 - val_mae: 435.2534\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339491.7500 - mae: 422.3244 - val_loss: 389911.8750 - val_mae: 436.1497\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339536.3438 - mae: 422.6678 - val_loss: 390964.0625 - val_mae: 435.3554\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338926.3438 - mae: 422.3955 - val_loss: 390832.6250 - val_mae: 435.4323\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339100.1562 - mae: 422.5298 - val_loss: 388372.6875 - val_mae: 434.5199\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338958.0938 - mae: 422.0785 - val_loss: 388413.2812 - val_mae: 434.8593\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338713.9062 - mae: 422.0371 - val_loss: 389907.9375 - val_mae: 434.1758\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338447.2812 - mae: 422.0080 - val_loss: 388366.9062 - val_mae: 433.5507\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338291.3750 - mae: 421.7084 - val_loss: 389079.6875 - val_mae: 435.6243\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337916.8438 - mae: 421.0974 - val_loss: 386671.0625 - val_mae: 435.5566\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338168.3750 - mae: 422.0121 - val_loss: 390159.0625 - val_mae: 434.4837\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337698.9062 - mae: 421.4617 - val_loss: 385961.2812 - val_mae: 433.9688\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337669.4375 - mae: 421.8753 - val_loss: 387551.9062 - val_mae: 433.3525\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337558.2500 - mae: 420.9710 - val_loss: 390114.4688 - val_mae: 434.8324\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337221.5938 - mae: 420.9770 - val_loss: 387927.4375 - val_mae: 434.0452\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337241.9688 - mae: 421.2868 - val_loss: 390314.9375 - val_mae: 435.2130\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337364.4375 - mae: 420.4981 - val_loss: 388456.7500 - val_mae: 434.0563\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336840.6562 - mae: 421.0754 - val_loss: 385470.2500 - val_mae: 433.4344\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336702.1250 - mae: 421.2041 - val_loss: 386499.4062 - val_mae: 433.3055\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336522.9062 - mae: 420.6960 - val_loss: 389545.5938 - val_mae: 434.4605\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336280.4688 - mae: 420.5404 - val_loss: 386803.0625 - val_mae: 433.2171\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335853.2500 - mae: 420.1548 - val_loss: 384976.2188 - val_mae: 433.1249\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335835.4688 - mae: 420.1964 - val_loss: 386191.3438 - val_mae: 432.2962\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 335805.7812 - mae: 420.1964 - val_loss: 385847.3125 - val_mae: 432.4555\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335417.0312 - mae: 420.7057 - val_loss: 387154.3438 - val_mae: 432.7083\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335448.8125 - mae: 420.1890 - val_loss: 385439.4688 - val_mae: 432.4963\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 334821.9062 - mae: 419.6891 - val_loss: 384609.2812 - val_mae: 432.1436\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334791.5000 - mae: 419.7822 - val_loss: 385619.3438 - val_mae: 432.8405\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334669.1250 - mae: 419.7295 - val_loss: 383061.0000 - val_mae: 432.3824\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334504.5000 - mae: 419.4676 - val_loss: 383130.8438 - val_mae: 431.2651\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334075.3750 - mae: 419.3994 - val_loss: 382774.6562 - val_mae: 431.1777\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334381.4062 - mae: 419.2207 - val_loss: 382402.7500 - val_mae: 431.4183\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334116.6875 - mae: 419.4307 - val_loss: 382715.7500 - val_mae: 431.4972\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 334062.4688 - mae: 419.2663 - val_loss: 381766.3125 - val_mae: 431.8127\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333652.4375 - mae: 418.9057 - val_loss: 382622.4688 - val_mae: 431.7666\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 333328.6875 - mae: 418.8446 - val_loss: 381956.0312 - val_mae: 430.9915\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333283.9375 - mae: 418.7864 - val_loss: 380195.0312 - val_mae: 430.9212\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332783.8438 - mae: 418.5573 - val_loss: 380327.9062 - val_mae: 431.4564\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332783.2500 - mae: 419.1287 - val_loss: 380649.0312 - val_mae: 430.2500\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332354.0312 - mae: 418.0628 - val_loss: 381802.2188 - val_mae: 431.8522\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331978.3125 - mae: 418.3934 - val_loss: 379569.4688 - val_mae: 432.0329\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331788.9062 - mae: 418.4881 - val_loss: 379744.8438 - val_mae: 430.8629\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331515.6562 - mae: 418.0159 - val_loss: 377380.8125 - val_mae: 430.0114\n",
      "Epoch 216/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331496.3438 - mae: 417.9304 - val_loss: 379382.0625 - val_mae: 430.4458\n",
      "Epoch 217/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331091.2812 - mae: 417.9279 - val_loss: 378878.2812 - val_mae: 430.8797\n",
      "Epoch 218/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331001.4688 - mae: 418.0973 - val_loss: 379149.8750 - val_mae: 430.2948\n",
      "Epoch 219/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330810.6875 - mae: 417.6412 - val_loss: 379036.7812 - val_mae: 430.2709\n",
      "Epoch 220/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330785.2500 - mae: 417.7863 - val_loss: 375724.4062 - val_mae: 429.4544\n",
      "Epoch 221/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330243.3125 - mae: 417.7582 - val_loss: 376376.4375 - val_mae: 429.3633\n",
      "Epoch 222/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330311.3750 - mae: 417.5579 - val_loss: 379658.9062 - val_mae: 430.5799\n",
      "Epoch 223/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329849.0625 - mae: 416.9341 - val_loss: 376507.5000 - val_mae: 429.9175\n",
      "Epoch 224/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329992.6250 - mae: 417.6012 - val_loss: 378841.2500 - val_mae: 430.1719\n",
      "Epoch 225/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329823.9375 - mae: 417.5261 - val_loss: 378832.1250 - val_mae: 430.2606\n",
      "Epoch 226/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329656.3750 - mae: 416.9471 - val_loss: 377133.4688 - val_mae: 430.4384\n",
      "Epoch 227/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329239.8125 - mae: 417.1519 - val_loss: 376208.5000 - val_mae: 429.3829\n",
      "Epoch 228/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 329314.7812 - mae: 416.8613 - val_loss: 374880.0625 - val_mae: 428.6090\n",
      "Epoch 229/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329027.5938 - mae: 416.9940 - val_loss: 377146.9062 - val_mae: 429.1814\n",
      "Epoch 230/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328793.5000 - mae: 416.7527 - val_loss: 378166.6562 - val_mae: 430.1270\n",
      "Epoch 231/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328968.2500 - mae: 416.4231 - val_loss: 374099.4688 - val_mae: 428.8796\n",
      "Epoch 232/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328645.4375 - mae: 416.8105 - val_loss: 375090.2500 - val_mae: 428.9321\n",
      "Epoch 233/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328700.0938 - mae: 416.9313 - val_loss: 374045.6562 - val_mae: 428.2656\n",
      "Epoch 234/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328698.8750 - mae: 416.4669 - val_loss: 374242.6875 - val_mae: 428.9764\n",
      "Epoch 235/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 328332.9375 - mae: 416.6659 - val_loss: 374140.3750 - val_mae: 428.7670\n",
      "Epoch 236/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328233.8438 - mae: 416.7037 - val_loss: 373905.0938 - val_mae: 428.4490\n",
      "Epoch 237/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328203.7500 - mae: 416.5465 - val_loss: 375635.4375 - val_mae: 430.0497\n",
      "Epoch 238/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 328347.1875 - mae: 416.7035 - val_loss: 375650.0000 - val_mae: 429.6524\n",
      "Epoch 239/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 328152.8125 - mae: 416.8261 - val_loss: 375783.2188 - val_mae: 427.9057\n",
      "Epoch 240/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 327989.5938 - mae: 416.2733 - val_loss: 372875.4688 - val_mae: 427.7356\n",
      "Epoch 241/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 327651.3438 - mae: 416.3493 - val_loss: 375311.9688 - val_mae: 428.9638\n",
      "Epoch 242/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 327954.3750 - mae: 416.0110 - val_loss: 371316.5312 - val_mae: 427.4214\n",
      "Epoch 243/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327459.9375 - mae: 416.0287 - val_loss: 373937.8125 - val_mae: 428.8509\n",
      "Epoch 244/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327734.3125 - mae: 416.3773 - val_loss: 373839.8750 - val_mae: 429.1564\n",
      "Epoch 245/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327523.9375 - mae: 416.2296 - val_loss: 373971.1875 - val_mae: 428.0533\n",
      "Epoch 246/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327343.6562 - mae: 415.7440 - val_loss: 375024.0000 - val_mae: 429.5525\n",
      "Epoch 247/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 327658.2812 - mae: 416.5305 - val_loss: 371249.9688 - val_mae: 427.7516\n",
      "Epoch 248/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327073.4062 - mae: 416.3467 - val_loss: 372498.1250 - val_mae: 427.7021\n",
      "Epoch 249/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327123.8750 - mae: 415.7447 - val_loss: 372448.6875 - val_mae: 428.2849\n",
      "Epoch 250/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326954.6562 - mae: 415.6755 - val_loss: 374355.3125 - val_mae: 429.0901\n"
     ]
    }
   ],
   "source": [
    "# 用梯度下降 - 小批量随机梯度下降（MBGD）- mse + adam\n",
    "\n",
    "result34_adam_dict = {\n",
    "    'units': [],\n",
    "    'batch_size': [],\n",
    "    'learning_rate': [],\n",
    "    'minimum_mae_error': []\n",
    "}\n",
    "\n",
    "for units in para_dict['hidden_units']:\n",
    "    for b_size in para_dict['batch_size']:\n",
    "        for rate in para_dict['learning_rate'][0]:\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor = 'val_mae',\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "            optimizer = Adam(learning_rate = rate)\n",
    "\n",
    "            model = create_model(columns = x_train.columns, units = units, loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "            best_model = model.fit(\n",
    "                x_scaled_train, y_train,\n",
    "                validation_data = (x_scaled_test, y_test),\n",
    "                batch_size = b_size,\n",
    "                epochs = 250,\n",
    "                callbacks = [early_stopping]\n",
    "            )\n",
    "\n",
    "            min_mae = early_stopping.best\n",
    "\n",
    "            result34_adam_dict['units'].append(units)\n",
    "            result34_adam_dict['batch_size'].append(b_size)\n",
    "            result34_adam_dict['learning_rate'].append(rate)\n",
    "            result34_adam_dict['minimum_mae_error'].append(min_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>minimum_mae_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>438.642181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>421.768707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>444.606171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>427.654205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>431.937073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>436.990997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>430.238525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>427.203339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>424.160950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>431.932556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>427.205109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>422.665009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>420.145844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>425.919342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>424.051697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>426.982269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>427.778381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>427.421387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  batch_size  learning_rate  minimum_mae_error\n",
       "0       7          16          0.008         438.642181\n",
       "1       7          16          0.010         421.768707\n",
       "2       7          32          0.008         444.606171\n",
       "3       7          32          0.010         427.654205\n",
       "4       7          64          0.008         431.937073\n",
       "5       7          64          0.010         436.990997\n",
       "6       8          16          0.008         430.238525\n",
       "7       8          16          0.010         427.203339\n",
       "8       8          32          0.008         424.160950\n",
       "9       8          32          0.010         431.932556\n",
       "10      8          64          0.008         427.205109\n",
       "11      8          64          0.010         422.665009\n",
       "12      9          16          0.008         420.145844\n",
       "13      9          16          0.010         425.919342\n",
       "14      9          32          0.008         424.051697\n",
       "15      9          32          0.010         426.982269\n",
       "16      9          64          0.008         427.778381\n",
       "17      9          64          0.010         427.421387"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result34_adam_df = pd.DataFrame(result34_adam_dict)\n",
    "\n",
    "result34_adam_df.to_csv('result34_adam.csv')\n",
    "\n",
    "result34_adam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5919 entries, 0 to 5918\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   lat              5919 non-null   float64\n",
      " 1   remaining_lease  5919 non-null   float64\n",
      " 2   DBSS             5919 non-null   bool   \n",
      " 3   Model A          5919 non-null   bool   \n",
      " 4   New Generation   5919 non-null   bool   \n",
      " 5   Type S1          5919 non-null   bool   \n",
      " 6   01 TO 03         5919 non-null   bool   \n",
      " 7   22 TO 24         5919 non-null   bool   \n",
      " 8   25 TO 27         5919 non-null   bool   \n",
      " 9   28 TO 30         5919 non-null   bool   \n",
      " 10  34 TO 36         5919 non-null   bool   \n",
      " 11  BUKIT MERAH      5919 non-null   bool   \n",
      " 12  CENTRAL AREA     5919 non-null   bool   \n",
      " 13  QUEENSTOWN       5919 non-null   bool   \n",
      " 14  WOODLANDS        5919 non-null   bool   \n",
      "dtypes: bool(13), float64(2)\n",
      "memory usage: 167.8 KB\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model 16\n",
    "'''\n",
    "\n",
    "# train set\n",
    "y_train = train16_df['resale_price_per_sqm']\n",
    "x_train = train16_df.drop('resale_price_per_sqm', axis = 1)\n",
    "\n",
    "# test set\n",
    "y_test = test16_df[['resale_price_per_sqm']]\n",
    "x_test = test16_df.drop('resale_price_per_sqm', axis = 1)\n",
    "\n",
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>01 TO 03</th>\n",
       "      <th>22 TO 24</th>\n",
       "      <th>25 TO 27</th>\n",
       "      <th>28 TO 30</th>\n",
       "      <th>34 TO 36</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156048</td>\n",
       "      <td>1.261190</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007990</td>\n",
       "      <td>-0.878525</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>2.772393</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>2.218645</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.354411</td>\n",
       "      <td>-0.200213</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>3.268705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.404001</td>\n",
       "      <td>1.371485</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.225188</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012449</td>\n",
       "      <td>-0.867495</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>-0.669887</td>\n",
       "      <td>-1.672645</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>2.218645</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>-0.934243</td>\n",
       "      <td>-1.126687</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>2.772393</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>0.433403</td>\n",
       "      <td>1.172955</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.225188</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>-0.738033</td>\n",
       "      <td>0.152730</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>0.439144</td>\n",
       "      <td>0.979939</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13811 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat  remaining_lease      DBSS   Model A  New Generation  \\\n",
       "0      0.156048         1.261190 -0.113286 -0.816201       -0.360699   \n",
       "1      0.007990        -0.878525 -0.113286 -0.816201        2.772393   \n",
       "2      1.354411        -0.200213 -0.113286 -0.816201       -0.360699   \n",
       "3     -0.404001         1.371485 -0.113286  1.225188       -0.360699   \n",
       "4      0.012449        -0.867495 -0.113286 -0.816201       -0.360699   \n",
       "...         ...              ...       ...       ...             ...   \n",
       "13806 -0.669887        -1.672645 -0.113286 -0.816201       -0.360699   \n",
       "13807 -0.934243        -1.126687 -0.113286 -0.816201        2.772393   \n",
       "13808  0.433403         1.172955 -0.113286  1.225188       -0.360699   \n",
       "13809 -0.738033         0.152730 -0.113286 -0.816201       -0.360699   \n",
       "13810  0.439144         0.979939 -0.113286 -0.816201       -0.360699   \n",
       "\n",
       "        Type S1  01 TO 03  22 TO 24  25 TO 27  28 TO 30  34 TO 36  \\\n",
       "0     -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "1     -0.039943  2.218645 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "2     -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "3     -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "4     -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "13806 -0.039943  2.218645 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "13807 -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "13808 -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "13809 -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "13810 -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "\n",
       "       BUKIT MERAH  CENTRAL AREA  QUEENSTOWN  WOODLANDS  \n",
       "0        -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "1        -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "2        -0.198981     -0.082337   -0.159825   3.268705  \n",
       "3        -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "4        -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "...            ...           ...         ...        ...  \n",
       "13806    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "13807    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "13808    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "13809    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "13810    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "\n",
       "[13811 rows x 15 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_scaled_train = scaler.fit_transform(x_train)\n",
    "\n",
    "x_scaled_train = pd.DataFrame(x_scaled_train, columns = x_train.columns)\n",
    "\n",
    "x_scaled_test = scaler.fit_transform(x_test)\n",
    "\n",
    "x_scaled_test = pd.DataFrame(x_scaled_test, columns = x_test.columns)\n",
    "\n",
    "x_scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4333.5039 - mae: 4333.5039 - val_loss: 640.2736 - val_mae: 640.2736\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 624.3925 - mae: 624.3925 - val_loss: 654.2614 - val_mae: 654.2614\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 621.2056 - mae: 621.2056 - val_loss: 634.6089 - val_mae: 634.6089\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 619.6724 - mae: 619.6724 - val_loss: 631.2358 - val_mae: 631.2358\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 615.4807 - mae: 615.4807 - val_loss: 624.4448 - val_mae: 624.4448\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610.7493 - mae: 610.7493 - val_loss: 618.1853 - val_mae: 618.1853\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599.5564 - mae: 599.5564 - val_loss: 600.0408 - val_mae: 600.0408\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585.3232 - mae: 585.3232 - val_loss: 582.6163 - val_mae: 582.6163\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 566.0663 - mae: 566.0663 - val_loss: 564.9841 - val_mae: 564.9841\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554.7086 - mae: 554.7086 - val_loss: 555.7256 - val_mae: 555.7256\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.2177 - mae: 549.2177 - val_loss: 563.2236 - val_mae: 563.2236\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544.0458 - mae: 544.0458 - val_loss: 567.4205 - val_mae: 567.4205\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544.2567 - mae: 544.2567 - val_loss: 547.1548 - val_mae: 547.1548\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.6989 - mae: 541.6989 - val_loss: 549.3489 - val_mae: 549.3489\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.7543 - mae: 541.7543 - val_loss: 548.5925 - val_mae: 548.5925\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 542.2908 - mae: 542.2908 - val_loss: 549.4255 - val_mae: 549.4255\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.5616 - mae: 539.5616 - val_loss: 537.0724 - val_mae: 537.0724\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.5100 - mae: 540.5100 - val_loss: 533.1183 - val_mae: 533.1183\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.3617 - mae: 539.3617 - val_loss: 542.3101 - val_mae: 542.3101\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.2269 - mae: 538.2269 - val_loss: 548.8228 - val_mae: 548.8228\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.2376 - mae: 538.2376 - val_loss: 550.3679 - val_mae: 550.3679\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.0284 - mae: 538.0284 - val_loss: 543.6431 - val_mae: 543.6431\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.1520 - mae: 536.1520 - val_loss: 548.4832 - val_mae: 548.4832\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.1403 - mae: 535.1403 - val_loss: 536.7810 - val_mae: 536.7810\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.8617 - mae: 535.8617 - val_loss: 547.4188 - val_mae: 547.4188\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.0471 - mae: 535.0471 - val_loss: 533.7971 - val_mae: 533.7971\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 534.5462 - mae: 534.5462 - val_loss: 533.4467 - val_mae: 533.4467\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 535.0129 - mae: 535.0129 - val_loss: 535.7701 - val_mae: 535.7701\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3441.4624 - mae: 3441.4624 - val_loss: 633.5718 - val_mae: 633.5718\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 619.9540 - mae: 619.9540 - val_loss: 632.4625 - val_mae: 632.4625\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 618.2764 - mae: 618.2764 - val_loss: 627.0689 - val_mae: 627.0689\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 615.8522 - mae: 615.8522 - val_loss: 620.9579 - val_mae: 620.9579\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 613.8469 - mae: 613.8469 - val_loss: 618.0873 - val_mae: 618.0873\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610.7003 - mae: 610.7003 - val_loss: 615.8779 - val_mae: 615.8779\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 607.9841 - mae: 607.9841 - val_loss: 608.4283 - val_mae: 608.4283\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602.1024 - mae: 602.1024 - val_loss: 589.3739 - val_mae: 589.3739\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 587.6037 - mae: 587.6037 - val_loss: 571.6570 - val_mae: 571.6570\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 568.5226 - mae: 568.5226 - val_loss: 575.3766 - val_mae: 575.3766\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558.7960 - mae: 558.7960 - val_loss: 560.4863 - val_mae: 560.4863\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.7890 - mae: 553.7890 - val_loss: 571.9749 - val_mae: 571.9749\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 552.4320 - mae: 552.4320 - val_loss: 558.9234 - val_mae: 558.9234\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.7245 - mae: 551.7245 - val_loss: 553.1135 - val_mae: 553.1135\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.6239 - mae: 549.6239 - val_loss: 581.5618 - val_mae: 581.5618\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.6120 - mae: 550.6120 - val_loss: 580.5406 - val_mae: 580.5406\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.9095 - mae: 551.9095 - val_loss: 551.3267 - val_mae: 551.3267\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 550.3713 - mae: 550.3713 - val_loss: 560.8787 - val_mae: 560.8787\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 551.1425 - mae: 551.1425 - val_loss: 552.9786 - val_mae: 552.9786\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 548.2153 - mae: 548.2153 - val_loss: 556.2802 - val_mae: 556.2802\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.0195 - mae: 550.0195 - val_loss: 553.5477 - val_mae: 553.5477\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.9970 - mae: 548.9970 - val_loss: 561.3571 - val_mae: 561.3571\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 549.1111 - mae: 549.1111 - val_loss: 550.5713 - val_mae: 550.5713\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 549.6846 - mae: 549.6846 - val_loss: 552.5463 - val_mae: 552.5463\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.6906 - mae: 548.6906 - val_loss: 554.6966 - val_mae: 554.6966\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.5888 - mae: 548.5888 - val_loss: 558.3516 - val_mae: 558.3516\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.2344 - mae: 549.2344 - val_loss: 551.7416 - val_mae: 551.7416\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 546.6866 - mae: 546.6866 - val_loss: 563.4911 - val_mae: 563.4911\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.4489 - mae: 547.4489 - val_loss: 544.0536 - val_mae: 544.0536\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 545.2858 - mae: 545.2858 - val_loss: 562.0409 - val_mae: 562.0409\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 546.4348 - mae: 546.4348 - val_loss: 582.3367 - val_mae: 582.3367\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546.2935 - mae: 546.2935 - val_loss: 548.9748 - val_mae: 548.9748\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546.0062 - mae: 546.0062 - val_loss: 557.6223 - val_mae: 557.6223\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 546.1885 - mae: 546.1885 - val_loss: 575.1020 - val_mae: 575.1020\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.9463 - mae: 545.9463 - val_loss: 548.1318 - val_mae: 548.1318\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 546.7844 - mae: 546.7844 - val_loss: 558.9910 - val_mae: 558.9910\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 546.8621 - mae: 546.8621 - val_loss: 546.8378 - val_mae: 546.8378\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 546.6307 - mae: 546.6307 - val_loss: 545.6093 - val_mae: 545.6093\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 546.0339 - mae: 546.0339 - val_loss: 575.3018 - val_mae: 575.3018\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6050.8574 - mae: 6050.8574 - val_loss: 6026.2539 - val_mae: 6026.2539\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4610.0493 - mae: 4610.0493 - val_loss: 688.6216 - val_mae: 688.6216\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619.1556 - mae: 619.1556 - val_loss: 601.5485 - val_mae: 601.5485\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602.8546 - mae: 602.8546 - val_loss: 598.5034 - val_mae: 598.5034\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596.0179 - mae: 596.0179 - val_loss: 595.7248 - val_mae: 595.7248\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593.1929 - mae: 593.1929 - val_loss: 595.5994 - val_mae: 595.5994\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591.3207 - mae: 591.3207 - val_loss: 592.9890 - val_mae: 592.9890\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589.7332 - mae: 589.7332 - val_loss: 595.1646 - val_mae: 595.1646\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588.3666 - mae: 588.3666 - val_loss: 585.5497 - val_mae: 585.5497\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585.5943 - mae: 585.5943 - val_loss: 593.7533 - val_mae: 593.7533\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584.5049 - mae: 584.5049 - val_loss: 582.7201 - val_mae: 582.7201\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580.5617 - mae: 580.5617 - val_loss: 588.4439 - val_mae: 588.4439\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579.1857 - mae: 579.1857 - val_loss: 581.8124 - val_mae: 581.8124\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576.9086 - mae: 576.9086 - val_loss: 585.5125 - val_mae: 585.5125\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573.8837 - mae: 573.8837 - val_loss: 578.8359 - val_mae: 578.8359\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572.7004 - mae: 572.7004 - val_loss: 573.7971 - val_mae: 573.7971\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570.0543 - mae: 570.0543 - val_loss: 576.8647 - val_mae: 576.8647\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567.5223 - mae: 567.5223 - val_loss: 575.0193 - val_mae: 575.0193\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564.1887 - mae: 564.1887 - val_loss: 567.1482 - val_mae: 567.1482\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561.5148 - mae: 561.5148 - val_loss: 563.9809 - val_mae: 563.9809\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558.1165 - mae: 558.1165 - val_loss: 574.0601 - val_mae: 574.0601\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555.7177 - mae: 555.7177 - val_loss: 559.1778 - val_mae: 559.1778\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.4252 - mae: 554.4252 - val_loss: 556.4796 - val_mae: 556.4796\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.1852 - mae: 552.1852 - val_loss: 556.6194 - val_mae: 556.6194\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.7460 - mae: 551.7460 - val_loss: 556.0938 - val_mae: 556.0938\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.0063 - mae: 550.0063 - val_loss: 558.4689 - val_mae: 558.4689\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.3875 - mae: 549.3875 - val_loss: 554.5888 - val_mae: 554.5888\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.5876 - mae: 548.5876 - val_loss: 548.1249 - val_mae: 548.1249\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.2152 - mae: 546.2152 - val_loss: 551.5244 - val_mae: 551.5244\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.6613 - mae: 546.6613 - val_loss: 546.1157 - val_mae: 546.1157\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.4326 - mae: 544.4326 - val_loss: 549.6279 - val_mae: 549.6279\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.7616 - mae: 543.7616 - val_loss: 545.2049 - val_mae: 545.2049\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.3069 - mae: 543.3069 - val_loss: 539.9751 - val_mae: 539.9751\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.1299 - mae: 543.1299 - val_loss: 545.0922 - val_mae: 545.0922\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.9292 - mae: 541.9292 - val_loss: 544.4599 - val_mae: 544.4599\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.9257 - mae: 540.9257 - val_loss: 543.9271 - val_mae: 543.9271\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.0287 - mae: 540.0287 - val_loss: 547.6863 - val_mae: 547.6863\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.3149 - mae: 540.3149 - val_loss: 539.0350 - val_mae: 539.0350\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.5477 - mae: 539.5477 - val_loss: 542.6868 - val_mae: 542.6868\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.8569 - mae: 539.8569 - val_loss: 545.2161 - val_mae: 545.2161\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.6859 - mae: 538.6859 - val_loss: 541.9400 - val_mae: 541.9400\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.0253 - mae: 539.0253 - val_loss: 538.8083 - val_mae: 538.8083\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.2153 - mae: 537.2153 - val_loss: 538.7601 - val_mae: 538.7601\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.9283 - mae: 537.9283 - val_loss: 535.4813 - val_mae: 535.4813\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.6575 - mae: 537.6575 - val_loss: 541.7601 - val_mae: 541.7601\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.3696 - mae: 536.3696 - val_loss: 540.8551 - val_mae: 540.8551\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.2427 - mae: 536.2427 - val_loss: 537.6658 - val_mae: 537.6658\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.6902 - mae: 536.6902 - val_loss: 539.1804 - val_mae: 539.1804\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.1580 - mae: 536.1580 - val_loss: 535.2094 - val_mae: 535.2094\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.5332 - mae: 536.5332 - val_loss: 536.5178 - val_mae: 536.5178\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.6544 - mae: 535.6544 - val_loss: 536.2901 - val_mae: 536.2901\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.0571 - mae: 535.0571 - val_loss: 538.8082 - val_mae: 538.8082\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.4179 - mae: 535.4179 - val_loss: 538.9879 - val_mae: 538.9879\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.9820 - mae: 533.9820 - val_loss: 534.5187 - val_mae: 534.5187\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.6541 - mae: 533.6541 - val_loss: 539.0950 - val_mae: 539.0950\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.7847 - mae: 533.7847 - val_loss: 533.6540 - val_mae: 533.6540\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.0184 - mae: 533.0184 - val_loss: 535.1174 - val_mae: 535.1174\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.4055 - mae: 533.4055 - val_loss: 532.7217 - val_mae: 532.7217\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.5192 - mae: 533.5192 - val_loss: 534.3087 - val_mae: 534.3087\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.1970 - mae: 533.1970 - val_loss: 533.7359 - val_mae: 533.7359\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.6237 - mae: 532.6237 - val_loss: 534.9754 - val_mae: 534.9754\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.3759 - mae: 533.3759 - val_loss: 531.4707 - val_mae: 531.4707\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.1838 - mae: 532.1838 - val_loss: 534.2406 - val_mae: 534.2406\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.8766 - mae: 531.8766 - val_loss: 533.3842 - val_mae: 533.3842\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.6281 - mae: 531.6281 - val_loss: 532.6876 - val_mae: 532.6876\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.1833 - mae: 532.1833 - val_loss: 530.6177 - val_mae: 530.6177\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.1705 - mae: 531.1705 - val_loss: 528.1663 - val_mae: 528.1663\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.8062 - mae: 530.8062 - val_loss: 535.7181 - val_mae: 535.7181\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.6255 - mae: 530.6255 - val_loss: 532.5141 - val_mae: 532.5141\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.3758 - mae: 530.3758 - val_loss: 529.9086 - val_mae: 529.9086\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.9053 - mae: 530.9053 - val_loss: 533.6172 - val_mae: 533.6172\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.8864 - mae: 529.8864 - val_loss: 536.4550 - val_mae: 536.4550\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.6559 - mae: 530.6559 - val_loss: 538.4211 - val_mae: 538.4211\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.5750 - mae: 530.5750 - val_loss: 531.3406 - val_mae: 531.3406\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.7803 - mae: 530.7803 - val_loss: 532.6524 - val_mae: 532.6524\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.9641 - mae: 529.9641 - val_loss: 529.6780 - val_mae: 529.6780\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.3126 - mae: 530.3126 - val_loss: 527.4268 - val_mae: 527.4268\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.1359 - mae: 530.1359 - val_loss: 533.1050 - val_mae: 533.1050\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.7794 - mae: 529.7794 - val_loss: 533.4122 - val_mae: 533.4122\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.3589 - mae: 528.3589 - val_loss: 530.1550 - val_mae: 530.1550\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.2585 - mae: 528.2585 - val_loss: 539.0283 - val_mae: 539.0283\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.1453 - mae: 528.1453 - val_loss: 533.6232 - val_mae: 533.6232\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.2518 - mae: 527.2518 - val_loss: 533.2750 - val_mae: 533.2750\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.0364 - mae: 527.0364 - val_loss: 526.9790 - val_mae: 526.9790\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.5646 - mae: 526.5646 - val_loss: 533.1325 - val_mae: 533.1325\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.2757 - mae: 527.2757 - val_loss: 526.3882 - val_mae: 526.3882\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.8854 - mae: 525.8854 - val_loss: 528.0579 - val_mae: 528.0579\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.0552 - mae: 526.0552 - val_loss: 529.4845 - val_mae: 529.4845\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.4379 - mae: 527.4379 - val_loss: 529.8419 - val_mae: 529.8419\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.4199 - mae: 526.4199 - val_loss: 531.8064 - val_mae: 531.8064\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.3329 - mae: 526.3329 - val_loss: 529.7806 - val_mae: 529.7806\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.8517 - mae: 525.8517 - val_loss: 531.6976 - val_mae: 531.6976\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.9770 - mae: 525.9770 - val_loss: 531.7338 - val_mae: 531.7338\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.6116 - mae: 526.6116 - val_loss: 527.4688 - val_mae: 527.4688\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.1096 - mae: 526.1096 - val_loss: 524.5026 - val_mae: 524.5026\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.9597 - mae: 525.9597 - val_loss: 528.4583 - val_mae: 528.4583\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.3282 - mae: 525.3282 - val_loss: 530.6321 - val_mae: 530.6321\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.1161 - mae: 526.1161 - val_loss: 527.6757 - val_mae: 527.6757\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.0370 - mae: 526.0370 - val_loss: 528.5035 - val_mae: 528.5035\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.7781 - mae: 525.7781 - val_loss: 532.0280 - val_mae: 532.0280\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.5602 - mae: 525.5602 - val_loss: 528.1517 - val_mae: 528.1517\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.9585 - mae: 524.9585 - val_loss: 530.0348 - val_mae: 530.0348\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.5333 - mae: 525.5333 - val_loss: 530.0147 - val_mae: 530.0147\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.7277 - mae: 525.7277 - val_loss: 528.6570 - val_mae: 528.6570\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.7272 - mae: 525.7272 - val_loss: 530.5757 - val_mae: 530.5757\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 5852.8950 - mae: 5852.8950 - val_loss: 4364.8560 - val_mae: 4364.8560\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 971.3000 - mae: 971.3000 - val_loss: 612.8929 - val_mae: 612.8929\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608.8215 - mae: 608.8215 - val_loss: 605.2964 - val_mae: 605.2964\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605.5872 - mae: 605.5872 - val_loss: 606.5737 - val_mae: 606.5737\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603.3401 - mae: 603.3401 - val_loss: 604.7956 - val_mae: 604.7956\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601.6246 - mae: 601.6246 - val_loss: 601.9092 - val_mae: 601.9092\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595.3055 - mae: 595.3055 - val_loss: 593.2010 - val_mae: 593.2010\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590.2397 - mae: 590.2397 - val_loss: 586.2909 - val_mae: 586.2909\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586.8719 - mae: 586.8719 - val_loss: 587.4822 - val_mae: 587.4822\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583.6295 - mae: 583.6295 - val_loss: 583.2121 - val_mae: 583.2121\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583.1661 - mae: 583.1661 - val_loss: 586.6177 - val_mae: 586.6177\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580.7675 - mae: 580.7675 - val_loss: 576.4590 - val_mae: 576.4590\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 577.5701 - mae: 577.5701 - val_loss: 580.7899 - val_mae: 580.7899\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573.1794 - mae: 573.1794 - val_loss: 569.5628 - val_mae: 569.5628\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571.0405 - mae: 571.0405 - val_loss: 567.2572 - val_mae: 567.2572\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570.7640 - mae: 570.7640 - val_loss: 565.4648 - val_mae: 565.4648\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568.8307 - mae: 568.8307 - val_loss: 569.1851 - val_mae: 569.1851\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566.3345 - mae: 566.3345 - val_loss: 564.0417 - val_mae: 564.0417\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560.1049 - mae: 560.1049 - val_loss: 554.7807 - val_mae: 554.7807\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555.9991 - mae: 555.9991 - val_loss: 551.6327 - val_mae: 551.6327\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.3560 - mae: 553.3560 - val_loss: 555.5300 - val_mae: 555.5300\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.3895 - mae: 551.3895 - val_loss: 548.5062 - val_mae: 548.5062\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.8766 - mae: 549.8766 - val_loss: 545.9787 - val_mae: 545.9787\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.7225 - mae: 547.7225 - val_loss: 545.9254 - val_mae: 545.9254\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.5225 - mae: 546.5225 - val_loss: 546.4489 - val_mae: 546.4489\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.3185 - mae: 544.3185 - val_loss: 541.5190 - val_mae: 541.5190\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.2658 - mae: 545.2658 - val_loss: 549.3530 - val_mae: 549.3530\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.7154 - mae: 544.7154 - val_loss: 547.5782 - val_mae: 547.5782\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.0543 - mae: 543.0543 - val_loss: 541.4838 - val_mae: 541.4838\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.4519 - mae: 541.4519 - val_loss: 537.1226 - val_mae: 537.1226\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.8098 - mae: 541.8098 - val_loss: 540.7340 - val_mae: 540.7340\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.6747 - mae: 540.6747 - val_loss: 538.1485 - val_mae: 538.1485\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.5276 - mae: 539.5276 - val_loss: 541.5335 - val_mae: 541.5335\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.3435 - mae: 538.3435 - val_loss: 536.8558 - val_mae: 536.8558\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.6465 - mae: 538.6465 - val_loss: 537.8737 - val_mae: 537.8737\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.5268 - mae: 537.5268 - val_loss: 539.6139 - val_mae: 539.6139\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.2286 - mae: 537.2286 - val_loss: 536.1240 - val_mae: 536.1240\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.7970 - mae: 536.7970 - val_loss: 541.3130 - val_mae: 541.3130\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.7017 - mae: 536.7017 - val_loss: 545.0188 - val_mae: 545.0188\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.1177 - mae: 536.1177 - val_loss: 536.4324 - val_mae: 536.4324\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.8763 - mae: 535.8763 - val_loss: 534.3763 - val_mae: 534.3763\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.5852 - mae: 535.5852 - val_loss: 531.7837 - val_mae: 531.7837\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.0626 - mae: 535.0626 - val_loss: 534.6245 - val_mae: 534.6245\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534.9451 - mae: 534.9451 - val_loss: 538.0308 - val_mae: 538.0308\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534.4498 - mae: 534.4498 - val_loss: 540.9614 - val_mae: 540.9614\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.8271 - mae: 533.8271 - val_loss: 533.4484 - val_mae: 533.4484\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.9634 - mae: 533.9634 - val_loss: 535.3411 - val_mae: 535.3411\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.1815 - mae: 533.1815 - val_loss: 532.5690 - val_mae: 532.5690\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.1171 - mae: 533.1171 - val_loss: 538.7043 - val_mae: 538.7043\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.1804 - mae: 531.1804 - val_loss: 535.2706 - val_mae: 535.2706\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.9380 - mae: 529.9380 - val_loss: 533.1667 - val_mae: 533.1667\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.1517 - mae: 529.1517 - val_loss: 528.2447 - val_mae: 528.2447\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.3038 - mae: 529.3038 - val_loss: 530.4763 - val_mae: 530.4763\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.4295 - mae: 529.4295 - val_loss: 530.7942 - val_mae: 530.7942\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.1680 - mae: 529.1680 - val_loss: 527.8487 - val_mae: 527.8487\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.2673 - mae: 528.2673 - val_loss: 526.0206 - val_mae: 526.0206\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.4250 - mae: 527.4250 - val_loss: 525.6493 - val_mae: 525.6493\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.9202 - mae: 527.9202 - val_loss: 529.9507 - val_mae: 529.9507\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.0889 - mae: 526.0889 - val_loss: 528.2266 - val_mae: 528.2266\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.1023 - mae: 527.1023 - val_loss: 525.9214 - val_mae: 525.9214\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.4831 - mae: 526.4831 - val_loss: 529.4244 - val_mae: 529.4244\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.1103 - mae: 526.1103 - val_loss: 529.6772 - val_mae: 529.6772\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.1175 - mae: 526.1175 - val_loss: 529.5844 - val_mae: 529.5844\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.6698 - mae: 525.6698 - val_loss: 531.9441 - val_mae: 531.9441\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.5936 - mae: 525.5936 - val_loss: 531.6860 - val_mae: 531.6860\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.5827 - mae: 525.5827 - val_loss: 529.4402 - val_mae: 529.4402\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.1091 - mae: 526.1091 - val_loss: 524.9858 - val_mae: 524.9858\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.9534 - mae: 524.9534 - val_loss: 524.5729 - val_mae: 524.5729\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.6196 - mae: 524.6196 - val_loss: 534.3677 - val_mae: 534.3677\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.7611 - mae: 525.7611 - val_loss: 527.9092 - val_mae: 527.9092\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.1395 - mae: 525.1395 - val_loss: 534.4064 - val_mae: 534.4064\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.2011 - mae: 526.2011 - val_loss: 524.0621 - val_mae: 524.0621\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.4603 - mae: 525.4603 - val_loss: 524.2502 - val_mae: 524.2502\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.4551 - mae: 525.4551 - val_loss: 528.3600 - val_mae: 528.3600\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.5693 - mae: 524.5693 - val_loss: 529.5330 - val_mae: 529.5330\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.2883 - mae: 524.2883 - val_loss: 531.3350 - val_mae: 531.3350\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.4023 - mae: 525.4023 - val_loss: 529.2484 - val_mae: 529.2484\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.5637 - mae: 524.5637 - val_loss: 530.1206 - val_mae: 530.1206\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.3598 - mae: 524.3598 - val_loss: 525.3687 - val_mae: 525.3687\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.6474 - mae: 524.6474 - val_loss: 525.8827 - val_mae: 525.8827\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.3046 - mae: 524.3046 - val_loss: 528.4164 - val_mae: 528.4164\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.4456 - mae: 524.4456 - val_loss: 525.9550 - val_mae: 525.9550\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6054.5708 - mae: 6054.5708 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5703 - mae: 6054.5703 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5708 - mae: 6054.5708 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5693 - mae: 6054.5693 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5674 - mae: 6054.5674 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5698 - mae: 6054.5698 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5703 - mae: 6054.5703 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5703 - mae: 6054.5703 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5698 - mae: 6054.5698 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5679 - mae: 6054.5679 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6054.5698 - mae: 6054.5698 - val_loss: 6046.2026 - val_mae: 6046.2026\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6046.0762 - mae: 6046.0762 - val_loss: 6015.7305 - val_mae: 6015.7305\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5676.9209 - mae: 5676.9209 - val_loss: 4457.7554 - val_mae: 4457.7554\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1410.5139 - mae: 1410.5139 - val_loss: 629.3766 - val_mae: 629.3766\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616.2766 - mae: 616.2766 - val_loss: 607.1395 - val_mae: 607.1395\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606.4231 - mae: 606.4231 - val_loss: 610.2651 - val_mae: 610.2651\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603.9166 - mae: 603.9166 - val_loss: 603.2723 - val_mae: 603.2723\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601.8674 - mae: 601.8674 - val_loss: 599.7338 - val_mae: 599.7338\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599.1724 - mae: 599.1724 - val_loss: 598.3293 - val_mae: 598.3293\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595.5836 - mae: 595.5836 - val_loss: 594.8761 - val_mae: 594.8761\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592.8576 - mae: 592.8576 - val_loss: 592.0094 - val_mae: 592.0094\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587.9042 - mae: 587.9042 - val_loss: 587.1606 - val_mae: 587.1606\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583.5993 - mae: 583.5993 - val_loss: 582.9951 - val_mae: 582.9951\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 579.0976 - mae: 579.0976 - val_loss: 577.7167 - val_mae: 577.7167\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 574.4695 - mae: 574.4695 - val_loss: 573.4078 - val_mae: 573.4078\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570.1893 - mae: 570.1893 - val_loss: 568.2701 - val_mae: 568.2701\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 565.6395 - mae: 565.6395 - val_loss: 561.7037 - val_mae: 561.7037\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 562.0928 - mae: 562.0928 - val_loss: 560.8865 - val_mae: 560.8865\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558.2921 - mae: 558.2921 - val_loss: 558.1995 - val_mae: 558.1995\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557.3224 - mae: 557.3224 - val_loss: 555.8329 - val_mae: 555.8329\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554.7134 - mae: 554.7134 - val_loss: 552.4249 - val_mae: 552.4249\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.8355 - mae: 552.8355 - val_loss: 552.8099 - val_mae: 552.8099\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.9102 - mae: 551.9102 - val_loss: 553.5402 - val_mae: 553.5402\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.3969 - mae: 551.3969 - val_loss: 556.1435 - val_mae: 556.1435\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.2897 - mae: 552.2897 - val_loss: 550.2876 - val_mae: 550.2876\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.7190 - mae: 551.7190 - val_loss: 549.2219 - val_mae: 549.2219\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.9869 - mae: 550.9869 - val_loss: 552.8509 - val_mae: 552.8509\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.0986 - mae: 551.0986 - val_loss: 551.2169 - val_mae: 551.2169\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.9401 - mae: 550.9401 - val_loss: 551.6395 - val_mae: 551.6395\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.5567 - mae: 550.5567 - val_loss: 551.2819 - val_mae: 551.2819\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.4185 - mae: 550.4185 - val_loss: 550.4046 - val_mae: 550.4046\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.1249 - mae: 551.1249 - val_loss: 548.3582 - val_mae: 548.3582\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.5626 - mae: 549.5626 - val_loss: 549.6788 - val_mae: 549.6788\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.0429 - mae: 550.0429 - val_loss: 551.3504 - val_mae: 551.3504\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.5782 - mae: 550.5782 - val_loss: 551.3868 - val_mae: 551.3868\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.5013 - mae: 550.5013 - val_loss: 550.7061 - val_mae: 550.7061\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.7567 - mae: 550.7567 - val_loss: 548.3585 - val_mae: 548.3585\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.3796 - mae: 549.3796 - val_loss: 552.5740 - val_mae: 552.5740\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.7643 - mae: 549.7643 - val_loss: 550.0965 - val_mae: 550.0965\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.8036 - mae: 549.8036 - val_loss: 554.8702 - val_mae: 554.8702\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.0963 - mae: 550.0963 - val_loss: 549.2589 - val_mae: 549.2589\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.6697 - mae: 549.6697 - val_loss: 551.3316 - val_mae: 551.3316\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3944.2109 - mae: 3944.2109 - val_loss: 619.0384 - val_mae: 619.0384\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 606.0864 - mae: 606.0864 - val_loss: 623.3640 - val_mae: 623.3640\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 601.7760 - mae: 601.7760 - val_loss: 616.7367 - val_mae: 616.7367\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599.2841 - mae: 599.2841 - val_loss: 601.6583 - val_mae: 601.6583\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 596.5336 - mae: 596.5336 - val_loss: 610.2084 - val_mae: 610.2084\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591.2333 - mae: 591.2333 - val_loss: 591.8183 - val_mae: 591.8183\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 582.9960 - mae: 582.9960 - val_loss: 584.3171 - val_mae: 584.3171\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572.2793 - mae: 572.2793 - val_loss: 580.6019 - val_mae: 580.6019\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565.4615 - mae: 565.4615 - val_loss: 575.9245 - val_mae: 575.9245\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.8713 - mae: 555.8713 - val_loss: 565.8416 - val_mae: 565.8416\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.4566 - mae: 553.4566 - val_loss: 553.7030 - val_mae: 553.7030\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 549.3190 - mae: 549.3190 - val_loss: 549.5405 - val_mae: 549.5405\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.9035 - mae: 547.9035 - val_loss: 563.2431 - val_mae: 563.2431\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544.8040 - mae: 544.8040 - val_loss: 542.2685 - val_mae: 542.2685\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.2581 - mae: 541.2581 - val_loss: 537.4600 - val_mae: 537.4600\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.0618 - mae: 541.0618 - val_loss: 541.5040 - val_mae: 541.5040\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.9189 - mae: 539.9189 - val_loss: 541.0939 - val_mae: 541.0939\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.7036 - mae: 538.7036 - val_loss: 544.1636 - val_mae: 544.1636\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.5884 - mae: 537.5884 - val_loss: 538.0929 - val_mae: 538.0929\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.0801 - mae: 538.0801 - val_loss: 541.6450 - val_mae: 541.6450\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.5493 - mae: 536.5493 - val_loss: 544.9847 - val_mae: 544.9847\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.8104 - mae: 535.8104 - val_loss: 537.0641 - val_mae: 537.0641\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.8558 - mae: 534.8558 - val_loss: 535.4360 - val_mae: 535.4360\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.8301 - mae: 535.8301 - val_loss: 537.5187 - val_mae: 537.5187\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.5709 - mae: 534.5709 - val_loss: 538.7573 - val_mae: 538.7573\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.4692 - mae: 533.4692 - val_loss: 538.8434 - val_mae: 538.8434\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.6473 - mae: 534.6473 - val_loss: 554.9026 - val_mae: 554.9026\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.9887 - mae: 534.9887 - val_loss: 539.2333 - val_mae: 539.2333\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.0692 - mae: 533.0692 - val_loss: 541.0307 - val_mae: 541.0307\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.8354 - mae: 532.8354 - val_loss: 548.6894 - val_mae: 548.6894\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.5028 - mae: 532.5028 - val_loss: 542.7812 - val_mae: 542.7812\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.0196 - mae: 532.0196 - val_loss: 545.0302 - val_mae: 545.0302\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.2305 - mae: 531.2305 - val_loss: 528.7842 - val_mae: 528.7842\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.1617 - mae: 530.1617 - val_loss: 543.8513 - val_mae: 543.8513\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.6845 - mae: 530.6845 - val_loss: 535.2820 - val_mae: 535.2820\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.6796 - mae: 531.6796 - val_loss: 545.8435 - val_mae: 545.8435\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.7158 - mae: 531.7158 - val_loss: 547.8312 - val_mae: 547.8312\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.9521 - mae: 530.9521 - val_loss: 548.3090 - val_mae: 548.3090\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.2612 - mae: 530.2612 - val_loss: 533.3316 - val_mae: 533.3316\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.8096 - mae: 530.8096 - val_loss: 545.8654 - val_mae: 545.8654\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.3698 - mae: 530.3698 - val_loss: 541.3023 - val_mae: 541.3023\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.4492 - mae: 530.4492 - val_loss: 547.5180 - val_mae: 547.5180\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.8326 - mae: 529.8326 - val_loss: 532.2708 - val_mae: 532.2708\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3477.8225 - mae: 3477.8225 - val_loss: 645.1560 - val_mae: 645.1560\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 616.9153 - mae: 616.9153 - val_loss: 630.9583 - val_mae: 630.9583\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610.4216 - mae: 610.4216 - val_loss: 605.2305 - val_mae: 605.2305\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602.8990 - mae: 602.8990 - val_loss: 629.1425 - val_mae: 629.1425\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588.3938 - mae: 588.3938 - val_loss: 580.5478 - val_mae: 580.5478\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570.7588 - mae: 570.7588 - val_loss: 594.4522 - val_mae: 594.4522\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 560.6929 - mae: 560.6929 - val_loss: 577.2341 - val_mae: 577.2341\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 554.5554 - mae: 554.5554 - val_loss: 571.1625 - val_mae: 571.1625\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.9363 - mae: 552.9363 - val_loss: 575.2402 - val_mae: 575.2402\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.1663 - mae: 551.1663 - val_loss: 552.7451 - val_mae: 552.7451\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.2280 - mae: 548.2280 - val_loss: 556.5338 - val_mae: 556.5338\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.7172 - mae: 549.7172 - val_loss: 547.8544 - val_mae: 547.8544\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 548.9397 - mae: 548.9397 - val_loss: 553.0652 - val_mae: 553.0652\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 545.8169 - mae: 545.8169 - val_loss: 552.9951 - val_mae: 552.9951\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.6600 - mae: 545.6600 - val_loss: 563.8873 - val_mae: 563.8873\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.1054 - mae: 545.1054 - val_loss: 563.3764 - val_mae: 563.3764\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 543.6601 - mae: 543.6601 - val_loss: 541.8974 - val_mae: 541.8974\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 542.3221 - mae: 542.3221 - val_loss: 556.2054 - val_mae: 556.2054\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.2984 - mae: 541.2984 - val_loss: 550.1664 - val_mae: 550.1664\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.8239 - mae: 540.8239 - val_loss: 546.0861 - val_mae: 546.0861\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.7394 - mae: 539.7394 - val_loss: 559.0967 - val_mae: 559.0967\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.7467 - mae: 537.7467 - val_loss: 541.7361 - val_mae: 541.7361\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.0316 - mae: 539.0316 - val_loss: 558.6876 - val_mae: 558.6876\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.1689 - mae: 537.1689 - val_loss: 539.2829 - val_mae: 539.2829\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.7578 - mae: 536.7578 - val_loss: 544.3697 - val_mae: 544.3697\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.3696 - mae: 536.3696 - val_loss: 551.2428 - val_mae: 551.2428\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 534.1227 - mae: 534.1227 - val_loss: 583.5002 - val_mae: 583.5002\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.3079 - mae: 534.3079 - val_loss: 557.8087 - val_mae: 557.8087\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.7042 - mae: 533.7042 - val_loss: 542.1307 - val_mae: 542.1307\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 532.5654 - mae: 532.5654 - val_loss: 534.4384 - val_mae: 534.4384\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 532.9509 - mae: 532.9509 - val_loss: 538.0936 - val_mae: 538.0936\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.4271 - mae: 530.4271 - val_loss: 551.8735 - val_mae: 551.8735\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.1065 - mae: 532.1065 - val_loss: 531.1767 - val_mae: 531.1767\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.4112 - mae: 529.4112 - val_loss: 545.3693 - val_mae: 545.3693\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.2009 - mae: 530.2009 - val_loss: 532.9866 - val_mae: 532.9866\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.0942 - mae: 529.0942 - val_loss: 537.1260 - val_mae: 537.1260\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.4705 - mae: 528.4705 - val_loss: 534.8969 - val_mae: 534.8969\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.9941 - mae: 526.9941 - val_loss: 539.1941 - val_mae: 539.1941\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.6110 - mae: 528.6110 - val_loss: 532.6990 - val_mae: 532.6990\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.2543 - mae: 527.2543 - val_loss: 546.9196 - val_mae: 546.9196\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.4385 - mae: 527.4385 - val_loss: 539.4651 - val_mae: 539.4651\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.6736 - mae: 526.6736 - val_loss: 534.2378 - val_mae: 534.2378\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 526.4683 - mae: 526.4683 - val_loss: 526.4012 - val_mae: 526.4012\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.4842 - mae: 526.4842 - val_loss: 527.7156 - val_mae: 527.7156\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.1157 - mae: 526.1157 - val_loss: 527.0888 - val_mae: 527.0888\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 524.6665 - mae: 524.6665 - val_loss: 525.1899 - val_mae: 525.1899\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 524.9244 - mae: 524.9244 - val_loss: 528.9769 - val_mae: 528.9769\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 523.3450 - mae: 523.3450 - val_loss: 551.5184 - val_mae: 551.5184\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 523.6486 - mae: 523.6486 - val_loss: 527.6373 - val_mae: 527.6373\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 522.0813 - mae: 522.0813 - val_loss: 523.9698 - val_mae: 523.9698\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 521.1924 - mae: 521.1924 - val_loss: 534.7471 - val_mae: 534.7471\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 520.6104 - mae: 520.6104 - val_loss: 549.5195 - val_mae: 549.5195\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 521.7106 - mae: 521.7106 - val_loss: 520.3384 - val_mae: 520.3384\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 519.8466 - mae: 519.8466 - val_loss: 552.1680 - val_mae: 552.1680\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 521.6351 - mae: 521.6351 - val_loss: 523.1794 - val_mae: 523.1794\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 519.0812 - mae: 519.0812 - val_loss: 538.6104 - val_mae: 538.6104\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 517.1354 - mae: 517.1354 - val_loss: 523.6681 - val_mae: 523.6681\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 518.1208 - mae: 518.1208 - val_loss: 534.6209 - val_mae: 534.6209\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 518.2117 - mae: 518.2117 - val_loss: 521.7902 - val_mae: 521.7902\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 518.1439 - mae: 518.1439 - val_loss: 520.7531 - val_mae: 520.7531\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 517.3696 - mae: 517.3696 - val_loss: 557.4073 - val_mae: 557.4073\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 519.0848 - mae: 519.0848 - val_loss: 547.3611 - val_mae: 547.3611\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 517.3277 - mae: 517.3277 - val_loss: 538.8105 - val_mae: 538.8105\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6018.0249 - mae: 6018.0249 - val_loss: 5817.9575 - val_mae: 5817.9575\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2543.5044 - mae: 2543.5044 - val_loss: 605.9588 - val_mae: 605.9588\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602.7269 - mae: 602.7269 - val_loss: 601.8766 - val_mae: 601.8766\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598.0353 - mae: 598.0353 - val_loss: 597.2323 - val_mae: 597.2323\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593.5312 - mae: 593.5312 - val_loss: 589.1978 - val_mae: 589.1978\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587.6235 - mae: 587.6235 - val_loss: 587.4888 - val_mae: 587.4888\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579.5880 - mae: 579.5880 - val_loss: 575.6132 - val_mae: 575.6132\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574.2690 - mae: 574.2690 - val_loss: 569.2085 - val_mae: 569.2085\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569.2941 - mae: 569.2941 - val_loss: 567.3856 - val_mae: 567.3856\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563.4534 - mae: 563.4534 - val_loss: 559.7691 - val_mae: 559.7691\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559.5136 - mae: 559.5136 - val_loss: 564.1326 - val_mae: 564.1326\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556.8488 - mae: 556.8488 - val_loss: 559.0952 - val_mae: 559.0952\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.1627 - mae: 554.1627 - val_loss: 554.3330 - val_mae: 554.3330\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.2532 - mae: 553.2532 - val_loss: 552.2268 - val_mae: 552.2268\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.0677 - mae: 552.0677 - val_loss: 549.8843 - val_mae: 549.8843\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.4493 - mae: 551.4493 - val_loss: 554.7872 - val_mae: 554.7872\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.5071 - mae: 551.5071 - val_loss: 554.0508 - val_mae: 554.0508\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.6539 - mae: 550.6539 - val_loss: 552.7273 - val_mae: 552.7273\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.1011 - mae: 550.1011 - val_loss: 552.0475 - val_mae: 552.0475\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.6837 - mae: 549.6837 - val_loss: 552.1038 - val_mae: 552.1038\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.2361 - mae: 548.2361 - val_loss: 553.2088 - val_mae: 553.2088\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.7525 - mae: 548.7525 - val_loss: 550.0169 - val_mae: 550.0169\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.0244 - mae: 548.0244 - val_loss: 547.3427 - val_mae: 547.3427\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.7123 - mae: 547.7123 - val_loss: 551.9075 - val_mae: 551.9075\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.9175 - mae: 546.9175 - val_loss: 548.5259 - val_mae: 548.5259\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.5988 - mae: 546.5988 - val_loss: 547.3315 - val_mae: 547.3315\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.1354 - mae: 545.1354 - val_loss: 552.9832 - val_mae: 552.9832\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.2428 - mae: 545.2428 - val_loss: 549.9851 - val_mae: 549.9851\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.3743 - mae: 544.3743 - val_loss: 544.9139 - val_mae: 544.9139\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.5590 - mae: 543.5590 - val_loss: 547.5483 - val_mae: 547.5483\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.1017 - mae: 544.1017 - val_loss: 548.4047 - val_mae: 548.4047\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542.6266 - mae: 542.6266 - val_loss: 545.9437 - val_mae: 545.9437\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542.5815 - mae: 542.5815 - val_loss: 541.4384 - val_mae: 541.4384\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.9236 - mae: 541.9236 - val_loss: 545.0693 - val_mae: 545.0693\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.9474 - mae: 541.9474 - val_loss: 542.6512 - val_mae: 542.6512\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.7046 - mae: 541.7046 - val_loss: 548.7993 - val_mae: 548.7993\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542.0208 - mae: 542.0208 - val_loss: 542.3177 - val_mae: 542.3177\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.2410 - mae: 541.2410 - val_loss: 546.9725 - val_mae: 546.9725\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.6629 - mae: 540.6629 - val_loss: 544.2801 - val_mae: 544.2801\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.1831 - mae: 540.1831 - val_loss: 538.6379 - val_mae: 538.6379\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.3518 - mae: 538.3518 - val_loss: 543.4136 - val_mae: 543.4136\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.9026 - mae: 535.9026 - val_loss: 540.5728 - val_mae: 540.5728\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.8879 - mae: 533.8879 - val_loss: 537.6270 - val_mae: 537.6270\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.8584 - mae: 533.8584 - val_loss: 534.4577 - val_mae: 534.4577\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.7574 - mae: 532.7574 - val_loss: 539.9956 - val_mae: 539.9956\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.4024 - mae: 531.4024 - val_loss: 533.4636 - val_mae: 533.4636\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.1813 - mae: 531.1813 - val_loss: 528.6993 - val_mae: 528.6993\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.2469 - mae: 530.2469 - val_loss: 529.4401 - val_mae: 529.4401\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.8380 - mae: 528.8380 - val_loss: 532.3214 - val_mae: 532.3214\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.2416 - mae: 529.2416 - val_loss: 531.4474 - val_mae: 531.4474\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.6330 - mae: 528.6330 - val_loss: 528.7137 - val_mae: 528.7137\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.0640 - mae: 528.0640 - val_loss: 525.3089 - val_mae: 525.3089\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.0423 - mae: 527.0423 - val_loss: 527.7245 - val_mae: 527.7245\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.1612 - mae: 527.1612 - val_loss: 533.5880 - val_mae: 533.5880\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.7543 - mae: 526.7543 - val_loss: 533.0596 - val_mae: 533.0596\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.9894 - mae: 525.9894 - val_loss: 534.5600 - val_mae: 534.5600\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.3928 - mae: 525.3928 - val_loss: 529.5018 - val_mae: 529.5018\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.8415 - mae: 525.8415 - val_loss: 529.1915 - val_mae: 529.1915\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.7916 - mae: 525.7916 - val_loss: 526.4644 - val_mae: 526.4644\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.5197 - mae: 524.5197 - val_loss: 529.9705 - val_mae: 529.9705\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.5580 - mae: 524.5580 - val_loss: 529.1957 - val_mae: 529.1957\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.2518 - mae: 525.2518 - val_loss: 528.4702 - val_mae: 528.4702\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 5838.7842 - mae: 5838.7842 - val_loss: 4265.7539 - val_mae: 4265.7539\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 943.1500 - mae: 943.1500 - val_loss: 612.4334 - val_mae: 612.4334\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607.1965 - mae: 607.1965 - val_loss: 606.0111 - val_mae: 606.0111\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605.6750 - mae: 605.6750 - val_loss: 602.4259 - val_mae: 602.4259\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604.4805 - mae: 604.4805 - val_loss: 599.9951 - val_mae: 599.9951\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602.1779 - mae: 602.1779 - val_loss: 600.3608 - val_mae: 600.3608\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601.4325 - mae: 601.4325 - val_loss: 603.2974 - val_mae: 603.2974\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598.2238 - mae: 598.2238 - val_loss: 603.4011 - val_mae: 603.4011\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591.8987 - mae: 591.8987 - val_loss: 586.4533 - val_mae: 586.4533\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581.6995 - mae: 581.6995 - val_loss: 574.0187 - val_mae: 574.0187\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570.9677 - mae: 570.9677 - val_loss: 566.7042 - val_mae: 566.7042\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562.2493 - mae: 562.2493 - val_loss: 564.5380 - val_mae: 564.5380\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.8515 - mae: 554.8515 - val_loss: 550.1279 - val_mae: 550.1279\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.9088 - mae: 550.9088 - val_loss: 554.3307 - val_mae: 554.3307\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.6583 - mae: 548.6583 - val_loss: 542.9138 - val_mae: 542.9138\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.8061 - mae: 548.8061 - val_loss: 549.2353 - val_mae: 549.2353\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.9477 - mae: 547.9477 - val_loss: 545.5065 - val_mae: 545.5065\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.0267 - mae: 547.0267 - val_loss: 548.9370 - val_mae: 548.9370\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.4189 - mae: 546.4189 - val_loss: 542.3688 - val_mae: 542.3688\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.3242 - mae: 545.3242 - val_loss: 557.4466 - val_mae: 557.4466\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.1279 - mae: 545.1279 - val_loss: 549.7051 - val_mae: 549.7051\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.5987 - mae: 546.5987 - val_loss: 545.1721 - val_mae: 545.1721\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.6140 - mae: 546.6140 - val_loss: 546.8815 - val_mae: 546.8815\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.1769 - mae: 545.1769 - val_loss: 553.6373 - val_mae: 553.6373\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.7286 - mae: 544.7286 - val_loss: 546.2408 - val_mae: 546.2408\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.4406 - mae: 545.4406 - val_loss: 545.9547 - val_mae: 545.9547\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.8553 - mae: 544.8553 - val_loss: 549.3176 - val_mae: 549.3176\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.8917 - mae: 544.8917 - val_loss: 552.8688 - val_mae: 552.8688\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.3221 - mae: 544.3221 - val_loss: 545.4036 - val_mae: 545.4036\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6053.9746 - mae: 6053.9746 - val_loss: 6043.9160 - val_mae: 6043.9160\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6041.7603 - mae: 6041.7603 - val_loss: 6006.5610 - val_mae: 6006.5610\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5777.7964 - mae: 5777.7964 - val_loss: 5110.6855 - val_mae: 5110.6855\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2466.3074 - mae: 2466.3074 - val_loss: 801.6982 - val_mae: 801.6982\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 627.8342 - mae: 627.8342 - val_loss: 605.4794 - val_mae: 605.4794\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605.0370 - mae: 605.0370 - val_loss: 603.1688 - val_mae: 603.1688\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603.2338 - mae: 603.2338 - val_loss: 600.4427 - val_mae: 600.4427\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601.3171 - mae: 601.3171 - val_loss: 599.4238 - val_mae: 599.4238\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599.4595 - mae: 599.4595 - val_loss: 599.1672 - val_mae: 599.1672\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598.1871 - mae: 598.1871 - val_loss: 596.1205 - val_mae: 596.1205\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595.0606 - mae: 595.0606 - val_loss: 596.2755 - val_mae: 596.2755\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592.9257 - mae: 592.9257 - val_loss: 590.3427 - val_mae: 590.3427\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588.8699 - mae: 588.8699 - val_loss: 584.6826 - val_mae: 584.6826\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585.8488 - mae: 585.8488 - val_loss: 582.3140 - val_mae: 582.3140\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581.9163 - mae: 581.9163 - val_loss: 581.0227 - val_mae: 581.0227\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578.3476 - mae: 578.3476 - val_loss: 574.6714 - val_mae: 574.6714\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 573.7061 - mae: 573.7061 - val_loss: 571.7583 - val_mae: 571.7583\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 568.9368 - mae: 568.9368 - val_loss: 572.6198 - val_mae: 572.6198\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 567.4852 - mae: 567.4852 - val_loss: 568.2938 - val_mae: 568.2938\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564.0422 - mae: 564.0422 - val_loss: 563.3123 - val_mae: 563.3123\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561.8358 - mae: 561.8358 - val_loss: 557.6741 - val_mae: 557.6741\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558.8044 - mae: 558.8044 - val_loss: 555.1329 - val_mae: 555.1329\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557.3325 - mae: 557.3325 - val_loss: 557.5114 - val_mae: 557.5114\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555.2954 - mae: 555.2954 - val_loss: 554.4630 - val_mae: 554.4630\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553.6501 - mae: 553.6501 - val_loss: 553.3077 - val_mae: 553.3077\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553.5240 - mae: 553.5240 - val_loss: 552.7587 - val_mae: 552.7587\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.6355 - mae: 552.6355 - val_loss: 553.6533 - val_mae: 553.6533\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.1961 - mae: 552.1961 - val_loss: 551.5474 - val_mae: 551.5474\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.0050 - mae: 551.0050 - val_loss: 558.5897 - val_mae: 558.5897\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.1000 - mae: 551.1000 - val_loss: 551.7775 - val_mae: 551.7775\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.5592 - mae: 550.5592 - val_loss: 550.4155 - val_mae: 550.4155\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.0862 - mae: 551.0862 - val_loss: 548.4024 - val_mae: 548.4024\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.3835 - mae: 550.3835 - val_loss: 553.0758 - val_mae: 553.0758\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.4724 - mae: 550.4724 - val_loss: 548.2715 - val_mae: 548.2715\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.0319 - mae: 550.0319 - val_loss: 552.2238 - val_mae: 552.2238\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.3176 - mae: 549.3176 - val_loss: 550.4901 - val_mae: 550.4901\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.2300 - mae: 550.2300 - val_loss: 546.9928 - val_mae: 546.9928\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.0920 - mae: 549.0920 - val_loss: 548.8732 - val_mae: 548.8732\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.6577 - mae: 548.6577 - val_loss: 546.9816 - val_mae: 546.9816\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.7160 - mae: 548.7160 - val_loss: 551.9739 - val_mae: 551.9739\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.5679 - mae: 548.5679 - val_loss: 548.6043 - val_mae: 548.6043\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.3244 - mae: 548.3244 - val_loss: 550.9436 - val_mae: 550.9436\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.0057 - mae: 549.0057 - val_loss: 548.5549 - val_mae: 548.5549\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.7961 - mae: 548.7961 - val_loss: 548.3076 - val_mae: 548.3076\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.2498 - mae: 548.2498 - val_loss: 547.9767 - val_mae: 547.9767\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.3565 - mae: 548.3565 - val_loss: 549.3633 - val_mae: 549.3633\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.5371 - mae: 548.5371 - val_loss: 546.9407 - val_mae: 546.9407\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.6440 - mae: 547.6440 - val_loss: 549.9823 - val_mae: 549.9823\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.1590 - mae: 548.1590 - val_loss: 546.4530 - val_mae: 546.4530\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.3878 - mae: 547.3878 - val_loss: 549.0912 - val_mae: 549.0912\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.3618 - mae: 547.3618 - val_loss: 547.8371 - val_mae: 547.8371\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.6293 - mae: 547.6293 - val_loss: 547.5604 - val_mae: 547.5604\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.4661 - mae: 546.4661 - val_loss: 546.4573 - val_mae: 546.4573\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.5729 - mae: 546.5729 - val_loss: 547.5855 - val_mae: 547.5855\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.5329 - mae: 546.5329 - val_loss: 548.3771 - val_mae: 548.3771\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.6587 - mae: 546.6587 - val_loss: 550.3623 - val_mae: 550.3623\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.0939 - mae: 546.0939 - val_loss: 546.1631 - val_mae: 546.1631\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.1603 - mae: 546.1603 - val_loss: 547.8193 - val_mae: 547.8193\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.9100 - mae: 544.9100 - val_loss: 545.6083 - val_mae: 545.6083\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.3387 - mae: 546.3387 - val_loss: 547.7881 - val_mae: 547.7881\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.5410 - mae: 545.5410 - val_loss: 544.5529 - val_mae: 544.5529\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.9312 - mae: 544.9312 - val_loss: 544.7139 - val_mae: 544.7139\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.1526 - mae: 545.1526 - val_loss: 546.3403 - val_mae: 546.3403\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.0632 - mae: 545.0632 - val_loss: 545.0399 - val_mae: 545.0399\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.4334 - mae: 544.4334 - val_loss: 543.7365 - val_mae: 543.7365\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.4260 - mae: 544.4260 - val_loss: 546.7461 - val_mae: 546.7461\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.6972 - mae: 544.6972 - val_loss: 543.3876 - val_mae: 543.3876\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.8891 - mae: 543.8891 - val_loss: 544.7921 - val_mae: 544.7921\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.7577 - mae: 543.7577 - val_loss: 543.3314 - val_mae: 543.3314\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.9036 - mae: 543.9036 - val_loss: 543.8488 - val_mae: 543.8488\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.9558 - mae: 543.9558 - val_loss: 542.7860 - val_mae: 542.7860\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.0815 - mae: 543.0815 - val_loss: 544.0349 - val_mae: 544.0349\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.1217 - mae: 543.1217 - val_loss: 546.1486 - val_mae: 546.1486\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.2463 - mae: 543.2463 - val_loss: 543.6035 - val_mae: 543.6035\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.0637 - mae: 543.0637 - val_loss: 543.0146 - val_mae: 543.0146\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.0255 - mae: 543.0255 - val_loss: 541.3474 - val_mae: 541.3474\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.4423 - mae: 542.4423 - val_loss: 541.1010 - val_mae: 541.1010\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.9414 - mae: 541.9414 - val_loss: 543.1664 - val_mae: 543.1664\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.3640 - mae: 542.3640 - val_loss: 540.3882 - val_mae: 540.3882\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.5674 - mae: 542.5674 - val_loss: 541.8007 - val_mae: 541.8007\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.3231 - mae: 542.3231 - val_loss: 542.3516 - val_mae: 542.3516\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.3316 - mae: 542.3316 - val_loss: 543.4362 - val_mae: 543.4362\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.3892 - mae: 541.3892 - val_loss: 540.7593 - val_mae: 540.7593\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.2443 - mae: 541.2443 - val_loss: 538.5978 - val_mae: 538.5978\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.4760 - mae: 541.4760 - val_loss: 541.7332 - val_mae: 541.7332\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.4180 - mae: 541.4180 - val_loss: 540.4215 - val_mae: 540.4215\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.2636 - mae: 541.2636 - val_loss: 539.7057 - val_mae: 539.7057\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.2122 - mae: 541.2122 - val_loss: 541.3563 - val_mae: 541.3563\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.8289 - mae: 540.8289 - val_loss: 542.6111 - val_mae: 542.6111\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.9160 - mae: 540.9160 - val_loss: 539.5246 - val_mae: 539.5246\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.3340 - mae: 540.3340 - val_loss: 539.0353 - val_mae: 539.0353\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.6349 - mae: 540.6349 - val_loss: 538.4007 - val_mae: 538.4007\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.3070 - mae: 540.3070 - val_loss: 540.1240 - val_mae: 540.1240\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.7625 - mae: 539.7625 - val_loss: 543.2438 - val_mae: 543.2438\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.9735 - mae: 540.9735 - val_loss: 544.6416 - val_mae: 544.6416\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.8781 - mae: 539.8781 - val_loss: 541.2603 - val_mae: 541.2603\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.8078 - mae: 539.8078 - val_loss: 544.4917 - val_mae: 544.4917\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.6353 - mae: 540.6353 - val_loss: 540.4115 - val_mae: 540.4115\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.7870 - mae: 539.7870 - val_loss: 538.6364 - val_mae: 538.6364\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.7004 - mae: 539.7004 - val_loss: 539.7693 - val_mae: 539.7693\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.6805 - mae: 539.6805 - val_loss: 539.2587 - val_mae: 539.2587\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.6868 - mae: 539.6868 - val_loss: 538.7739 - val_mae: 538.7739\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6052.3833 - mae: 6052.3833 - val_loss: 6038.4092 - val_mae: 6038.4092\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5979.3101 - mae: 5979.3101 - val_loss: 5746.0278 - val_mae: 5746.0278\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3411.0527 - mae: 3411.0527 - val_loss: 696.6143 - val_mae: 696.6143\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 622.0479 - mae: 622.0479 - val_loss: 612.9851 - val_mae: 612.9851\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612.9030 - mae: 612.9030 - val_loss: 611.3788 - val_mae: 611.3788\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612.7903 - mae: 612.7903 - val_loss: 609.1185 - val_mae: 609.1185\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611.7900 - mae: 611.7900 - val_loss: 609.1153 - val_mae: 609.1153\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609.9776 - mae: 609.9776 - val_loss: 610.7462 - val_mae: 610.7462\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609.1625 - mae: 609.1625 - val_loss: 604.5671 - val_mae: 604.5671\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607.9545 - mae: 607.9545 - val_loss: 603.5134 - val_mae: 603.5134\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606.3633 - mae: 606.3633 - val_loss: 604.1129 - val_mae: 604.1129\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603.5845 - mae: 603.5845 - val_loss: 604.1987 - val_mae: 604.1987\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601.1245 - mae: 601.1245 - val_loss: 598.2902 - val_mae: 598.2902\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596.0071 - mae: 596.0071 - val_loss: 588.3386 - val_mae: 588.3386\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591.5067 - mae: 591.5067 - val_loss: 583.7839 - val_mae: 583.7839\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582.9672 - mae: 582.9672 - val_loss: 577.8492 - val_mae: 577.8492\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 576.2564 - mae: 576.2564 - val_loss: 573.8539 - val_mae: 573.8539\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570.0943 - mae: 570.0943 - val_loss: 566.4420 - val_mae: 566.4420\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564.5098 - mae: 564.5098 - val_loss: 559.2252 - val_mae: 559.2252\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560.5762 - mae: 560.5762 - val_loss: 558.0901 - val_mae: 558.0901\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557.4387 - mae: 557.4387 - val_loss: 554.6143 - val_mae: 554.6143\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554.8289 - mae: 554.8289 - val_loss: 554.3873 - val_mae: 554.3873\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554.2100 - mae: 554.2100 - val_loss: 549.6574 - val_mae: 549.6574\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.5582 - mae: 552.5582 - val_loss: 549.2764 - val_mae: 549.2764\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.6125 - mae: 551.6125 - val_loss: 550.9456 - val_mae: 550.9456\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.2811 - mae: 551.2811 - val_loss: 551.6437 - val_mae: 551.6437\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.9027 - mae: 550.9027 - val_loss: 549.5002 - val_mae: 549.5002\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.4634 - mae: 550.4634 - val_loss: 548.6617 - val_mae: 548.6617\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.8487 - mae: 549.8487 - val_loss: 549.7848 - val_mae: 549.7848\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.9733 - mae: 549.9733 - val_loss: 551.7410 - val_mae: 551.7410\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.9660 - mae: 548.9660 - val_loss: 548.7424 - val_mae: 548.7424\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.2718 - mae: 548.2718 - val_loss: 547.5689 - val_mae: 547.5689\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.1546 - mae: 548.1546 - val_loss: 546.3553 - val_mae: 546.3553\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.5986 - mae: 547.5986 - val_loss: 544.6879 - val_mae: 544.6879\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 546.5982 - mae: 546.5982 - val_loss: 548.9345 - val_mae: 548.9345\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.8700 - mae: 546.8700 - val_loss: 544.3961 - val_mae: 544.3961\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.7676 - mae: 545.7676 - val_loss: 545.3214 - val_mae: 545.3214\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.6130 - mae: 545.6130 - val_loss: 542.9854 - val_mae: 542.9854\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.9778 - mae: 543.9778 - val_loss: 543.6059 - val_mae: 543.6059\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.3547 - mae: 544.3547 - val_loss: 544.6618 - val_mae: 544.6618\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.5687 - mae: 543.5687 - val_loss: 546.1109 - val_mae: 546.1109\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.9315 - mae: 543.9315 - val_loss: 543.1199 - val_mae: 543.1199\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.7086 - mae: 543.7086 - val_loss: 548.5807 - val_mae: 548.5807\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.4438 - mae: 543.4438 - val_loss: 541.6848 - val_mae: 541.6848\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.1323 - mae: 543.1323 - val_loss: 546.4838 - val_mae: 546.4838\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.9294 - mae: 542.9294 - val_loss: 542.9150 - val_mae: 542.9150\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.9294 - mae: 542.9294 - val_loss: 542.2893 - val_mae: 542.2893\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.1041 - mae: 542.1041 - val_loss: 543.7848 - val_mae: 543.7848\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.1103 - mae: 542.1103 - val_loss: 543.7610 - val_mae: 543.7610\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.8937 - mae: 541.8937 - val_loss: 547.3456 - val_mae: 547.3456\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.3851 - mae: 542.3851 - val_loss: 541.7734 - val_mae: 541.7734\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.8423 - mae: 541.8423 - val_loss: 539.2332 - val_mae: 539.2332\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.5499 - mae: 541.5499 - val_loss: 544.0921 - val_mae: 544.0921\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.2183 - mae: 541.2183 - val_loss: 544.8255 - val_mae: 544.8255\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.0053 - mae: 541.0053 - val_loss: 542.6468 - val_mae: 542.6468\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.0689 - mae: 541.0689 - val_loss: 540.9909 - val_mae: 540.9909\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.3149 - mae: 541.3149 - val_loss: 543.0870 - val_mae: 543.0870\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.2104 - mae: 541.2104 - val_loss: 545.1981 - val_mae: 545.1981\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.6846 - mae: 541.6846 - val_loss: 539.6271 - val_mae: 539.6271\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.0329 - mae: 541.0329 - val_loss: 540.4496 - val_mae: 540.4496\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.0701 - mae: 541.0701 - val_loss: 539.9664 - val_mae: 539.9664\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.0866 - mae: 541.0866 - val_loss: 541.5215 - val_mae: 541.5215\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4337.5850 - mae: 4337.5850 - val_loss: 629.2233 - val_mae: 629.2233\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 608.3336 - mae: 608.3336 - val_loss: 604.5009 - val_mae: 604.5009\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599.0764 - mae: 599.0764 - val_loss: 588.2540 - val_mae: 588.2540\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584.2559 - mae: 584.2559 - val_loss: 594.0891 - val_mae: 594.0891\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576.3196 - mae: 576.3196 - val_loss: 574.8578 - val_mae: 574.8578\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572.3085 - mae: 572.3085 - val_loss: 582.8477 - val_mae: 582.8477\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565.8733 - mae: 565.8733 - val_loss: 571.6597 - val_mae: 571.6597\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563.3643 - mae: 563.3643 - val_loss: 568.1309 - val_mae: 568.1309\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560.3264 - mae: 560.3264 - val_loss: 565.9954 - val_mae: 565.9954\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557.3674 - mae: 557.3674 - val_loss: 555.2885 - val_mae: 555.2885\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.1711 - mae: 555.1711 - val_loss: 568.0666 - val_mae: 568.0666\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.3374 - mae: 553.3374 - val_loss: 580.1220 - val_mae: 580.1220\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.1168 - mae: 550.1168 - val_loss: 552.1323 - val_mae: 552.1323\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.3719 - mae: 550.3719 - val_loss: 555.1541 - val_mae: 555.1541\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.1730 - mae: 548.1730 - val_loss: 546.4046 - val_mae: 546.4046\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.6782 - mae: 545.6782 - val_loss: 546.2056 - val_mae: 546.2056\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 543.9511 - mae: 543.9511 - val_loss: 548.5291 - val_mae: 548.5291\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.7767 - mae: 541.7767 - val_loss: 539.4465 - val_mae: 539.4465\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.9400 - mae: 540.9400 - val_loss: 539.0167 - val_mae: 539.0167\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.3855 - mae: 539.3855 - val_loss: 545.7249 - val_mae: 545.7249\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.1979 - mae: 539.1979 - val_loss: 552.6727 - val_mae: 552.6727\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 538.0356 - mae: 538.0356 - val_loss: 538.5874 - val_mae: 538.5874\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.4978 - mae: 536.4978 - val_loss: 542.7760 - val_mae: 542.7760\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.8425 - mae: 536.8425 - val_loss: 547.2380 - val_mae: 547.2380\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.0996 - mae: 537.0996 - val_loss: 543.4205 - val_mae: 543.4205\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.5893 - mae: 535.5893 - val_loss: 533.6951 - val_mae: 533.6951\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.9669 - mae: 534.9669 - val_loss: 533.4891 - val_mae: 533.4891\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.5509 - mae: 534.5509 - val_loss: 533.0889 - val_mae: 533.0889\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.7133 - mae: 534.7133 - val_loss: 529.8749 - val_mae: 529.8749\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.4092 - mae: 533.4092 - val_loss: 541.2508 - val_mae: 541.2508\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.8444 - mae: 532.8444 - val_loss: 539.9050 - val_mae: 539.9050\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.9546 - mae: 532.9546 - val_loss: 534.8654 - val_mae: 534.8654\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.2827 - mae: 532.2827 - val_loss: 531.4592 - val_mae: 531.4592\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.7724 - mae: 532.7724 - val_loss: 538.7306 - val_mae: 538.7306\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.9321 - mae: 531.9321 - val_loss: 532.1396 - val_mae: 532.1396\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 532.1940 - mae: 532.1940 - val_loss: 536.9404 - val_mae: 536.9404\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 530.9341 - mae: 530.9341 - val_loss: 536.5006 - val_mae: 536.5006\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.0547 - mae: 531.0547 - val_loss: 541.4349 - val_mae: 541.4349\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.6440 - mae: 529.6440 - val_loss: 538.0749 - val_mae: 538.0749\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3739.5945 - mae: 3739.5945 - val_loss: 623.7900 - val_mae: 623.7900\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 624.6025 - mae: 624.6025 - val_loss: 624.8206 - val_mae: 624.8206\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 623.8776 - mae: 623.8776 - val_loss: 642.8694 - val_mae: 642.8694\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 616.3331 - mae: 616.3331 - val_loss: 606.9120 - val_mae: 606.9120\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592.8528 - mae: 592.8528 - val_loss: 580.5246 - val_mae: 580.5246\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570.0367 - mae: 570.0367 - val_loss: 561.8982 - val_mae: 561.8982\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 561.2883 - mae: 561.2883 - val_loss: 572.7284 - val_mae: 572.7284\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557.1550 - mae: 557.1550 - val_loss: 555.6168 - val_mae: 555.6168\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556.4769 - mae: 556.4769 - val_loss: 566.6749 - val_mae: 566.6749\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.5557 - mae: 553.5557 - val_loss: 583.7812 - val_mae: 583.7812\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 553.2860 - mae: 553.2860 - val_loss: 566.7139 - val_mae: 566.7139\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.5676 - mae: 550.5676 - val_loss: 569.5743 - val_mae: 569.5743\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.0160 - mae: 552.0160 - val_loss: 546.1275 - val_mae: 546.1275\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.8097 - mae: 549.8097 - val_loss: 557.0120 - val_mae: 557.0120\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.2592 - mae: 550.2592 - val_loss: 549.6963 - val_mae: 549.6963\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.4106 - mae: 548.4106 - val_loss: 568.6660 - val_mae: 568.6660\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 549.9709 - mae: 549.9709 - val_loss: 544.8206 - val_mae: 544.8206\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.3056 - mae: 548.3056 - val_loss: 556.9423 - val_mae: 556.9423\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.5032 - mae: 548.5032 - val_loss: 569.2347 - val_mae: 569.2347\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 545.4940 - mae: 545.4940 - val_loss: 555.9664 - val_mae: 555.9664\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544.2161 - mae: 544.2161 - val_loss: 549.8108 - val_mae: 549.8108\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 543.4615 - mae: 543.4615 - val_loss: 543.8006 - val_mae: 543.8006\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.0780 - mae: 541.0780 - val_loss: 553.3813 - val_mae: 553.3813\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.4553 - mae: 541.4553 - val_loss: 543.2554 - val_mae: 543.2554\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.2907 - mae: 541.2907 - val_loss: 541.6149 - val_mae: 541.6149\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 542.0226 - mae: 542.0226 - val_loss: 541.9279 - val_mae: 541.9279\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.7483 - mae: 540.7483 - val_loss: 550.4355 - val_mae: 550.4355\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.4727 - mae: 539.4727 - val_loss: 540.0742 - val_mae: 540.0742\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.4836 - mae: 537.4836 - val_loss: 540.6778 - val_mae: 540.6778\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.6167 - mae: 537.6167 - val_loss: 542.2886 - val_mae: 542.2886\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.1534 - mae: 536.1534 - val_loss: 540.2992 - val_mae: 540.2992\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 534.4075 - mae: 534.4075 - val_loss: 535.6033 - val_mae: 535.6033\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 534.5339 - mae: 534.5339 - val_loss: 559.5685 - val_mae: 559.5685\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 534.7097 - mae: 534.7097 - val_loss: 557.3477 - val_mae: 557.3477\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.3081 - mae: 534.3081 - val_loss: 554.7366 - val_mae: 554.7366\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.1886 - mae: 533.1886 - val_loss: 533.0756 - val_mae: 533.0756\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.5593 - mae: 534.5593 - val_loss: 536.9913 - val_mae: 536.9913\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 532.7141 - mae: 532.7141 - val_loss: 539.9442 - val_mae: 539.9442\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.8647 - mae: 531.8647 - val_loss: 533.5765 - val_mae: 533.5765\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.6371 - mae: 532.6371 - val_loss: 534.8530 - val_mae: 534.8530\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 530.8246 - mae: 530.8246 - val_loss: 537.4202 - val_mae: 537.4202\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.5528 - mae: 531.5528 - val_loss: 537.4710 - val_mae: 537.4710\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.9382 - mae: 531.9382 - val_loss: 526.6104 - val_mae: 526.6104\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 529.8654 - mae: 529.8654 - val_loss: 542.1143 - val_mae: 542.1143\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.1999 - mae: 531.1999 - val_loss: 543.6926 - val_mae: 543.6926\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.9105 - mae: 528.9105 - val_loss: 542.8021 - val_mae: 542.8021\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 531.3813 - mae: 531.3813 - val_loss: 544.3333 - val_mae: 544.3333\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 529.8420 - mae: 529.8420 - val_loss: 540.1180 - val_mae: 540.1180\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 529.8618 - mae: 529.8618 - val_loss: 531.8953 - val_mae: 531.8953\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 529.7684 - mae: 529.7684 - val_loss: 539.4327 - val_mae: 539.4327\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.0897 - mae: 529.0897 - val_loss: 536.0084 - val_mae: 536.0084\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 529.1140 - mae: 529.1140 - val_loss: 530.3560 - val_mae: 530.3560\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 527.7030 - mae: 527.7030 - val_loss: 545.9183 - val_mae: 545.9183\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6008.9268 - mae: 6008.9268 - val_loss: 5759.7085 - val_mae: 5759.7085\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2307.4941 - mae: 2307.4941 - val_loss: 623.7254 - val_mae: 623.7254\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617.6210 - mae: 617.6210 - val_loss: 617.7057 - val_mae: 617.7057\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612.9012 - mae: 612.9012 - val_loss: 614.1332 - val_mae: 614.1332\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609.8025 - mae: 609.8025 - val_loss: 602.5146 - val_mae: 602.5146\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605.0917 - mae: 605.0917 - val_loss: 602.0095 - val_mae: 602.0095\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600.1855 - mae: 600.1855 - val_loss: 595.1932 - val_mae: 595.1932\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590.1140 - mae: 590.1140 - val_loss: 588.3352 - val_mae: 588.3352\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581.8773 - mae: 581.8773 - val_loss: 581.6321 - val_mae: 581.6321\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575.2643 - mae: 575.2643 - val_loss: 575.5966 - val_mae: 575.5966\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569.7158 - mae: 569.7158 - val_loss: 567.3578 - val_mae: 567.3578\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564.8129 - mae: 564.8129 - val_loss: 570.1374 - val_mae: 570.1374\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559.9832 - mae: 559.9832 - val_loss: 558.1128 - val_mae: 558.1128\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557.7960 - mae: 557.7960 - val_loss: 557.1755 - val_mae: 557.1755\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.9075 - mae: 553.9075 - val_loss: 556.6194 - val_mae: 556.6194\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.7317 - mae: 551.7317 - val_loss: 555.1774 - val_mae: 555.1774\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.3211 - mae: 550.3211 - val_loss: 546.3676 - val_mae: 546.3676\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.6380 - mae: 547.6380 - val_loss: 546.7913 - val_mae: 546.7913\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.4392 - mae: 547.4392 - val_loss: 548.1239 - val_mae: 548.1239\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.7653 - mae: 544.7653 - val_loss: 544.9127 - val_mae: 544.9127\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.2485 - mae: 544.2485 - val_loss: 550.0206 - val_mae: 550.0206\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.9663 - mae: 540.9663 - val_loss: 539.2180 - val_mae: 539.2180\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.1044 - mae: 540.1044 - val_loss: 539.7335 - val_mae: 539.7335\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.1872 - mae: 539.1872 - val_loss: 547.6325 - val_mae: 547.6325\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.5007 - mae: 538.5007 - val_loss: 538.9603 - val_mae: 538.9603\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.7238 - mae: 538.7238 - val_loss: 538.6551 - val_mae: 538.6551\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.9885 - mae: 537.9885 - val_loss: 541.0098 - val_mae: 541.0098\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.0784 - mae: 537.0784 - val_loss: 540.8100 - val_mae: 540.8100\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.0093 - mae: 537.0093 - val_loss: 536.0261 - val_mae: 536.0261\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534.7971 - mae: 534.7971 - val_loss: 537.5409 - val_mae: 537.5409\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534.4138 - mae: 534.4138 - val_loss: 537.4322 - val_mae: 537.4322\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534.6241 - mae: 534.6241 - val_loss: 533.7020 - val_mae: 533.7020\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.3628 - mae: 533.3628 - val_loss: 534.0954 - val_mae: 534.0954\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.6678 - mae: 532.6678 - val_loss: 532.4617 - val_mae: 532.4617\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.1644 - mae: 532.1644 - val_loss: 535.2883 - val_mae: 535.2883\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.4867 - mae: 531.4867 - val_loss: 538.2832 - val_mae: 538.2832\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.2583 - mae: 531.2583 - val_loss: 536.5082 - val_mae: 536.5082\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.3514 - mae: 531.3514 - val_loss: 535.8739 - val_mae: 535.8739\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.9587 - mae: 531.9587 - val_loss: 530.7033 - val_mae: 530.7033\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.9626 - mae: 530.9626 - val_loss: 533.8316 - val_mae: 533.8316\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.7480 - mae: 530.7480 - val_loss: 530.9921 - val_mae: 530.9921\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.3660 - mae: 529.3660 - val_loss: 535.8684 - val_mae: 535.8684\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.9710 - mae: 528.9710 - val_loss: 532.8842 - val_mae: 532.8842\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.1619 - mae: 530.1619 - val_loss: 532.1265 - val_mae: 532.1265\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.3684 - mae: 529.3684 - val_loss: 532.4323 - val_mae: 532.4323\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.9128 - mae: 529.9128 - val_loss: 531.3820 - val_mae: 531.3820\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.3710 - mae: 528.3710 - val_loss: 531.1729 - val_mae: 531.1729\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.5475 - mae: 528.5475 - val_loss: 531.0302 - val_mae: 531.0302\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.7473 - mae: 528.7473 - val_loss: 530.8207 - val_mae: 530.8207\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 5774.8628 - mae: 5774.8628 - val_loss: 3721.8264 - val_mae: 3721.8264\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 830.3001 - mae: 830.3001 - val_loss: 605.3547 - val_mae: 605.3547\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608.6960 - mae: 608.6960 - val_loss: 609.5847 - val_mae: 609.5847\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599.1975 - mae: 599.1975 - val_loss: 587.2230 - val_mae: 587.2230\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583.4415 - mae: 583.4415 - val_loss: 575.1786 - val_mae: 575.1786\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573.7875 - mae: 573.7875 - val_loss: 567.3276 - val_mae: 567.3276\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566.7495 - mae: 566.7495 - val_loss: 558.3543 - val_mae: 558.3543\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560.6323 - mae: 560.6323 - val_loss: 559.6671 - val_mae: 559.6671\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559.4543 - mae: 559.4543 - val_loss: 560.6609 - val_mae: 560.6609\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556.6232 - mae: 556.6232 - val_loss: 552.8074 - val_mae: 552.8074\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.9623 - mae: 554.9623 - val_loss: 560.5002 - val_mae: 560.5002\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.6219 - mae: 554.6219 - val_loss: 557.1776 - val_mae: 557.1776\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.0976 - mae: 553.0976 - val_loss: 557.0579 - val_mae: 557.0579\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.1766 - mae: 553.1766 - val_loss: 553.6608 - val_mae: 553.6608\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.3569 - mae: 552.3569 - val_loss: 555.5153 - val_mae: 555.5153\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.0477 - mae: 553.0477 - val_loss: 549.7943 - val_mae: 549.7943\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.5503 - mae: 552.5503 - val_loss: 555.9120 - val_mae: 555.9120\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.6389 - mae: 551.6389 - val_loss: 548.9429 - val_mae: 548.9429\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.0565 - mae: 550.0565 - val_loss: 545.7332 - val_mae: 545.7332\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.2713 - mae: 549.2713 - val_loss: 546.4248 - val_mae: 546.4248\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.8931 - mae: 548.8931 - val_loss: 548.1271 - val_mae: 548.1271\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.4152 - mae: 548.4152 - val_loss: 552.7877 - val_mae: 552.7877\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.9154 - mae: 548.9154 - val_loss: 549.9908 - val_mae: 549.9908\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.6757 - mae: 548.6757 - val_loss: 550.0224 - val_mae: 550.0224\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.5739 - mae: 548.5739 - val_loss: 550.4742 - val_mae: 550.4742\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.2966 - mae: 549.2966 - val_loss: 548.8055 - val_mae: 548.8055\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.4973 - mae: 548.4973 - val_loss: 548.1392 - val_mae: 548.1392\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.6198 - mae: 546.6198 - val_loss: 545.8348 - val_mae: 545.8348\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.3636 - mae: 547.3636 - val_loss: 555.5573 - val_mae: 555.5573\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6050.4946 - mae: 6050.4946 - val_loss: 6034.1792 - val_mae: 6034.1792\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5976.2900 - mae: 5976.2900 - val_loss: 5782.3618 - val_mae: 5782.3618\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4091.4136 - mae: 4091.4136 - val_loss: 872.8124 - val_mae: 872.8124\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 658.7115 - mae: 658.7115 - val_loss: 612.6165 - val_mae: 612.6165\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614.2231 - mae: 614.2231 - val_loss: 614.2654 - val_mae: 614.2654\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612.9190 - mae: 612.9190 - val_loss: 613.5728 - val_mae: 613.5728\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611.1173 - mae: 611.1173 - val_loss: 608.3711 - val_mae: 608.3711\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609.1020 - mae: 609.1020 - val_loss: 608.5215 - val_mae: 608.5215\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608.1232 - mae: 608.1232 - val_loss: 608.4161 - val_mae: 608.4161\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606.6771 - mae: 606.6771 - val_loss: 608.7191 - val_mae: 608.7191\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605.4973 - mae: 605.4973 - val_loss: 607.5807 - val_mae: 607.5807\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604.7560 - mae: 604.7560 - val_loss: 603.7941 - val_mae: 603.7941\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603.1149 - mae: 603.1149 - val_loss: 602.5755 - val_mae: 602.5755\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601.1003 - mae: 601.1003 - val_loss: 596.4619 - val_mae: 596.4619\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597.6593 - mae: 597.6593 - val_loss: 592.4301 - val_mae: 592.4301\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594.6658 - mae: 594.6658 - val_loss: 593.2280 - val_mae: 593.2280\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590.7073 - mae: 590.7073 - val_loss: 586.6388 - val_mae: 586.6388\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587.0886 - mae: 587.0886 - val_loss: 582.0834 - val_mae: 582.0834\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581.9814 - mae: 581.9814 - val_loss: 579.8765 - val_mae: 579.8765\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 575.5787 - mae: 575.5787 - val_loss: 572.2695 - val_mae: 572.2695\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570.4387 - mae: 570.4387 - val_loss: 568.7207 - val_mae: 568.7207\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 566.9359 - mae: 566.9359 - val_loss: 562.8624 - val_mae: 562.8624\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563.7687 - mae: 563.7687 - val_loss: 559.1683 - val_mae: 559.1683\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560.9897 - mae: 560.9897 - val_loss: 556.4918 - val_mae: 556.4918\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557.6003 - mae: 557.6003 - val_loss: 553.4634 - val_mae: 553.4634\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555.2253 - mae: 555.2253 - val_loss: 551.2413 - val_mae: 551.2413\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553.7561 - mae: 553.7561 - val_loss: 550.1117 - val_mae: 550.1117\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.6125 - mae: 551.6125 - val_loss: 551.6881 - val_mae: 551.6881\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.1472 - mae: 550.1472 - val_loss: 550.1183 - val_mae: 550.1183\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.2574 - mae: 549.2574 - val_loss: 548.0050 - val_mae: 548.0050\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.1284 - mae: 548.1284 - val_loss: 546.1746 - val_mae: 546.1746\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.8370 - mae: 546.8370 - val_loss: 548.2617 - val_mae: 548.2617\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.4338 - mae: 546.4338 - val_loss: 548.8526 - val_mae: 548.8526\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.4905 - mae: 545.4905 - val_loss: 546.4307 - val_mae: 546.4307\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.8867 - mae: 544.8867 - val_loss: 545.5046 - val_mae: 545.5046\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.6880 - mae: 544.6880 - val_loss: 544.7167 - val_mae: 544.7167\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.8766 - mae: 543.8766 - val_loss: 543.4589 - val_mae: 543.4589\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.4190 - mae: 543.4190 - val_loss: 542.1023 - val_mae: 542.1023\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.1010 - mae: 543.1010 - val_loss: 541.2265 - val_mae: 541.2265\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.6563 - mae: 541.6563 - val_loss: 542.4100 - val_mae: 542.4100\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.6307 - mae: 540.6307 - val_loss: 542.7118 - val_mae: 542.7118\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.7343 - mae: 538.7343 - val_loss: 537.1157 - val_mae: 537.1157\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.6219 - mae: 537.6219 - val_loss: 538.7930 - val_mae: 538.7930\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.2963 - mae: 537.2963 - val_loss: 539.8622 - val_mae: 539.8622\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.9693 - mae: 537.9693 - val_loss: 536.8901 - val_mae: 536.8901\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.2762 - mae: 536.2762 - val_loss: 535.4697 - val_mae: 535.4697\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.0289 - mae: 536.0289 - val_loss: 534.7189 - val_mae: 534.7189\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.6523 - mae: 535.6523 - val_loss: 538.3424 - val_mae: 538.3424\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.9988 - mae: 534.9988 - val_loss: 535.9000 - val_mae: 535.9000\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.6356 - mae: 534.6356 - val_loss: 533.0106 - val_mae: 533.0106\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.6922 - mae: 534.6922 - val_loss: 533.2469 - val_mae: 533.2469\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.7323 - mae: 533.7323 - val_loss: 536.5819 - val_mae: 536.5819\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.0493 - mae: 534.0493 - val_loss: 537.7284 - val_mae: 537.7284\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.9772 - mae: 532.9772 - val_loss: 535.2510 - val_mae: 535.2510\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.8942 - mae: 532.8942 - val_loss: 530.6754 - val_mae: 530.6754\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.4917 - mae: 532.4917 - val_loss: 534.8094 - val_mae: 534.8094\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.6623 - mae: 532.6623 - val_loss: 535.3416 - val_mae: 535.3416\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.4902 - mae: 532.4902 - val_loss: 532.2260 - val_mae: 532.2260\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.2939 - mae: 532.2939 - val_loss: 531.6845 - val_mae: 531.6845\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.9141 - mae: 531.9141 - val_loss: 531.6386 - val_mae: 531.6386\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.9264 - mae: 531.9264 - val_loss: 530.4272 - val_mae: 530.4272\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.3875 - mae: 531.3875 - val_loss: 532.5539 - val_mae: 532.5539\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.1473 - mae: 531.1473 - val_loss: 531.7273 - val_mae: 531.7273\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.8746 - mae: 530.8746 - val_loss: 531.1500 - val_mae: 531.1500\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.9568 - mae: 530.9568 - val_loss: 529.8801 - val_mae: 529.8801\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.8146 - mae: 530.8146 - val_loss: 529.6465 - val_mae: 529.6465\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.3988 - mae: 530.3988 - val_loss: 529.9917 - val_mae: 529.9917\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.4444 - mae: 530.4444 - val_loss: 531.4684 - val_mae: 531.4684\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.5518 - mae: 530.5518 - val_loss: 530.6429 - val_mae: 530.6429\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.9111 - mae: 529.9111 - val_loss: 530.1852 - val_mae: 530.1852\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.5142 - mae: 529.5142 - val_loss: 531.9659 - val_mae: 531.9659\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.7463 - mae: 529.7463 - val_loss: 530.5309 - val_mae: 530.5309\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.2842 - mae: 529.2842 - val_loss: 532.7806 - val_mae: 532.7806\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.2345 - mae: 529.2345 - val_loss: 532.8284 - val_mae: 532.8284\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.1908 - mae: 529.1908 - val_loss: 528.9582 - val_mae: 528.9582\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.4760 - mae: 529.4760 - val_loss: 530.0211 - val_mae: 530.0211\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.4089 - mae: 529.4089 - val_loss: 527.2354 - val_mae: 527.2354\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.5908 - mae: 528.5908 - val_loss: 528.1845 - val_mae: 528.1845\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.6358 - mae: 528.6358 - val_loss: 534.8640 - val_mae: 534.8640\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.7965 - mae: 528.7965 - val_loss: 530.2745 - val_mae: 530.2745\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.2263 - mae: 529.2263 - val_loss: 529.0496 - val_mae: 529.0496\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.6570 - mae: 528.6570 - val_loss: 530.4368 - val_mae: 530.4368\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.3858 - mae: 528.3858 - val_loss: 531.6843 - val_mae: 531.6843\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.1433 - mae: 528.1433 - val_loss: 529.3430 - val_mae: 529.3430\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.7990 - mae: 528.7990 - val_loss: 527.8975 - val_mae: 527.8975\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.8680 - mae: 527.8680 - val_loss: 528.1464 - val_mae: 528.1464\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.1989 - mae: 528.1989 - val_loss: 527.4509 - val_mae: 527.4509\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6044.1289 - mae: 6044.1289 - val_loss: 6007.9478 - val_mae: 6007.9478\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5556.0537 - mae: 5556.0537 - val_loss: 3914.2927 - val_mae: 3914.2927\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1128.5249 - mae: 1128.5249 - val_loss: 617.2951 - val_mae: 617.2951\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614.6216 - mae: 614.6216 - val_loss: 613.2874 - val_mae: 613.2874\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614.8466 - mae: 614.8466 - val_loss: 615.5560 - val_mae: 615.5560\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615.2573 - mae: 615.2573 - val_loss: 614.2741 - val_mae: 614.2741\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614.1005 - mae: 614.1005 - val_loss: 616.8481 - val_mae: 616.8481\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613.2659 - mae: 613.2659 - val_loss: 613.7918 - val_mae: 613.7918\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613.8811 - mae: 613.8811 - val_loss: 610.0176 - val_mae: 610.0176\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612.3345 - mae: 612.3345 - val_loss: 611.9934 - val_mae: 611.9934\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612.2217 - mae: 612.2217 - val_loss: 608.3854 - val_mae: 608.3854\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610.8435 - mae: 610.8435 - val_loss: 610.4849 - val_mae: 610.4849\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608.8802 - mae: 608.8802 - val_loss: 608.5984 - val_mae: 608.5984\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606.5866 - mae: 606.5866 - val_loss: 611.8355 - val_mae: 611.8355\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604.0795 - mae: 604.0795 - val_loss: 603.9322 - val_mae: 603.9322\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599.7585 - mae: 599.7585 - val_loss: 595.0756 - val_mae: 595.0756\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595.5088 - mae: 595.5088 - val_loss: 592.3557 - val_mae: 592.3557\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590.3088 - mae: 590.3088 - val_loss: 588.1239 - val_mae: 588.1239\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584.6649 - mae: 584.6649 - val_loss: 582.4099 - val_mae: 582.4099\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578.5771 - mae: 578.5771 - val_loss: 570.3426 - val_mae: 570.3426\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 572.0300 - mae: 572.0300 - val_loss: 569.0862 - val_mae: 569.0862\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 567.2169 - mae: 567.2169 - val_loss: 562.1535 - val_mae: 562.1535\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563.3149 - mae: 563.3149 - val_loss: 564.7963 - val_mae: 564.7963\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559.7172 - mae: 559.7172 - val_loss: 555.3652 - val_mae: 555.3652\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557.6609 - mae: 557.6609 - val_loss: 556.7266 - val_mae: 556.7266\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555.3716 - mae: 555.3716 - val_loss: 550.8833 - val_mae: 550.8833\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553.7029 - mae: 553.7029 - val_loss: 557.0287 - val_mae: 557.0287\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553.2462 - mae: 553.2462 - val_loss: 556.2098 - val_mae: 556.2098\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.4743 - mae: 552.4743 - val_loss: 554.1963 - val_mae: 554.1963\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.8947 - mae: 552.8947 - val_loss: 552.6670 - val_mae: 552.6670\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.9031 - mae: 551.9031 - val_loss: 549.1165 - val_mae: 549.1165\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.8310 - mae: 551.8310 - val_loss: 550.2763 - val_mae: 550.2763\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.3597 - mae: 552.3597 - val_loss: 550.3857 - val_mae: 550.3857\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.7361 - mae: 551.7361 - val_loss: 551.7757 - val_mae: 551.7757\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.3441 - mae: 551.3441 - val_loss: 552.0648 - val_mae: 552.0648\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.4399 - mae: 551.4399 - val_loss: 552.1633 - val_mae: 552.1633\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.7675 - mae: 550.7675 - val_loss: 552.9119 - val_mae: 552.9119\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.4897 - mae: 551.4897 - val_loss: 550.6068 - val_mae: 550.6068\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.0250 - mae: 552.0250 - val_loss: 550.6427 - val_mae: 550.6427\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.5330 - mae: 551.5330 - val_loss: 552.7059 - val_mae: 552.7059\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.8873 - mae: 551.8873 - val_loss: 551.7545 - val_mae: 551.7545\n"
     ]
    }
   ],
   "source": [
    "# 用梯度下降 - 小批量随机梯度下降（MBGD）- mae + sgd\n",
    "\n",
    "result16_dict = {\n",
    "    'units': [],\n",
    "    'batch_size': [],\n",
    "    'learning_rate': [],\n",
    "    'minimum_mae_error': []\n",
    "}\n",
    "\n",
    "for units in para_dict['hidden_units']:\n",
    "    for b_size in para_dict['batch_size']:\n",
    "        for rate in para_dict['learning_rate'][0]:\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "            optimizer = SGD(learning_rate = rate)\n",
    "\n",
    "            model = create_model(columns = x_train.columns, units = units, optimizer = optimizer)\n",
    "\n",
    "            best_model = model.fit(\n",
    "                x_scaled_train, y_train,\n",
    "                validation_data = (x_scaled_test, y_test),\n",
    "                batch_size = b_size,\n",
    "                epochs = 250,\n",
    "                callbacks = [early_stopping]\n",
    "            )\n",
    "\n",
    "            min_mae = early_stopping.best\n",
    "\n",
    "            result16_dict['units'].append(units)\n",
    "            result16_dict['batch_size'].append(b_size)\n",
    "            result16_dict['learning_rate'].append(rate)\n",
    "            result16_dict['minimum_mae_error'].append(min_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>minimum_mae_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>533.118286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>544.053589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>524.502625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>524.062134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>6046.202637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>548.358154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>528.784241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>520.338440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>525.308899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>542.368774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>538.400696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>539.233154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>529.874939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>526.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>530.703308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>545.733215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>527.235413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>549.116516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  batch_size  learning_rate  minimum_mae_error\n",
       "0       7          16          0.008         533.118286\n",
       "1       7          16          0.010         544.053589\n",
       "2       7          32          0.008         524.502625\n",
       "3       7          32          0.010         524.062134\n",
       "4       7          64          0.008        6046.202637\n",
       "5       7          64          0.010         548.358154\n",
       "6       8          16          0.008         528.784241\n",
       "7       8          16          0.010         520.338440\n",
       "8       8          32          0.008         525.308899\n",
       "9       8          32          0.010         542.368774\n",
       "10      8          64          0.008         538.400696\n",
       "11      8          64          0.010         539.233154\n",
       "12      9          16          0.008         529.874939\n",
       "13      9          16          0.010         526.610352\n",
       "14      9          32          0.008         530.703308\n",
       "15      9          32          0.010         545.733215\n",
       "16      9          64          0.008         527.235413\n",
       "17      9          64          0.010         549.116516"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result16_sgd_df = pd.DataFrame(result16_dict)\n",
    "\n",
    "result16_sgd_df.to_csv('result16_sgd.csv')\n",
    "\n",
    "result16_sgd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 33764916.0000 - mae: 5639.6899 - val_loss: 24582466.0000 - val_mae: 4798.4893\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 14529671.0000 - mae: 3514.8708 - val_loss: 6433597.5000 - val_mae: 2211.1931\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3394161.7500 - mae: 1351.4941 - val_loss: 1792912.2500 - val_mae: 867.7614\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1539530.8750 - mae: 787.2482 - val_loss: 1318663.0000 - val_mae: 732.8066\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1256597.3750 - mae: 728.3976 - val_loss: 1144379.6250 - val_mae: 703.9740\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1103670.3750 - mae: 699.6934 - val_loss: 1028257.7500 - val_mae: 685.5306\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 998530.8125 - mae: 680.1686 - val_loss: 944210.6250 - val_mae: 669.6862\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 921653.3125 - mae: 664.0143 - val_loss: 879079.6875 - val_mae: 653.3306\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 863873.6250 - mae: 650.2001 - val_loss: 836294.0000 - val_mae: 646.3865\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 827464.0625 - mae: 641.1554 - val_loss: 809329.3750 - val_mae: 635.8734\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 804441.8125 - mae: 634.5396 - val_loss: 790545.8750 - val_mae: 631.8141\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 786773.5000 - mae: 628.9636 - val_loss: 774921.1875 - val_mae: 629.5328\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 773561.0000 - mae: 625.5271 - val_loss: 761179.5625 - val_mae: 620.8081\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 763086.5625 - mae: 621.4678 - val_loss: 754848.7500 - val_mae: 617.8098\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 753237.8125 - mae: 618.2561 - val_loss: 744964.9375 - val_mae: 616.3455\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 743263.5625 - mae: 615.0781 - val_loss: 731925.0000 - val_mae: 610.9591\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 731597.3750 - mae: 610.0108 - val_loss: 723555.1875 - val_mae: 610.0380\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 721431.3750 - mae: 606.9606 - val_loss: 715654.8125 - val_mae: 602.6039\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 713490.1250 - mae: 603.1898 - val_loss: 709991.3125 - val_mae: 601.5349\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 706824.6875 - mae: 600.8448 - val_loss: 704400.8750 - val_mae: 600.3658\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 699872.3750 - mae: 598.3407 - val_loss: 697662.0625 - val_mae: 600.4897\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 693891.9375 - mae: 596.6989 - val_loss: 693274.0625 - val_mae: 598.4615\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 687866.6875 - mae: 595.0285 - val_loss: 684956.0625 - val_mae: 590.8123\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 682043.6875 - mae: 592.0240 - val_loss: 678286.4375 - val_mae: 592.0179\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 677061.5625 - mae: 590.9687 - val_loss: 675719.8125 - val_mae: 588.0163\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 671820.9375 - mae: 588.2734 - val_loss: 671376.3750 - val_mae: 587.1846\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 667122.2500 - mae: 586.7125 - val_loss: 665216.4375 - val_mae: 585.5128\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 662862.0000 - mae: 584.8963 - val_loss: 660374.3750 - val_mae: 582.0775\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 659362.8750 - mae: 583.5174 - val_loss: 659147.4375 - val_mae: 580.5896\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 655317.8750 - mae: 581.6318 - val_loss: 656411.9375 - val_mae: 581.7534\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 652498.6875 - mae: 580.8120 - val_loss: 652749.0625 - val_mae: 578.6838\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 649241.3125 - mae: 579.6750 - val_loss: 650754.6250 - val_mae: 578.6623\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 646143.8750 - mae: 578.6129 - val_loss: 651903.5000 - val_mae: 574.7721\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 643233.6250 - mae: 576.8361 - val_loss: 645067.2500 - val_mae: 574.9515\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 641093.3125 - mae: 576.1738 - val_loss: 643651.7500 - val_mae: 573.9316\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 638438.0625 - mae: 575.4800 - val_loss: 644034.3125 - val_mae: 573.6194\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 635759.9375 - mae: 573.9531 - val_loss: 638880.5000 - val_mae: 572.4970\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 633665.0625 - mae: 572.9853 - val_loss: 638408.5000 - val_mae: 577.6734\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 631517.8125 - mae: 572.9131 - val_loss: 635605.1250 - val_mae: 570.1264\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 628974.9375 - mae: 571.1288 - val_loss: 633356.0625 - val_mae: 571.9022\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 627202.2500 - mae: 570.5947 - val_loss: 629664.1875 - val_mae: 568.8000\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 624801.2500 - mae: 569.5192 - val_loss: 631917.4375 - val_mae: 572.5286\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 623418.0625 - mae: 568.9224 - val_loss: 627875.8750 - val_mae: 567.9139\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 620996.6875 - mae: 568.0457 - val_loss: 628799.2500 - val_mae: 569.0107\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 618551.8750 - mae: 567.7332 - val_loss: 625596.3125 - val_mae: 569.4327\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 616424.3750 - mae: 566.7532 - val_loss: 623083.0625 - val_mae: 569.0840\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 614285.3750 - mae: 565.9885 - val_loss: 621064.3750 - val_mae: 568.5331\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 612663.0625 - mae: 565.4693 - val_loss: 619985.1875 - val_mae: 567.4775\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610018.8125 - mae: 564.1731 - val_loss: 617968.3125 - val_mae: 563.8496\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 608001.8125 - mae: 563.6476 - val_loss: 613273.6250 - val_mae: 564.8558\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 605478.0625 - mae: 562.6279 - val_loss: 615641.5625 - val_mae: 564.5211\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602898.5000 - mae: 561.6367 - val_loss: 615306.5625 - val_mae: 567.2964\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 600723.1875 - mae: 561.0648 - val_loss: 612579.4375 - val_mae: 564.4711\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 598986.3125 - mae: 560.3755 - val_loss: 609804.0625 - val_mae: 563.6734\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 596600.3750 - mae: 560.0613 - val_loss: 611610.9375 - val_mae: 561.8788\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595525.8125 - mae: 559.5882 - val_loss: 608896.6875 - val_mae: 562.5405\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593969.6250 - mae: 558.6361 - val_loss: 610701.3125 - val_mae: 562.0594\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592813.5000 - mae: 558.2271 - val_loss: 608188.0000 - val_mae: 562.5873\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591401.6250 - mae: 558.1530 - val_loss: 607571.6250 - val_mae: 560.8513\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590547.3125 - mae: 556.9954 - val_loss: 606938.4375 - val_mae: 562.7448\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588735.5000 - mae: 556.6558 - val_loss: 604425.8750 - val_mae: 564.3586\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588094.6250 - mae: 556.8417 - val_loss: 605057.6875 - val_mae: 559.2894\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 587221.1875 - mae: 555.9000 - val_loss: 605768.9375 - val_mae: 558.4894\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585765.4375 - mae: 554.8571 - val_loss: 605202.3125 - val_mae: 559.1479\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584924.0000 - mae: 554.7610 - val_loss: 602392.3750 - val_mae: 559.8309\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 583404.6875 - mae: 554.1356 - val_loss: 604228.3125 - val_mae: 557.7713\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 582610.6875 - mae: 553.7207 - val_loss: 605247.8750 - val_mae: 560.0798\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 582096.6875 - mae: 552.9172 - val_loss: 601233.1875 - val_mae: 557.3922\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 581150.1250 - mae: 552.8314 - val_loss: 600111.9375 - val_mae: 558.3666\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579969.3125 - mae: 552.3877 - val_loss: 599573.5000 - val_mae: 556.7232\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579678.5000 - mae: 551.9026 - val_loss: 598400.5000 - val_mae: 556.3012\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579254.5625 - mae: 551.5522 - val_loss: 598294.1250 - val_mae: 555.2476\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 578492.0625 - mae: 550.8733 - val_loss: 600681.9375 - val_mae: 558.6449\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 578108.7500 - mae: 551.2755 - val_loss: 603915.1875 - val_mae: 556.0743\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 577004.2500 - mae: 550.2878 - val_loss: 599179.3750 - val_mae: 556.7301\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576939.6875 - mae: 550.0182 - val_loss: 601595.4375 - val_mae: 559.2837\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576689.4375 - mae: 550.5992 - val_loss: 599217.1250 - val_mae: 555.1316\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576439.4375 - mae: 550.2588 - val_loss: 600619.1875 - val_mae: 556.1257\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575929.9375 - mae: 549.8234 - val_loss: 596362.1250 - val_mae: 553.6660\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575991.1875 - mae: 549.5580 - val_loss: 596313.9375 - val_mae: 556.1964\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575550.1875 - mae: 550.3149 - val_loss: 599500.2500 - val_mae: 553.8850\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574945.7500 - mae: 549.1997 - val_loss: 600743.5000 - val_mae: 555.5538\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574551.6875 - mae: 549.4510 - val_loss: 596627.1250 - val_mae: 551.5215\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574993.1875 - mae: 549.2578 - val_loss: 598481.0625 - val_mae: 553.6457\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574609.3750 - mae: 549.4437 - val_loss: 595576.6250 - val_mae: 553.8610\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574000.2500 - mae: 549.0132 - val_loss: 598478.8125 - val_mae: 555.2598\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 573950.5000 - mae: 549.1014 - val_loss: 598203.1875 - val_mae: 556.0328\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 573543.4375 - mae: 548.8622 - val_loss: 595659.5000 - val_mae: 555.1429\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 573363.8750 - mae: 548.9113 - val_loss: 597078.5625 - val_mae: 554.2203\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572896.5000 - mae: 548.4515 - val_loss: 601080.0625 - val_mae: 554.8389\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572295.0625 - mae: 548.0062 - val_loss: 598245.7500 - val_mae: 557.9492\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572077.3750 - mae: 548.1482 - val_loss: 596464.7500 - val_mae: 555.7979\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572095.9375 - mae: 547.9866 - val_loss: 595368.3125 - val_mae: 555.0684\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 31380096.0000 - mae: 5415.5317 - val_loss: 18653354.0000 - val_mae: 4143.5190\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 8823033.0000 - mae: 2554.6929 - val_loss: 2936621.7500 - val_mae: 1288.0455\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1703358.2500 - mae: 925.1390 - val_loss: 1171548.7500 - val_mae: 746.2083\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1006340.8125 - mae: 700.3036 - val_loss: 952679.4375 - val_mae: 661.5177\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 871258.5000 - mae: 651.1461 - val_loss: 889784.3125 - val_mae: 646.7777\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 817634.1875 - mae: 633.8192 - val_loss: 853539.1250 - val_mae: 634.5063\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 788101.6875 - mae: 624.0253 - val_loss: 830663.6250 - val_mae: 626.8882\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 769906.5625 - mae: 617.2819 - val_loss: 813455.1875 - val_mae: 616.8674\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 755768.1875 - mae: 612.7424 - val_loss: 799656.7500 - val_mae: 614.8794\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 745642.1875 - mae: 609.4540 - val_loss: 793479.1875 - val_mae: 616.5302\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 738880.4375 - mae: 608.0599 - val_loss: 783355.7500 - val_mae: 612.6629\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 732632.3750 - mae: 605.6285 - val_loss: 780301.0000 - val_mae: 615.9698\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 726624.2500 - mae: 603.3599 - val_loss: 773489.9375 - val_mae: 607.6646\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 719500.7500 - mae: 600.7363 - val_loss: 766482.1875 - val_mae: 609.0193\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 713887.6875 - mae: 599.2960 - val_loss: 761433.5000 - val_mae: 603.2002\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 710614.1250 - mae: 597.6718 - val_loss: 759997.0000 - val_mae: 598.7535\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 706833.4375 - mae: 595.2896 - val_loss: 754845.9375 - val_mae: 602.8184\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 703194.9375 - mae: 593.5422 - val_loss: 752893.5625 - val_mae: 599.8724\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 700269.8750 - mae: 592.9291 - val_loss: 746378.0000 - val_mae: 597.4658\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 696985.0625 - mae: 590.6953 - val_loss: 743139.0000 - val_mae: 598.9315\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 694546.3125 - mae: 589.2275 - val_loss: 740290.6875 - val_mae: 598.4152\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 692175.0625 - mae: 588.3871 - val_loss: 736761.6250 - val_mae: 598.1486\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 689531.1250 - mae: 587.7360 - val_loss: 732810.3750 - val_mae: 595.5259\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 686509.7500 - mae: 586.4135 - val_loss: 727896.6875 - val_mae: 592.6082\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 683273.1250 - mae: 584.3022 - val_loss: 723731.8750 - val_mae: 587.8354\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 680644.8750 - mae: 582.7656 - val_loss: 722726.3750 - val_mae: 587.6100\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 678487.0625 - mae: 581.9895 - val_loss: 718531.0000 - val_mae: 584.4767\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 677287.3750 - mae: 580.8917 - val_loss: 715847.0000 - val_mae: 583.7568\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 675109.6250 - mae: 579.7545 - val_loss: 719143.7500 - val_mae: 587.7070\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 671734.5000 - mae: 578.3340 - val_loss: 715717.6875 - val_mae: 583.1724\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 670677.0000 - mae: 577.1667 - val_loss: 715941.2500 - val_mae: 590.0089\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 668635.5000 - mae: 577.1705 - val_loss: 711653.1875 - val_mae: 578.4045\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 667761.8750 - mae: 576.0746 - val_loss: 709101.5625 - val_mae: 579.1158\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 666188.9375 - mae: 575.3271 - val_loss: 705189.7500 - val_mae: 580.7030\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 664658.7500 - mae: 574.2313 - val_loss: 709856.7500 - val_mae: 588.7320\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 663034.8750 - mae: 573.8040 - val_loss: 700911.8750 - val_mae: 580.7897\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 661168.6250 - mae: 572.5784 - val_loss: 696500.3750 - val_mae: 579.0654\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 659656.5000 - mae: 572.1725 - val_loss: 693183.6250 - val_mae: 576.2266\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 657904.9375 - mae: 571.2111 - val_loss: 691341.1250 - val_mae: 575.7068\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 656312.5000 - mae: 570.3010 - val_loss: 687780.5625 - val_mae: 576.5175\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 655173.6250 - mae: 569.2900 - val_loss: 686137.3750 - val_mae: 577.0267\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 653551.7500 - mae: 569.5259 - val_loss: 684552.8125 - val_mae: 575.6360\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 651028.9375 - mae: 568.0331 - val_loss: 681397.9375 - val_mae: 573.2456\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 648581.1250 - mae: 566.8875 - val_loss: 675074.1875 - val_mae: 573.1234\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 644810.8750 - mae: 565.9857 - val_loss: 669763.3125 - val_mae: 572.9350\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 640003.1250 - mae: 564.8514 - val_loss: 663138.9375 - val_mae: 571.9575\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 636161.0000 - mae: 563.6606 - val_loss: 658689.6250 - val_mae: 572.1486\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 632233.7500 - mae: 562.9828 - val_loss: 655123.2500 - val_mae: 569.3157\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 628963.8750 - mae: 562.0189 - val_loss: 651436.6875 - val_mae: 568.0377\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 626231.1250 - mae: 561.7688 - val_loss: 645767.0625 - val_mae: 567.7987\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 623336.3125 - mae: 561.4464 - val_loss: 645404.5625 - val_mae: 563.6718\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 620884.0625 - mae: 560.4251 - val_loss: 644104.5000 - val_mae: 566.0591\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 618641.5625 - mae: 560.4193 - val_loss: 638178.8750 - val_mae: 570.9891\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 616355.3750 - mae: 560.2221 - val_loss: 632774.5000 - val_mae: 564.5615\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 614020.5625 - mae: 559.1822 - val_loss: 630769.8750 - val_mae: 565.1763\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 612727.0625 - mae: 560.2548 - val_loss: 632008.7500 - val_mae: 561.1898\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 611202.0625 - mae: 558.9850 - val_loss: 629579.3125 - val_mae: 564.2789\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610014.5625 - mae: 558.9902 - val_loss: 629817.0625 - val_mae: 567.4846\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 608542.1875 - mae: 559.0807 - val_loss: 623612.0625 - val_mae: 562.4218\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 606993.5000 - mae: 558.9027 - val_loss: 620758.1250 - val_mae: 564.7628\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 605575.7500 - mae: 558.8236 - val_loss: 617112.5625 - val_mae: 560.2247\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 605048.2500 - mae: 558.6252 - val_loss: 617294.1250 - val_mae: 563.4329\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 603670.6250 - mae: 558.2560 - val_loss: 615460.2500 - val_mae: 564.2120\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 603087.0000 - mae: 558.5438 - val_loss: 615872.4375 - val_mae: 559.3771\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 601674.0000 - mae: 557.9635 - val_loss: 614238.6250 - val_mae: 558.0385\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 600969.6875 - mae: 558.1902 - val_loss: 608405.9375 - val_mae: 558.3577\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 600228.8125 - mae: 558.0925 - val_loss: 610599.6250 - val_mae: 560.1656\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599642.6250 - mae: 557.9818 - val_loss: 608252.0625 - val_mae: 559.4040\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599256.8125 - mae: 557.5748 - val_loss: 609896.3125 - val_mae: 559.9809\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 597985.6250 - mae: 557.4944 - val_loss: 609219.0625 - val_mae: 562.8397\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 597764.5625 - mae: 557.6464 - val_loss: 602929.4375 - val_mae: 557.6608\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 596877.6875 - mae: 557.5249 - val_loss: 606560.1250 - val_mae: 559.9572\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 596663.8750 - mae: 557.3851 - val_loss: 607198.4375 - val_mae: 557.5827\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 595604.1250 - mae: 556.8825 - val_loss: 605586.3750 - val_mae: 561.2784\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595187.1250 - mae: 556.4738 - val_loss: 604121.6875 - val_mae: 560.9772\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594318.7500 - mae: 556.3994 - val_loss: 605818.3750 - val_mae: 560.9825\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594429.8750 - mae: 557.4177 - val_loss: 603585.7500 - val_mae: 555.0013\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593746.8125 - mae: 556.3948 - val_loss: 605942.3750 - val_mae: 561.4366\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 593931.3750 - mae: 557.2139 - val_loss: 602349.3125 - val_mae: 556.2678\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 593387.6250 - mae: 556.5785 - val_loss: 603274.6875 - val_mae: 556.5090\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592802.1250 - mae: 556.0446 - val_loss: 600766.4375 - val_mae: 555.0090\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592673.6250 - mae: 556.0800 - val_loss: 600369.6875 - val_mae: 555.9070\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 592107.0625 - mae: 556.1422 - val_loss: 602268.8125 - val_mae: 556.4223\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591973.6875 - mae: 556.2267 - val_loss: 599972.7500 - val_mae: 554.9736\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591040.7500 - mae: 555.3119 - val_loss: 602322.1875 - val_mae: 561.1418\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590747.2500 - mae: 556.1480 - val_loss: 600595.2500 - val_mae: 557.2410\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590520.0625 - mae: 556.0101 - val_loss: 600590.9375 - val_mae: 555.7137\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 590797.8125 - mae: 555.4562 - val_loss: 599695.0000 - val_mae: 556.2620\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 590015.0000 - mae: 555.7505 - val_loss: 598771.3750 - val_mae: 556.8201\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590086.1250 - mae: 555.5741 - val_loss: 602596.6875 - val_mae: 557.7978\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 590179.8750 - mae: 555.5174 - val_loss: 604272.5625 - val_mae: 560.0264\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590237.9375 - mae: 555.7013 - val_loss: 600372.1875 - val_mae: 559.3799\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 589308.9375 - mae: 555.6959 - val_loss: 600289.8125 - val_mae: 552.3438\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 589773.1875 - mae: 555.4313 - val_loss: 598492.3125 - val_mae: 558.4006\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 589278.5000 - mae: 555.2227 - val_loss: 599904.1250 - val_mae: 556.7592\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588891.4375 - mae: 555.1493 - val_loss: 599946.9375 - val_mae: 556.6335\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588694.5000 - mae: 555.4021 - val_loss: 599316.9375 - val_mae: 556.8860\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588324.0625 - mae: 555.1883 - val_loss: 596547.6250 - val_mae: 555.1111\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 588718.3750 - mae: 555.4183 - val_loss: 597289.6250 - val_mae: 554.4044\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 588074.1875 - mae: 554.8421 - val_loss: 602094.8750 - val_mae: 555.3652\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 588151.0000 - mae: 555.0253 - val_loss: 598807.9375 - val_mae: 556.9114\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 588285.3750 - mae: 555.4051 - val_loss: 596772.8750 - val_mae: 557.3138\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588199.6875 - mae: 554.8522 - val_loss: 599818.0000 - val_mae: 560.7933\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 37225792.0000 - mae: 5944.6504 - val_loss: 34155164.0000 - val_mae: 5695.1084\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 29261570.0000 - mae: 5242.9487 - val_loss: 23449662.0000 - val_mae: 4681.0215\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 18079176.0000 - mae: 4039.5874 - val_loss: 12765168.0000 - val_mae: 3340.7795\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 9119807.0000 - mae: 2693.2922 - val_loss: 5956046.5000 - val_mae: 2048.9773\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4285757.0000 - mae: 1631.3683 - val_loss: 3031120.0000 - val_mae: 1274.6593\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2481144.7500 - mae: 1106.6603 - val_loss: 2167551.0000 - val_mae: 980.2941\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1962561.2500 - mae: 924.3555 - val_loss: 1931935.7500 - val_mae: 892.2515\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1790002.1250 - mae: 866.5492 - val_loss: 1830792.5000 - val_mae: 854.8444\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1696659.5000 - mae: 835.0517 - val_loss: 1768067.2500 - val_mae: 829.3484\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1633232.7500 - mae: 810.1353 - val_loss: 1722559.3750 - val_mae: 809.1901\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1585790.1250 - mae: 789.8838 - val_loss: 1685610.2500 - val_mae: 793.1214\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1549969.3750 - mae: 774.5214 - val_loss: 1656494.1250 - val_mae: 777.0877\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1522619.3750 - mae: 761.3921 - val_loss: 1635229.2500 - val_mae: 768.5773\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1498689.5000 - mae: 751.1264 - val_loss: 1610029.5000 - val_mae: 755.2365\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1465406.0000 - mae: 739.2220 - val_loss: 1574538.6250 - val_mae: 744.5526\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1425949.2500 - mae: 726.2020 - val_loss: 1535091.3750 - val_mae: 729.5156\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1380624.1250 - mae: 710.7259 - val_loss: 1495655.5000 - val_mae: 715.6065\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1343984.5000 - mae: 698.8604 - val_loss: 1466669.8750 - val_mae: 705.5821\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1316023.2500 - mae: 689.5180 - val_loss: 1446563.8750 - val_mae: 699.7289\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1292073.0000 - mae: 681.2164 - val_loss: 1430740.5000 - val_mae: 694.6910\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1271314.0000 - mae: 673.1365 - val_loss: 1409266.0000 - val_mae: 686.7800\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1253047.3750 - mae: 664.9741 - val_loss: 1393210.3750 - val_mae: 676.7363\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1238982.5000 - mae: 658.1372 - val_loss: 1381354.2500 - val_mae: 668.5439\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1226728.2500 - mae: 650.7310 - val_loss: 1371894.7500 - val_mae: 664.5764\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1217475.5000 - mae: 645.3625 - val_loss: 1365856.8750 - val_mae: 661.0646\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1210845.3750 - mae: 641.4739 - val_loss: 1359745.5000 - val_mae: 658.2750\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1205010.7500 - mae: 638.3074 - val_loss: 1353499.3750 - val_mae: 653.7339\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1199845.6250 - mae: 635.2012 - val_loss: 1348810.1250 - val_mae: 651.0876\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1196176.0000 - mae: 633.3535 - val_loss: 1346822.6250 - val_mae: 650.7603\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1192914.3750 - mae: 631.8121 - val_loss: 1344310.1250 - val_mae: 648.7431\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1190129.5000 - mae: 630.3132 - val_loss: 1339143.6250 - val_mae: 649.0557\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1187430.2500 - mae: 629.1849 - val_loss: 1334842.7500 - val_mae: 646.0521\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1185244.5000 - mae: 628.3688 - val_loss: 1331065.3750 - val_mae: 647.5782\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1183255.1250 - mae: 627.0141 - val_loss: 1328142.2500 - val_mae: 648.4656\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1181095.6250 - mae: 626.5416 - val_loss: 1327945.3750 - val_mae: 648.7224\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1179535.2500 - mae: 625.7186 - val_loss: 1324307.6250 - val_mae: 648.0673\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1177558.0000 - mae: 625.0369 - val_loss: 1320007.2500 - val_mae: 645.7159\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1175569.2500 - mae: 625.0271 - val_loss: 1316623.5000 - val_mae: 641.9218\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1170996.7500 - mae: 623.0327 - val_loss: 1293693.1250 - val_mae: 643.6832\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1151126.7500 - mae: 622.7707 - val_loss: 1263092.1250 - val_mae: 641.4743\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1121088.6250 - mae: 620.7911 - val_loss: 1219256.6250 - val_mae: 635.8196\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1088287.7500 - mae: 618.9312 - val_loss: 1164221.3750 - val_mae: 633.7460\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1046497.0000 - mae: 617.0497 - val_loss: 1102288.2500 - val_mae: 629.2487\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 992116.0625 - mae: 613.9771 - val_loss: 1036899.3125 - val_mae: 624.6180\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 941750.3750 - mae: 610.9722 - val_loss: 982360.1875 - val_mae: 622.7911\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 895419.5000 - mae: 608.1152 - val_loss: 929220.2500 - val_mae: 620.9446\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 848920.1875 - mae: 604.6691 - val_loss: 879029.0000 - val_mae: 617.8536\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 807806.6250 - mae: 602.0479 - val_loss: 835342.5625 - val_mae: 612.9844\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 771758.8750 - mae: 598.5361 - val_loss: 794836.8125 - val_mae: 610.1023\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 741141.1875 - mae: 596.1698 - val_loss: 758735.3750 - val_mae: 604.7762\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 714604.1875 - mae: 592.9459 - val_loss: 732531.9375 - val_mae: 603.4077\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 692772.8125 - mae: 590.0835 - val_loss: 706727.0625 - val_mae: 598.2856\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 674561.6875 - mae: 587.1570 - val_loss: 687588.8125 - val_mae: 595.4645\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 659988.4375 - mae: 584.9275 - val_loss: 671130.6875 - val_mae: 588.6684\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 647917.7500 - mae: 581.2436 - val_loss: 658410.0000 - val_mae: 587.8782\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 638982.7500 - mae: 579.4628 - val_loss: 645991.8750 - val_mae: 585.5938\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 631159.7500 - mae: 577.2186 - val_loss: 636842.5000 - val_mae: 584.0914\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625431.6250 - mae: 575.6247 - val_loss: 630183.5625 - val_mae: 582.2422\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621334.3125 - mae: 575.2303 - val_loss: 622045.1250 - val_mae: 577.1144\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617613.8125 - mae: 573.1847 - val_loss: 619471.1250 - val_mae: 577.0521\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614647.9375 - mae: 572.6467 - val_loss: 618568.8125 - val_mae: 574.4443\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612865.4375 - mae: 571.4227 - val_loss: 615118.6875 - val_mae: 573.8511\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 610717.8125 - mae: 570.5217 - val_loss: 612188.1875 - val_mae: 574.4805\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608994.3750 - mae: 569.8199 - val_loss: 610328.7500 - val_mae: 572.0212\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607017.5000 - mae: 568.9991 - val_loss: 607741.6875 - val_mae: 569.5116\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605391.5000 - mae: 567.4494 - val_loss: 606878.4375 - val_mae: 571.6438\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604159.2500 - mae: 567.0896 - val_loss: 605726.9375 - val_mae: 569.9158\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602564.0625 - mae: 566.0397 - val_loss: 606038.8750 - val_mae: 569.7175\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601601.9375 - mae: 565.9098 - val_loss: 604164.6875 - val_mae: 566.5779\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600230.3125 - mae: 564.0323 - val_loss: 604168.9375 - val_mae: 566.6904\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598911.1250 - mae: 563.7409 - val_loss: 600458.0625 - val_mae: 563.6479\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598039.6250 - mae: 563.1910 - val_loss: 601412.8750 - val_mae: 564.4268\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596899.1875 - mae: 562.1281 - val_loss: 599861.0000 - val_mae: 562.7977\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595871.3750 - mae: 561.5234 - val_loss: 600284.6875 - val_mae: 565.5677\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595033.6250 - mae: 561.1816 - val_loss: 599787.0625 - val_mae: 565.2005\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594302.6875 - mae: 560.8959 - val_loss: 600903.5625 - val_mae: 564.3366\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593350.0625 - mae: 559.6657 - val_loss: 597605.6250 - val_mae: 562.9579\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592691.2500 - mae: 559.6575 - val_loss: 598471.8750 - val_mae: 562.1030\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591585.1250 - mae: 558.4995 - val_loss: 599136.6250 - val_mae: 563.0460\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590903.3750 - mae: 558.4579 - val_loss: 597363.0000 - val_mae: 560.4279\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590041.1875 - mae: 557.9520 - val_loss: 596061.0000 - val_mae: 559.9760\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589726.0000 - mae: 557.6998 - val_loss: 596773.8125 - val_mae: 559.8172\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588994.5625 - mae: 556.7569 - val_loss: 595816.5625 - val_mae: 561.1893\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588129.1875 - mae: 557.0456 - val_loss: 596216.5000 - val_mae: 558.6690\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587572.3750 - mae: 556.1231 - val_loss: 597005.4375 - val_mae: 561.8228\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587132.3750 - mae: 556.1228 - val_loss: 594281.8125 - val_mae: 559.4905\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587128.1875 - mae: 555.7444 - val_loss: 595705.3750 - val_mae: 560.5424\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586213.0000 - mae: 555.8998 - val_loss: 597688.0625 - val_mae: 561.5483\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585867.1875 - mae: 555.5600 - val_loss: 596634.4375 - val_mae: 560.3126\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585540.0000 - mae: 554.8238 - val_loss: 595151.7500 - val_mae: 561.1958\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584959.3750 - mae: 555.1604 - val_loss: 590663.6875 - val_mae: 555.6107\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584283.0625 - mae: 554.2886 - val_loss: 596367.2500 - val_mae: 563.3140\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584036.8750 - mae: 554.7813 - val_loss: 593299.9375 - val_mae: 558.2543\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583877.5625 - mae: 554.3631 - val_loss: 591610.5625 - val_mae: 557.5340\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583194.4375 - mae: 554.0815 - val_loss: 590927.8750 - val_mae: 556.3718\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583021.8750 - mae: 554.0681 - val_loss: 591424.4375 - val_mae: 557.1580\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582530.7500 - mae: 553.7511 - val_loss: 593180.8750 - val_mae: 556.5746\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582312.0625 - mae: 553.1859 - val_loss: 593695.8125 - val_mae: 560.5583\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582014.7500 - mae: 553.3423 - val_loss: 594222.4375 - val_mae: 560.9963\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581313.4375 - mae: 553.7625 - val_loss: 591972.1875 - val_mae: 554.9780\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581098.5625 - mae: 552.6876 - val_loss: 590842.7500 - val_mae: 556.6538\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580614.0625 - mae: 552.3253 - val_loss: 593431.6875 - val_mae: 559.0865\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580438.0000 - mae: 552.5572 - val_loss: 590469.3125 - val_mae: 558.0883\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579845.5000 - mae: 552.3070 - val_loss: 589463.6875 - val_mae: 556.0733\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579650.5000 - mae: 551.8016 - val_loss: 591031.8750 - val_mae: 556.8341\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579856.6875 - mae: 552.3674 - val_loss: 590192.4375 - val_mae: 556.8682\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579203.5625 - mae: 551.7694 - val_loss: 589574.8125 - val_mae: 556.9029\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579011.5625 - mae: 551.2809 - val_loss: 590248.3125 - val_mae: 559.0167\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578961.8125 - mae: 551.7500 - val_loss: 587163.7500 - val_mae: 554.6827\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578229.6250 - mae: 551.5302 - val_loss: 587612.8750 - val_mae: 554.0286\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 577433.8125 - mae: 549.9653 - val_loss: 591666.5000 - val_mae: 561.3843\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 577335.8750 - mae: 551.7045 - val_loss: 585099.0000 - val_mae: 552.8724\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576652.7500 - mae: 550.1223 - val_loss: 587345.5625 - val_mae: 557.1114\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576085.6250 - mae: 550.5169 - val_loss: 584074.6875 - val_mae: 553.4816\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576015.1875 - mae: 550.5138 - val_loss: 585409.6875 - val_mae: 553.1704\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575511.8750 - mae: 549.6051 - val_loss: 584738.3125 - val_mae: 555.3163\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575121.1875 - mae: 549.5574 - val_loss: 586405.6250 - val_mae: 555.8456\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575025.0000 - mae: 549.7659 - val_loss: 585880.1875 - val_mae: 557.1740\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574293.1250 - mae: 550.0644 - val_loss: 584332.8750 - val_mae: 550.9531\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573301.6250 - mae: 548.2087 - val_loss: 586335.1250 - val_mae: 557.9516\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573544.3750 - mae: 549.2272 - val_loss: 580921.7500 - val_mae: 552.9020\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573327.6875 - mae: 548.9799 - val_loss: 582442.8750 - val_mae: 552.6665\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573146.0625 - mae: 548.6379 - val_loss: 585896.1250 - val_mae: 556.2731\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572557.2500 - mae: 548.6233 - val_loss: 581309.7500 - val_mae: 550.5708\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572798.3750 - mae: 548.4842 - val_loss: 582332.9375 - val_mae: 553.5962\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572266.1875 - mae: 548.6767 - val_loss: 581169.0000 - val_mae: 551.0058\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572566.1250 - mae: 548.3502 - val_loss: 583182.1250 - val_mae: 554.6788\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571946.3125 - mae: 548.5281 - val_loss: 582432.3750 - val_mae: 550.4319\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572090.4375 - mae: 548.4105 - val_loss: 581712.6875 - val_mae: 552.3256\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571234.2500 - mae: 547.9278 - val_loss: 584368.6875 - val_mae: 555.8779\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571777.3125 - mae: 548.0273 - val_loss: 582446.4375 - val_mae: 554.0717\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571476.8750 - mae: 548.4311 - val_loss: 581735.5000 - val_mae: 551.1306\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571289.8125 - mae: 548.1114 - val_loss: 581847.8750 - val_mae: 555.1378\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571402.8750 - mae: 547.8701 - val_loss: 580190.0625 - val_mae: 554.4008\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571351.6875 - mae: 548.6079 - val_loss: 582491.4375 - val_mae: 552.5729\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570666.4375 - mae: 547.7065 - val_loss: 584623.3125 - val_mae: 557.3587\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571015.5000 - mae: 548.3273 - val_loss: 581582.3750 - val_mae: 552.9084\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570964.1250 - mae: 547.9197 - val_loss: 580052.8125 - val_mae: 551.2278\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 36482368.0000 - mae: 5884.1123 - val_loss: 31721362.0000 - val_mae: 5492.6250\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 24705250.0000 - mae: 4794.6987 - val_loss: 17231166.0000 - val_mae: 3973.8818\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 11805892.0000 - mae: 3128.7576 - val_loss: 7093583.5000 - val_mae: 2311.0925\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4701865.0000 - mae: 1756.0905 - val_loss: 2749763.0000 - val_mae: 1293.6931\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2094489.0000 - mae: 1074.8616 - val_loss: 1495929.8750 - val_mae: 896.2979\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1365950.7500 - mae: 863.3385 - val_loss: 1155554.7500 - val_mae: 798.9549\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1109368.2500 - mae: 789.0174 - val_loss: 1000680.7500 - val_mae: 749.2316\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 970498.8125 - mae: 739.2869 - val_loss: 910167.1250 - val_mae: 713.7019\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 885569.6875 - mae: 703.6031 - val_loss: 851418.1875 - val_mae: 688.8038\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 829777.1250 - mae: 679.1709 - val_loss: 810429.3750 - val_mae: 669.5032\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 790477.5000 - mae: 660.5679 - val_loss: 778576.7500 - val_mae: 655.0085\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 759688.8750 - mae: 645.9327 - val_loss: 749263.8750 - val_mae: 638.4273\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 733485.3125 - mae: 632.6278 - val_loss: 726560.2500 - val_mae: 626.4593\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 711044.0625 - mae: 620.6606 - val_loss: 705377.8125 - val_mae: 616.6395\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 691260.1875 - mae: 610.6688 - val_loss: 690983.8750 - val_mae: 609.9828\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 674601.7500 - mae: 602.9447 - val_loss: 677099.5625 - val_mae: 597.5028\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 664899.9375 - mae: 596.5074 - val_loss: 669336.1875 - val_mae: 595.0081\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 657640.1250 - mae: 593.5118 - val_loss: 662253.8125 - val_mae: 592.2550\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 652563.7500 - mae: 591.2850 - val_loss: 659877.2500 - val_mae: 589.2110\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 648528.1875 - mae: 588.2993 - val_loss: 652419.2500 - val_mae: 587.4810\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 644210.5625 - mae: 586.5934 - val_loss: 651382.1875 - val_mae: 588.4067\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 640486.3125 - mae: 585.1716 - val_loss: 649351.3125 - val_mae: 584.7790\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 637112.3125 - mae: 583.5576 - val_loss: 645472.5000 - val_mae: 583.7123\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 634328.2500 - mae: 582.4018 - val_loss: 645257.8125 - val_mae: 581.3965\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 630616.3750 - mae: 580.3770 - val_loss: 641881.6875 - val_mae: 580.2731\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 626653.8750 - mae: 579.0454 - val_loss: 637336.1250 - val_mae: 579.1790\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 624429.0625 - mae: 577.9119 - val_loss: 637165.1250 - val_mae: 578.7902\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 622591.0625 - mae: 577.5621 - val_loss: 634675.8125 - val_mae: 574.9991\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 620968.9375 - mae: 576.2611 - val_loss: 636135.7500 - val_mae: 576.3986\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619511.0625 - mae: 575.8569 - val_loss: 634815.1875 - val_mae: 576.0020\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618889.7500 - mae: 575.5813 - val_loss: 632553.0625 - val_mae: 574.2311\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617626.9375 - mae: 574.9507 - val_loss: 633103.7500 - val_mae: 576.0302\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616450.0625 - mae: 574.7601 - val_loss: 630327.5625 - val_mae: 574.5535\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615265.3125 - mae: 574.2979 - val_loss: 632017.5625 - val_mae: 573.2150\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613954.4375 - mae: 573.3478 - val_loss: 629310.2500 - val_mae: 575.1522\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613061.3125 - mae: 573.8725 - val_loss: 629434.3125 - val_mae: 571.5763\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612787.4375 - mae: 573.2014 - val_loss: 627982.9375 - val_mae: 572.1537\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611642.8750 - mae: 572.5293 - val_loss: 627226.5000 - val_mae: 575.8531\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611688.0000 - mae: 573.2772 - val_loss: 627570.3125 - val_mae: 571.9543\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 610282.0000 - mae: 572.0322 - val_loss: 626223.1250 - val_mae: 573.1060\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609938.8125 - mae: 572.0872 - val_loss: 625134.3125 - val_mae: 571.1738\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608696.6250 - mae: 571.8387 - val_loss: 622787.7500 - val_mae: 570.9777\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608036.0625 - mae: 571.6906 - val_loss: 626209.0625 - val_mae: 572.3142\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607460.5625 - mae: 570.5970 - val_loss: 624603.0000 - val_mae: 572.9975\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606629.0000 - mae: 570.8345 - val_loss: 625418.8750 - val_mae: 571.0372\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606212.6250 - mae: 570.7976 - val_loss: 623931.7500 - val_mae: 569.9031\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605693.6875 - mae: 570.4525 - val_loss: 622517.9375 - val_mae: 571.0227\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604717.8750 - mae: 570.1309 - val_loss: 621233.1875 - val_mae: 569.8199\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604068.8125 - mae: 569.6594 - val_loss: 621920.1250 - val_mae: 571.2717\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603100.8125 - mae: 569.3650 - val_loss: 620786.4375 - val_mae: 568.2755\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602482.2500 - mae: 569.0793 - val_loss: 619966.6250 - val_mae: 568.2621\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601390.8125 - mae: 568.5608 - val_loss: 620414.5625 - val_mae: 568.6295\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600082.7500 - mae: 567.4579 - val_loss: 619017.8750 - val_mae: 572.0782\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599452.5625 - mae: 567.8745 - val_loss: 619057.2500 - val_mae: 569.2643\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598587.1875 - mae: 567.0952 - val_loss: 618672.7500 - val_mae: 567.6705\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597906.6250 - mae: 566.9888 - val_loss: 618138.3750 - val_mae: 566.2273\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597020.3750 - mae: 566.3072 - val_loss: 615363.7500 - val_mae: 568.0665\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596330.8750 - mae: 566.0579 - val_loss: 616848.5625 - val_mae: 568.1369\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595659.3750 - mae: 565.7042 - val_loss: 613840.0000 - val_mae: 566.4423\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595336.1250 - mae: 565.4495 - val_loss: 615152.8125 - val_mae: 570.4208\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594267.3750 - mae: 565.0551 - val_loss: 612778.3125 - val_mae: 566.6979\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594049.0625 - mae: 564.9222 - val_loss: 612127.1875 - val_mae: 566.7562\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593396.5625 - mae: 564.7461 - val_loss: 613543.1250 - val_mae: 564.3980\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593030.4375 - mae: 564.3993 - val_loss: 612290.4375 - val_mae: 565.3384\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592446.4375 - mae: 564.2031 - val_loss: 615623.5625 - val_mae: 565.1146\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592252.3125 - mae: 564.0748 - val_loss: 613046.1250 - val_mae: 564.9111\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592009.8125 - mae: 563.5753 - val_loss: 611790.6250 - val_mae: 566.3442\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591224.6250 - mae: 563.4470 - val_loss: 609575.6250 - val_mae: 565.1450\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590813.5000 - mae: 563.2744 - val_loss: 610382.3750 - val_mae: 566.3452\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590596.6250 - mae: 563.1083 - val_loss: 609907.6875 - val_mae: 565.4981\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590271.3125 - mae: 563.0451 - val_loss: 611061.9375 - val_mae: 565.3591\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589676.5000 - mae: 562.9691 - val_loss: 609103.9375 - val_mae: 563.6227\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589797.0625 - mae: 562.6557 - val_loss: 610421.2500 - val_mae: 564.3301\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589330.0000 - mae: 562.7410 - val_loss: 609108.0625 - val_mae: 563.5923\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589211.8750 - mae: 562.2905 - val_loss: 609047.0000 - val_mae: 565.8911\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588766.5000 - mae: 561.9443 - val_loss: 609525.6875 - val_mae: 563.8976\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588192.4375 - mae: 561.4866 - val_loss: 607555.0625 - val_mae: 563.8895\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587381.0000 - mae: 561.6470 - val_loss: 608665.1250 - val_mae: 562.6371\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586236.1250 - mae: 560.5272 - val_loss: 605628.4375 - val_mae: 561.5047\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584466.2500 - mae: 559.3137 - val_loss: 605688.6250 - val_mae: 562.3250\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583345.8750 - mae: 558.7335 - val_loss: 603446.1875 - val_mae: 562.0504\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581493.1875 - mae: 557.8384 - val_loss: 601439.0000 - val_mae: 561.1782\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580319.9375 - mae: 556.9970 - val_loss: 600610.0625 - val_mae: 561.5327\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578643.3125 - mae: 556.3974 - val_loss: 598825.3750 - val_mae: 560.5125\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578119.6250 - mae: 555.7437 - val_loss: 596081.7500 - val_mae: 558.5615\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576496.4375 - mae: 554.6895 - val_loss: 597638.7500 - val_mae: 560.1335\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575709.4375 - mae: 554.0338 - val_loss: 595651.3750 - val_mae: 556.1939\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573935.3750 - mae: 552.5420 - val_loss: 594111.3125 - val_mae: 559.9357\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572781.5625 - mae: 552.4890 - val_loss: 594776.6875 - val_mae: 555.5634\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571917.3750 - mae: 551.3421 - val_loss: 593094.5000 - val_mae: 556.2934\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570624.1875 - mae: 550.1247 - val_loss: 592303.1250 - val_mae: 554.0916\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569148.5000 - mae: 549.7134 - val_loss: 591345.0625 - val_mae: 555.9181\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568329.0000 - mae: 548.8083 - val_loss: 590812.5625 - val_mae: 555.6381\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567439.8125 - mae: 548.4758 - val_loss: 591615.5000 - val_mae: 551.6395\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567018.9375 - mae: 547.4669 - val_loss: 590711.1250 - val_mae: 551.4535\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566073.1250 - mae: 546.5976 - val_loss: 586471.5000 - val_mae: 552.3098\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565413.4375 - mae: 546.6768 - val_loss: 589657.1250 - val_mae: 550.0137\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565582.7500 - mae: 546.5782 - val_loss: 587216.6875 - val_mae: 549.5695\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565226.1875 - mae: 546.0631 - val_loss: 587017.6875 - val_mae: 549.5312\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564790.6250 - mae: 545.6616 - val_loss: 586360.2500 - val_mae: 550.6210\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564271.0625 - mae: 545.5226 - val_loss: 586324.4375 - val_mae: 550.7133\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563940.0000 - mae: 544.8394 - val_loss: 586298.9375 - val_mae: 550.4244\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563596.7500 - mae: 545.1871 - val_loss: 585740.6250 - val_mae: 548.5663\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562334.3125 - mae: 543.9805 - val_loss: 585110.7500 - val_mae: 548.8934\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561029.3125 - mae: 543.9310 - val_loss: 585741.5000 - val_mae: 548.4809\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560674.3125 - mae: 543.7196 - val_loss: 583725.5000 - val_mae: 547.2189\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560026.3750 - mae: 543.1320 - val_loss: 583302.3125 - val_mae: 545.8513\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559255.2500 - mae: 542.7336 - val_loss: 582006.2500 - val_mae: 547.9852\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559267.1875 - mae: 543.1496 - val_loss: 583453.3125 - val_mae: 546.1889\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558770.0625 - mae: 542.5848 - val_loss: 582572.0000 - val_mae: 548.4286\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558882.0625 - mae: 542.5807 - val_loss: 582666.1250 - val_mae: 547.3304\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558332.7500 - mae: 542.4212 - val_loss: 580989.0625 - val_mae: 546.0004\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558287.1875 - mae: 541.9474 - val_loss: 581908.3750 - val_mae: 548.3358\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557867.5625 - mae: 542.8755 - val_loss: 582331.5625 - val_mae: 546.1078\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557602.7500 - mae: 541.8379 - val_loss: 579806.0000 - val_mae: 545.8707\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556871.3750 - mae: 541.4585 - val_loss: 580180.4375 - val_mae: 543.9166\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557000.2500 - mae: 541.1892 - val_loss: 582080.0000 - val_mae: 546.2672\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556093.8125 - mae: 541.0353 - val_loss: 581424.2500 - val_mae: 546.4343\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556145.8125 - mae: 541.2235 - val_loss: 580622.7500 - val_mae: 543.4019\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555883.7500 - mae: 541.0553 - val_loss: 579736.8750 - val_mae: 544.9004\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555909.7500 - mae: 540.5722 - val_loss: 579174.8750 - val_mae: 546.8068\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556077.5000 - mae: 541.2090 - val_loss: 579393.2500 - val_mae: 545.9687\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555972.0625 - mae: 540.6458 - val_loss: 579749.5625 - val_mae: 545.4365\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555835.8750 - mae: 540.4971 - val_loss: 579010.5625 - val_mae: 546.1829\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555721.8750 - mae: 541.0029 - val_loss: 582213.6875 - val_mae: 545.3063\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555901.0000 - mae: 540.4315 - val_loss: 581171.6250 - val_mae: 544.8687\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555567.3125 - mae: 540.7034 - val_loss: 578555.7500 - val_mae: 543.5004\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555596.0625 - mae: 540.9253 - val_loss: 578540.2500 - val_mae: 544.0974\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555469.8125 - mae: 540.5649 - val_loss: 577407.9375 - val_mae: 545.8832\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38342440.0000 - mae: 6035.7065 - val_loss: 37639248.0000 - val_mae: 5986.3232\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 36321444.0000 - mae: 5877.8223 - val_loss: 34196432.0000 - val_mae: 5714.1484\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 31830252.0000 - mae: 5509.6582 - val_loss: 28916388.0000 - val_mae: 5261.4619\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 26124552.0000 - mae: 4989.8228 - val_loss: 22972554.0000 - val_mae: 4682.6851\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 20202332.0000 - mae: 4368.7539 - val_loss: 17236468.0000 - val_mae: 4025.8020\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 14776228.0000 - mae: 3691.7141 - val_loss: 12258743.0000 - val_mae: 3339.0735\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 10268277.0000 - mae: 3008.3088 - val_loss: 8311596.5000 - val_mae: 2671.6438\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6853070.5000 - mae: 2368.1370 - val_loss: 5475016.5000 - val_mae: 2069.6677\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4505078.5000 - mae: 1819.5981 - val_loss: 3621085.7500 - val_mae: 1593.8180\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3026879.7500 - mae: 1425.1270 - val_loss: 2509027.5000 - val_mae: 1278.2760\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2169314.0000 - mae: 1169.9800 - val_loss: 1888428.1250 - val_mae: 1079.5155\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1700976.0000 - mae: 1015.1357 - val_loss: 1554614.5000 - val_mae: 965.7864\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1442206.6250 - mae: 926.8694 - val_loss: 1361973.8750 - val_mae: 900.4052\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1283539.8750 - mae: 871.6762 - val_loss: 1234949.5000 - val_mae: 854.2228\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1171929.8750 - mae: 832.3020 - val_loss: 1139260.5000 - val_mae: 817.1047\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1083624.2500 - mae: 798.0460 - val_loss: 1061684.6250 - val_mae: 783.9098\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1010690.8750 - mae: 766.6176 - val_loss: 999372.6250 - val_mae: 754.5397\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 951662.1250 - mae: 738.6366 - val_loss: 948595.1875 - val_mae: 728.4078\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 903489.1250 - mae: 713.9406 - val_loss: 906585.5000 - val_mae: 705.9028\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 864732.8125 - mae: 692.7952 - val_loss: 873158.8750 - val_mae: 688.1109\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 833802.1875 - mae: 676.9219 - val_loss: 847427.5625 - val_mae: 674.0718\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 809379.0000 - mae: 664.5067 - val_loss: 825413.3750 - val_mae: 662.6088\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 788573.0625 - mae: 653.5375 - val_loss: 807745.4375 - val_mae: 653.9953\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 772018.6250 - mae: 646.4003 - val_loss: 794154.0625 - val_mae: 647.1223\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 757504.0000 - mae: 638.5905 - val_loss: 781317.4375 - val_mae: 640.5793\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 745107.8750 - mae: 633.4771 - val_loss: 770336.5625 - val_mae: 633.8200\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 734242.7500 - mae: 627.3607 - val_loss: 759524.8750 - val_mae: 630.6670\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 724927.8125 - mae: 623.5128 - val_loss: 750715.1875 - val_mae: 625.6482\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 716658.6250 - mae: 619.5624 - val_loss: 743056.3750 - val_mae: 621.3314\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 708830.9375 - mae: 615.5553 - val_loss: 735071.8125 - val_mae: 617.7531\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 701796.1875 - mae: 612.5345 - val_loss: 728449.0000 - val_mae: 615.7396\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 695551.4375 - mae: 610.1551 - val_loss: 721627.3125 - val_mae: 612.2136\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 689444.5000 - mae: 606.7424 - val_loss: 716239.6250 - val_mae: 610.0822\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 683737.3750 - mae: 604.6010 - val_loss: 711014.1875 - val_mae: 606.6482\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 678841.6875 - mae: 601.5543 - val_loss: 706040.5000 - val_mae: 605.5139\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 674218.1875 - mae: 599.7125 - val_loss: 702094.3750 - val_mae: 603.7243\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 670108.9375 - mae: 598.8309 - val_loss: 696200.4375 - val_mae: 598.8143\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 665549.8750 - mae: 595.7354 - val_loss: 692366.6250 - val_mae: 597.6951\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 661665.5000 - mae: 593.3831 - val_loss: 689698.1250 - val_mae: 596.2436\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 658310.1875 - mae: 591.8010 - val_loss: 684794.6875 - val_mae: 593.5933\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 654438.1250 - mae: 589.9429 - val_loss: 683618.2500 - val_mae: 592.0629\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 651394.5625 - mae: 588.3793 - val_loss: 680995.8750 - val_mae: 590.0627\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 648544.6250 - mae: 586.7625 - val_loss: 677277.3750 - val_mae: 589.9012\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 646057.2500 - mae: 585.8840 - val_loss: 675774.8750 - val_mae: 587.6799\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 643784.3750 - mae: 584.1864 - val_loss: 674343.3750 - val_mae: 587.3671\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 642106.8125 - mae: 583.8029 - val_loss: 670990.1875 - val_mae: 584.7773\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 640003.8125 - mae: 582.5700 - val_loss: 670943.1250 - val_mae: 584.5621\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637897.0625 - mae: 581.5035 - val_loss: 667771.0000 - val_mae: 582.3681\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 636409.3125 - mae: 580.5654 - val_loss: 665549.2500 - val_mae: 582.8865\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 634871.3125 - mae: 580.0783 - val_loss: 663629.1250 - val_mae: 582.0456\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 633989.7500 - mae: 579.4380 - val_loss: 662827.8750 - val_mae: 581.0978\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 632069.6250 - mae: 578.7994 - val_loss: 661983.8125 - val_mae: 581.5162\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 631220.1250 - mae: 578.3653 - val_loss: 660929.1250 - val_mae: 580.7504\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 629921.4375 - mae: 577.7953 - val_loss: 660086.0000 - val_mae: 580.3508\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 628883.9375 - mae: 577.5726 - val_loss: 658955.0000 - val_mae: 578.3817\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 628278.2500 - mae: 577.0972 - val_loss: 657174.6875 - val_mae: 578.6406\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 627020.2500 - mae: 575.9143 - val_loss: 657000.8125 - val_mae: 578.9821\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 626174.8750 - mae: 575.6559 - val_loss: 655494.0625 - val_mae: 578.2897\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 625169.5625 - mae: 575.2952 - val_loss: 654843.4375 - val_mae: 578.7480\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 624667.9375 - mae: 575.6070 - val_loss: 654993.2500 - val_mae: 578.4061\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 623975.0000 - mae: 574.4875 - val_loss: 653978.0000 - val_mae: 577.3616\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 623079.1875 - mae: 574.5223 - val_loss: 652574.8125 - val_mae: 577.7136\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 622554.8750 - mae: 574.2688 - val_loss: 651844.6250 - val_mae: 576.7278\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 621878.1250 - mae: 574.0197 - val_loss: 652264.5000 - val_mae: 576.0012\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 621489.6875 - mae: 573.8990 - val_loss: 651925.3125 - val_mae: 576.3680\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 621138.5000 - mae: 573.5833 - val_loss: 649980.6250 - val_mae: 576.2653\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 620584.3750 - mae: 573.5106 - val_loss: 649488.8125 - val_mae: 577.9547\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 620226.5625 - mae: 573.4601 - val_loss: 647606.9375 - val_mae: 576.0219\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619575.8750 - mae: 573.0490 - val_loss: 646357.9375 - val_mae: 576.4694\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619417.1250 - mae: 573.3320 - val_loss: 646809.9375 - val_mae: 575.5718\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 618864.1875 - mae: 572.5358 - val_loss: 646368.6250 - val_mae: 575.9942\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 618365.1875 - mae: 572.8126 - val_loss: 647118.3750 - val_mae: 574.9702\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 618591.0000 - mae: 572.1074 - val_loss: 645867.5625 - val_mae: 576.0438\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 618099.5000 - mae: 572.7941 - val_loss: 644905.5000 - val_mae: 573.8965\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617568.2500 - mae: 572.0174 - val_loss: 644282.1250 - val_mae: 574.0021\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617145.1875 - mae: 571.9134 - val_loss: 644581.1875 - val_mae: 575.5052\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617005.5625 - mae: 572.3689 - val_loss: 644748.6250 - val_mae: 573.2015\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616884.3125 - mae: 571.1499 - val_loss: 643734.4375 - val_mae: 575.5811\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616700.6250 - mae: 572.3628 - val_loss: 644250.6875 - val_mae: 573.1298\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616322.1250 - mae: 571.4675 - val_loss: 643842.0625 - val_mae: 574.2336\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615923.3125 - mae: 571.3360 - val_loss: 642599.1250 - val_mae: 575.6526\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616160.6250 - mae: 571.6740 - val_loss: 643092.1250 - val_mae: 572.8295\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615861.2500 - mae: 571.1614 - val_loss: 641845.6875 - val_mae: 575.6478\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615647.2500 - mae: 571.3338 - val_loss: 641419.8750 - val_mae: 574.2654\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615410.7500 - mae: 571.3425 - val_loss: 641934.7500 - val_mae: 572.5957\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615077.7500 - mae: 570.5197 - val_loss: 643432.8750 - val_mae: 574.8843\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615107.5625 - mae: 570.8487 - val_loss: 641657.4375 - val_mae: 574.2783\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614654.8750 - mae: 570.8975 - val_loss: 641619.8750 - val_mae: 574.5612\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614570.4375 - mae: 570.8178 - val_loss: 640978.1250 - val_mae: 573.0635\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614160.1875 - mae: 570.4018 - val_loss: 641694.7500 - val_mae: 574.8076\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613931.1875 - mae: 570.1757 - val_loss: 639926.8750 - val_mae: 572.4133\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613400.1875 - mae: 569.9849 - val_loss: 640058.1875 - val_mae: 571.8085\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613232.6250 - mae: 569.4029 - val_loss: 639086.6250 - val_mae: 572.9459\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612914.0625 - mae: 569.8434 - val_loss: 638669.2500 - val_mae: 571.1359\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612473.3750 - mae: 568.9065 - val_loss: 638723.7500 - val_mae: 573.6215\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612083.6875 - mae: 569.2613 - val_loss: 637938.0625 - val_mae: 571.0985\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612046.5000 - mae: 568.8176 - val_loss: 637703.8125 - val_mae: 571.5623\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611551.3125 - mae: 569.1915 - val_loss: 637753.5000 - val_mae: 571.8200\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611762.8125 - mae: 568.7487 - val_loss: 636634.6875 - val_mae: 570.0912\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611432.0000 - mae: 568.4956 - val_loss: 636497.1875 - val_mae: 571.5795\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611139.8750 - mae: 568.5500 - val_loss: 636082.1250 - val_mae: 571.4808\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610915.9375 - mae: 568.1537 - val_loss: 634604.5625 - val_mae: 571.2043\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610525.7500 - mae: 568.8707 - val_loss: 636186.6875 - val_mae: 569.7933\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610625.6875 - mae: 568.4088 - val_loss: 635509.9375 - val_mae: 569.4419\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610025.9375 - mae: 567.7325 - val_loss: 635331.5625 - val_mae: 571.4999\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610211.2500 - mae: 568.3950 - val_loss: 634590.6250 - val_mae: 570.7050\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609730.4375 - mae: 568.1694 - val_loss: 634864.6250 - val_mae: 570.0201\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609806.5000 - mae: 568.0659 - val_loss: 634918.4375 - val_mae: 569.8613\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609729.0625 - mae: 567.9996 - val_loss: 634559.8750 - val_mae: 569.2523\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609830.6250 - mae: 567.8015 - val_loss: 634884.5000 - val_mae: 570.3842\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609436.9375 - mae: 567.6965 - val_loss: 633905.1875 - val_mae: 570.8079\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609444.3750 - mae: 568.4905 - val_loss: 633836.0000 - val_mae: 569.1049\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609184.7500 - mae: 567.6591 - val_loss: 634765.1250 - val_mae: 568.6464\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609230.5000 - mae: 567.4998 - val_loss: 633575.9375 - val_mae: 570.6290\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609024.0625 - mae: 567.5773 - val_loss: 632929.4375 - val_mae: 569.5328\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608794.8125 - mae: 567.5656 - val_loss: 632945.3750 - val_mae: 570.0982\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608734.8125 - mae: 567.7236 - val_loss: 633384.6875 - val_mae: 568.8801\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608712.1875 - mae: 567.5541 - val_loss: 634077.1875 - val_mae: 569.0190\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608245.8750 - mae: 567.1338 - val_loss: 632716.3125 - val_mae: 568.5887\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608263.6875 - mae: 567.4700 - val_loss: 633801.8125 - val_mae: 568.0631\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607832.0625 - mae: 567.5493 - val_loss: 633970.8125 - val_mae: 567.6905\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608467.0000 - mae: 567.0436 - val_loss: 632420.3125 - val_mae: 568.3345\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 607792.8750 - mae: 567.3657 - val_loss: 633208.3750 - val_mae: 568.9728\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607547.2500 - mae: 566.6469 - val_loss: 630535.8125 - val_mae: 569.7333\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607851.3750 - mae: 567.3318 - val_loss: 631681.5000 - val_mae: 570.1346\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607559.4375 - mae: 567.1768 - val_loss: 632908.4375 - val_mae: 568.8138\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607272.1250 - mae: 566.9811 - val_loss: 631992.3125 - val_mae: 568.6608\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607319.8125 - mae: 567.3599 - val_loss: 632607.3750 - val_mae: 567.5976\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607205.9375 - mae: 566.5812 - val_loss: 630188.1875 - val_mae: 568.1796\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607169.6875 - mae: 567.1682 - val_loss: 631029.3125 - val_mae: 569.1940\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607031.0625 - mae: 566.5405 - val_loss: 631647.2500 - val_mae: 570.3299\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606982.0000 - mae: 567.0952 - val_loss: 631186.5625 - val_mae: 569.0673\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606930.6875 - mae: 566.8741 - val_loss: 630389.5000 - val_mae: 568.8790\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607103.8750 - mae: 567.0920 - val_loss: 630497.5625 - val_mae: 568.2362\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606536.3750 - mae: 566.4564 - val_loss: 630294.6875 - val_mae: 570.1476\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606693.3750 - mae: 566.3983 - val_loss: 630426.0625 - val_mae: 570.9741\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606675.0625 - mae: 566.9680 - val_loss: 630844.0625 - val_mae: 569.7572\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606436.0000 - mae: 567.1183 - val_loss: 630973.0625 - val_mae: 568.4277\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38242744.0000 - mae: 6026.9385 - val_loss: 37206436.0000 - val_mae: 5949.4312\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 35161408.0000 - mae: 5779.1221 - val_loss: 32195718.0000 - val_mae: 5538.6162\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 28877238.0000 - mae: 5237.5444 - val_loss: 25068802.0000 - val_mae: 4884.0107\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 21468066.0000 - mae: 4499.6133 - val_loss: 17708990.0000 - val_mae: 4078.2312\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 14507037.0000 - mae: 3656.3564 - val_loss: 11344894.0000 - val_mae: 3213.2390\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 8885377.0000 - mae: 2796.8547 - val_loss: 6588341.0000 - val_mae: 2380.5618\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4990969.5000 - mae: 2012.6893 - val_loss: 3582682.0000 - val_mae: 1651.8209\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2741318.7500 - mae: 1376.3907 - val_loss: 2027922.7500 - val_mae: 1134.9058\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1674932.7500 - mae: 995.6671 - val_loss: 1362157.8750 - val_mae: 881.7349\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1247614.3750 - mae: 827.3145 - val_loss: 1111649.6250 - val_mae: 781.9081\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1087740.5000 - mae: 764.8377 - val_loss: 1012724.6875 - val_mae: 743.2103\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1018925.3125 - mae: 739.2148 - val_loss: 963491.5000 - val_mae: 723.7357\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 978784.9375 - mae: 723.7015 - val_loss: 928622.0625 - val_mae: 708.4938\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 948749.8750 - mae: 710.6229 - val_loss: 901153.5000 - val_mae: 695.2042\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 923628.1875 - mae: 697.7173 - val_loss: 878615.6875 - val_mae: 684.6404\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 902888.7500 - mae: 687.9938 - val_loss: 859811.1250 - val_mae: 674.3998\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 884873.6875 - mae: 678.0562 - val_loss: 844239.7500 - val_mae: 666.7966\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 869948.1875 - mae: 670.7988 - val_loss: 830867.5000 - val_mae: 658.8214\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 856973.4375 - mae: 662.7517 - val_loss: 820865.6875 - val_mae: 654.2565\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 846600.8125 - mae: 657.9596 - val_loss: 810819.1875 - val_mae: 648.4501\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 835467.4375 - mae: 652.6238 - val_loss: 798314.3125 - val_mae: 642.6885\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 819306.3750 - mae: 646.2932 - val_loss: 779000.0000 - val_mae: 637.1614\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 797647.0625 - mae: 640.6544 - val_loss: 760546.7500 - val_mae: 630.6143\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 779568.9375 - mae: 634.4683 - val_loss: 745866.2500 - val_mae: 629.0048\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 763460.1875 - mae: 631.1240 - val_loss: 731791.6875 - val_mae: 624.4465\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 748593.2500 - mae: 626.3950 - val_loss: 720023.3125 - val_mae: 621.8423\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 735514.0000 - mae: 623.1780 - val_loss: 711274.6250 - val_mae: 616.8839\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 723396.7500 - mae: 619.5554 - val_loss: 701081.6250 - val_mae: 613.6204\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 712596.1250 - mae: 616.1461 - val_loss: 691483.8750 - val_mae: 610.4156\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 702748.5000 - mae: 612.8630 - val_loss: 685384.5000 - val_mae: 609.7496\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 694324.6250 - mae: 610.7093 - val_loss: 676116.9375 - val_mae: 605.5545\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 686038.5000 - mae: 607.7842 - val_loss: 671847.1250 - val_mae: 604.1471\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 677479.1875 - mae: 604.4659 - val_loss: 664060.3750 - val_mae: 600.2458\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 669558.4375 - mae: 601.3687 - val_loss: 657623.8125 - val_mae: 596.9421\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 660980.0000 - mae: 597.6068 - val_loss: 652748.9375 - val_mae: 596.6879\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 652859.5000 - mae: 595.4272 - val_loss: 647350.4375 - val_mae: 593.9547\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 647161.9375 - mae: 592.2801 - val_loss: 642924.5625 - val_mae: 592.9739\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 641667.8125 - mae: 590.4800 - val_loss: 639858.9375 - val_mae: 590.7789\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637763.8750 - mae: 588.7219 - val_loss: 636871.3125 - val_mae: 588.6544\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 633844.0625 - mae: 586.0671 - val_loss: 632833.3750 - val_mae: 586.2203\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 630690.1875 - mae: 585.0024 - val_loss: 633422.8125 - val_mae: 586.2427\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 628148.4375 - mae: 583.9358 - val_loss: 629270.1875 - val_mae: 582.9641\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 625498.1250 - mae: 581.3674 - val_loss: 628196.5625 - val_mae: 584.0190\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 623232.3750 - mae: 581.0296 - val_loss: 627622.1875 - val_mae: 583.5797\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 620888.5625 - mae: 579.3470 - val_loss: 625357.1875 - val_mae: 581.2181\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 618895.6875 - mae: 578.3830 - val_loss: 624250.0625 - val_mae: 578.8666\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616921.4375 - mae: 576.8672 - val_loss: 622343.0000 - val_mae: 578.0623\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615507.5000 - mae: 576.3325 - val_loss: 621677.8750 - val_mae: 578.8021\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613688.3750 - mae: 574.9406 - val_loss: 622902.5000 - val_mae: 580.6079\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613010.5625 - mae: 575.3359 - val_loss: 620817.0625 - val_mae: 577.7773\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611522.8750 - mae: 574.2002 - val_loss: 621541.8750 - val_mae: 578.5007\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610357.0625 - mae: 573.5317 - val_loss: 619084.1875 - val_mae: 577.7484\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608939.9375 - mae: 572.8945 - val_loss: 618330.2500 - val_mae: 577.8322\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608804.2500 - mae: 572.9123 - val_loss: 617431.6875 - val_mae: 576.8060\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607731.4375 - mae: 572.4234 - val_loss: 617244.3125 - val_mae: 577.6943\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607270.0625 - mae: 571.7491 - val_loss: 616854.8750 - val_mae: 576.4764\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606377.1250 - mae: 571.4826 - val_loss: 615882.1875 - val_mae: 575.9550\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605481.1250 - mae: 571.3505 - val_loss: 615366.4375 - val_mae: 575.5396\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605356.1875 - mae: 571.3759 - val_loss: 615754.1875 - val_mae: 575.3704\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604448.3125 - mae: 570.4055 - val_loss: 615132.3125 - val_mae: 575.7729\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604068.3750 - mae: 570.2229 - val_loss: 615361.9375 - val_mae: 575.4061\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603671.4375 - mae: 570.3964 - val_loss: 615263.4375 - val_mae: 574.4879\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603151.3125 - mae: 569.4311 - val_loss: 613621.0000 - val_mae: 576.9815\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602623.1250 - mae: 569.9562 - val_loss: 614594.6875 - val_mae: 575.5004\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601851.0000 - mae: 569.4396 - val_loss: 613409.8750 - val_mae: 574.4042\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601603.0625 - mae: 569.2626 - val_loss: 611503.1875 - val_mae: 573.6927\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601137.6875 - mae: 568.9647 - val_loss: 613781.5000 - val_mae: 573.9432\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600529.0625 - mae: 568.9362 - val_loss: 613756.4375 - val_mae: 571.9565\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600682.0625 - mae: 568.4692 - val_loss: 612005.7500 - val_mae: 572.3925\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599953.6250 - mae: 568.0815 - val_loss: 614283.6875 - val_mae: 573.0833\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599784.5625 - mae: 567.9264 - val_loss: 612676.9375 - val_mae: 575.1776\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598833.5625 - mae: 568.0635 - val_loss: 611147.5000 - val_mae: 571.7571\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599013.6875 - mae: 567.2173 - val_loss: 612415.5000 - val_mae: 574.9631\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597952.8125 - mae: 567.8250 - val_loss: 611384.9375 - val_mae: 572.4424\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598120.5625 - mae: 567.2493 - val_loss: 611013.2500 - val_mae: 572.9235\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597937.3750 - mae: 566.9764 - val_loss: 610693.1250 - val_mae: 571.8361\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597423.5000 - mae: 566.9453 - val_loss: 609982.8125 - val_mae: 572.3678\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597406.0625 - mae: 567.1462 - val_loss: 610206.2500 - val_mae: 572.6034\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597083.5000 - mae: 567.1273 - val_loss: 610098.7500 - val_mae: 570.7450\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596769.6250 - mae: 566.9914 - val_loss: 609790.6875 - val_mae: 570.4976\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596358.3125 - mae: 566.0959 - val_loss: 611055.8750 - val_mae: 573.2120\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596257.0000 - mae: 566.5967 - val_loss: 610359.8750 - val_mae: 570.7291\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596025.3750 - mae: 565.9696 - val_loss: 609041.5000 - val_mae: 570.6382\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596331.6875 - mae: 566.7045 - val_loss: 608496.6250 - val_mae: 571.0848\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595449.1250 - mae: 565.4691 - val_loss: 610485.3750 - val_mae: 574.6551\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594914.5000 - mae: 566.4768 - val_loss: 609968.7500 - val_mae: 572.3778\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595264.1250 - mae: 566.0955 - val_loss: 609619.5000 - val_mae: 571.6913\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594913.3125 - mae: 565.5675 - val_loss: 608497.7500 - val_mae: 571.8809\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595078.4375 - mae: 566.0693 - val_loss: 608926.3125 - val_mae: 572.2553\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594985.7500 - mae: 565.8999 - val_loss: 607744.6250 - val_mae: 572.5411\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 33345600.0000 - mae: 5593.8760 - val_loss: 23358884.0000 - val_mae: 4658.7573\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 13001464.0000 - mae: 3294.0630 - val_loss: 4973612.0000 - val_mae: 1932.1844\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 2349586.5000 - mae: 1156.8881 - val_loss: 1165199.6250 - val_mae: 761.0893\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 963521.3750 - mae: 709.7255 - val_loss: 879383.9375 - val_mae: 679.7018\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 807544.1250 - mae: 662.1557 - val_loss: 794409.8125 - val_mae: 659.4597\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 752576.0625 - mae: 643.9825 - val_loss: 754235.9375 - val_mae: 641.6771\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 725368.4375 - mae: 631.8924 - val_loss: 734401.5625 - val_mae: 635.1125\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 708131.1875 - mae: 624.2645 - val_loss: 718212.3750 - val_mae: 626.2970\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 694068.1250 - mae: 617.0059 - val_loss: 707115.3125 - val_mae: 620.8372\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 683427.8750 - mae: 611.3015 - val_loss: 700481.1875 - val_mae: 617.2718\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 674783.6875 - mae: 606.6068 - val_loss: 688798.1250 - val_mae: 611.5348\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 667998.8750 - mae: 603.5541 - val_loss: 683491.1875 - val_mae: 609.2319\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 661600.1875 - mae: 599.8473 - val_loss: 677186.0625 - val_mae: 605.5388\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 656234.8125 - mae: 597.3303 - val_loss: 672371.8125 - val_mae: 602.2714\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 651038.8750 - mae: 594.7656 - val_loss: 664867.4375 - val_mae: 597.6910\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 646439.0000 - mae: 592.8998 - val_loss: 664963.1875 - val_mae: 596.5806\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 642551.5625 - mae: 589.9523 - val_loss: 659850.8750 - val_mae: 596.3747\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 638371.3750 - mae: 587.9837 - val_loss: 654977.4375 - val_mae: 594.3000\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 634206.5000 - mae: 586.3734 - val_loss: 652907.2500 - val_mae: 594.7933\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 631104.1250 - mae: 584.7296 - val_loss: 647385.7500 - val_mae: 590.7724\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 627918.2500 - mae: 583.2275 - val_loss: 643973.0625 - val_mae: 586.7515\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 624600.5000 - mae: 581.3487 - val_loss: 641022.0000 - val_mae: 583.5123\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 622531.2500 - mae: 579.8822 - val_loss: 639197.5625 - val_mae: 587.6116\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 620114.3125 - mae: 579.1028 - val_loss: 635684.9375 - val_mae: 584.5327\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 617140.3750 - mae: 577.6560 - val_loss: 630282.2500 - val_mae: 580.2435\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 615596.4375 - mae: 576.6972 - val_loss: 631313.7500 - val_mae: 582.1176\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 613800.5625 - mae: 575.5997 - val_loss: 632199.7500 - val_mae: 582.9421\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 612240.8750 - mae: 575.0472 - val_loss: 630432.9375 - val_mae: 578.7802\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610230.3125 - mae: 573.9995 - val_loss: 630551.6250 - val_mae: 580.4237\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 608724.8750 - mae: 572.6918 - val_loss: 629901.5625 - val_mae: 582.1659\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 607206.5000 - mae: 572.1279 - val_loss: 624512.0625 - val_mae: 581.3592\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 605216.7500 - mae: 571.4411 - val_loss: 621485.5000 - val_mae: 574.6909\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602438.8125 - mae: 569.8176 - val_loss: 617095.3125 - val_mae: 573.2110\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 600469.8750 - mae: 568.5744 - val_loss: 613878.2500 - val_mae: 568.1761\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 598896.4375 - mae: 567.4529 - val_loss: 614643.5625 - val_mae: 571.8289\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 597272.3750 - mae: 566.4100 - val_loss: 610885.1250 - val_mae: 571.7736\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595702.5000 - mae: 565.9698 - val_loss: 608562.2500 - val_mae: 568.4891\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594494.8750 - mae: 564.8908 - val_loss: 608622.5000 - val_mae: 570.2444\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593197.0625 - mae: 564.5170 - val_loss: 604358.1875 - val_mae: 567.7759\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592248.2500 - mae: 564.1082 - val_loss: 604694.0000 - val_mae: 566.6390\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591197.7500 - mae: 563.2953 - val_loss: 608039.5000 - val_mae: 570.2864\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590353.0000 - mae: 563.0294 - val_loss: 602271.4375 - val_mae: 563.9740\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 589441.4375 - mae: 562.0961 - val_loss: 603822.1875 - val_mae: 567.5850\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588225.6250 - mae: 562.1060 - val_loss: 600849.8750 - val_mae: 560.8136\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588466.2500 - mae: 561.5314 - val_loss: 600431.0000 - val_mae: 564.4392\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 587647.9375 - mae: 561.1783 - val_loss: 601879.5000 - val_mae: 566.5761\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 586684.8125 - mae: 560.5767 - val_loss: 599483.3750 - val_mae: 564.8410\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 586435.3125 - mae: 560.5051 - val_loss: 599034.8750 - val_mae: 563.6373\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 586367.4375 - mae: 560.4532 - val_loss: 598167.0625 - val_mae: 563.5615\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585438.5625 - mae: 560.1682 - val_loss: 601033.8750 - val_mae: 564.8331\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584801.9375 - mae: 559.4797 - val_loss: 603464.3750 - val_mae: 567.2208\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584337.8125 - mae: 559.4247 - val_loss: 599419.5625 - val_mae: 563.3630\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 583934.0625 - mae: 559.4595 - val_loss: 599649.1250 - val_mae: 563.9842\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 583690.1875 - mae: 559.0502 - val_loss: 602478.8750 - val_mae: 566.6434\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584116.0000 - mae: 6054.5703 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584148.0000 - mae: 6054.5708 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584140.0000 - mae: 6054.5708 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584148.0000 - mae: 6054.5674 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584120.0000 - mae: 6054.5708 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584156.0000 - mae: 6054.5718 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584124.0000 - mae: 6054.5708 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584140.0000 - mae: 6054.5698 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584168.0000 - mae: 6054.5703 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584144.0000 - mae: 6054.5698 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 38584148.0000 - mae: 6054.5728 - val_loss: 38409080.0000 - val_mae: 6046.2012\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 37140616.0000 - mae: 5935.1069 - val_loss: 33890340.0000 - val_mae: 5668.2900\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 28508568.0000 - mae: 5165.5068 - val_loss: 22329222.0000 - val_mae: 4557.8467\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 16574335.0000 - mae: 3846.8137 - val_loss: 11225117.0000 - val_mae: 3117.1104\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 7527591.5000 - mae: 2413.5913 - val_loss: 4558387.0000 - val_mae: 1778.1691\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3003848.5000 - mae: 1305.0460 - val_loss: 1870717.2500 - val_mae: 976.5293\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1418974.3750 - mae: 814.9561 - val_loss: 1073669.2500 - val_mae: 718.2413\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 969219.6250 - mae: 688.8038 - val_loss: 848101.7500 - val_mae: 658.0719\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 817988.8750 - mae: 653.6097 - val_loss: 758095.1875 - val_mae: 635.8055\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 753028.1250 - mae: 635.1251 - val_loss: 717569.6875 - val_mae: 623.7395\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 722926.1250 - mae: 625.1138 - val_loss: 698846.3750 - val_mae: 614.7388\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 706778.5000 - mae: 617.6474 - val_loss: 687381.1250 - val_mae: 609.1127\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 695457.3125 - mae: 611.8690 - val_loss: 680065.3750 - val_mae: 605.8835\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 686779.8125 - mae: 607.9141 - val_loss: 673390.1875 - val_mae: 602.2679\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 680024.6250 - mae: 604.2772 - val_loss: 666755.3125 - val_mae: 600.3837\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 674258.8125 - mae: 601.6816 - val_loss: 664412.5000 - val_mae: 597.4752\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 669709.1250 - mae: 599.1639 - val_loss: 660534.6250 - val_mae: 595.7711\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 665442.6875 - mae: 597.0544 - val_loss: 656853.9375 - val_mae: 593.7406\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 661553.5000 - mae: 594.9490 - val_loss: 652793.5625 - val_mae: 592.2333\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 658041.1875 - mae: 593.3527 - val_loss: 652462.5625 - val_mae: 591.1314\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 654854.1250 - mae: 592.3455 - val_loss: 651962.4375 - val_mae: 589.2228\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 652167.8125 - mae: 590.8992 - val_loss: 650701.7500 - val_mae: 588.6609\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 649541.5000 - mae: 589.9189 - val_loss: 647717.7500 - val_mae: 587.1641\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 646668.9375 - mae: 587.9784 - val_loss: 641192.0000 - val_mae: 586.7411\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 643935.7500 - mae: 586.7133 - val_loss: 640804.7500 - val_mae: 587.3795\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 641688.2500 - mae: 585.7331 - val_loss: 638532.3750 - val_mae: 586.3350\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 639429.8125 - mae: 585.1152 - val_loss: 636748.7500 - val_mae: 583.0689\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 637841.0000 - mae: 584.4692 - val_loss: 635995.1875 - val_mae: 582.0106\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 635336.1875 - mae: 583.1462 - val_loss: 634831.0000 - val_mae: 582.9183\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 633963.5000 - mae: 582.3983 - val_loss: 634446.3750 - val_mae: 582.8430\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 631926.6875 - mae: 582.1907 - val_loss: 634304.4375 - val_mae: 580.7529\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 630525.4375 - mae: 580.6265 - val_loss: 631321.8125 - val_mae: 582.1932\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 628656.0625 - mae: 580.5422 - val_loss: 629490.5625 - val_mae: 581.1329\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 627393.3125 - mae: 579.7774 - val_loss: 631915.0000 - val_mae: 579.8550\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625701.7500 - mae: 578.7693 - val_loss: 628582.8750 - val_mae: 578.9573\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 624068.5625 - mae: 578.0415 - val_loss: 627058.2500 - val_mae: 578.7188\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 622901.1250 - mae: 577.0391 - val_loss: 624719.2500 - val_mae: 578.4885\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621508.2500 - mae: 576.9060 - val_loss: 626368.1875 - val_mae: 578.1426\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 620526.2500 - mae: 576.8610 - val_loss: 626244.0000 - val_mae: 577.3771\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619490.8750 - mae: 575.6340 - val_loss: 626133.3125 - val_mae: 578.7982\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618358.5625 - mae: 575.6006 - val_loss: 622340.3750 - val_mae: 576.6443\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617703.4375 - mae: 575.2144 - val_loss: 622395.1250 - val_mae: 576.1605\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616518.8125 - mae: 574.5526 - val_loss: 620671.0000 - val_mae: 574.8400\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615433.8125 - mae: 574.2872 - val_loss: 621840.6250 - val_mae: 574.1020\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614877.8125 - mae: 573.2861 - val_loss: 622563.1250 - val_mae: 578.2715\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613888.0625 - mae: 573.9182 - val_loss: 620653.3125 - val_mae: 572.8065\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613475.0000 - mae: 572.8716 - val_loss: 619629.6250 - val_mae: 574.3520\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612368.2500 - mae: 572.5811 - val_loss: 620358.1250 - val_mae: 574.9873\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611634.4375 - mae: 572.9664 - val_loss: 618904.1875 - val_mae: 572.7212\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611419.1250 - mae: 571.6514 - val_loss: 617259.7500 - val_mae: 574.1914\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 610074.0000 - mae: 571.4009 - val_loss: 617164.0625 - val_mae: 574.9570\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609547.0000 - mae: 571.3986 - val_loss: 615095.7500 - val_mae: 573.7777\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608752.8125 - mae: 571.1124 - val_loss: 615653.7500 - val_mae: 572.1412\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607966.4375 - mae: 570.4683 - val_loss: 616758.1250 - val_mae: 574.5176\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607578.6875 - mae: 570.4605 - val_loss: 615324.6875 - val_mae: 571.4493\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606416.6875 - mae: 569.6929 - val_loss: 614546.1250 - val_mae: 572.1816\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606079.5625 - mae: 569.6041 - val_loss: 613837.8125 - val_mae: 571.9084\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605021.8125 - mae: 569.1751 - val_loss: 612615.1250 - val_mae: 572.1077\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604283.1250 - mae: 568.8841 - val_loss: 612632.5625 - val_mae: 570.6823\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603915.1250 - mae: 568.8563 - val_loss: 612349.1250 - val_mae: 571.1301\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603016.6875 - mae: 568.9249 - val_loss: 609650.2500 - val_mae: 568.5690\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602425.3750 - mae: 568.0425 - val_loss: 610948.3125 - val_mae: 571.0934\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602085.5625 - mae: 568.2216 - val_loss: 611022.7500 - val_mae: 569.7016\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601406.6875 - mae: 567.6401 - val_loss: 610539.3125 - val_mae: 570.0267\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601209.5000 - mae: 567.8801 - val_loss: 607993.0000 - val_mae: 569.4481\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600273.1875 - mae: 567.0573 - val_loss: 608185.8125 - val_mae: 571.7274\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600047.2500 - mae: 567.8334 - val_loss: 606270.6250 - val_mae: 569.0317\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599384.8125 - mae: 567.2277 - val_loss: 606380.3125 - val_mae: 569.1224\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598657.3750 - mae: 567.0592 - val_loss: 609501.5000 - val_mae: 570.2753\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598412.8750 - mae: 566.8501 - val_loss: 608405.0000 - val_mae: 569.2189\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598142.9375 - mae: 566.2310 - val_loss: 607545.5000 - val_mae: 570.1348\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 36151284.0000 - mae: 5854.2554 - val_loss: 30904774.0000 - val_mae: 5411.0308\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 23550976.0000 - mae: 4646.8120 - val_loss: 16115615.0000 - val_mae: 3771.7705\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 10844751.0000 - mae: 2919.7681 - val_loss: 6572728.0000 - val_mae: 2136.1401\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4204626.5000 - mae: 1602.2682 - val_loss: 2551677.5000 - val_mae: 1173.6394\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1849606.7500 - mae: 941.3568 - val_loss: 1484541.2500 - val_mae: 794.0925\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1340736.2500 - mae: 752.9768 - val_loss: 1277040.7500 - val_mae: 726.4886\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1215582.3750 - mae: 716.9047 - val_loss: 1191279.3750 - val_mae: 705.1817\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1149129.0000 - mae: 700.0400 - val_loss: 1137650.0000 - val_mae: 688.8052\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1100309.3750 - mae: 683.0821 - val_loss: 1094004.7500 - val_mae: 672.6624\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1059727.1250 - mae: 667.5443 - val_loss: 1058478.5000 - val_mae: 658.1288\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1029005.3750 - mae: 654.2385 - val_loss: 1031826.6250 - val_mae: 646.5450\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1005675.1875 - mae: 643.6860 - val_loss: 1011939.0625 - val_mae: 640.8219\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 988346.6250 - mae: 637.3249 - val_loss: 997865.1875 - val_mae: 631.6951\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 972076.8750 - mae: 629.7834 - val_loss: 984094.1250 - val_mae: 625.2853\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 956938.8125 - mae: 623.6296 - val_loss: 972526.1250 - val_mae: 620.4378\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 943789.6875 - mae: 618.5354 - val_loss: 966013.3125 - val_mae: 617.8333\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 934057.8125 - mae: 614.5744 - val_loss: 957125.9375 - val_mae: 612.9976\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 926882.5000 - mae: 611.0444 - val_loss: 953671.7500 - val_mae: 610.0080\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 921900.3125 - mae: 609.1069 - val_loss: 948178.6875 - val_mae: 609.0531\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 917110.8750 - mae: 607.2877 - val_loss: 949517.3750 - val_mae: 611.2156\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 912250.3125 - mae: 605.5224 - val_loss: 942673.1250 - val_mae: 606.0747\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 907319.6250 - mae: 603.6749 - val_loss: 938246.5000 - val_mae: 603.5333\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 903104.6250 - mae: 601.6329 - val_loss: 934432.6875 - val_mae: 601.0218\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 900124.1250 - mae: 600.4157 - val_loss: 932884.2500 - val_mae: 597.7485\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 896809.8125 - mae: 598.4574 - val_loss: 934599.1250 - val_mae: 602.5064\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 894623.5000 - mae: 598.3940 - val_loss: 931746.5000 - val_mae: 602.3559\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 891682.6250 - mae: 597.8147 - val_loss: 927193.9375 - val_mae: 596.2384\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 889224.2500 - mae: 596.0178 - val_loss: 929074.8125 - val_mae: 602.0442\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 887159.0000 - mae: 596.0482 - val_loss: 927494.6250 - val_mae: 596.8479\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 885290.2500 - mae: 594.6284 - val_loss: 924692.7500 - val_mae: 598.7724\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 883238.3750 - mae: 594.4146 - val_loss: 922529.3125 - val_mae: 594.6442\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 881346.5000 - mae: 593.5998 - val_loss: 920158.3750 - val_mae: 593.4113\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 878943.8750 - mae: 592.5932 - val_loss: 924444.0000 - val_mae: 599.5173\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 877563.6875 - mae: 592.2249 - val_loss: 920637.6875 - val_mae: 593.9442\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 875660.5000 - mae: 591.6422 - val_loss: 916611.5000 - val_mae: 593.2017\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 874069.1250 - mae: 590.3416 - val_loss: 920459.5000 - val_mae: 597.2238\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 873181.9375 - mae: 590.4222 - val_loss: 918397.7500 - val_mae: 597.8516\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 871982.1250 - mae: 589.8450 - val_loss: 917890.6875 - val_mae: 597.4277\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 870564.6875 - mae: 589.7333 - val_loss: 915022.3125 - val_mae: 594.2023\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 870158.0625 - mae: 589.4016 - val_loss: 917836.3125 - val_mae: 596.9343\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 869427.3750 - mae: 589.4197 - val_loss: 917160.0625 - val_mae: 594.8178\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 868254.2500 - mae: 589.4273 - val_loss: 912270.9375 - val_mae: 591.2086\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 866636.0000 - mae: 588.4069 - val_loss: 913555.5625 - val_mae: 595.2646\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 864863.2500 - mae: 588.2685 - val_loss: 911179.0625 - val_mae: 593.3096\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 863297.5625 - mae: 587.6992 - val_loss: 909414.1875 - val_mae: 595.0261\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 861651.3125 - mae: 587.8859 - val_loss: 905862.3125 - val_mae: 591.5166\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 860172.6250 - mae: 587.3149 - val_loss: 905554.5000 - val_mae: 592.4711\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 858926.1875 - mae: 586.9127 - val_loss: 902202.9375 - val_mae: 591.6843\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 857315.5625 - mae: 587.1027 - val_loss: 898975.0625 - val_mae: 589.1526\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 856132.8125 - mae: 586.2833 - val_loss: 898971.2500 - val_mae: 593.5534\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 853846.3125 - mae: 585.9604 - val_loss: 894820.5625 - val_mae: 592.5907\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 851911.0000 - mae: 585.7300 - val_loss: 889112.3750 - val_mae: 588.0573\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 851027.0625 - mae: 585.3134 - val_loss: 890165.5625 - val_mae: 591.0535\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 844904.1875 - mae: 585.3949 - val_loss: 860370.6250 - val_mae: 589.4346\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 801477.1250 - mae: 584.0277 - val_loss: 812189.0625 - val_mae: 587.8525\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 764023.9375 - mae: 582.7362 - val_loss: 777887.6250 - val_mae: 583.4442\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 736178.8125 - mae: 580.9985 - val_loss: 749267.2500 - val_mae: 583.1428\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 713022.0000 - mae: 580.3782 - val_loss: 727270.6250 - val_mae: 581.8240\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 693692.9375 - mae: 579.7750 - val_loss: 706081.3750 - val_mae: 579.4135\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 677308.0000 - mae: 578.3214 - val_loss: 690501.8750 - val_mae: 579.9418\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 663714.1250 - mae: 577.9113 - val_loss: 674258.2500 - val_mae: 576.0699\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 653937.3750 - mae: 576.7191 - val_loss: 667249.0000 - val_mae: 579.4777\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 645606.0625 - mae: 576.5068 - val_loss: 657549.7500 - val_mae: 580.2765\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 638145.3750 - mae: 576.0119 - val_loss: 646628.1250 - val_mae: 575.9744\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 631958.0000 - mae: 575.2675 - val_loss: 639710.6875 - val_mae: 575.7302\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 626356.0625 - mae: 574.5123 - val_loss: 634609.8750 - val_mae: 574.2533\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621829.3125 - mae: 573.5331 - val_loss: 629058.0625 - val_mae: 573.5051\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616778.3750 - mae: 572.4838 - val_loss: 622831.6250 - val_mae: 572.0833\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613297.0625 - mae: 571.8110 - val_loss: 621021.0625 - val_mae: 572.5825\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609388.3750 - mae: 570.8699 - val_loss: 617304.8125 - val_mae: 568.1715\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606869.2500 - mae: 570.1115 - val_loss: 615679.5625 - val_mae: 573.5043\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604478.1250 - mae: 569.3898 - val_loss: 612435.3750 - val_mae: 572.9238\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602061.7500 - mae: 568.9375 - val_loss: 607740.3750 - val_mae: 566.8121\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600404.3750 - mae: 568.1625 - val_loss: 610334.5000 - val_mae: 573.3422\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598700.8750 - mae: 567.7803 - val_loss: 605273.6875 - val_mae: 570.2079\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597654.5625 - mae: 567.5205 - val_loss: 603401.3125 - val_mae: 567.0889\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596473.9375 - mae: 566.5679 - val_loss: 604167.2500 - val_mae: 570.5640\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595567.6875 - mae: 566.3632 - val_loss: 603049.0000 - val_mae: 568.3579\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595089.9375 - mae: 565.9599 - val_loss: 604545.0625 - val_mae: 571.2782\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594710.5000 - mae: 566.0174 - val_loss: 603383.6250 - val_mae: 569.0854\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593950.7500 - mae: 565.4632 - val_loss: 603074.0625 - val_mae: 567.7572\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593878.3750 - mae: 565.3250 - val_loss: 601361.6250 - val_mae: 568.5649\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593756.7500 - mae: 565.6833 - val_loss: 601175.8125 - val_mae: 566.4831\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593187.5000 - mae: 564.5970 - val_loss: 599772.0625 - val_mae: 567.4343\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593040.6250 - mae: 565.4121 - val_loss: 598394.8750 - val_mae: 566.5231\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592721.1250 - mae: 564.3631 - val_loss: 604293.8125 - val_mae: 572.4589\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592638.2500 - mae: 565.0228 - val_loss: 600586.8125 - val_mae: 565.5700\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592219.3750 - mae: 564.5208 - val_loss: 601234.5625 - val_mae: 565.0806\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591861.7500 - mae: 563.5996 - val_loss: 601963.9375 - val_mae: 569.8138\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592240.2500 - mae: 564.6293 - val_loss: 603049.0000 - val_mae: 568.3621\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591737.0000 - mae: 564.0046 - val_loss: 600179.0625 - val_mae: 566.3919\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591655.9375 - mae: 564.1522 - val_loss: 600426.3125 - val_mae: 567.8127\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591684.5000 - mae: 563.9180 - val_loss: 601935.0000 - val_mae: 569.1615\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591514.8750 - mae: 563.7933 - val_loss: 600317.3750 - val_mae: 567.6501\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591284.8125 - mae: 563.9770 - val_loss: 601875.2500 - val_mae: 570.2316\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590825.6250 - mae: 564.0818 - val_loss: 598721.5625 - val_mae: 564.7538\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591081.3125 - mae: 563.4274 - val_loss: 599962.8125 - val_mae: 565.7107\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590670.6250 - mae: 563.6329 - val_loss: 598788.8125 - val_mae: 565.2969\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590633.1875 - mae: 563.2462 - val_loss: 600117.0625 - val_mae: 567.3962\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590497.5625 - mae: 563.6305 - val_loss: 600080.3750 - val_mae: 566.6977\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590497.1250 - mae: 563.3658 - val_loss: 598540.7500 - val_mae: 566.1638\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589921.5625 - mae: 563.4865 - val_loss: 600721.0000 - val_mae: 566.5707\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589698.0000 - mae: 563.3532 - val_loss: 599152.3125 - val_mae: 567.3640\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589441.0625 - mae: 562.5243 - val_loss: 600027.8125 - val_mae: 567.4865\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589906.0000 - mae: 563.4857 - val_loss: 600059.5625 - val_mae: 566.8382\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589408.7500 - mae: 563.3438 - val_loss: 598517.1250 - val_mae: 561.8333\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589877.0000 - mae: 563.2840 - val_loss: 598175.8750 - val_mae: 564.2668\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589121.8750 - mae: 562.8790 - val_loss: 598340.1875 - val_mae: 565.8666\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588932.3125 - mae: 562.7354 - val_loss: 596420.1250 - val_mae: 564.3034\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588586.1250 - mae: 562.7587 - val_loss: 597468.0625 - val_mae: 563.6179\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588363.3125 - mae: 562.1720 - val_loss: 599477.0625 - val_mae: 568.2059\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588636.3125 - mae: 562.6678 - val_loss: 601246.1250 - val_mae: 570.2477\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588251.5000 - mae: 562.3417 - val_loss: 600140.5625 - val_mae: 569.5766\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587917.5625 - mae: 562.1194 - val_loss: 600441.8125 - val_mae: 570.6648\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588108.4375 - mae: 562.4509 - val_loss: 597367.6875 - val_mae: 566.2411\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587641.9375 - mae: 562.0824 - val_loss: 597220.6875 - val_mae: 564.4589\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38220188.0000 - mae: 6026.0376 - val_loss: 37228244.0000 - val_mae: 5952.7651\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 35636884.0000 - mae: 5817.4673 - val_loss: 33324838.0000 - val_mae: 5630.3320\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 30704190.0000 - mae: 5394.8301 - val_loss: 27609470.0000 - val_mae: 5117.9932\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 24497998.0000 - mae: 4804.4224 - val_loss: 21194508.0000 - val_mae: 4465.0361\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 18134260.0000 - mae: 4102.9858 - val_loss: 15114992.0000 - val_mae: 3729.5955\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 12499294.0000 - mae: 3347.1030 - val_loss: 10081323.0000 - val_mae: 2972.3784\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 8106902.5000 - mae: 2603.0098 - val_loss: 6390962.0000 - val_mae: 2265.4868\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5057712.5000 - mae: 1951.9595 - val_loss: 3965855.0000 - val_mae: 1697.3414\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3153057.7500 - mae: 1470.4308 - val_loss: 2514018.0000 - val_mae: 1302.4618\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2063759.0000 - mae: 1148.5000 - val_loss: 1717034.1250 - val_mae: 1041.1418\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1491890.8750 - mae: 940.4707 - val_loss: 1310803.2500 - val_mae: 879.8509\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1204359.0000 - mae: 821.4296 - val_loss: 1102937.8750 - val_mae: 787.5607\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1055873.1250 - mae: 756.9030 - val_loss: 994344.3750 - val_mae: 740.3448\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 970960.1250 - mae: 723.7340 - val_loss: 926555.0625 - val_mae: 713.3673\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 913910.2500 - mae: 702.4290 - val_loss: 878679.1875 - val_mae: 694.9485\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 872220.3750 - mae: 686.9560 - val_loss: 844624.5625 - val_mae: 681.1882\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 839797.4375 - mae: 674.7239 - val_loss: 817074.7500 - val_mae: 668.5488\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 813617.3125 - mae: 663.6965 - val_loss: 795609.5000 - val_mae: 658.2037\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 793525.6250 - mae: 654.6321 - val_loss: 779831.1250 - val_mae: 650.2007\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 777094.9375 - mae: 647.2250 - val_loss: 765517.9375 - val_mae: 642.5472\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 762946.1875 - mae: 640.2729 - val_loss: 754099.4375 - val_mae: 636.6891\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 751616.3125 - mae: 635.5426 - val_loss: 745164.8125 - val_mae: 630.9944\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 741735.2500 - mae: 630.2021 - val_loss: 737571.0000 - val_mae: 626.9313\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 733845.7500 - mae: 626.5678 - val_loss: 731326.7500 - val_mae: 623.6259\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 727061.1250 - mae: 623.3104 - val_loss: 724531.6250 - val_mae: 620.1625\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 720889.9375 - mae: 620.2770 - val_loss: 718833.8750 - val_mae: 617.3079\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 715260.5000 - mae: 617.8928 - val_loss: 714188.9375 - val_mae: 614.8017\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 709822.1875 - mae: 615.2068 - val_loss: 710827.0000 - val_mae: 613.1597\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 704028.4375 - mae: 613.2405 - val_loss: 707613.6875 - val_mae: 610.4891\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 698684.3750 - mae: 610.3260 - val_loss: 702539.3125 - val_mae: 609.2275\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 693576.4375 - mae: 608.3834 - val_loss: 698734.4375 - val_mae: 608.2787\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 688053.0625 - mae: 606.6441 - val_loss: 693811.0625 - val_mae: 605.2225\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 682576.5000 - mae: 604.7576 - val_loss: 690242.9375 - val_mae: 602.4961\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 678082.0625 - mae: 602.3689 - val_loss: 686341.9375 - val_mae: 602.4858\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 673849.0625 - mae: 601.3357 - val_loss: 682958.5000 - val_mae: 600.3735\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 670051.3750 - mae: 599.0924 - val_loss: 679825.6875 - val_mae: 599.5343\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 666237.0000 - mae: 597.8888 - val_loss: 677649.1875 - val_mae: 599.3232\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 662607.8750 - mae: 596.9871 - val_loss: 674688.8125 - val_mae: 596.4838\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 659458.0000 - mae: 595.7308 - val_loss: 671930.8125 - val_mae: 594.8507\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 656428.8125 - mae: 594.1724 - val_loss: 669167.4375 - val_mae: 595.0611\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 653352.4375 - mae: 592.9717 - val_loss: 667043.4375 - val_mae: 594.8111\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 650828.7500 - mae: 592.4111 - val_loss: 665405.0000 - val_mae: 592.3206\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 648163.0000 - mae: 589.9357 - val_loss: 661009.8750 - val_mae: 592.5645\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 645097.3750 - mae: 589.2816 - val_loss: 658806.5625 - val_mae: 590.8140\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 642251.3750 - mae: 588.0291 - val_loss: 656661.1250 - val_mae: 589.0802\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 639958.1250 - mae: 586.2380 - val_loss: 655551.3125 - val_mae: 587.4168\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637815.1250 - mae: 585.2028 - val_loss: 652322.2500 - val_mae: 586.2149\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 635869.0625 - mae: 583.8976 - val_loss: 652244.9375 - val_mae: 586.2226\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 634011.2500 - mae: 583.6453 - val_loss: 650957.0000 - val_mae: 584.3366\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 632260.7500 - mae: 582.1038 - val_loss: 649383.0625 - val_mae: 583.8200\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 630736.6250 - mae: 581.4925 - val_loss: 648633.0000 - val_mae: 585.3516\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 629244.1875 - mae: 581.0863 - val_loss: 647890.5625 - val_mae: 584.0279\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 627739.9375 - mae: 580.3947 - val_loss: 648013.8750 - val_mae: 582.5708\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 626991.3750 - mae: 580.1278 - val_loss: 648907.3750 - val_mae: 581.1371\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 625433.6875 - mae: 579.0670 - val_loss: 645436.6250 - val_mae: 581.1772\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 624170.6250 - mae: 578.4791 - val_loss: 644265.8750 - val_mae: 581.5533\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 623086.3750 - mae: 578.5072 - val_loss: 643428.0625 - val_mae: 579.5817\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 621954.1875 - mae: 577.8406 - val_loss: 643979.0625 - val_mae: 580.1623\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 620831.2500 - mae: 576.5876 - val_loss: 642243.0000 - val_mae: 579.7430\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619637.9375 - mae: 576.6528 - val_loss: 641297.0625 - val_mae: 580.0349\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 618502.1250 - mae: 576.0209 - val_loss: 640596.5625 - val_mae: 579.7640\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617373.0000 - mae: 575.2013 - val_loss: 639190.8125 - val_mae: 582.5291\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616661.1875 - mae: 575.1410 - val_loss: 639234.7500 - val_mae: 580.0283\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615368.1250 - mae: 575.0667 - val_loss: 637139.3125 - val_mae: 578.4802\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614308.9375 - mae: 574.0309 - val_loss: 637227.2500 - val_mae: 577.6380\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613035.8125 - mae: 574.2426 - val_loss: 636014.3125 - val_mae: 576.6191\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612056.0625 - mae: 572.6656 - val_loss: 635557.3125 - val_mae: 577.6468\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611223.2500 - mae: 573.5984 - val_loss: 635375.9375 - val_mae: 577.1876\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609901.1250 - mae: 571.6154 - val_loss: 633620.1250 - val_mae: 578.5222\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609278.7500 - mae: 572.3728 - val_loss: 632637.1875 - val_mae: 577.2213\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608064.8750 - mae: 571.3281 - val_loss: 630694.3125 - val_mae: 577.8663\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607395.2500 - mae: 571.5459 - val_loss: 630500.0625 - val_mae: 575.8753\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606252.6875 - mae: 570.5555 - val_loss: 630306.3125 - val_mae: 576.1113\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605247.3125 - mae: 569.9288 - val_loss: 629266.0000 - val_mae: 575.2827\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604659.5625 - mae: 570.1670 - val_loss: 630293.2500 - val_mae: 574.5977\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603774.3125 - mae: 569.0239 - val_loss: 628533.0000 - val_mae: 575.2077\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602716.6250 - mae: 569.0219 - val_loss: 628435.5000 - val_mae: 574.1852\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601949.7500 - mae: 568.4327 - val_loss: 626669.9375 - val_mae: 575.3532\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601272.3125 - mae: 568.6531 - val_loss: 626681.0625 - val_mae: 573.6618\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600467.3125 - mae: 567.9694 - val_loss: 626604.5000 - val_mae: 572.3983\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599663.3125 - mae: 567.0462 - val_loss: 624634.5625 - val_mae: 573.4266\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 598821.3750 - mae: 567.2041 - val_loss: 625867.0000 - val_mae: 571.9976\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597748.1250 - mae: 566.6363 - val_loss: 623342.5000 - val_mae: 572.1161\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597625.3125 - mae: 565.9735 - val_loss: 623521.6875 - val_mae: 572.2380\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596916.5000 - mae: 566.2043 - val_loss: 621596.2500 - val_mae: 570.7978\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596183.1875 - mae: 565.5312 - val_loss: 621147.2500 - val_mae: 570.8674\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595452.5000 - mae: 565.3829 - val_loss: 621074.7500 - val_mae: 570.7735\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594924.5625 - mae: 564.6002 - val_loss: 618989.3750 - val_mae: 570.1506\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594284.9375 - mae: 564.5543 - val_loss: 619443.5625 - val_mae: 571.3593\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594010.1250 - mae: 564.6298 - val_loss: 619152.6875 - val_mae: 570.0782\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593061.2500 - mae: 563.9974 - val_loss: 618757.0625 - val_mae: 568.6157\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592504.6875 - mae: 563.0919 - val_loss: 619161.5625 - val_mae: 569.1026\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592110.6875 - mae: 563.1366 - val_loss: 618014.1875 - val_mae: 570.3239\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591810.8750 - mae: 563.3451 - val_loss: 618011.8750 - val_mae: 569.0219\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590904.4375 - mae: 562.8539 - val_loss: 616117.5625 - val_mae: 567.9090\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590390.8750 - mae: 561.8531 - val_loss: 615348.8125 - val_mae: 568.7700\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589615.0000 - mae: 562.1012 - val_loss: 615153.1875 - val_mae: 567.2810\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588977.5625 - mae: 561.6045 - val_loss: 614830.1875 - val_mae: 568.9170\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588639.7500 - mae: 561.5175 - val_loss: 613029.5625 - val_mae: 566.8444\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587914.1875 - mae: 561.1943 - val_loss: 613941.1875 - val_mae: 565.6476\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586682.5000 - mae: 560.2782 - val_loss: 614211.1875 - val_mae: 565.5046\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586345.1250 - mae: 559.6530 - val_loss: 612767.4375 - val_mae: 566.2913\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585219.4375 - mae: 559.2380 - val_loss: 613179.1250 - val_mae: 565.9270\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584417.2500 - mae: 558.3806 - val_loss: 611414.0625 - val_mae: 563.6953\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583576.6250 - mae: 557.9225 - val_loss: 610826.9375 - val_mae: 563.9363\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582991.8125 - mae: 557.4606 - val_loss: 608647.9375 - val_mae: 563.3157\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582177.8125 - mae: 556.8859 - val_loss: 608737.3125 - val_mae: 562.7742\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581499.8750 - mae: 556.1545 - val_loss: 606861.0000 - val_mae: 562.1258\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580907.3750 - mae: 556.0972 - val_loss: 607674.5625 - val_mae: 561.8131\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580091.0625 - mae: 555.4780 - val_loss: 607064.6875 - val_mae: 561.8669\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 579821.4375 - mae: 554.9638 - val_loss: 606204.8125 - val_mae: 562.1232\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 579342.0000 - mae: 554.3533 - val_loss: 604473.7500 - val_mae: 562.0613\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578710.3750 - mae: 555.1572 - val_loss: 604729.9375 - val_mae: 559.0942\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578217.0000 - mae: 553.7183 - val_loss: 604740.6250 - val_mae: 559.8602\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 577509.8125 - mae: 553.5751 - val_loss: 604202.6250 - val_mae: 559.4208\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 577282.5625 - mae: 553.4103 - val_loss: 604107.3750 - val_mae: 559.1083\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 576819.5000 - mae: 552.9643 - val_loss: 603479.6875 - val_mae: 558.5581\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 576503.3750 - mae: 552.2853 - val_loss: 602341.2500 - val_mae: 561.2676\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 575500.4375 - mae: 552.1144 - val_loss: 602754.9375 - val_mae: 561.8820\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 575696.0625 - mae: 552.5356 - val_loss: 601539.8750 - val_mae: 559.1024\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 575241.7500 - mae: 552.2545 - val_loss: 601816.6250 - val_mae: 558.2233\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 574879.1875 - mae: 551.8963 - val_loss: 600757.3750 - val_mae: 555.7515\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 574804.0625 - mae: 551.5417 - val_loss: 600265.6250 - val_mae: 556.2629\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 574526.8125 - mae: 551.3585 - val_loss: 599795.6250 - val_mae: 555.7812\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 573963.5000 - mae: 551.2770 - val_loss: 600081.1250 - val_mae: 555.8494\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 573606.8125 - mae: 550.3519 - val_loss: 598184.8125 - val_mae: 556.8668\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 573477.4375 - mae: 550.8250 - val_loss: 597626.4375 - val_mae: 557.1188\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 572427.1250 - mae: 550.5536 - val_loss: 598479.3750 - val_mae: 553.6951\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 572924.1250 - mae: 549.9970 - val_loss: 597929.6875 - val_mae: 554.2443\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 572119.0000 - mae: 549.8630 - val_loss: 596362.8750 - val_mae: 554.7183\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571951.8750 - mae: 549.9432 - val_loss: 596413.0625 - val_mae: 554.2090\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571825.1875 - mae: 549.4810 - val_loss: 595243.1250 - val_mae: 555.1084\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571358.8125 - mae: 549.9434 - val_loss: 596346.9375 - val_mae: 553.5552\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571260.1250 - mae: 548.6870 - val_loss: 595467.0625 - val_mae: 554.4738\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571002.8750 - mae: 549.0781 - val_loss: 595123.0000 - val_mae: 553.5839\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570881.9375 - mae: 548.6332 - val_loss: 594517.0625 - val_mae: 553.7017\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570131.8750 - mae: 548.1379 - val_loss: 595508.5625 - val_mae: 556.2236\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570360.1250 - mae: 548.6053 - val_loss: 593357.3750 - val_mae: 555.3233\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570018.9375 - mae: 548.6287 - val_loss: 594395.3750 - val_mae: 553.1996\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 569490.2500 - mae: 547.5428 - val_loss: 593723.0625 - val_mae: 553.3940\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 569126.8125 - mae: 547.6075 - val_loss: 592429.6250 - val_mae: 551.7585\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 568347.9375 - mae: 547.1030 - val_loss: 591674.7500 - val_mae: 551.6450\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 567724.6250 - mae: 546.3204 - val_loss: 591436.4375 - val_mae: 552.1719\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 567273.8125 - mae: 546.3470 - val_loss: 591839.2500 - val_mae: 550.9252\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 566588.8750 - mae: 545.8384 - val_loss: 590490.8125 - val_mae: 549.9467\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 566140.3125 - mae: 544.9304 - val_loss: 589430.1875 - val_mae: 550.3907\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 565610.0625 - mae: 544.9050 - val_loss: 589600.7500 - val_mae: 550.6190\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 565139.8125 - mae: 544.8636 - val_loss: 589108.7500 - val_mae: 548.5578\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564862.4375 - mae: 543.9351 - val_loss: 587809.8750 - val_mae: 548.8107\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564444.2500 - mae: 544.5480 - val_loss: 587582.6250 - val_mae: 547.0295\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564433.3125 - mae: 543.7185 - val_loss: 588961.3750 - val_mae: 549.0418\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563738.6875 - mae: 543.7132 - val_loss: 587900.7500 - val_mae: 550.2178\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563297.9375 - mae: 543.1135 - val_loss: 587746.5000 - val_mae: 549.4106\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563152.6875 - mae: 543.4455 - val_loss: 585710.5000 - val_mae: 548.2586\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 562932.6250 - mae: 543.0809 - val_loss: 586856.8125 - val_mae: 548.0101\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 562637.9375 - mae: 542.6467 - val_loss: 585335.6875 - val_mae: 548.2328\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561912.6250 - mae: 542.5969 - val_loss: 585606.5000 - val_mae: 547.9556\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561962.6875 - mae: 541.9678 - val_loss: 584088.0625 - val_mae: 547.1099\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561855.5000 - mae: 542.5704 - val_loss: 584073.4375 - val_mae: 546.1161\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561672.3125 - mae: 541.9286 - val_loss: 583487.6875 - val_mae: 547.2667\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561206.0000 - mae: 542.5372 - val_loss: 583486.6875 - val_mae: 546.5200\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560978.5000 - mae: 541.5558 - val_loss: 583756.0625 - val_mae: 548.6633\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560773.0000 - mae: 542.0493 - val_loss: 583392.7500 - val_mae: 545.5554\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560733.5625 - mae: 541.6835 - val_loss: 583611.6250 - val_mae: 545.2306\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560492.6250 - mae: 541.4826 - val_loss: 583301.8750 - val_mae: 546.3834\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560380.6250 - mae: 541.4630 - val_loss: 581679.2500 - val_mae: 546.0778\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560060.4375 - mae: 540.9001 - val_loss: 580670.4375 - val_mae: 546.1871\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560144.0625 - mae: 541.5926 - val_loss: 581025.0000 - val_mae: 546.4464\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559849.5625 - mae: 541.1287 - val_loss: 581519.2500 - val_mae: 545.6646\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559675.9375 - mae: 541.1190 - val_loss: 580016.6250 - val_mae: 545.8266\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559582.7500 - mae: 540.8959 - val_loss: 579443.3750 - val_mae: 544.6183\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559180.7500 - mae: 540.8107 - val_loss: 580333.1250 - val_mae: 544.2910\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559158.5625 - mae: 540.2580 - val_loss: 579213.8750 - val_mae: 545.6470\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559098.7500 - mae: 540.8991 - val_loss: 579898.1875 - val_mae: 545.3754\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558796.0000 - mae: 540.2415 - val_loss: 578040.3750 - val_mae: 544.9037\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558411.3750 - mae: 540.8987 - val_loss: 579490.8750 - val_mae: 546.1402\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558302.7500 - mae: 540.4574 - val_loss: 579772.3750 - val_mae: 544.8954\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558323.8125 - mae: 539.7174 - val_loss: 578167.6875 - val_mae: 545.6362\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558240.8125 - mae: 540.1929 - val_loss: 578171.5625 - val_mae: 545.8828\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557879.5000 - mae: 540.0544 - val_loss: 578270.3750 - val_mae: 544.7283\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557708.8750 - mae: 540.1998 - val_loss: 579540.1250 - val_mae: 544.8022\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557637.1875 - mae: 539.6551 - val_loss: 579089.0625 - val_mae: 544.9343\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38116280.0000 - mae: 6018.4561 - val_loss: 36734676.0000 - val_mae: 5915.5088\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 34100844.0000 - mae: 5695.8945 - val_loss: 30529618.0000 - val_mae: 5398.5742\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 26679746.0000 - mae: 5032.6631 - val_loss: 22357548.0000 - val_mae: 4605.9346\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 18542172.0000 - mae: 4156.2290 - val_loss: 14615376.0000 - val_mae: 3665.1201\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 11612707.0000 - mae: 3201.0935 - val_loss: 8675799.0000 - val_mae: 2726.8396\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6718278.5000 - mae: 2322.2324 - val_loss: 4868349.5000 - val_mae: 1919.5043\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3799295.2500 - mae: 1638.8423 - val_loss: 2805147.7500 - val_mae: 1378.1970\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2317723.7500 - mae: 1229.1849 - val_loss: 1843943.6250 - val_mae: 1083.5907\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1650186.7500 - mae: 1007.2506 - val_loss: 1428585.8750 - val_mae: 930.0211\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1352575.7500 - mae: 891.9704 - val_loss: 1233537.3750 - val_mae: 851.8895\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1196395.8750 - mae: 830.4611 - val_loss: 1119536.3750 - val_mae: 805.8365\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1094682.3750 - mae: 790.4532 - val_loss: 1032671.8125 - val_mae: 770.9525\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1016877.1250 - mae: 759.4443 - val_loss: 967935.4375 - val_mae: 742.5293\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 956262.1250 - mae: 734.2799 - val_loss: 915261.3750 - val_mae: 719.5911\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 906791.4375 - mae: 713.3273 - val_loss: 872777.5625 - val_mae: 700.1437\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 866538.0625 - mae: 695.5255 - val_loss: 837670.9375 - val_mae: 685.0419\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 833182.2500 - mae: 681.6655 - val_loss: 807676.5000 - val_mae: 671.6989\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 803525.8750 - mae: 668.4773 - val_loss: 779077.4375 - val_mae: 660.2025\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 777266.8125 - mae: 658.1806 - val_loss: 755661.5000 - val_mae: 649.5166\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 755440.8125 - mae: 648.6712 - val_loss: 735394.2500 - val_mae: 641.4870\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 738025.8125 - mae: 641.0657 - val_loss: 720118.8125 - val_mae: 635.3876\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 722104.1250 - mae: 634.6614 - val_loss: 705633.3125 - val_mae: 627.4632\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 707903.3125 - mae: 627.3228 - val_loss: 692910.0000 - val_mae: 623.0905\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 695468.5625 - mae: 622.3323 - val_loss: 682333.6875 - val_mae: 615.3387\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 684475.6875 - mae: 615.9486 - val_loss: 673877.1250 - val_mae: 611.4407\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 674464.8750 - mae: 610.9859 - val_loss: 664709.8125 - val_mae: 606.5339\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 666597.2500 - mae: 606.7353 - val_loss: 658624.8750 - val_mae: 602.4272\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 659828.5000 - mae: 602.7667 - val_loss: 654672.3750 - val_mae: 601.5194\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 654315.0000 - mae: 600.8118 - val_loss: 648730.8750 - val_mae: 596.3380\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 649371.1250 - mae: 597.1828 - val_loss: 644654.0625 - val_mae: 593.9843\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 645496.4375 - mae: 594.8182 - val_loss: 640682.5625 - val_mae: 591.3905\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 641194.0000 - mae: 592.8226 - val_loss: 639091.5625 - val_mae: 589.7833\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637337.3750 - mae: 590.4222 - val_loss: 635224.0000 - val_mae: 587.7076\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 634320.8125 - mae: 588.4680 - val_loss: 632418.8125 - val_mae: 585.3329\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 631297.7500 - mae: 586.6437 - val_loss: 630014.6875 - val_mae: 584.5078\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 628409.0000 - mae: 585.0834 - val_loss: 627718.7500 - val_mae: 584.9797\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 626673.0000 - mae: 584.1765 - val_loss: 627703.6250 - val_mae: 585.0500\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 624696.7500 - mae: 583.7064 - val_loss: 626017.0000 - val_mae: 580.9730\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 622720.9375 - mae: 582.0660 - val_loss: 625221.8125 - val_mae: 583.3795\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 621367.3750 - mae: 581.2674 - val_loss: 622954.0000 - val_mae: 581.6064\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619947.1875 - mae: 580.6146 - val_loss: 624305.6875 - val_mae: 584.5563\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619597.0000 - mae: 580.9125 - val_loss: 623341.2500 - val_mae: 579.7921\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617932.1875 - mae: 579.6410 - val_loss: 619222.1250 - val_mae: 579.1195\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616901.1875 - mae: 578.9796 - val_loss: 619906.8125 - val_mae: 579.5128\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615542.2500 - mae: 578.5361 - val_loss: 620733.6250 - val_mae: 575.3716\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614822.5000 - mae: 577.3035 - val_loss: 616714.4375 - val_mae: 577.4302\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613244.5000 - mae: 576.9248 - val_loss: 617988.2500 - val_mae: 577.2749\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612575.8125 - mae: 576.4406 - val_loss: 615415.2500 - val_mae: 576.8564\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611150.3750 - mae: 575.5483 - val_loss: 614657.3750 - val_mae: 577.1835\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610541.5625 - mae: 575.4360 - val_loss: 614257.3750 - val_mae: 575.4337\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609094.5000 - mae: 574.3403 - val_loss: 612920.3125 - val_mae: 575.3077\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608130.6875 - mae: 574.3547 - val_loss: 611349.6875 - val_mae: 571.5239\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607386.2500 - mae: 572.9134 - val_loss: 609881.9375 - val_mae: 572.9536\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605618.7500 - mae: 572.5211 - val_loss: 609941.3750 - val_mae: 572.7430\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605412.6250 - mae: 571.9623 - val_loss: 608552.7500 - val_mae: 570.3890\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604520.1250 - mae: 571.5619 - val_loss: 606958.0000 - val_mae: 570.5952\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604031.2500 - mae: 571.1630 - val_loss: 608388.6250 - val_mae: 569.5407\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603612.0625 - mae: 570.4453 - val_loss: 608461.9375 - val_mae: 570.8452\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602672.0625 - mae: 570.2679 - val_loss: 607221.8750 - val_mae: 569.3667\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602141.3750 - mae: 569.7209 - val_loss: 606465.2500 - val_mae: 570.4172\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601685.8125 - mae: 569.8481 - val_loss: 606606.9375 - val_mae: 570.5641\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601256.2500 - mae: 569.0628 - val_loss: 607762.8750 - val_mae: 570.7892\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601074.0625 - mae: 569.1619 - val_loss: 606288.6875 - val_mae: 568.6474\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600566.3750 - mae: 569.1533 - val_loss: 604629.6250 - val_mae: 569.1088\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600107.5000 - mae: 569.1714 - val_loss: 605736.1875 - val_mae: 567.5777\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599944.9375 - mae: 568.1916 - val_loss: 603803.3750 - val_mae: 569.2014\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599568.3750 - mae: 568.2588 - val_loss: 604036.7500 - val_mae: 568.3563\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599653.6250 - mae: 568.3127 - val_loss: 603849.1875 - val_mae: 568.6648\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599168.0625 - mae: 567.9282 - val_loss: 604961.8125 - val_mae: 568.1719\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598911.5625 - mae: 567.5283 - val_loss: 604489.5000 - val_mae: 569.2001\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598462.6250 - mae: 567.8561 - val_loss: 603730.8125 - val_mae: 567.4687\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598392.3750 - mae: 567.8671 - val_loss: 604237.8125 - val_mae: 567.8932\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598229.6250 - mae: 567.2272 - val_loss: 604349.3750 - val_mae: 569.3511\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598370.5000 - mae: 567.6218 - val_loss: 602692.3750 - val_mae: 566.6855\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597993.8125 - mae: 567.3224 - val_loss: 604160.6250 - val_mae: 566.8588\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597426.9375 - mae: 566.8492 - val_loss: 602617.1875 - val_mae: 566.5792\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597064.5625 - mae: 566.3674 - val_loss: 603286.0625 - val_mae: 569.0779\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597117.6875 - mae: 567.0782 - val_loss: 602683.0625 - val_mae: 566.6386\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596417.8125 - mae: 566.1671 - val_loss: 602476.8750 - val_mae: 566.0388\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596202.1250 - mae: 566.1038 - val_loss: 601012.5625 - val_mae: 565.5237\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595396.9375 - mae: 565.9293 - val_loss: 601614.8125 - val_mae: 564.9031\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594996.5625 - mae: 565.1957 - val_loss: 602128.5000 - val_mae: 567.2770\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594373.6250 - mae: 565.1293 - val_loss: 601319.6250 - val_mae: 566.9640\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593897.5000 - mae: 565.0704 - val_loss: 600342.8125 - val_mae: 566.0910\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593138.1250 - mae: 564.2745 - val_loss: 599056.7500 - val_mae: 564.9388\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592845.9375 - mae: 564.1069 - val_loss: 598017.1875 - val_mae: 563.2315\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591916.8125 - mae: 563.1564 - val_loss: 597810.1250 - val_mae: 564.0278\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591212.7500 - mae: 563.0263 - val_loss: 597570.6875 - val_mae: 561.8314\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590584.5625 - mae: 562.4733 - val_loss: 596910.3125 - val_mae: 564.0099\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589697.3750 - mae: 561.5959 - val_loss: 597037.3125 - val_mae: 563.9144\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589352.1250 - mae: 561.1882 - val_loss: 596739.8750 - val_mae: 563.6113\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588687.4375 - mae: 560.8957 - val_loss: 595924.8125 - val_mae: 561.9585\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588482.6875 - mae: 560.3354 - val_loss: 595577.6875 - val_mae: 564.3353\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588217.7500 - mae: 560.6513 - val_loss: 593835.1875 - val_mae: 561.3691\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587728.4375 - mae: 559.7071 - val_loss: 595304.5000 - val_mae: 561.9301\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587620.8125 - mae: 559.4521 - val_loss: 595687.1875 - val_mae: 562.0497\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587011.6875 - mae: 559.7693 - val_loss: 594260.7500 - val_mae: 562.0303\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586209.6875 - mae: 559.2137 - val_loss: 593303.1875 - val_mae: 559.7425\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586068.1250 - mae: 558.4966 - val_loss: 592375.5000 - val_mae: 560.3299\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585727.4375 - mae: 558.1132 - val_loss: 593338.8750 - val_mae: 562.5446\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585503.1875 - mae: 558.7130 - val_loss: 592405.3125 - val_mae: 560.0361\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585530.5000 - mae: 558.0176 - val_loss: 592051.5000 - val_mae: 560.3848\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584750.3125 - mae: 558.0252 - val_loss: 592578.0000 - val_mae: 560.7344\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584650.4375 - mae: 557.9431 - val_loss: 592494.1250 - val_mae: 560.1492\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584112.7500 - mae: 557.9409 - val_loss: 592445.8750 - val_mae: 559.2343\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584068.1250 - mae: 557.2267 - val_loss: 591195.6250 - val_mae: 558.9459\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584156.8125 - mae: 557.2556 - val_loss: 591294.6875 - val_mae: 561.1022\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583940.8125 - mae: 557.4494 - val_loss: 591408.4375 - val_mae: 560.2342\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583949.0000 - mae: 557.5516 - val_loss: 590321.0625 - val_mae: 558.9536\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584086.2500 - mae: 557.9383 - val_loss: 592394.3750 - val_mae: 558.5804\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583509.7500 - mae: 556.9492 - val_loss: 593949.0625 - val_mae: 562.9849\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583308.6250 - mae: 557.0067 - val_loss: 591023.3125 - val_mae: 560.1043\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583648.9375 - mae: 557.2783 - val_loss: 593269.8750 - val_mae: 561.4687\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583759.3125 - mae: 557.7057 - val_loss: 592164.8750 - val_mae: 559.7213\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583032.2500 - mae: 556.7536 - val_loss: 592633.0625 - val_mae: 562.3528\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583212.0000 - mae: 557.2741 - val_loss: 591822.0000 - val_mae: 559.8798\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583088.3125 - mae: 556.6771 - val_loss: 590800.8750 - val_mae: 560.4873\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583070.0000 - mae: 557.4444 - val_loss: 591825.0625 - val_mae: 560.3672\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582896.9375 - mae: 557.2557 - val_loss: 591443.0625 - val_mae: 559.2795\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582767.3750 - mae: 556.7890 - val_loss: 591263.0625 - val_mae: 557.7652\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582863.7500 - mae: 556.7366 - val_loss: 591014.6250 - val_mae: 557.7886\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582372.3125 - mae: 556.6235 - val_loss: 590594.2500 - val_mae: 559.4575\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582302.8750 - mae: 557.0541 - val_loss: 590112.8750 - val_mae: 557.4449\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582475.2500 - mae: 556.8448 - val_loss: 589860.2500 - val_mae: 558.0622\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582391.8125 - mae: 556.8327 - val_loss: 591377.3125 - val_mae: 558.7557\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582386.0000 - mae: 556.6023 - val_loss: 590392.3125 - val_mae: 559.3129\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582212.6875 - mae: 556.7856 - val_loss: 589789.1250 - val_mae: 559.1895\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582277.0000 - mae: 557.1287 - val_loss: 590269.4375 - val_mae: 557.1894\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582255.1250 - mae: 556.5521 - val_loss: 590318.1250 - val_mae: 559.0577\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581860.1250 - mae: 556.5204 - val_loss: 591749.4375 - val_mae: 560.6113\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582188.6250 - mae: 556.9735 - val_loss: 589143.9375 - val_mae: 557.6832\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582141.0625 - mae: 556.8224 - val_loss: 588603.8750 - val_mae: 558.6535\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581869.1875 - mae: 556.7447 - val_loss: 589819.3125 - val_mae: 558.1910\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581699.3125 - mae: 556.2365 - val_loss: 592387.3125 - val_mae: 562.1442\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581726.4375 - mae: 557.1555 - val_loss: 591512.2500 - val_mae: 557.8299\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581658.7500 - mae: 556.2479 - val_loss: 589023.1875 - val_mae: 558.2464\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581615.6875 - mae: 556.7585 - val_loss: 589453.3750 - val_mae: 556.7919\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581506.7500 - mae: 555.6359 - val_loss: 588365.9375 - val_mae: 560.7854\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581374.3750 - mae: 556.8099 - val_loss: 588601.3125 - val_mae: 556.2645\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581257.6875 - mae: 556.2125 - val_loss: 587976.8125 - val_mae: 557.3529\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581627.8750 - mae: 556.6464 - val_loss: 588795.7500 - val_mae: 558.1315\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581344.0625 - mae: 556.3820 - val_loss: 588840.4375 - val_mae: 558.1852\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581375.0000 - mae: 556.5406 - val_loss: 588615.9375 - val_mae: 557.6404\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581067.6250 - mae: 555.6385 - val_loss: 589678.6250 - val_mae: 561.4120\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580805.0000 - mae: 556.6409 - val_loss: 590186.1250 - val_mae: 556.9588\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580882.3125 - mae: 556.1094 - val_loss: 589106.8125 - val_mae: 557.8480\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580761.4375 - mae: 556.1055 - val_loss: 590353.5000 - val_mae: 560.5911\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581037.6875 - mae: 555.9565 - val_loss: 588033.1250 - val_mae: 557.6783\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580503.8750 - mae: 556.4516 - val_loss: 590055.8125 - val_mae: 556.9626\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 32555554.0000 - mae: 5526.9312 - val_loss: 21270258.0000 - val_mae: 4462.8335\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 10735599.0000 - mae: 2958.6348 - val_loss: 3440518.5000 - val_mae: 1550.8624\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1803370.5000 - mae: 992.0732 - val_loss: 1080687.8750 - val_mae: 764.0554\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1024369.6875 - mae: 742.3826 - val_loss: 915120.4375 - val_mae: 703.5654\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 894163.8750 - mae: 692.2249 - val_loss: 847595.4375 - val_mae: 671.7953\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 823638.6250 - mae: 661.5005 - val_loss: 793306.5625 - val_mae: 651.5692\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 777917.7500 - mae: 643.5609 - val_loss: 760192.0000 - val_mae: 635.1016\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 743878.0000 - mae: 629.9966 - val_loss: 736373.3750 - val_mae: 623.9449\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 718452.5625 - mae: 619.5453 - val_loss: 716457.4375 - val_mae: 614.8313\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 700078.4375 - mae: 612.1275 - val_loss: 699722.1250 - val_mae: 608.8324\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 686445.8125 - mae: 606.4043 - val_loss: 690679.8750 - val_mae: 607.7888\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 675368.7500 - mae: 602.1657 - val_loss: 679838.5000 - val_mae: 601.7041\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 666196.9375 - mae: 597.6902 - val_loss: 671242.0625 - val_mae: 597.1364\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 658346.0625 - mae: 593.9500 - val_loss: 669751.6250 - val_mae: 597.4219\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 653346.3125 - mae: 591.0981 - val_loss: 665442.8125 - val_mae: 592.4417\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 647563.5000 - mae: 587.8815 - val_loss: 657708.8750 - val_mae: 586.9810\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 641086.3750 - mae: 584.7126 - val_loss: 659008.5625 - val_mae: 583.3705\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 635824.8125 - mae: 580.2814 - val_loss: 650653.5625 - val_mae: 581.2618\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 629718.3125 - mae: 577.0079 - val_loss: 642817.5000 - val_mae: 577.0745\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 623126.3750 - mae: 573.8223 - val_loss: 638930.9375 - val_mae: 573.9510\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 615477.2500 - mae: 569.7248 - val_loss: 633088.3750 - val_mae: 570.0962\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 609786.2500 - mae: 566.8988 - val_loss: 627365.0625 - val_mae: 569.9919\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 605346.0625 - mae: 564.7755 - val_loss: 622533.0000 - val_mae: 570.2076\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602252.6875 - mae: 563.6697 - val_loss: 620615.6875 - val_mae: 570.2552\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599686.1875 - mae: 562.3557 - val_loss: 618502.2500 - val_mae: 566.3873\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 596589.6250 - mae: 560.2206 - val_loss: 613883.0625 - val_mae: 564.6755\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594797.3125 - mae: 558.8572 - val_loss: 609398.0625 - val_mae: 562.3367\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591913.3125 - mae: 557.6961 - val_loss: 609270.8750 - val_mae: 558.9514\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588866.3750 - mae: 555.7638 - val_loss: 610468.1875 - val_mae: 558.1780\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 587301.5000 - mae: 554.3294 - val_loss: 606821.4375 - val_mae: 558.7206\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584628.7500 - mae: 553.8735 - val_loss: 607265.3750 - val_mae: 554.8499\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584048.0625 - mae: 552.1703 - val_loss: 605075.7500 - val_mae: 555.8370\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 582753.3750 - mae: 551.6493 - val_loss: 603886.5000 - val_mae: 554.8657\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 581182.3125 - mae: 551.2435 - val_loss: 598864.9375 - val_mae: 554.4462\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 580272.6250 - mae: 550.0848 - val_loss: 601036.8125 - val_mae: 556.8783\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579866.0625 - mae: 550.0383 - val_loss: 601166.3750 - val_mae: 554.4388\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 578509.3750 - mae: 549.2772 - val_loss: 597570.3750 - val_mae: 550.1550\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 577833.4375 - mae: 548.6425 - val_loss: 600192.4375 - val_mae: 549.5987\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 577141.6875 - mae: 547.8134 - val_loss: 595530.9375 - val_mae: 554.5377\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576458.2500 - mae: 548.4578 - val_loss: 598875.5000 - val_mae: 551.7192\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576293.5625 - mae: 547.2891 - val_loss: 594574.5000 - val_mae: 550.9885\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575736.2500 - mae: 547.4062 - val_loss: 595926.3750 - val_mae: 550.7587\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575261.2500 - mae: 547.0291 - val_loss: 598398.2500 - val_mae: 552.8431\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575265.6875 - mae: 547.0234 - val_loss: 597774.3750 - val_mae: 549.7690\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574229.0000 - mae: 546.2026 - val_loss: 593631.0625 - val_mae: 551.6801\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574196.8750 - mae: 546.9630 - val_loss: 595839.5625 - val_mae: 549.0186\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 573450.6250 - mae: 546.3038 - val_loss: 592332.9375 - val_mae: 548.6855\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572958.9375 - mae: 545.7878 - val_loss: 589322.6250 - val_mae: 549.6761\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 573044.3125 - mae: 546.2142 - val_loss: 594937.0625 - val_mae: 548.2891\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 573018.8125 - mae: 545.5988 - val_loss: 594666.7500 - val_mae: 552.2318\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572143.9375 - mae: 545.5427 - val_loss: 594037.7500 - val_mae: 547.9571\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 571400.2500 - mae: 545.2053 - val_loss: 593048.8750 - val_mae: 550.3478\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 571743.6875 - mae: 545.3102 - val_loss: 594448.6250 - val_mae: 552.6032\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 571232.2500 - mae: 545.4402 - val_loss: 591597.4375 - val_mae: 548.7333\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570737.2500 - mae: 545.1410 - val_loss: 591551.8125 - val_mae: 547.4139\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570747.8125 - mae: 544.9352 - val_loss: 588435.6875 - val_mae: 547.3652\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570263.4375 - mae: 545.0294 - val_loss: 591419.3125 - val_mae: 547.8012\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 569800.6250 - mae: 544.7194 - val_loss: 589709.9375 - val_mae: 549.7861\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 569640.2500 - mae: 544.7080 - val_loss: 590743.1250 - val_mae: 549.5248\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 569307.9375 - mae: 544.2574 - val_loss: 593639.3750 - val_mae: 550.6272\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 568437.3125 - mae: 543.9709 - val_loss: 590733.2500 - val_mae: 547.4387\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 568596.4375 - mae: 543.8464 - val_loss: 590263.1875 - val_mae: 546.3959\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 568118.1875 - mae: 544.0934 - val_loss: 594778.1250 - val_mae: 548.4885\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 568342.5625 - mae: 543.6037 - val_loss: 587854.0625 - val_mae: 547.4203\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 567907.8125 - mae: 543.6604 - val_loss: 589078.1875 - val_mae: 548.8843\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 567497.3125 - mae: 543.7667 - val_loss: 588029.8125 - val_mae: 545.7878\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 567357.1250 - mae: 542.8943 - val_loss: 583085.0625 - val_mae: 547.1597\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 566733.2500 - mae: 543.0932 - val_loss: 592262.1875 - val_mae: 549.8148\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 566738.9375 - mae: 542.9158 - val_loss: 585641.4375 - val_mae: 546.5665\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 566644.9375 - mae: 543.2776 - val_loss: 586172.5000 - val_mae: 546.4104\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565991.3125 - mae: 542.9893 - val_loss: 586850.3125 - val_mae: 544.3532\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565931.3125 - mae: 542.4492 - val_loss: 590624.5625 - val_mae: 548.7044\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565746.0000 - mae: 542.6732 - val_loss: 587175.8125 - val_mae: 548.6251\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565216.6250 - mae: 542.6237 - val_loss: 589587.1875 - val_mae: 547.6824\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565317.6875 - mae: 542.1032 - val_loss: 587863.3750 - val_mae: 548.8329\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 564601.5000 - mae: 542.2578 - val_loss: 591192.3125 - val_mae: 551.6583\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 564646.8125 - mae: 542.1460 - val_loss: 590626.6250 - val_mae: 546.9733\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563922.8750 - mae: 541.5909 - val_loss: 585951.0625 - val_mae: 546.2203\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563653.5625 - mae: 541.8582 - val_loss: 586371.3125 - val_mae: 544.9832\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 562840.8750 - mae: 541.0895 - val_loss: 588454.7500 - val_mae: 546.0261\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563394.1875 - mae: 541.5684 - val_loss: 588206.1250 - val_mae: 545.5338\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 29608292.0000 - mae: 5247.1172 - val_loss: 14742534.0000 - val_mae: 3704.1956\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 5731757.0000 - mae: 2013.1179 - val_loss: 1458632.8750 - val_mae: 924.8422\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1004204.6875 - mae: 754.4317 - val_loss: 849243.5625 - val_mae: 682.9267\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 795302.2500 - mae: 662.2441 - val_loss: 775339.4375 - val_mae: 649.6575\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 746715.2500 - mae: 639.0575 - val_loss: 744239.6875 - val_mae: 637.2580\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 718110.9375 - mae: 626.4474 - val_loss: 714087.8750 - val_mae: 622.9589\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 695370.7500 - mae: 616.5193 - val_loss: 696703.0000 - val_mae: 614.1022\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 676694.4375 - mae: 607.5802 - val_loss: 677367.8125 - val_mae: 606.3671\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 663573.3750 - mae: 601.9626 - val_loss: 673652.0625 - val_mae: 602.0122\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 655479.6250 - mae: 597.4702 - val_loss: 666410.5000 - val_mae: 599.2426\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 650600.0625 - mae: 595.6035 - val_loss: 665291.8750 - val_mae: 597.5543\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 646598.3750 - mae: 592.4812 - val_loss: 663848.8125 - val_mae: 596.0570\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 643999.8125 - mae: 591.3909 - val_loss: 658351.5000 - val_mae: 595.6990\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 640655.3750 - mae: 589.8361 - val_loss: 657943.6875 - val_mae: 593.7993\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 635060.5625 - mae: 587.0809 - val_loss: 648096.5000 - val_mae: 585.4092\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 626213.2500 - mae: 581.7469 - val_loss: 641256.0000 - val_mae: 583.5473\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 621811.5625 - mae: 579.0405 - val_loss: 638657.4375 - val_mae: 580.4558\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 618911.1250 - mae: 577.6239 - val_loss: 634135.2500 - val_mae: 579.2787\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 616389.9375 - mae: 576.5292 - val_loss: 631844.8750 - val_mae: 578.4131\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 614621.1875 - mae: 575.5139 - val_loss: 636161.3750 - val_mae: 582.1735\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 612155.0000 - mae: 574.4664 - val_loss: 633011.8125 - val_mae: 581.5302\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610176.1875 - mae: 573.8074 - val_loss: 626029.1875 - val_mae: 576.1385\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 607839.8125 - mae: 572.6151 - val_loss: 625363.4375 - val_mae: 579.4069\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 605633.0000 - mae: 571.8073 - val_loss: 623561.0000 - val_mae: 573.7351\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 603673.1250 - mae: 570.5134 - val_loss: 619109.4375 - val_mae: 574.4193\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602433.1250 - mae: 569.9283 - val_loss: 621767.2500 - val_mae: 576.2090\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 601224.6250 - mae: 569.3341 - val_loss: 621977.4375 - val_mae: 577.3531\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599838.1875 - mae: 568.8643 - val_loss: 618248.9375 - val_mae: 571.0581\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 598994.7500 - mae: 567.7574 - val_loss: 618059.3125 - val_mae: 573.5647\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 597397.5000 - mae: 567.6226 - val_loss: 614285.4375 - val_mae: 567.3430\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 596185.2500 - mae: 566.8264 - val_loss: 613753.3750 - val_mae: 572.1567\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595505.6250 - mae: 566.1534 - val_loss: 611701.3750 - val_mae: 566.9305\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594422.0000 - mae: 565.9454 - val_loss: 610779.7500 - val_mae: 565.5723\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593149.5625 - mae: 564.3245 - val_loss: 605491.7500 - val_mae: 568.0192\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 589847.9375 - mae: 562.6210 - val_loss: 603892.6875 - val_mae: 565.8797\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 587988.9375 - mae: 561.5057 - val_loss: 603714.4375 - val_mae: 563.2570\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 587276.0625 - mae: 560.7875 - val_loss: 601038.1875 - val_mae: 563.2740\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584629.6250 - mae: 559.3394 - val_loss: 595066.6250 - val_mae: 561.3688\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 583714.0625 - mae: 558.6390 - val_loss: 597828.6250 - val_mae: 560.3297\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 581991.3125 - mae: 557.4936 - val_loss: 597465.3125 - val_mae: 564.9399\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 580226.3750 - mae: 557.7931 - val_loss: 599478.6875 - val_mae: 555.4922\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579731.8125 - mae: 556.4323 - val_loss: 594680.5000 - val_mae: 559.3749\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 578526.6875 - mae: 555.6227 - val_loss: 590600.5000 - val_mae: 557.5509\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 577008.1250 - mae: 554.5374 - val_loss: 593115.6875 - val_mae: 563.5070\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575749.1250 - mae: 554.7735 - val_loss: 587656.5625 - val_mae: 559.9984\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574521.7500 - mae: 553.7442 - val_loss: 590199.8125 - val_mae: 560.3277\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 574140.6250 - mae: 553.7949 - val_loss: 585516.9375 - val_mae: 553.8688\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572155.6250 - mae: 552.3456 - val_loss: 583347.4375 - val_mae: 553.7923\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570768.1250 - mae: 551.1978 - val_loss: 587681.1875 - val_mae: 556.7094\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 569569.5625 - mae: 551.1381 - val_loss: 582380.9375 - val_mae: 555.0042\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 568642.2500 - mae: 550.6103 - val_loss: 583566.6250 - val_mae: 551.0203\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 566923.1250 - mae: 549.0627 - val_loss: 580635.8125 - val_mae: 549.4474\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565807.7500 - mae: 548.1025 - val_loss: 579037.6875 - val_mae: 551.0907\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565451.4375 - mae: 548.0131 - val_loss: 579549.1250 - val_mae: 551.9361\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 564232.2500 - mae: 547.3194 - val_loss: 580250.5000 - val_mae: 553.3940\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563558.1250 - mae: 547.1069 - val_loss: 577670.3750 - val_mae: 550.7944\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563330.0625 - mae: 546.7234 - val_loss: 579123.7500 - val_mae: 548.7304\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 562279.9375 - mae: 546.0952 - val_loss: 577822.6875 - val_mae: 550.4057\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 562129.8125 - mae: 545.8798 - val_loss: 573780.0625 - val_mae: 548.6031\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 561640.6875 - mae: 545.7764 - val_loss: 576119.8750 - val_mae: 549.9148\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 561461.6875 - mae: 545.5713 - val_loss: 573526.0000 - val_mae: 546.7594\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560710.5625 - mae: 545.1203 - val_loss: 572942.6875 - val_mae: 545.3953\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 559907.3750 - mae: 544.9672 - val_loss: 580420.3125 - val_mae: 547.7475\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560093.1250 - mae: 544.7726 - val_loss: 575491.7500 - val_mae: 546.0520\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 559110.6875 - mae: 544.1079 - val_loss: 573950.5625 - val_mae: 545.6824\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 559193.5000 - mae: 544.4087 - val_loss: 572851.6875 - val_mae: 545.0334\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558253.8750 - mae: 543.2988 - val_loss: 570133.3750 - val_mae: 543.9417\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558099.0625 - mae: 543.7458 - val_loss: 574240.2500 - val_mae: 546.3865\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557060.1875 - mae: 543.0040 - val_loss: 570217.5000 - val_mae: 544.9249\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556647.3125 - mae: 542.7811 - val_loss: 571943.2500 - val_mae: 546.5287\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555275.1875 - mae: 541.8770 - val_loss: 572366.2500 - val_mae: 543.1272\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555327.1875 - mae: 541.2972 - val_loss: 577074.4375 - val_mae: 552.4795\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554806.6875 - mae: 541.7867 - val_loss: 570240.6875 - val_mae: 543.7026\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554755.6250 - mae: 541.2360 - val_loss: 570942.3125 - val_mae: 546.4658\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554082.1875 - mae: 541.2548 - val_loss: 568117.0000 - val_mae: 543.9824\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553309.3750 - mae: 540.8289 - val_loss: 566906.8750 - val_mae: 542.2183\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552257.4375 - mae: 540.5278 - val_loss: 569971.3750 - val_mae: 543.3716\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551901.8750 - mae: 539.9136 - val_loss: 568549.9375 - val_mae: 545.3093\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551821.5000 - mae: 540.3419 - val_loss: 565369.8750 - val_mae: 540.7418\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550693.1875 - mae: 539.7255 - val_loss: 567559.4375 - val_mae: 540.3536\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550592.0625 - mae: 539.5775 - val_loss: 567156.8750 - val_mae: 541.9825\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549569.7500 - mae: 538.9891 - val_loss: 563308.7500 - val_mae: 539.2950\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549570.8750 - mae: 538.5990 - val_loss: 564469.0000 - val_mae: 540.6307\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549232.8125 - mae: 538.5093 - val_loss: 563294.0000 - val_mae: 541.6471\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549200.2500 - mae: 538.6567 - val_loss: 564265.6250 - val_mae: 542.5400\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548797.5625 - mae: 538.6719 - val_loss: 564855.0000 - val_mae: 540.2517\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548625.6250 - mae: 538.6470 - val_loss: 566077.7500 - val_mae: 540.7469\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548953.0625 - mae: 538.5828 - val_loss: 564167.5000 - val_mae: 540.9697\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548748.6875 - mae: 538.2380 - val_loss: 561737.3750 - val_mae: 538.5051\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548342.3125 - mae: 538.3059 - val_loss: 565086.0000 - val_mae: 537.9559\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547743.4375 - mae: 537.9505 - val_loss: 564755.8125 - val_mae: 544.3918\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548173.5625 - mae: 538.1361 - val_loss: 563481.9375 - val_mae: 542.1948\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547690.0000 - mae: 538.1252 - val_loss: 565286.5000 - val_mae: 540.8506\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547958.1875 - mae: 537.8133 - val_loss: 562094.5000 - val_mae: 541.5943\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547496.6250 - mae: 537.8381 - val_loss: 564624.8125 - val_mae: 538.3333\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546925.3125 - mae: 536.9678 - val_loss: 562616.8750 - val_mae: 539.4984\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546793.5000 - mae: 536.8127 - val_loss: 561792.2500 - val_mae: 541.3387\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546825.4375 - mae: 537.4646 - val_loss: 567580.8125 - val_mae: 542.2217\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546511.1875 - mae: 537.5065 - val_loss: 563376.4375 - val_mae: 536.3049\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546000.6875 - mae: 536.4150 - val_loss: 566574.4375 - val_mae: 544.4444\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545726.8125 - mae: 536.1183 - val_loss: 560577.0000 - val_mae: 539.3494\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545500.4375 - mae: 536.4848 - val_loss: 562516.2500 - val_mae: 539.0255\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545762.0625 - mae: 536.9330 - val_loss: 562899.0000 - val_mae: 537.6735\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545316.2500 - mae: 536.0219 - val_loss: 562361.3125 - val_mae: 540.7143\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544940.1875 - mae: 536.2355 - val_loss: 561634.1875 - val_mae: 540.6099\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545032.5000 - mae: 535.8027 - val_loss: 562411.8750 - val_mae: 540.0719\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544302.3125 - mae: 535.5435 - val_loss: 563740.0000 - val_mae: 544.8461\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544563.1250 - mae: 536.0020 - val_loss: 564230.3125 - val_mae: 541.4799\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544980.5625 - mae: 535.4838 - val_loss: 561716.4375 - val_mae: 542.8303\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 37312884.0000 - mae: 5950.9111 - val_loss: 34489944.0000 - val_mae: 5721.4658\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 29724716.0000 - mae: 5283.4551 - val_loss: 23989320.0000 - val_mae: 4737.3008\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 18447108.0000 - mae: 4094.9854 - val_loss: 12711120.0000 - val_mae: 3364.9502\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 8269610.0000 - mae: 2598.1375 - val_loss: 4609646.5000 - val_mae: 1858.5077\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2869298.7500 - mae: 1335.9076 - val_loss: 1698888.0000 - val_mae: 952.4483\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1318854.3750 - mae: 818.8184 - val_loss: 1097104.8750 - val_mae: 740.3143\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1016671.8750 - mae: 720.3831 - val_loss: 975413.3750 - val_mae: 700.7651\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 928295.8750 - mae: 693.7057 - val_loss: 918779.0000 - val_mae: 682.7700\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 875914.6875 - mae: 676.5340 - val_loss: 878299.6250 - val_mae: 669.0310\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 835153.4375 - mae: 660.3805 - val_loss: 839345.4375 - val_mae: 658.3209\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 800298.8125 - mae: 647.6949 - val_loss: 804779.0625 - val_mae: 645.7285\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 769652.0000 - mae: 635.7290 - val_loss: 772999.3125 - val_mae: 632.5549\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 742565.8125 - mae: 624.5782 - val_loss: 745702.9375 - val_mae: 621.4852\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 719496.1875 - mae: 616.0629 - val_loss: 725567.0625 - val_mae: 611.6268\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 701771.3750 - mae: 607.7209 - val_loss: 705868.2500 - val_mae: 605.6022\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 687504.8125 - mae: 602.3976 - val_loss: 690306.1250 - val_mae: 599.9035\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 675218.2500 - mae: 597.0034 - val_loss: 679847.6250 - val_mae: 595.9335\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 664880.0625 - mae: 592.3208 - val_loss: 668696.5000 - val_mae: 589.6527\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 656704.4375 - mae: 587.8507 - val_loss: 658215.7500 - val_mae: 586.1719\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 649915.3125 - mae: 585.1163 - val_loss: 651140.6875 - val_mae: 584.2205\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 645041.7500 - mae: 583.4907 - val_loss: 645434.5000 - val_mae: 582.0266\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 640848.0625 - mae: 581.3379 - val_loss: 639435.2500 - val_mae: 581.2470\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 637267.1875 - mae: 580.1473 - val_loss: 637458.9375 - val_mae: 579.0875\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 633908.0000 - mae: 578.5466 - val_loss: 634014.3750 - val_mae: 575.9308\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 631213.0000 - mae: 576.8326 - val_loss: 631193.0625 - val_mae: 577.6497\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 627923.0625 - mae: 575.9113 - val_loss: 629060.8750 - val_mae: 577.3438\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625750.3125 - mae: 575.3481 - val_loss: 627666.8750 - val_mae: 573.5469\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 622744.9375 - mae: 574.1229 - val_loss: 623291.0000 - val_mae: 571.8260\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 620476.6875 - mae: 572.4484 - val_loss: 622392.2500 - val_mae: 573.1767\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617931.8125 - mae: 572.1019 - val_loss: 621504.6250 - val_mae: 571.3001\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615374.4375 - mae: 570.9578 - val_loss: 619041.0625 - val_mae: 570.7075\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613370.3125 - mae: 570.2142 - val_loss: 616975.4375 - val_mae: 569.1585\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611202.7500 - mae: 569.3398 - val_loss: 616159.6875 - val_mae: 569.4193\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609349.9375 - mae: 568.1732 - val_loss: 613967.1250 - val_mae: 570.2642\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607527.9375 - mae: 567.6973 - val_loss: 612223.5625 - val_mae: 568.7756\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606001.8125 - mae: 567.7448 - val_loss: 613872.0000 - val_mae: 567.3177\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604154.6875 - mae: 566.4974 - val_loss: 612607.0625 - val_mae: 566.6467\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602674.1875 - mae: 566.0345 - val_loss: 609405.3125 - val_mae: 565.0651\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601186.3750 - mae: 565.4348 - val_loss: 607546.8750 - val_mae: 565.8646\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600137.5000 - mae: 565.0806 - val_loss: 610073.8125 - val_mae: 565.8431\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598542.3750 - mae: 564.5003 - val_loss: 608621.1875 - val_mae: 564.3429\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597951.2500 - mae: 563.6722 - val_loss: 608841.3750 - val_mae: 565.7365\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596604.6250 - mae: 563.2554 - val_loss: 607286.0000 - val_mae: 566.1089\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595571.2500 - mae: 563.2874 - val_loss: 606529.3750 - val_mae: 563.9698\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594199.1250 - mae: 561.8802 - val_loss: 606283.3750 - val_mae: 564.9676\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593177.8750 - mae: 561.9117 - val_loss: 606078.0625 - val_mae: 564.9732\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592010.9375 - mae: 561.3796 - val_loss: 606524.3125 - val_mae: 563.5096\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590837.1250 - mae: 560.6617 - val_loss: 606366.1875 - val_mae: 565.6265\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589848.7500 - mae: 560.2731 - val_loss: 606164.4375 - val_mae: 563.4394\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588605.1875 - mae: 559.1931 - val_loss: 605003.0000 - val_mae: 565.4570\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588138.5000 - mae: 559.8448 - val_loss: 603587.5625 - val_mae: 561.9492\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586941.1250 - mae: 558.6459 - val_loss: 601744.8750 - val_mae: 563.1038\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586045.7500 - mae: 558.3465 - val_loss: 602328.0000 - val_mae: 563.0526\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585215.9375 - mae: 557.8795 - val_loss: 601387.0000 - val_mae: 561.3827\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584240.6875 - mae: 557.8738 - val_loss: 600150.1875 - val_mae: 559.0005\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583301.6875 - mae: 556.6688 - val_loss: 598394.0000 - val_mae: 559.0062\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581997.3125 - mae: 556.1890 - val_loss: 599363.1875 - val_mae: 561.5886\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580951.6875 - mae: 555.5205 - val_loss: 601328.1875 - val_mae: 560.2183\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579559.8750 - mae: 555.0360 - val_loss: 598410.2500 - val_mae: 558.3137\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578480.5000 - mae: 553.8105 - val_loss: 596491.1875 - val_mae: 559.1860\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576854.0000 - mae: 553.1603 - val_loss: 596941.0000 - val_mae: 555.3259\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576253.4375 - mae: 552.2352 - val_loss: 594190.4375 - val_mae: 555.7476\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574989.1875 - mae: 551.3311 - val_loss: 595725.0000 - val_mae: 555.3135\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574642.5625 - mae: 551.1274 - val_loss: 592187.5625 - val_mae: 554.8110\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573771.5000 - mae: 550.5803 - val_loss: 592882.0000 - val_mae: 553.5065\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572908.3750 - mae: 549.8492 - val_loss: 591947.0625 - val_mae: 555.1580\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572700.8125 - mae: 549.8817 - val_loss: 594004.4375 - val_mae: 554.2582\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571582.8125 - mae: 548.9857 - val_loss: 593468.3750 - val_mae: 555.8849\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571393.3125 - mae: 549.1119 - val_loss: 591438.1250 - val_mae: 552.9713\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570993.3125 - mae: 548.9487 - val_loss: 591737.9375 - val_mae: 552.8393\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570029.3125 - mae: 548.4312 - val_loss: 591727.0625 - val_mae: 553.5436\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569233.7500 - mae: 547.4590 - val_loss: 589497.5000 - val_mae: 553.9171\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568860.0000 - mae: 547.8695 - val_loss: 591434.7500 - val_mae: 552.3478\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568025.0000 - mae: 547.2501 - val_loss: 589076.3750 - val_mae: 549.7482\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567831.0000 - mae: 547.1927 - val_loss: 589918.5625 - val_mae: 549.8088\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567420.8125 - mae: 546.6590 - val_loss: 591087.8750 - val_mae: 551.8698\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567045.1875 - mae: 546.7723 - val_loss: 588733.4375 - val_mae: 549.0952\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566630.6875 - mae: 546.5724 - val_loss: 589397.4375 - val_mae: 549.7450\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566112.3125 - mae: 545.8064 - val_loss: 586878.6250 - val_mae: 550.4451\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565640.1250 - mae: 546.0486 - val_loss: 587484.3750 - val_mae: 549.5220\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565188.4375 - mae: 545.6025 - val_loss: 587655.7500 - val_mae: 549.4773\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564748.1250 - mae: 545.3066 - val_loss: 586092.6875 - val_mae: 548.9543\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564109.6875 - mae: 544.8747 - val_loss: 586778.7500 - val_mae: 549.8876\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563538.3750 - mae: 545.0455 - val_loss: 584038.6250 - val_mae: 549.8887\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562622.6875 - mae: 544.7000 - val_loss: 584290.7500 - val_mae: 548.5657\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561540.3750 - mae: 543.8242 - val_loss: 584216.8750 - val_mae: 547.6630\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560265.3750 - mae: 543.3207 - val_loss: 588820.3750 - val_mae: 547.9105\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560104.1875 - mae: 543.2814 - val_loss: 583479.0000 - val_mae: 547.2059\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559236.0625 - mae: 542.7963 - val_loss: 584780.3125 - val_mae: 546.5912\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558645.3750 - mae: 542.3300 - val_loss: 580406.1875 - val_mae: 545.8709\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557628.1875 - mae: 541.6325 - val_loss: 581055.7500 - val_mae: 547.5019\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556475.9375 - mae: 541.6163 - val_loss: 584793.6875 - val_mae: 548.5282\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555935.8750 - mae: 541.5761 - val_loss: 581767.0000 - val_mae: 547.4423\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555340.3125 - mae: 541.0552 - val_loss: 581944.5000 - val_mae: 545.6014\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554532.3125 - mae: 540.4158 - val_loss: 580620.6875 - val_mae: 546.6800\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553485.8125 - mae: 539.5328 - val_loss: 580244.0625 - val_mae: 547.2119\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553385.0625 - mae: 540.5087 - val_loss: 580731.1250 - val_mae: 545.1875\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552747.9375 - mae: 539.9537 - val_loss: 579872.4375 - val_mae: 544.2238\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552196.3750 - mae: 539.4371 - val_loss: 579110.5625 - val_mae: 544.2664\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551905.6875 - mae: 539.1845 - val_loss: 579104.5000 - val_mae: 545.3531\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551384.8125 - mae: 538.8037 - val_loss: 579815.5625 - val_mae: 546.1068\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551211.4375 - mae: 538.5917 - val_loss: 577167.7500 - val_mae: 546.2849\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550639.7500 - mae: 538.5375 - val_loss: 577484.0625 - val_mae: 548.1354\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550463.1250 - mae: 539.2388 - val_loss: 577431.4375 - val_mae: 544.8121\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549748.1875 - mae: 538.0784 - val_loss: 578646.0000 - val_mae: 542.1018\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549633.0000 - mae: 537.7377 - val_loss: 575210.8750 - val_mae: 543.4243\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549344.2500 - mae: 537.5364 - val_loss: 577380.8750 - val_mae: 544.8152\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549300.2500 - mae: 537.9316 - val_loss: 576060.1875 - val_mae: 542.6080\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549092.7500 - mae: 537.3906 - val_loss: 575720.7500 - val_mae: 544.1011\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548563.0625 - mae: 537.4478 - val_loss: 576991.0625 - val_mae: 545.6309\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548623.7500 - mae: 537.6010 - val_loss: 575877.6250 - val_mae: 543.9323\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548133.8750 - mae: 537.2353 - val_loss: 574290.6250 - val_mae: 543.0496\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547792.8750 - mae: 536.9466 - val_loss: 574535.2500 - val_mae: 542.0923\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547798.0000 - mae: 536.9251 - val_loss: 577103.1250 - val_mae: 543.3682\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547194.1250 - mae: 536.7829 - val_loss: 577392.5625 - val_mae: 546.9710\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547414.3125 - mae: 537.1280 - val_loss: 574601.5000 - val_mae: 542.0726\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546916.0625 - mae: 536.6509 - val_loss: 575778.9375 - val_mae: 541.9818\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546710.4375 - mae: 536.5720 - val_loss: 573810.5625 - val_mae: 541.9717\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546478.5625 - mae: 536.0946 - val_loss: 574074.3125 - val_mae: 542.0850\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546507.6875 - mae: 536.0547 - val_loss: 575016.5000 - val_mae: 543.3945\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546268.5000 - mae: 536.6557 - val_loss: 575368.5000 - val_mae: 542.2706\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545926.8750 - mae: 535.8691 - val_loss: 575621.1875 - val_mae: 542.9672\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546032.5000 - mae: 536.2714 - val_loss: 574358.5000 - val_mae: 542.0883\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545922.2500 - mae: 535.8647 - val_loss: 575917.0625 - val_mae: 544.4954\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545703.3125 - mae: 535.7756 - val_loss: 574744.0625 - val_mae: 541.7933\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545404.6875 - mae: 535.0978 - val_loss: 573868.2500 - val_mae: 544.1083\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545303.1250 - mae: 535.4858 - val_loss: 572575.1875 - val_mae: 541.2714\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544891.3125 - mae: 535.1385 - val_loss: 575256.8750 - val_mae: 542.3566\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544983.1875 - mae: 535.1231 - val_loss: 573454.2500 - val_mae: 541.9033\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545051.0625 - mae: 535.3881 - val_loss: 572844.1875 - val_mae: 542.8842\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544695.6250 - mae: 535.4053 - val_loss: 571674.5000 - val_mae: 541.5619\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544499.0000 - mae: 535.0924 - val_loss: 573946.2500 - val_mae: 541.0469\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544335.4375 - mae: 534.8352 - val_loss: 572679.2500 - val_mae: 541.4537\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544200.8125 - mae: 534.6365 - val_loss: 571958.2500 - val_mae: 542.3516\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544104.5000 - mae: 534.8427 - val_loss: 573037.7500 - val_mae: 542.5278\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544109.0000 - mae: 534.8727 - val_loss: 571562.8125 - val_mae: 541.3112\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543956.0000 - mae: 534.2801 - val_loss: 571899.8750 - val_mae: 544.2184\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543728.3125 - mae: 534.7183 - val_loss: 573223.1875 - val_mae: 542.0613\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543638.6875 - mae: 534.3682 - val_loss: 573115.1875 - val_mae: 541.1211\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543383.9375 - mae: 534.7338 - val_loss: 573639.7500 - val_mae: 539.7816\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543497.6875 - mae: 533.8966 - val_loss: 571042.9375 - val_mae: 539.9608\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543243.0625 - mae: 533.6426 - val_loss: 572111.1875 - val_mae: 543.8558\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543214.3750 - mae: 533.9886 - val_loss: 571840.4375 - val_mae: 541.8491\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543167.9375 - mae: 534.0318 - val_loss: 572664.8125 - val_mae: 540.6638\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542849.1250 - mae: 533.7252 - val_loss: 569553.3125 - val_mae: 539.4872\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543037.1875 - mae: 533.9578 - val_loss: 573453.1250 - val_mae: 541.4383\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542678.6875 - mae: 533.5337 - val_loss: 569931.1250 - val_mae: 540.4720\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542972.0000 - mae: 534.2952 - val_loss: 572738.9375 - val_mae: 540.4724\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542536.4375 - mae: 533.4628 - val_loss: 572271.8750 - val_mae: 540.9015\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542473.8125 - mae: 533.5420 - val_loss: 572572.3125 - val_mae: 540.3625\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542412.8750 - mae: 533.4258 - val_loss: 572611.0625 - val_mae: 540.9884\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542416.2500 - mae: 533.9255 - val_loss: 570550.7500 - val_mae: 539.1750\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542049.3125 - mae: 533.5629 - val_loss: 573432.3125 - val_mae: 538.5165\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542085.3125 - mae: 533.4283 - val_loss: 573800.0625 - val_mae: 539.4803\n",
      "Epoch 155/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541851.8750 - mae: 533.2288 - val_loss: 574128.2500 - val_mae: 539.0421\n",
      "Epoch 156/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541535.2500 - mae: 533.1360 - val_loss: 570450.9375 - val_mae: 539.0084\n",
      "Epoch 157/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541980.8125 - mae: 533.0197 - val_loss: 569164.2500 - val_mae: 540.7648\n",
      "Epoch 158/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541889.1875 - mae: 533.4000 - val_loss: 569016.1250 - val_mae: 539.7589\n",
      "Epoch 159/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541806.7500 - mae: 533.0600 - val_loss: 570856.6250 - val_mae: 541.0186\n",
      "Epoch 160/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541642.8750 - mae: 532.9980 - val_loss: 571766.1875 - val_mae: 540.7121\n",
      "Epoch 161/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541669.6250 - mae: 533.1754 - val_loss: 571509.7500 - val_mae: 540.5926\n",
      "Epoch 162/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541541.2500 - mae: 533.2455 - val_loss: 571131.9375 - val_mae: 541.0118\n",
      "Epoch 163/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541343.6875 - mae: 532.8389 - val_loss: 570919.8750 - val_mae: 541.8540\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 36060344.0000 - mae: 5851.0903 - val_loss: 30344204.0000 - val_mae: 5379.8906\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 22104502.0000 - mae: 4545.6899 - val_loss: 13888584.0000 - val_mae: 3587.0496\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 8236393.0000 - mae: 2622.3318 - val_loss: 4014935.7500 - val_mae: 1739.2031\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2298942.5000 - mae: 1199.3318 - val_loss: 1304739.6250 - val_mae: 849.8661\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1060233.7500 - mae: 750.4624 - val_loss: 923961.8125 - val_mae: 699.8641\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 887550.2500 - mae: 691.5015 - val_loss: 850177.4375 - val_mae: 677.7521\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 830718.3750 - mae: 673.6086 - val_loss: 806535.8750 - val_mae: 661.1403\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 789827.6250 - mae: 657.7034 - val_loss: 769667.5000 - val_mae: 649.0847\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 753907.2500 - mae: 644.9430 - val_loss: 738786.8750 - val_mae: 635.8153\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 723667.3750 - mae: 632.1819 - val_loss: 710072.4375 - val_mae: 625.7452\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 698219.1250 - mae: 621.9835 - val_loss: 692230.2500 - val_mae: 614.9131\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 678760.0000 - mae: 611.4506 - val_loss: 679967.8125 - val_mae: 610.2914\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 663982.3750 - mae: 604.1567 - val_loss: 666631.5000 - val_mae: 601.0397\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 652966.2500 - mae: 597.7380 - val_loss: 659550.7500 - val_mae: 593.9435\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 645170.2500 - mae: 592.6700 - val_loss: 653396.4375 - val_mae: 590.1813\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 638354.3750 - mae: 588.1351 - val_loss: 648888.3750 - val_mae: 590.4560\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 633342.2500 - mae: 585.3576 - val_loss: 648132.8125 - val_mae: 588.5764\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 629780.7500 - mae: 583.3878 - val_loss: 641136.6875 - val_mae: 582.4349\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 626356.1250 - mae: 580.6964 - val_loss: 638152.5000 - val_mae: 584.8182\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 623188.8125 - mae: 579.1357 - val_loss: 635345.1875 - val_mae: 582.8383\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621314.9375 - mae: 578.4762 - val_loss: 634025.3750 - val_mae: 581.1761\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619495.8750 - mae: 576.7885 - val_loss: 638220.7500 - val_mae: 584.8140\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617704.7500 - mae: 576.4244 - val_loss: 632793.6875 - val_mae: 578.3387\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616125.9375 - mae: 574.9719 - val_loss: 630435.2500 - val_mae: 577.4323\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615057.5625 - mae: 574.8270 - val_loss: 630319.4375 - val_mae: 578.8658\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613235.2500 - mae: 573.6378 - val_loss: 629795.5625 - val_mae: 578.0346\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612307.6250 - mae: 572.9015 - val_loss: 628566.7500 - val_mae: 578.1144\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611416.1875 - mae: 572.6876 - val_loss: 627995.0000 - val_mae: 578.6660\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 610775.0625 - mae: 572.4427 - val_loss: 627286.0625 - val_mae: 576.2983\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609940.5000 - mae: 571.7072 - val_loss: 627331.1250 - val_mae: 576.1768\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608997.8750 - mae: 570.9625 - val_loss: 624895.1250 - val_mae: 575.1851\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607679.1875 - mae: 570.9010 - val_loss: 625758.4375 - val_mae: 575.7272\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607288.2500 - mae: 570.3136 - val_loss: 625115.3750 - val_mae: 573.1038\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606004.8750 - mae: 569.5135 - val_loss: 621986.6875 - val_mae: 573.3696\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605125.8125 - mae: 569.0859 - val_loss: 621463.4375 - val_mae: 571.6360\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604051.1875 - mae: 568.4290 - val_loss: 621975.1875 - val_mae: 572.9684\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603422.1250 - mae: 567.4156 - val_loss: 622769.0625 - val_mae: 573.8840\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601740.4375 - mae: 566.7121 - val_loss: 620912.8125 - val_mae: 575.1302\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601867.5000 - mae: 567.0772 - val_loss: 619127.0000 - val_mae: 573.9564\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601057.3125 - mae: 566.2338 - val_loss: 619053.5000 - val_mae: 572.3748\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599982.2500 - mae: 565.6970 - val_loss: 618057.6250 - val_mae: 570.8707\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598464.6250 - mae: 564.2259 - val_loss: 622205.5625 - val_mae: 579.5989\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597962.8750 - mae: 564.9800 - val_loss: 618062.3750 - val_mae: 571.7904\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597329.0000 - mae: 564.0593 - val_loss: 616431.6250 - val_mae: 570.5774\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596820.3125 - mae: 563.3304 - val_loss: 616906.4375 - val_mae: 571.0734\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596431.1250 - mae: 563.4334 - val_loss: 613551.1875 - val_mae: 567.6249\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595788.8125 - mae: 562.8431 - val_loss: 618467.9375 - val_mae: 574.2740\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595734.6250 - mae: 563.1079 - val_loss: 614435.5625 - val_mae: 569.8987\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594403.5000 - mae: 562.5335 - val_loss: 614494.6875 - val_mae: 571.0796\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594490.7500 - mae: 562.1443 - val_loss: 613233.0000 - val_mae: 571.0980\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593624.7500 - mae: 562.0149 - val_loss: 616817.4375 - val_mae: 572.3214\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592993.1875 - mae: 561.8745 - val_loss: 612115.8750 - val_mae: 569.3561\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592245.5000 - mae: 561.7328 - val_loss: 608724.6875 - val_mae: 565.2989\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591368.7500 - mae: 560.3205 - val_loss: 611627.2500 - val_mae: 570.6288\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591205.3125 - mae: 561.0417 - val_loss: 610604.3125 - val_mae: 567.7643\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590058.5625 - mae: 559.7141 - val_loss: 609781.2500 - val_mae: 568.3683\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589872.5000 - mae: 560.4559 - val_loss: 606903.3125 - val_mae: 563.3309\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588991.6875 - mae: 558.6705 - val_loss: 608138.2500 - val_mae: 567.2452\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588672.3125 - mae: 558.8477 - val_loss: 606823.1250 - val_mae: 567.5644\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588016.5000 - mae: 558.8182 - val_loss: 608309.9375 - val_mae: 566.2382\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587011.2500 - mae: 558.6382 - val_loss: 606021.0000 - val_mae: 562.5176\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586072.3125 - mae: 557.2231 - val_loss: 607509.8125 - val_mae: 564.4561\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586396.0625 - mae: 557.3320 - val_loss: 607323.6875 - val_mae: 567.7881\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584985.2500 - mae: 556.7770 - val_loss: 609293.3125 - val_mae: 569.4556\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584484.7500 - mae: 556.8344 - val_loss: 605136.3125 - val_mae: 564.3854\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584534.6875 - mae: 556.5205 - val_loss: 603139.1250 - val_mae: 564.4589\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584237.3750 - mae: 556.2089 - val_loss: 603300.8125 - val_mae: 561.3534\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583203.0625 - mae: 555.7105 - val_loss: 604072.2500 - val_mae: 565.2913\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583434.0000 - mae: 555.8019 - val_loss: 603197.8750 - val_mae: 564.6266\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582781.9375 - mae: 555.8052 - val_loss: 603269.8125 - val_mae: 562.2246\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582430.8125 - mae: 554.8673 - val_loss: 603269.3750 - val_mae: 565.6498\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582200.4375 - mae: 555.9044 - val_loss: 602709.8750 - val_mae: 563.2953\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582114.2500 - mae: 555.5744 - val_loss: 602662.1250 - val_mae: 562.1108\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581307.6875 - mae: 554.6214 - val_loss: 605096.0000 - val_mae: 567.2805\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581323.4375 - mae: 555.2967 - val_loss: 603351.5000 - val_mae: 565.4183\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581217.7500 - mae: 555.2385 - val_loss: 604043.0625 - val_mae: 562.4736\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581068.8125 - mae: 554.2856 - val_loss: 602068.8750 - val_mae: 565.6792\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38278796.0000 - mae: 6029.2812 - val_loss: 37362816.0000 - val_mae: 5960.5732\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 35492184.0000 - mae: 5801.1099 - val_loss: 32711242.0000 - val_mae: 5574.7510\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 29598936.0000 - mae: 5289.8506 - val_loss: 25902556.0000 - val_mae: 4952.8999\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 22402644.0000 - mae: 4582.6260 - val_loss: 18611864.0000 - val_mae: 4174.9575\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 15426847.0000 - mae: 3760.0852 - val_loss: 12162436.0000 - val_mae: 3324.1406\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 9716607.0000 - mae: 2909.2329 - val_loss: 7318857.0000 - val_mae: 2487.0627\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5724575.5000 - mae: 2117.5366 - val_loss: 4206647.0000 - val_mae: 1765.8131\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3333169.7500 - mae: 1512.1747 - val_loss: 2490109.2500 - val_mae: 1285.6715\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2084517.5000 - mae: 1144.4624 - val_loss: 1661919.8750 - val_mae: 1011.4987\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1501028.7500 - mae: 937.9540 - val_loss: 1296307.0000 - val_mae: 868.6419\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1237976.3750 - mae: 836.3242 - val_loss: 1133802.6250 - val_mae: 801.8865\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1109645.3750 - mae: 788.8043 - val_loss: 1048535.0000 - val_mae: 768.0574\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1033011.7500 - mae: 760.7675 - val_loss: 993527.1250 - val_mae: 747.1084\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 977480.9375 - mae: 740.7874 - val_loss: 950572.5625 - val_mae: 729.6937\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 932361.7500 - mae: 723.4814 - val_loss: 914040.8125 - val_mae: 715.0805\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 894677.0625 - mae: 708.3796 - val_loss: 882781.6250 - val_mae: 701.4212\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 862806.5625 - mae: 694.3762 - val_loss: 855915.1250 - val_mae: 689.6575\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 835617.0000 - mae: 682.6769 - val_loss: 833221.5000 - val_mae: 679.3170\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 812742.6250 - mae: 672.0640 - val_loss: 813067.5625 - val_mae: 668.5898\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 792262.7500 - mae: 661.6385 - val_loss: 795143.4375 - val_mae: 659.9788\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 774251.3125 - mae: 653.4321 - val_loss: 780081.9375 - val_mae: 650.6933\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 757837.5625 - mae: 643.0961 - val_loss: 765208.6875 - val_mae: 643.2330\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 744426.5000 - mae: 636.0701 - val_loss: 754512.5625 - val_mae: 637.2763\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 733339.5625 - mae: 629.9969 - val_loss: 743552.0000 - val_mae: 630.1076\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 723765.6875 - mae: 624.1470 - val_loss: 735216.9375 - val_mae: 625.3007\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 716135.0000 - mae: 619.3793 - val_loss: 728291.0625 - val_mae: 619.7877\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 708789.5625 - mae: 615.2965 - val_loss: 722909.2500 - val_mae: 615.5024\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 703322.3125 - mae: 611.3050 - val_loss: 717793.7500 - val_mae: 612.4792\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 697969.6875 - mae: 608.5865 - val_loss: 712938.1875 - val_mae: 609.1251\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 693829.4375 - mae: 605.2225 - val_loss: 708115.7500 - val_mae: 608.2238\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 689865.4375 - mae: 603.6447 - val_loss: 705678.8750 - val_mae: 604.3761\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 686152.0000 - mae: 600.7110 - val_loss: 702596.3750 - val_mae: 603.7977\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 683010.8750 - mae: 598.9728 - val_loss: 699777.1250 - val_mae: 602.4221\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 680023.9375 - mae: 597.1396 - val_loss: 697073.1875 - val_mae: 600.9184\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 677364.0000 - mae: 596.0500 - val_loss: 695571.7500 - val_mae: 599.9873\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 674883.1875 - mae: 594.3496 - val_loss: 693376.0000 - val_mae: 598.5868\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 672684.4375 - mae: 593.6385 - val_loss: 691302.6875 - val_mae: 597.0734\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 670793.2500 - mae: 592.6968 - val_loss: 689193.4375 - val_mae: 595.0724\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 669230.6250 - mae: 591.1404 - val_loss: 686277.6875 - val_mae: 595.7465\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 667096.9375 - mae: 590.8179 - val_loss: 684449.8125 - val_mae: 595.4982\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 665466.4375 - mae: 590.4592 - val_loss: 684110.5625 - val_mae: 592.4841\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 663988.4375 - mae: 589.2914 - val_loss: 684042.0000 - val_mae: 593.4703\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 663183.5625 - mae: 588.8145 - val_loss: 680374.5000 - val_mae: 593.5102\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 661512.8125 - mae: 587.8998 - val_loss: 680910.5000 - val_mae: 592.8957\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 660123.3750 - mae: 587.5075 - val_loss: 678984.2500 - val_mae: 592.5043\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 659348.1250 - mae: 587.3488 - val_loss: 678259.4375 - val_mae: 590.9025\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 658126.7500 - mae: 586.6296 - val_loss: 678073.5625 - val_mae: 591.0209\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 657325.3750 - mae: 586.1579 - val_loss: 676762.5625 - val_mae: 590.5326\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 656257.5000 - mae: 585.7565 - val_loss: 676277.2500 - val_mae: 589.7120\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 654843.7500 - mae: 584.5117 - val_loss: 675065.1875 - val_mae: 592.1016\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 654314.5000 - mae: 585.4789 - val_loss: 672711.8750 - val_mae: 588.7991\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 653575.1250 - mae: 584.4440 - val_loss: 673332.6875 - val_mae: 589.6933\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 652342.1250 - mae: 584.0916 - val_loss: 672242.2500 - val_mae: 587.6772\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 651565.3125 - mae: 582.9301 - val_loss: 670999.5625 - val_mae: 589.3655\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 650646.3125 - mae: 583.5432 - val_loss: 672100.3125 - val_mae: 588.6309\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 649446.3750 - mae: 582.9482 - val_loss: 671909.9375 - val_mae: 586.2609\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 649715.5625 - mae: 582.1581 - val_loss: 669201.7500 - val_mae: 587.4225\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 648435.5625 - mae: 582.4153 - val_loss: 669516.8125 - val_mae: 586.4391\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 647571.9375 - mae: 581.5625 - val_loss: 666187.8750 - val_mae: 586.1165\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 646381.9375 - mae: 581.6321 - val_loss: 666567.3125 - val_mae: 587.1068\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 645811.6250 - mae: 581.0723 - val_loss: 665659.5625 - val_mae: 587.8266\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 645239.1250 - mae: 581.2642 - val_loss: 664551.3750 - val_mae: 586.4429\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 644185.0000 - mae: 580.7393 - val_loss: 663806.6250 - val_mae: 586.8238\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 643762.0000 - mae: 580.5941 - val_loss: 663770.8750 - val_mae: 587.6620\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 643117.6250 - mae: 580.6024 - val_loss: 662736.4375 - val_mae: 584.8392\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 642261.6250 - mae: 579.9579 - val_loss: 663053.3750 - val_mae: 584.3265\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 641765.1250 - mae: 579.8187 - val_loss: 663290.3750 - val_mae: 585.5431\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 640788.3125 - mae: 579.8174 - val_loss: 660348.6875 - val_mae: 584.5888\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 640259.7500 - mae: 579.3105 - val_loss: 659935.4375 - val_mae: 585.1165\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 639576.6875 - mae: 579.0849 - val_loss: 659512.8125 - val_mae: 584.2292\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 639103.8125 - mae: 579.0871 - val_loss: 658091.5625 - val_mae: 583.5218\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 638303.0000 - mae: 579.2394 - val_loss: 658413.6875 - val_mae: 583.1499\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637789.5625 - mae: 578.1231 - val_loss: 656002.4375 - val_mae: 584.8814\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637080.5000 - mae: 578.8978 - val_loss: 655554.4375 - val_mae: 583.6168\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 636312.6250 - mae: 578.3716 - val_loss: 655164.4375 - val_mae: 583.7054\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 635567.4375 - mae: 577.6770 - val_loss: 655174.6875 - val_mae: 584.1032\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 634655.5000 - mae: 577.8005 - val_loss: 656637.1875 - val_mae: 582.9160\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 634098.5000 - mae: 577.5693 - val_loss: 654248.8750 - val_mae: 583.5235\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 633106.8750 - mae: 577.3302 - val_loss: 653900.3125 - val_mae: 582.1420\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 632486.5000 - mae: 576.8021 - val_loss: 653143.7500 - val_mae: 582.9529\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 631808.2500 - mae: 576.8848 - val_loss: 653975.1875 - val_mae: 581.9763\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 631024.8125 - mae: 576.1336 - val_loss: 652919.8750 - val_mae: 583.2203\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 630673.3125 - mae: 576.5355 - val_loss: 650694.0000 - val_mae: 582.2271\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 629846.8750 - mae: 576.0057 - val_loss: 649870.6250 - val_mae: 581.9156\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 629052.3750 - mae: 576.0042 - val_loss: 647758.3750 - val_mae: 581.2125\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 628304.4375 - mae: 576.0003 - val_loss: 647283.3750 - val_mae: 581.2235\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 627255.7500 - mae: 575.4940 - val_loss: 647271.8750 - val_mae: 580.9243\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 626876.1875 - mae: 575.3134 - val_loss: 645558.5000 - val_mae: 580.1131\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 626355.6875 - mae: 574.9735 - val_loss: 645704.6875 - val_mae: 580.0803\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 625255.5625 - mae: 574.9417 - val_loss: 645529.8125 - val_mae: 580.5287\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 624859.3125 - mae: 575.1332 - val_loss: 644767.1250 - val_mae: 579.0441\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 624584.6250 - mae: 574.5131 - val_loss: 643635.1250 - val_mae: 579.7809\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 624151.6250 - mae: 575.0375 - val_loss: 642774.5625 - val_mae: 579.5689\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 623194.6875 - mae: 574.3123 - val_loss: 642178.2500 - val_mae: 579.9265\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 622633.3750 - mae: 574.3377 - val_loss: 642068.0000 - val_mae: 579.2827\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 622165.6250 - mae: 574.2402 - val_loss: 642054.1875 - val_mae: 578.2064\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 621635.6250 - mae: 573.3021 - val_loss: 639900.3750 - val_mae: 580.7938\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 621181.8750 - mae: 574.0631 - val_loss: 639064.3750 - val_mae: 579.5346\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 620534.5000 - mae: 573.8576 - val_loss: 639275.0625 - val_mae: 577.3038\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619983.0000 - mae: 572.6459 - val_loss: 638058.2500 - val_mae: 580.1792\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619908.5625 - mae: 573.9166 - val_loss: 638077.6250 - val_mae: 577.9585\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619086.8750 - mae: 572.5373 - val_loss: 636579.1250 - val_mae: 579.0906\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 618414.5625 - mae: 573.0815 - val_loss: 636240.5625 - val_mae: 577.0871\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617923.7500 - mae: 572.4408 - val_loss: 634796.8125 - val_mae: 577.8582\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617533.6875 - mae: 572.2682 - val_loss: 636079.0625 - val_mae: 576.8580\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617011.0000 - mae: 572.0233 - val_loss: 633951.1250 - val_mae: 577.7664\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616296.4375 - mae: 572.1479 - val_loss: 635475.4375 - val_mae: 577.0316\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615814.2500 - mae: 571.0519 - val_loss: 633521.4375 - val_mae: 578.9091\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615569.5000 - mae: 571.8973 - val_loss: 633277.3125 - val_mae: 576.9968\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615060.8750 - mae: 570.9064 - val_loss: 631146.8125 - val_mae: 578.1575\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614697.3125 - mae: 571.6282 - val_loss: 630111.9375 - val_mae: 575.5998\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614137.8750 - mae: 570.9659 - val_loss: 630365.3750 - val_mae: 574.3562\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613558.1875 - mae: 570.4835 - val_loss: 629117.3125 - val_mae: 575.3920\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613235.2500 - mae: 571.0204 - val_loss: 628980.6875 - val_mae: 574.3403\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612679.4375 - mae: 569.8720 - val_loss: 628635.5000 - val_mae: 576.0487\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612229.0000 - mae: 570.4789 - val_loss: 628537.6875 - val_mae: 573.4312\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611863.1250 - mae: 569.5097 - val_loss: 627896.1875 - val_mae: 574.2193\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610879.5000 - mae: 569.5599 - val_loss: 625750.6250 - val_mae: 574.2930\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 610721.6250 - mae: 569.0928 - val_loss: 625223.3750 - val_mae: 573.2587\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609979.5625 - mae: 568.8681 - val_loss: 625438.0625 - val_mae: 574.3063\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609793.7500 - mae: 569.2932 - val_loss: 623798.3125 - val_mae: 572.4265\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608822.0625 - mae: 567.8398 - val_loss: 624109.9375 - val_mae: 574.9958\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608292.1875 - mae: 568.1422 - val_loss: 624766.0625 - val_mae: 571.8502\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607643.3125 - mae: 567.9648 - val_loss: 625109.3750 - val_mae: 570.9340\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607237.6250 - mae: 566.9399 - val_loss: 623018.4375 - val_mae: 571.2006\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606448.8125 - mae: 566.9690 - val_loss: 621668.4375 - val_mae: 570.4296\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606206.9375 - mae: 566.3946 - val_loss: 621813.0000 - val_mae: 574.4799\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605704.2500 - mae: 566.7706 - val_loss: 621782.8750 - val_mae: 571.0578\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605238.3750 - mae: 565.8064 - val_loss: 620452.5000 - val_mae: 571.5169\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604551.6875 - mae: 566.5508 - val_loss: 622080.1875 - val_mae: 568.9034\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604707.9375 - mae: 565.2455 - val_loss: 620117.1250 - val_mae: 570.3453\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604165.5625 - mae: 565.4609 - val_loss: 619857.5000 - val_mae: 569.4312\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603517.9375 - mae: 564.8976 - val_loss: 619495.1875 - val_mae: 569.8281\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603132.5625 - mae: 565.0947 - val_loss: 617519.3750 - val_mae: 567.9857\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602417.1875 - mae: 563.8597 - val_loss: 617862.7500 - val_mae: 569.5497\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602341.3750 - mae: 564.3702 - val_loss: 617134.7500 - val_mae: 568.5986\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601337.6250 - mae: 564.0580 - val_loss: 617615.6250 - val_mae: 566.8809\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601085.1250 - mae: 562.8964 - val_loss: 617069.0625 - val_mae: 569.2653\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600639.0625 - mae: 563.2031 - val_loss: 616425.0000 - val_mae: 568.4238\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600200.4375 - mae: 563.4184 - val_loss: 614556.4375 - val_mae: 567.8104\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599788.1875 - mae: 562.2728 - val_loss: 613574.7500 - val_mae: 567.7331\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599378.5625 - mae: 562.8245 - val_loss: 615610.6875 - val_mae: 566.7495\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598835.6875 - mae: 561.9361 - val_loss: 613936.1875 - val_mae: 567.3949\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598687.7500 - mae: 561.7696 - val_loss: 614158.1250 - val_mae: 566.7535\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598200.9375 - mae: 561.7549 - val_loss: 613126.3750 - val_mae: 566.1976\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597720.3750 - mae: 561.3794 - val_loss: 613029.9375 - val_mae: 566.9474\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597220.1250 - mae: 561.5530 - val_loss: 612704.5000 - val_mae: 565.4655\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596862.6875 - mae: 560.9899 - val_loss: 612631.0625 - val_mae: 564.8278\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595965.7500 - mae: 560.9392 - val_loss: 612586.8750 - val_mae: 566.3425\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595771.2500 - mae: 560.8323 - val_loss: 611131.6250 - val_mae: 564.0825\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594810.3125 - mae: 559.2326 - val_loss: 609858.2500 - val_mae: 567.2172\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594963.5000 - mae: 560.4208 - val_loss: 609241.4375 - val_mae: 564.7131\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593880.4375 - mae: 559.7008 - val_loss: 608792.3750 - val_mae: 564.5185\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593513.9375 - mae: 559.6379 - val_loss: 607879.3125 - val_mae: 562.8924\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592884.7500 - mae: 559.3202 - val_loss: 607434.9375 - val_mae: 563.1677\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592080.2500 - mae: 558.7199 - val_loss: 606728.7500 - val_mae: 564.2574\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591552.6250 - mae: 558.7390 - val_loss: 606135.5625 - val_mae: 564.5742\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591346.3750 - mae: 558.5559 - val_loss: 604612.8750 - val_mae: 562.5804\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590777.7500 - mae: 558.6201 - val_loss: 604671.0000 - val_mae: 563.9600\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590489.3125 - mae: 558.4318 - val_loss: 604878.5000 - val_mae: 562.5439\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589405.8125 - mae: 558.2625 - val_loss: 604321.1875 - val_mae: 560.5918\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589211.1250 - mae: 557.2350 - val_loss: 603293.5000 - val_mae: 562.7114\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588816.0000 - mae: 557.6337 - val_loss: 602827.4375 - val_mae: 562.1539\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588540.0625 - mae: 557.6554 - val_loss: 602485.5625 - val_mae: 560.9356\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587775.2500 - mae: 556.9484 - val_loss: 601421.0625 - val_mae: 560.9909\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587549.6875 - mae: 557.0999 - val_loss: 601551.6250 - val_mae: 560.9931\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587295.5625 - mae: 556.7292 - val_loss: 599779.2500 - val_mae: 560.8082\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586863.3125 - mae: 556.5389 - val_loss: 600531.3750 - val_mae: 560.8850\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586162.4375 - mae: 556.2197 - val_loss: 600241.0000 - val_mae: 560.2486\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585877.0000 - mae: 555.8680 - val_loss: 599663.7500 - val_mae: 561.6599\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585711.9375 - mae: 556.7424 - val_loss: 599766.5000 - val_mae: 558.3966\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585192.3125 - mae: 555.8587 - val_loss: 598465.3125 - val_mae: 560.2222\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584944.5000 - mae: 555.7059 - val_loss: 597722.7500 - val_mae: 560.5641\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584650.5625 - mae: 555.7327 - val_loss: 598820.0625 - val_mae: 559.6721\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584235.8125 - mae: 555.4180 - val_loss: 597224.8750 - val_mae: 558.5815\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584095.0000 - mae: 555.2177 - val_loss: 597637.5000 - val_mae: 559.7845\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583781.6875 - mae: 555.3613 - val_loss: 597200.7500 - val_mae: 559.2886\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583646.8125 - mae: 554.7628 - val_loss: 595990.6875 - val_mae: 560.1471\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583119.5000 - mae: 554.6802 - val_loss: 596100.3125 - val_mae: 559.1671\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582912.5625 - mae: 554.8738 - val_loss: 596473.5000 - val_mae: 560.4486\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582622.0625 - mae: 554.6155 - val_loss: 595786.2500 - val_mae: 559.8932\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 38017756.0000 - mae: 6008.9136 - val_loss: 36483192.0000 - val_mae: 5891.3223\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 33675884.0000 - mae: 5651.4165 - val_loss: 29932770.0000 - val_mae: 5331.6372\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 25921452.0000 - mae: 4937.4839 - val_loss: 21488792.0000 - val_mae: 4485.9385\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 17588724.0000 - mae: 4009.8867 - val_loss: 13612898.0000 - val_mae: 3500.4814\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 10562155.0000 - mae: 3021.4084 - val_loss: 7607788.0000 - val_mae: 2530.3887\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5636968.5000 - mae: 2105.2935 - val_loss: 3827374.2500 - val_mae: 1680.3065\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2846613.0000 - mae: 1374.3478 - val_loss: 1972583.1250 - val_mae: 1099.4629\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1603288.0000 - mae: 960.7370 - val_loss: 1255954.3750 - val_mae: 845.8688\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1143473.5000 - mae: 794.0450 - val_loss: 1011167.1875 - val_mae: 749.3219\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 974083.9375 - mae: 729.4333 - val_loss: 919504.3125 - val_mae: 710.0773\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 898159.6875 - mae: 698.5873 - val_loss: 874658.8750 - val_mae: 690.3309\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 855346.1250 - mae: 681.6542 - val_loss: 846564.4375 - val_mae: 678.1437\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 824926.1875 - mae: 668.9371 - val_loss: 821088.1250 - val_mae: 667.4746\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 799194.4375 - mae: 658.7227 - val_loss: 800162.5000 - val_mae: 659.0176\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 777387.1250 - mae: 649.3981 - val_loss: 781788.2500 - val_mae: 650.8037\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 758508.5625 - mae: 641.8849 - val_loss: 764751.1875 - val_mae: 643.2456\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 742280.6875 - mae: 635.1248 - val_loss: 749561.3125 - val_mae: 635.6783\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 727911.5000 - mae: 628.4322 - val_loss: 737724.4375 - val_mae: 631.7820\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 715520.0000 - mae: 623.7498 - val_loss: 725542.0625 - val_mae: 627.0437\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 705029.6250 - mae: 619.9921 - val_loss: 717038.1250 - val_mae: 622.6243\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 696120.0625 - mae: 615.5663 - val_loss: 708286.0000 - val_mae: 619.0601\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 687654.2500 - mae: 612.4824 - val_loss: 700460.6250 - val_mae: 616.1759\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 679591.4375 - mae: 609.6891 - val_loss: 693704.8750 - val_mae: 612.4795\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 672326.7500 - mae: 606.3312 - val_loss: 687025.8125 - val_mae: 608.8161\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 665454.6875 - mae: 602.4431 - val_loss: 680820.3750 - val_mae: 606.6306\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 659554.4375 - mae: 599.8295 - val_loss: 677793.3125 - val_mae: 606.5076\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 654406.5000 - mae: 597.9904 - val_loss: 673090.5000 - val_mae: 602.8868\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 649571.1250 - mae: 595.2567 - val_loss: 668070.8750 - val_mae: 599.0092\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 645210.2500 - mae: 592.5645 - val_loss: 663104.3750 - val_mae: 596.8474\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 640862.1250 - mae: 589.6845 - val_loss: 659165.5000 - val_mae: 595.0220\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637428.2500 - mae: 587.4937 - val_loss: 654708.1875 - val_mae: 590.5159\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 633440.7500 - mae: 584.5200 - val_loss: 654054.1250 - val_mae: 592.3560\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 629960.8750 - mae: 583.1624 - val_loss: 650918.6250 - val_mae: 588.5178\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 626797.6875 - mae: 581.6390 - val_loss: 647850.6875 - val_mae: 582.9946\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 624597.0000 - mae: 579.0753 - val_loss: 645158.6875 - val_mae: 584.4629\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 621534.8125 - mae: 577.2899 - val_loss: 644017.8750 - val_mae: 586.9440\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 620328.7500 - mae: 577.6760 - val_loss: 640366.3125 - val_mae: 580.5099\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617778.3125 - mae: 575.7896 - val_loss: 637974.0000 - val_mae: 580.9041\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615591.9375 - mae: 574.9039 - val_loss: 637121.6250 - val_mae: 578.9465\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613959.1250 - mae: 573.6171 - val_loss: 637264.5625 - val_mae: 579.4171\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613079.5625 - mae: 572.9871 - val_loss: 634585.5625 - val_mae: 578.2652\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611596.1875 - mae: 572.0093 - val_loss: 632378.8750 - val_mae: 579.8141\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609847.3750 - mae: 571.9130 - val_loss: 629677.8750 - val_mae: 576.5518\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608709.1875 - mae: 571.0417 - val_loss: 630201.2500 - val_mae: 574.9483\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607177.6875 - mae: 570.0182 - val_loss: 628128.9375 - val_mae: 576.7683\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606516.1250 - mae: 569.2499 - val_loss: 626570.0625 - val_mae: 575.3023\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605158.6875 - mae: 568.5674 - val_loss: 626872.6250 - val_mae: 576.1032\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604084.8125 - mae: 568.6772 - val_loss: 625550.2500 - val_mae: 575.4662\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603127.8125 - mae: 567.4741 - val_loss: 625298.0000 - val_mae: 576.6573\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602822.6875 - mae: 567.6285 - val_loss: 622081.0625 - val_mae: 574.9706\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601767.3125 - mae: 567.1270 - val_loss: 623451.7500 - val_mae: 575.5712\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600624.3750 - mae: 566.7493 - val_loss: 623085.1250 - val_mae: 573.8768\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600397.5625 - mae: 566.1415 - val_loss: 622102.9375 - val_mae: 572.8197\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599345.5625 - mae: 565.9045 - val_loss: 620497.0000 - val_mae: 571.4024\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598847.3125 - mae: 565.2095 - val_loss: 619396.4375 - val_mae: 573.5593\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597982.9375 - mae: 565.4065 - val_loss: 618586.7500 - val_mae: 571.9517\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597611.1250 - mae: 564.6732 - val_loss: 617912.8750 - val_mae: 572.8956\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596774.1875 - mae: 564.5480 - val_loss: 616049.1250 - val_mae: 568.9993\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596194.6875 - mae: 564.2162 - val_loss: 616916.1250 - val_mae: 569.8259\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595701.3750 - mae: 563.5038 - val_loss: 616366.7500 - val_mae: 572.5172\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595094.7500 - mae: 563.8314 - val_loss: 615960.8125 - val_mae: 569.6240\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594768.1250 - mae: 563.1136 - val_loss: 616137.3750 - val_mae: 571.8343\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594229.5625 - mae: 563.1871 - val_loss: 615759.5625 - val_mae: 573.0668\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593940.0000 - mae: 563.1768 - val_loss: 614790.8125 - val_mae: 568.9708\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593482.5000 - mae: 562.3778 - val_loss: 615422.5000 - val_mae: 570.7276\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592866.8750 - mae: 561.9892 - val_loss: 614173.8750 - val_mae: 569.3633\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592480.4375 - mae: 562.1106 - val_loss: 613527.0000 - val_mae: 570.3301\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591805.8750 - mae: 561.6966 - val_loss: 612371.4375 - val_mae: 568.6387\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591382.4375 - mae: 561.5806 - val_loss: 614107.6875 - val_mae: 568.2353\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591241.1875 - mae: 561.8965 - val_loss: 613506.8750 - val_mae: 568.2618\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590563.1250 - mae: 560.5222 - val_loss: 610497.4375 - val_mae: 568.5058\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590136.7500 - mae: 560.9730 - val_loss: 611286.1250 - val_mae: 570.8856\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589481.6875 - mae: 560.9088 - val_loss: 612329.1875 - val_mae: 566.3280\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588838.9375 - mae: 559.8604 - val_loss: 609466.4375 - val_mae: 569.3765\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588600.0625 - mae: 560.1877 - val_loss: 610811.3750 - val_mae: 567.2839\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587978.5000 - mae: 559.5007 - val_loss: 608700.5625 - val_mae: 568.1003\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587239.0625 - mae: 559.5835 - val_loss: 606313.0625 - val_mae: 565.6996\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586941.9375 - mae: 559.0192 - val_loss: 605470.1875 - val_mae: 565.0613\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586385.0000 - mae: 559.0104 - val_loss: 607971.0000 - val_mae: 565.8054\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585997.3750 - mae: 558.3765 - val_loss: 605487.5625 - val_mae: 564.4884\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585717.0625 - mae: 558.2089 - val_loss: 605245.6250 - val_mae: 564.5235\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585395.4375 - mae: 557.9651 - val_loss: 604641.3750 - val_mae: 562.9510\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584497.0000 - mae: 557.4550 - val_loss: 605701.0000 - val_mae: 563.3426\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584123.0000 - mae: 556.5021 - val_loss: 605926.3125 - val_mae: 567.2532\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583733.8750 - mae: 556.9211 - val_loss: 606195.3750 - val_mae: 564.3946\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583030.6250 - mae: 556.2913 - val_loss: 602901.2500 - val_mae: 564.1793\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582817.2500 - mae: 556.2139 - val_loss: 603873.1875 - val_mae: 563.5522\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582200.2500 - mae: 555.5853 - val_loss: 604235.3125 - val_mae: 560.6593\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581949.5000 - mae: 555.0031 - val_loss: 603208.1250 - val_mae: 565.0293\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581504.1875 - mae: 555.2895 - val_loss: 602131.0000 - val_mae: 562.0704\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580919.9375 - mae: 554.8789 - val_loss: 599169.3750 - val_mae: 561.3385\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580269.7500 - mae: 553.6487 - val_loss: 600152.7500 - val_mae: 562.6284\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580255.1875 - mae: 553.9581 - val_loss: 600356.5625 - val_mae: 562.7899\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 579716.3750 - mae: 554.0582 - val_loss: 599583.8750 - val_mae: 561.4882\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 579372.1250 - mae: 553.0070 - val_loss: 601854.8125 - val_mae: 565.0956\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 579222.9375 - mae: 553.4910 - val_loss: 600168.6250 - val_mae: 563.2533\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578436.3125 - mae: 553.0112 - val_loss: 600904.5000 - val_mae: 562.7123\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578543.8125 - mae: 552.4908 - val_loss: 599913.8125 - val_mae: 562.9885\n"
     ]
    }
   ],
   "source": [
    "# 用梯度下降 - 小批量随机梯度下降（MBGD）- mse + adam\n",
    "\n",
    "result16_adam_dict = {\n",
    "    'units': [],\n",
    "    'batch_size': [],\n",
    "    'learning_rate': [],\n",
    "    'minimum_mae_error': []\n",
    "}\n",
    "\n",
    "for units in para_dict['hidden_units']:\n",
    "    for b_size in para_dict['batch_size']:\n",
    "        for rate in para_dict['learning_rate'][0]:\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor = 'val_mae',\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "            optimizer = Adam(learning_rate = rate)\n",
    "\n",
    "            model = create_model(columns = x_train.columns, units = units, loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "            best_model = model.fit(\n",
    "                x_scaled_train, y_train,\n",
    "                validation_data = (x_scaled_test, y_test),\n",
    "                batch_size = b_size,\n",
    "                epochs = 250,\n",
    "                callbacks = [early_stopping]\n",
    "            )\n",
    "\n",
    "            min_mae = early_stopping.best\n",
    "\n",
    "            result16_adam_dict['units'].append(units)\n",
    "            result16_adam_dict['batch_size'].append(b_size)\n",
    "            result16_adam_dict['learning_rate'].append(rate)\n",
    "            result16_adam_dict['minimum_mae_error'].append(min_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>minimum_mae_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>551.521484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>552.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>550.431946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>543.401855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>567.597595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>570.497620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>560.813599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6046.201172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>568.569031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>561.833313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>544.290955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>556.264465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>544.353210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>536.304932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>538.516541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>561.353394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>558.396606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>560.659302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  batch_size  learning_rate  minimum_mae_error\n",
       "0       7          16          0.008         551.521484\n",
       "1       7          16          0.010         552.343750\n",
       "2       7          32          0.008         550.431946\n",
       "3       7          32          0.010         543.401855\n",
       "4       7          64          0.008         567.597595\n",
       "5       7          64          0.010         570.497620\n",
       "6       8          16          0.008         560.813599\n",
       "7       8          16          0.010        6046.201172\n",
       "8       8          32          0.008         568.569031\n",
       "9       8          32          0.010         561.833313\n",
       "10      8          64          0.008         544.290955\n",
       "11      8          64          0.010         556.264465\n",
       "12      9          16          0.008         544.353210\n",
       "13      9          16          0.010         536.304932\n",
       "14      9          32          0.008         538.516541\n",
       "15      9          32          0.010         561.353394\n",
       "16      9          64          0.008         558.396606\n",
       "17      9          64          0.010         560.659302"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result16_adam_df = pd.DataFrame(result16_adam_dict)\n",
    "\n",
    "result16_adam_df.to_csv('result16_adam.csv')\n",
    "\n",
    "result16_adam_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
