{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>minPrimary_transitTime</th>\n",
       "      <th>min_dis</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Improved</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>Type S2</th>\n",
       "      <th>...</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>CHOA CHU KANG</th>\n",
       "      <th>CLEMENTI</th>\n",
       "      <th>JURONG WEST</th>\n",
       "      <th>KALLANG/WHAMPOA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "      <th>YISHUN</th>\n",
       "      <th>resale_price_per_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.377567</td>\n",
       "      <td>759.0</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>93.166667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6410.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.371036</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5186.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.430421</td>\n",
       "      <td>964.0</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>71.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5335.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.352865</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>94.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6691.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.371233</td>\n",
       "      <td>454.0</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5476.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>1.341138</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>48.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4908.045977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>1.329478</td>\n",
       "      <td>868.0</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>57.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5176.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>1.389799</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>91.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6246.107527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>1.338132</td>\n",
       "      <td>397.0</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>76.416667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5709.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>1.390053</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6145.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13811 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat  minPrimary_transitTime   min_dis  remaining_lease   DBSS  \\\n",
       "0      1.377567                   759.0  0.001040        93.166667  False   \n",
       "1      1.371036                   368.0  0.018341        60.833333  False   \n",
       "2      1.430421                   964.0  0.005845        71.083333  False   \n",
       "3      1.352865                   448.0  0.009913        94.833333  False   \n",
       "4      1.371233                   454.0  0.005618        61.000000  False   \n",
       "...         ...                     ...       ...              ...    ...   \n",
       "13806  1.341138                   514.0  0.003085        48.833333  False   \n",
       "13807  1.329478                   868.0  0.006544        57.083333  False   \n",
       "13808  1.389799                   254.0  0.002423        91.833333  False   \n",
       "13809  1.338132                   397.0  0.004211        76.416667  False   \n",
       "13810  1.390053                   353.0  0.002005        88.916667  False   \n",
       "\n",
       "       Improved  Model A  New Generation  Type S1  Type S2  ...  BUKIT MERAH  \\\n",
       "0          True    False           False    False    False  ...        False   \n",
       "1         False    False            True    False    False  ...        False   \n",
       "2         False    False           False    False    False  ...        False   \n",
       "3         False     True           False    False    False  ...        False   \n",
       "4         False    False           False    False    False  ...        False   \n",
       "...         ...      ...             ...      ...      ...  ...          ...   \n",
       "13806      True    False           False    False    False  ...        False   \n",
       "13807     False    False            True    False    False  ...        False   \n",
       "13808     False     True           False    False    False  ...        False   \n",
       "13809      True    False           False    False    False  ...        False   \n",
       "13810     False    False           False    False    False  ...        False   \n",
       "\n",
       "       CENTRAL AREA  CHOA CHU KANG  CLEMENTI  JURONG WEST  KALLANG/WHAMPOA  \\\n",
       "0             False           True     False        False            False   \n",
       "1             False          False     False        False            False   \n",
       "2             False          False     False        False            False   \n",
       "3             False          False     False        False            False   \n",
       "4             False          False     False        False            False   \n",
       "...             ...            ...       ...          ...              ...   \n",
       "13806         False          False     False        False            False   \n",
       "13807         False          False     False        False            False   \n",
       "13808         False          False     False        False            False   \n",
       "13809         False          False     False         True            False   \n",
       "13810         False          False     False        False            False   \n",
       "\n",
       "       QUEENSTOWN  WOODLANDS  YISHUN  resale_price_per_sqm  \n",
       "0           False      False   False           6410.714286  \n",
       "1           False      False   False           5186.813187  \n",
       "2           False       True   False           5335.365854  \n",
       "3           False      False   False           6691.176471  \n",
       "4           False      False   False           5476.190476  \n",
       "...           ...        ...     ...                   ...  \n",
       "13806       False      False   False           4908.045977  \n",
       "13807       False      False   False           5176.470588  \n",
       "13808       False      False   False           6246.107527  \n",
       "13809       False      False   False           5709.090909  \n",
       "13810       False      False   False           6145.833333  \n",
       "\n",
       "[13811 rows x 34 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train = pd.read_csv('full_hdb_perSqm_train_f34.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "test = pd.read_csv('full_hdb_perSqm_test_f34.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13811, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'resale_price_per_sqm'}>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.hist('resale_price_per_sqm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat                       0\n",
       "minPrimary_transitTime    0\n",
       "min_dis                   0\n",
       "remaining_lease           0\n",
       "DBSS                      0\n",
       "Improved                  0\n",
       "Model A                   0\n",
       "New Generation            0\n",
       "Type S1                   0\n",
       "Type S2                   0\n",
       "2 ROOM                    0\n",
       "01 TO 03                  0\n",
       "04 TO 06                  0\n",
       "16 TO 18                  0\n",
       "19 TO 21                  0\n",
       "22 TO 24                  0\n",
       "25 TO 27                  0\n",
       "28 TO 30                  0\n",
       "31 TO 33                  0\n",
       "34 TO 36                  0\n",
       "37 TO 39                  0\n",
       "40 TO 42                  0\n",
       "43 TO 45                  0\n",
       "BISHAN                    0\n",
       "BUKIT MERAH               0\n",
       "CENTRAL AREA              0\n",
       "CHOA CHU KANG             0\n",
       "CLEMENTI                  0\n",
       "JURONG WEST               0\n",
       "KALLANG/WHAMPOA           0\n",
       "QUEENSTOWN                0\n",
       "WOODLANDS                 0\n",
       "YISHUN                    0\n",
       "resale_price_per_sqm      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict = {\n",
    "    'hidden_units' : [7, 8, 9],\n",
    "    'batch_size' : [16, 32, 64],\n",
    "    'learning_rate' : [[0.008, 0.01], [0.0008, 0.001]]\n",
    "}\n",
    "\n",
    "def create_model(columns, units = 8, activation = 'relu', loss = 'mae', optimizer = 'SGD', metrics = 'mae'):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(units, input_shape = (len(columns), ), activation = activation),\n",
    "        Dense(1, activation = activation)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = loss,\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13811 entries, 0 to 13810\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   lat                     13811 non-null  float64\n",
      " 1   minPrimary_transitTime  13811 non-null  float64\n",
      " 2   min_dis                 13811 non-null  float64\n",
      " 3   remaining_lease         13811 non-null  float64\n",
      " 4   DBSS                    13811 non-null  bool   \n",
      " 5   Improved                13811 non-null  bool   \n",
      " 6   Model A                 13811 non-null  bool   \n",
      " 7   New Generation          13811 non-null  bool   \n",
      " 8   Type S1                 13811 non-null  bool   \n",
      " 9   Type S2                 13811 non-null  bool   \n",
      " 10  2 ROOM                  13811 non-null  bool   \n",
      " 11  01 TO 03                13811 non-null  bool   \n",
      " 12  04 TO 06                13811 non-null  bool   \n",
      " 13  16 TO 18                13811 non-null  bool   \n",
      " 14  19 TO 21                13811 non-null  bool   \n",
      " 15  22 TO 24                13811 non-null  bool   \n",
      " 16  25 TO 27                13811 non-null  bool   \n",
      " 17  28 TO 30                13811 non-null  bool   \n",
      " 18  31 TO 33                13811 non-null  bool   \n",
      " 19  34 TO 36                13811 non-null  bool   \n",
      " 20  37 TO 39                13811 non-null  bool   \n",
      " 21  40 TO 42                13811 non-null  bool   \n",
      " 22  43 TO 45                13811 non-null  bool   \n",
      " 23  BISHAN                  13811 non-null  bool   \n",
      " 24  BUKIT MERAH             13811 non-null  bool   \n",
      " 25  CENTRAL AREA            13811 non-null  bool   \n",
      " 26  CHOA CHU KANG           13811 non-null  bool   \n",
      " 27  CLEMENTI                13811 non-null  bool   \n",
      " 28  JURONG WEST             13811 non-null  bool   \n",
      " 29  KALLANG/WHAMPOA         13811 non-null  bool   \n",
      " 30  QUEENSTOWN              13811 non-null  bool   \n",
      " 31  WOODLANDS               13811 non-null  bool   \n",
      " 32  YISHUN                  13811 non-null  bool   \n",
      "dtypes: bool(29), float64(4)\n",
      "memory usage: 822.9 KB\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model 34\n",
    "'''\n",
    "\n",
    "# train set\n",
    "y_train = train['resale_price_per_sqm']\n",
    "x_train = train.drop(['resale_price_per_sqm'], axis = 1)\n",
    "\n",
    "# test set\n",
    "y_test = test['resale_price_per_sqm']\n",
    "x_test = test.drop(['resale_price_per_sqm'], axis = 1).astype(float)\n",
    "\n",
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>minPrimary_transitTime</th>\n",
       "      <th>min_dis</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Improved</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>Type S2</th>\n",
       "      <th>...</th>\n",
       "      <th>BISHAN</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>CHOA CHU KANG</th>\n",
       "      <th>CLEMENTI</th>\n",
       "      <th>JURONG WEST</th>\n",
       "      <th>KALLANG/WHAMPOA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "      <th>YISHUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156048</td>\n",
       "      <td>-0.026266</td>\n",
       "      <td>-1.299018</td>\n",
       "      <td>1.261190</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.800836</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>4.855382</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007990</td>\n",
       "      <td>-1.229159</td>\n",
       "      <td>3.027768</td>\n",
       "      <td>-0.878525</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>2.772393</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.354411</td>\n",
       "      <td>0.604407</td>\n",
       "      <td>-0.097186</td>\n",
       "      <td>-0.200213</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>3.268705</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.404001</td>\n",
       "      <td>-0.983043</td>\n",
       "      <td>0.920124</td>\n",
       "      <td>1.371485</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>1.225188</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012449</td>\n",
       "      <td>-0.964584</td>\n",
       "      <td>-0.154118</td>\n",
       "      <td>-0.867495</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>-0.669887</td>\n",
       "      <td>-0.779997</td>\n",
       "      <td>-0.787476</td>\n",
       "      <td>-1.672645</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.800836</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>-0.934243</td>\n",
       "      <td>0.309068</td>\n",
       "      <td>0.077641</td>\n",
       "      <td>-1.126687</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>2.772393</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>0.433403</td>\n",
       "      <td>-1.579874</td>\n",
       "      <td>-0.953137</td>\n",
       "      <td>1.172955</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>1.225188</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>-0.738033</td>\n",
       "      <td>-1.139942</td>\n",
       "      <td>-0.505835</td>\n",
       "      <td>0.152730</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.800836</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>3.937080</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>0.439144</td>\n",
       "      <td>-1.275306</td>\n",
       "      <td>-1.057544</td>\n",
       "      <td>0.979939</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.555298</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.205957</td>\n",
       "      <td>-0.145157</td>\n",
       "      <td>-0.253995</td>\n",
       "      <td>-0.18119</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "      <td>-0.278484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13811 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat  minPrimary_transitTime   min_dis  remaining_lease      DBSS  \\\n",
       "0      0.156048               -0.026266 -1.299018         1.261190 -0.113286   \n",
       "1      0.007990               -1.229159  3.027768        -0.878525 -0.113286   \n",
       "2      1.354411                0.604407 -0.097186        -0.200213 -0.113286   \n",
       "3     -0.404001               -0.983043  0.920124         1.371485 -0.113286   \n",
       "4      0.012449               -0.964584 -0.154118        -0.867495 -0.113286   \n",
       "...         ...                     ...       ...              ...       ...   \n",
       "13806 -0.669887               -0.779997 -0.787476        -1.672645 -0.113286   \n",
       "13807 -0.934243                0.309068  0.077641        -1.126687 -0.113286   \n",
       "13808  0.433403               -1.579874 -0.953137         1.172955 -0.113286   \n",
       "13809 -0.738033               -1.139942 -0.505835         0.152730 -0.113286   \n",
       "13810  0.439144               -1.275306 -1.057544         0.979939 -0.113286   \n",
       "\n",
       "       Improved   Model A  New Generation   Type S1   Type S2  ...    BISHAN  \\\n",
       "0      1.800836 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "1     -0.555298 -0.816201        2.772393 -0.039943 -0.022519  ... -0.121219   \n",
       "2     -0.555298 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "3     -0.555298  1.225188       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "4     -0.555298 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "...         ...       ...             ...       ...       ...  ...       ...   \n",
       "13806  1.800836 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "13807 -0.555298 -0.816201        2.772393 -0.039943 -0.022519  ... -0.121219   \n",
       "13808 -0.555298  1.225188       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "13809  1.800836 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "13810 -0.555298 -0.816201       -0.360699 -0.039943 -0.022519  ... -0.121219   \n",
       "\n",
       "       BUKIT MERAH  CENTRAL AREA  CHOA CHU KANG  CLEMENTI  JURONG WEST  \\\n",
       "0        -0.198981     -0.082337       4.855382 -0.145157    -0.253995   \n",
       "1        -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "2        -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "3        -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "4        -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "...            ...           ...            ...       ...          ...   \n",
       "13806    -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "13807    -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "13808    -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "13809    -0.198981     -0.082337      -0.205957 -0.145157     3.937080   \n",
       "13810    -0.198981     -0.082337      -0.205957 -0.145157    -0.253995   \n",
       "\n",
       "       KALLANG/WHAMPOA  QUEENSTOWN  WOODLANDS    YISHUN  \n",
       "0             -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "1             -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "2             -0.18119   -0.159825   3.268705 -0.278484  \n",
       "3             -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "4             -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "...                ...         ...        ...       ...  \n",
       "13806         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "13807         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "13808         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "13809         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "13810         -0.18119   -0.159825  -0.305932 -0.278484  \n",
       "\n",
       "[13811 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_columns = list(train.columns)\n",
    "x_columns.remove('resale_price_per_sqm')\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns = x_columns)\n",
    "\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "x_test = pd.DataFrame(x_test, columns = x_columns)\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4139.4106 - mae: 4139.4106 - val_loss: 525.4608 - val_mae: 525.4608\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 515.5820 - mae: 515.5820 - val_loss: 509.5664 - val_mae: 509.5664\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 489.2473 - mae: 489.2473 - val_loss: 482.0092 - val_mae: 482.0092\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 471.3762 - mae: 471.3762 - val_loss: 473.6479 - val_mae: 473.6479\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 458.3053 - mae: 458.3053 - val_loss: 479.1013 - val_mae: 479.1013\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 450.7209 - mae: 450.7209 - val_loss: 457.3479 - val_mae: 457.3479\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441.7387 - mae: 441.7387 - val_loss: 451.5699 - val_mae: 451.5699\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439.0721 - mae: 439.0721 - val_loss: 443.1071 - val_mae: 443.1071\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435.5179 - mae: 435.5179 - val_loss: 444.3476 - val_mae: 444.3476\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433.6493 - mae: 433.6493 - val_loss: 439.0594 - val_mae: 439.0594\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430.2639 - mae: 430.2639 - val_loss: 447.5645 - val_mae: 447.5645\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428.0124 - mae: 428.0124 - val_loss: 430.5576 - val_mae: 430.5576\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424.7390 - mae: 424.7390 - val_loss: 429.3557 - val_mae: 429.3557\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422.9744 - mae: 422.9744 - val_loss: 414.8264 - val_mae: 414.8264\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.7372 - mae: 420.7372 - val_loss: 430.5172 - val_mae: 430.5172\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.0102 - mae: 421.0102 - val_loss: 414.5170 - val_mae: 414.5170\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.8141 - mae: 418.8141 - val_loss: 439.6413 - val_mae: 439.6413\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.5401 - mae: 418.5401 - val_loss: 421.6158 - val_mae: 421.6158\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.0022 - mae: 416.0022 - val_loss: 418.3379 - val_mae: 418.3379\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.7818 - mae: 415.7818 - val_loss: 420.4578 - val_mae: 420.4578\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.7961 - mae: 415.7961 - val_loss: 422.1661 - val_mae: 422.1661\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.7706 - mae: 414.7706 - val_loss: 416.8319 - val_mae: 416.8319\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.0187 - mae: 415.0187 - val_loss: 431.8008 - val_mae: 431.8008\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.8272 - mae: 412.8272 - val_loss: 411.7918 - val_mae: 411.7918\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.0094 - mae: 413.0094 - val_loss: 404.2793 - val_mae: 404.2793\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.4769 - mae: 412.4769 - val_loss: 418.4300 - val_mae: 418.4300\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.3967 - mae: 411.3967 - val_loss: 413.0265 - val_mae: 413.0265\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.1661 - mae: 411.1661 - val_loss: 413.8896 - val_mae: 413.8896\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.8802 - mae: 410.8802 - val_loss: 411.7180 - val_mae: 411.7180\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.2563 - mae: 411.2563 - val_loss: 426.5121 - val_mae: 426.5121\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.6097 - mae: 409.6097 - val_loss: 417.2065 - val_mae: 417.2065\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.4900 - mae: 410.4900 - val_loss: 417.5732 - val_mae: 417.5732\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.9199 - mae: 409.9199 - val_loss: 412.4869 - val_mae: 412.4869\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.2411 - mae: 411.2411 - val_loss: 415.4113 - val_mae: 415.4113\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.4196 - mae: 409.4196 - val_loss: 411.6357 - val_mae: 411.6357\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3826.1716 - mae: 3826.1716 - val_loss: 533.3957 - val_mae: 533.3957\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 520.2998 - mae: 520.2998 - val_loss: 544.0365 - val_mae: 544.0365\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 501.7867 - mae: 501.7867 - val_loss: 486.3536 - val_mae: 486.3536\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 476.0035 - mae: 476.0035 - val_loss: 478.2001 - val_mae: 478.2001\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 464.2653 - mae: 464.2653 - val_loss: 465.7264 - val_mae: 465.7264\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 458.2709 - mae: 458.2709 - val_loss: 479.3902 - val_mae: 479.3902\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453.1647 - mae: 453.1647 - val_loss: 460.1979 - val_mae: 460.1979\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 450.8976 - mae: 450.8976 - val_loss: 462.5608 - val_mae: 462.5608\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 446.1426 - mae: 446.1426 - val_loss: 461.1037 - val_mae: 461.1037\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442.0249 - mae: 442.0249 - val_loss: 449.1368 - val_mae: 449.1368\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441.3115 - mae: 441.3115 - val_loss: 453.1984 - val_mae: 453.1984\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437.4802 - mae: 437.4802 - val_loss: 436.9221 - val_mae: 436.9221\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432.9574 - mae: 432.9574 - val_loss: 431.1699 - val_mae: 431.1699\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433.5849 - mae: 433.5849 - val_loss: 446.7682 - val_mae: 446.7682\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430.7020 - mae: 430.7020 - val_loss: 433.3403 - val_mae: 433.3403\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427.3647 - mae: 427.3647 - val_loss: 444.1833 - val_mae: 444.1833\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427.4034 - mae: 427.4034 - val_loss: 433.8110 - val_mae: 433.8110\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427.6673 - mae: 427.6673 - val_loss: 433.2887 - val_mae: 433.2887\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.2451 - mae: 425.2451 - val_loss: 453.0718 - val_mae: 453.0718\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.9658 - mae: 423.9658 - val_loss: 428.4440 - val_mae: 428.4440\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.8293 - mae: 423.8293 - val_loss: 427.4014 - val_mae: 427.4014\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422.3723 - mae: 422.3723 - val_loss: 419.7911 - val_mae: 419.7911\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.4786 - mae: 420.4786 - val_loss: 421.5881 - val_mae: 421.5881\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.8635 - mae: 420.8635 - val_loss: 417.2166 - val_mae: 417.2166\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.8745 - mae: 418.8745 - val_loss: 429.7719 - val_mae: 429.7719\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.6229 - mae: 418.6229 - val_loss: 441.2285 - val_mae: 441.2285\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.6654 - mae: 416.6654 - val_loss: 412.9857 - val_mae: 412.9857\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.6350 - mae: 415.6350 - val_loss: 432.0522 - val_mae: 432.0522\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.8091 - mae: 414.8091 - val_loss: 415.6994 - val_mae: 415.6994\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.3891 - mae: 414.3891 - val_loss: 415.3666 - val_mae: 415.3666\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.1780 - mae: 414.1780 - val_loss: 416.5490 - val_mae: 416.5490\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.8392 - mae: 413.8392 - val_loss: 414.5688 - val_mae: 414.5688\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.0146 - mae: 413.0146 - val_loss: 413.5006 - val_mae: 413.5006\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.1034 - mae: 412.1034 - val_loss: 415.0971 - val_mae: 415.0971\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.2369 - mae: 410.2369 - val_loss: 419.4639 - val_mae: 419.4639\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.3023 - mae: 410.3023 - val_loss: 426.2675 - val_mae: 426.2675\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.4488 - mae: 409.4488 - val_loss: 412.4320 - val_mae: 412.4320\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.0045 - mae: 409.0045 - val_loss: 406.7987 - val_mae: 406.7987\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.4357 - mae: 407.4357 - val_loss: 408.0113 - val_mae: 408.0113\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.2546 - mae: 408.2546 - val_loss: 428.5419 - val_mae: 428.5419\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.0907 - mae: 407.0907 - val_loss: 414.1573 - val_mae: 414.1573\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406.5201 - mae: 406.5201 - val_loss: 412.4551 - val_mae: 412.4551\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.6717 - mae: 405.6717 - val_loss: 411.7943 - val_mae: 411.7943\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.2771 - mae: 407.2771 - val_loss: 427.5463 - val_mae: 427.5463\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.9452 - mae: 407.9452 - val_loss: 396.2411 - val_mae: 396.2411\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.6005 - mae: 405.6005 - val_loss: 431.5700 - val_mae: 431.5700\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.6956 - mae: 404.6956 - val_loss: 436.5999 - val_mae: 436.5999\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.3822 - mae: 405.3822 - val_loss: 407.9639 - val_mae: 407.9639\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.8272 - mae: 404.8272 - val_loss: 405.9334 - val_mae: 405.9334\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.7351 - mae: 404.7351 - val_loss: 404.8296 - val_mae: 404.8296\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 403.7786 - mae: 403.7786 - val_loss: 407.8653 - val_mae: 407.8653\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 405.1123 - mae: 405.1123 - val_loss: 403.1117 - val_mae: 403.1117\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.4287 - mae: 404.4287 - val_loss: 404.5744 - val_mae: 404.5744\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404.5807 - mae: 404.5807 - val_loss: 397.7079 - val_mae: 397.7079\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 402.8387 - mae: 402.8387 - val_loss: 405.6422 - val_mae: 405.6422\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 6019.9243 - mae: 6019.9243 - val_loss: 5839.0107 - val_mae: 5839.0107\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 3s 6ms/step - loss: 2447.4211 - mae: 2447.4211 - val_loss: 512.2665 - val_mae: 512.2665\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 509.1115 - mae: 509.1115 - val_loss: 510.8597 - val_mae: 510.8597\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 507.3844 - mae: 507.3844 - val_loss: 506.2715 - val_mae: 506.2715\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 504.9360 - mae: 504.9360 - val_loss: 511.4504 - val_mae: 511.4504\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 503.6867 - mae: 503.6867 - val_loss: 502.1618 - val_mae: 502.1618\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 500.8475 - mae: 500.8475 - val_loss: 490.1207 - val_mae: 490.1207\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 493.0062 - mae: 493.0062 - val_loss: 487.0389 - val_mae: 487.0389\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 482.7289 - mae: 482.7289 - val_loss: 475.4337 - val_mae: 475.4337\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 471.9178 - mae: 471.9178 - val_loss: 471.6071 - val_mae: 471.6071\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 463.3224 - mae: 463.3224 - val_loss: 456.0798 - val_mae: 456.0798\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 454.1526 - mae: 454.1526 - val_loss: 453.8979 - val_mae: 453.8979\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 448.3122 - mae: 448.3122 - val_loss: 443.2136 - val_mae: 443.2136\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442.1817 - mae: 442.1817 - val_loss: 444.6185 - val_mae: 444.6185\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437.9304 - mae: 437.9304 - val_loss: 431.4185 - val_mae: 431.4185\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 434.4024 - mae: 434.4024 - val_loss: 444.9406 - val_mae: 444.9406\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 431.5732 - mae: 431.5732 - val_loss: 432.0423 - val_mae: 432.0423\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429.9071 - mae: 429.9071 - val_loss: 424.3665 - val_mae: 424.3665\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426.7876 - mae: 426.7876 - val_loss: 424.0386 - val_mae: 424.0386\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.7724 - mae: 424.7724 - val_loss: 425.1829 - val_mae: 425.1829\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.0436 - mae: 424.0436 - val_loss: 420.6343 - val_mae: 420.6343\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.6378 - mae: 421.6378 - val_loss: 416.7029 - val_mae: 416.7029\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.2546 - mae: 420.2546 - val_loss: 423.8817 - val_mae: 423.8817\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.4800 - mae: 420.4800 - val_loss: 415.7005 - val_mae: 415.7005\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.1961 - mae: 420.1961 - val_loss: 416.5383 - val_mae: 416.5383\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 419.1489 - mae: 419.1489 - val_loss: 419.8431 - val_mae: 419.8431\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 419.5440 - mae: 419.5440 - val_loss: 414.6773 - val_mae: 414.6773\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 417.9124 - mae: 417.9124 - val_loss: 416.0854 - val_mae: 416.0854\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 417.3498 - mae: 417.3498 - val_loss: 417.0661 - val_mae: 417.0661\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.5998 - mae: 418.5998 - val_loss: 415.3865 - val_mae: 415.3865\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.4540 - mae: 417.4540 - val_loss: 420.9636 - val_mae: 420.9636\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.4810 - mae: 417.4810 - val_loss: 414.7953 - val_mae: 414.7953\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.9753 - mae: 416.9753 - val_loss: 409.9375 - val_mae: 409.9375\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.6582 - mae: 416.6582 - val_loss: 416.0450 - val_mae: 416.0450\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.4164 - mae: 417.4164 - val_loss: 410.4457 - val_mae: 410.4457\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 416.3796 - mae: 416.3796 - val_loss: 418.3206 - val_mae: 418.3206\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 416.6396 - mae: 416.6396 - val_loss: 417.9013 - val_mae: 417.9013\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.7647 - mae: 416.7647 - val_loss: 419.7151 - val_mae: 419.7151\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 417.0606 - mae: 417.0606 - val_loss: 413.0460 - val_mae: 413.0460\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 415.7589 - mae: 415.7589 - val_loss: 427.0204 - val_mae: 427.0204\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 415.8867 - mae: 415.8867 - val_loss: 410.7314 - val_mae: 410.7314\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.8837 - mae: 415.8837 - val_loss: 414.0423 - val_mae: 414.0423\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.0056 - mae: 416.0056 - val_loss: 414.6794 - val_mae: 414.6794\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 5884.2217 - mae: 5884.2217 - val_loss: 4656.6226 - val_mae: 4656.6226\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 981.0187 - mae: 981.0187 - val_loss: 500.0167 - val_mae: 500.0167\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 501.5551 - mae: 501.5551 - val_loss: 495.7990 - val_mae: 495.7990\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 487.8093 - mae: 487.8093 - val_loss: 484.6698 - val_mae: 484.6698\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 478.3863 - mae: 478.3863 - val_loss: 472.1500 - val_mae: 472.1500\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 470.5060 - mae: 470.5060 - val_loss: 479.8248 - val_mae: 479.8248\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 466.8131 - mae: 466.8131 - val_loss: 458.4764 - val_mae: 458.4764\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 460.3875 - mae: 460.3875 - val_loss: 460.4131 - val_mae: 460.4131\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 456.4701 - mae: 456.4701 - val_loss: 449.5002 - val_mae: 449.5002\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 451.8217 - mae: 451.8217 - val_loss: 445.2456 - val_mae: 445.2456\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 445.0928 - mae: 445.0928 - val_loss: 439.6395 - val_mae: 439.6395\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 440.8513 - mae: 440.8513 - val_loss: 443.6646 - val_mae: 443.6646\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 435.6566 - mae: 435.6566 - val_loss: 435.0813 - val_mae: 435.0813\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 433.6792 - mae: 433.6792 - val_loss: 429.7441 - val_mae: 429.7441\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 430.2256 - mae: 430.2256 - val_loss: 422.0686 - val_mae: 422.0686\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426.9282 - mae: 426.9282 - val_loss: 445.1605 - val_mae: 445.1605\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425.6962 - mae: 425.6962 - val_loss: 420.9513 - val_mae: 420.9513\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.3622 - mae: 422.3622 - val_loss: 417.4396 - val_mae: 417.4396\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.0577 - mae: 422.0577 - val_loss: 421.9011 - val_mae: 421.9011\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.2521 - mae: 420.2521 - val_loss: 422.4336 - val_mae: 422.4336\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.4936 - mae: 417.4936 - val_loss: 426.7213 - val_mae: 426.7213\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.8133 - mae: 418.8133 - val_loss: 420.0266 - val_mae: 420.0266\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.0940 - mae: 418.0940 - val_loss: 414.9017 - val_mae: 414.9017\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.7491 - mae: 416.7491 - val_loss: 415.4384 - val_mae: 415.4384\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.5654 - mae: 417.5654 - val_loss: 413.8491 - val_mae: 413.8491\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.5463 - mae: 416.5463 - val_loss: 411.0022 - val_mae: 411.0022\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.7870 - mae: 415.7870 - val_loss: 411.7186 - val_mae: 411.7186\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.3373 - mae: 414.3373 - val_loss: 411.5617 - val_mae: 411.5617\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.1913 - mae: 414.1913 - val_loss: 413.1243 - val_mae: 413.1243\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.8102 - mae: 411.8102 - val_loss: 413.4823 - val_mae: 413.4823\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.9996 - mae: 412.9996 - val_loss: 410.8241 - val_mae: 410.8241\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.8348 - mae: 412.8348 - val_loss: 414.7645 - val_mae: 414.7645\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413.5084 - mae: 413.5084 - val_loss: 414.0714 - val_mae: 414.0714\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.7713 - mae: 411.7713 - val_loss: 409.6614 - val_mae: 409.6614\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.7961 - mae: 411.7961 - val_loss: 406.5126 - val_mae: 406.5126\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.8729 - mae: 411.8729 - val_loss: 409.2117 - val_mae: 409.2117\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.9952 - mae: 410.9952 - val_loss: 409.0790 - val_mae: 409.0790\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.9593 - mae: 410.9593 - val_loss: 410.8369 - val_mae: 410.8369\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.5768 - mae: 410.5768 - val_loss: 414.1461 - val_mae: 414.1461\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.9295 - mae: 409.9295 - val_loss: 408.2188 - val_mae: 408.2188\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.1201 - mae: 411.1201 - val_loss: 407.3515 - val_mae: 407.3515\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.6915 - mae: 409.6915 - val_loss: 409.1475 - val_mae: 409.1475\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.7036 - mae: 410.7036 - val_loss: 406.4613 - val_mae: 406.4613\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.7552 - mae: 408.7552 - val_loss: 408.5282 - val_mae: 408.5282\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.6872 - mae: 409.6872 - val_loss: 410.4691 - val_mae: 410.4691\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.4487 - mae: 409.4487 - val_loss: 404.5500 - val_mae: 404.5500\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.6483 - mae: 408.6483 - val_loss: 404.8291 - val_mae: 404.8291\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.7163 - mae: 407.7163 - val_loss: 405.8107 - val_mae: 405.8107\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.0107 - mae: 409.0107 - val_loss: 409.1012 - val_mae: 409.1012\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.1089 - mae: 409.1089 - val_loss: 405.5518 - val_mae: 405.5518\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.3469 - mae: 408.3469 - val_loss: 405.5473 - val_mae: 405.5473\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.7756 - mae: 407.7756 - val_loss: 406.3253 - val_mae: 406.3253\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.0716 - mae: 407.0716 - val_loss: 407.9752 - val_mae: 407.9752\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.7221 - mae: 406.7221 - val_loss: 408.9629 - val_mae: 408.9629\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.6043 - mae: 407.6043 - val_loss: 406.8185 - val_mae: 406.8185\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.5337 - mae: 407.5337 - val_loss: 402.0106 - val_mae: 402.0106\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.6034 - mae: 405.6034 - val_loss: 406.3026 - val_mae: 406.3026\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.6499 - mae: 405.6499 - val_loss: 412.9487 - val_mae: 412.9487\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.4354 - mae: 405.4354 - val_loss: 401.7572 - val_mae: 401.7572\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.6246 - mae: 405.6246 - val_loss: 408.9528 - val_mae: 408.9528\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.1788 - mae: 406.1788 - val_loss: 402.7860 - val_mae: 402.7860\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1102 - mae: 404.1102 - val_loss: 400.2610 - val_mae: 400.2610\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.7530 - mae: 405.7530 - val_loss: 399.6020 - val_mae: 399.6020\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.2623 - mae: 404.2623 - val_loss: 401.5363 - val_mae: 401.5363\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.4493 - mae: 404.4493 - val_loss: 404.1955 - val_mae: 404.1955\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.8156 - mae: 402.8156 - val_loss: 398.0416 - val_mae: 398.0416\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 404.1122 - mae: 404.1122 - val_loss: 401.3897 - val_mae: 401.3897\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.7477 - mae: 403.7477 - val_loss: 398.6686 - val_mae: 398.6686\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.6941 - mae: 403.6941 - val_loss: 398.4199 - val_mae: 398.4199\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.1885 - mae: 402.1885 - val_loss: 401.4977 - val_mae: 401.4977\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.3987 - mae: 402.3987 - val_loss: 397.8065 - val_mae: 397.8065\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.2717 - mae: 402.2717 - val_loss: 403.6605 - val_mae: 403.6605\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.0519 - mae: 402.0519 - val_loss: 405.0540 - val_mae: 405.0540\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6207 - mae: 402.6207 - val_loss: 401.0990 - val_mae: 401.0990\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.8282 - mae: 402.8282 - val_loss: 399.1320 - val_mae: 399.1320\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6628 - mae: 402.6628 - val_loss: 401.7115 - val_mae: 401.7115\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.2482 - mae: 401.2482 - val_loss: 401.1619 - val_mae: 401.1619\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.3281 - mae: 402.3281 - val_loss: 401.6617 - val_mae: 401.6617\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.1870 - mae: 401.1870 - val_loss: 399.5704 - val_mae: 399.5704\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.3687 - mae: 402.3687 - val_loss: 395.6712 - val_mae: 395.6712\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.9522 - mae: 400.9522 - val_loss: 396.8576 - val_mae: 396.8576\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.5419 - mae: 401.5419 - val_loss: 401.1586 - val_mae: 401.1586\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.0107 - mae: 401.0107 - val_loss: 403.7233 - val_mae: 403.7233\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.4168 - mae: 402.4168 - val_loss: 397.5572 - val_mae: 397.5572\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.5009 - mae: 400.5009 - val_loss: 402.1342 - val_mae: 402.1342\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.3781 - mae: 401.3781 - val_loss: 397.3145 - val_mae: 397.3145\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.8216 - mae: 401.8216 - val_loss: 399.0101 - val_mae: 399.0101\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.4073 - mae: 400.4073 - val_loss: 398.7634 - val_mae: 398.7634\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 400.5936 - mae: 400.5936 - val_loss: 399.3137 - val_mae: 399.3137\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.5694 - mae: 401.5694 - val_loss: 400.0610 - val_mae: 400.0610\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6053.0059 - mae: 6053.0059 - val_loss: 6049.2363 - val_mae: 6049.2363\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6025.1348 - mae: 6025.1348 - val_loss: 5960.2568 - val_mae: 5960.2568\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 5342.7695 - mae: 5342.7695 - val_loss: 3582.0732 - val_mae: 3582.0732\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1043.2867 - mae: 1043.2867 - val_loss: 504.8029 - val_mae: 504.8029\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 501.2983 - mae: 501.2983 - val_loss: 496.1357 - val_mae: 496.1357\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 495.8406 - mae: 495.8406 - val_loss: 494.8498 - val_mae: 494.8498\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 491.2122 - mae: 491.2122 - val_loss: 489.0703 - val_mae: 489.0703\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 488.0811 - mae: 488.0811 - val_loss: 482.6768 - val_mae: 482.6768\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482.7211 - mae: 482.7211 - val_loss: 479.3458 - val_mae: 479.3458\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 475.0097 - mae: 475.0097 - val_loss: 471.6498 - val_mae: 471.6498\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 469.6270 - mae: 469.6270 - val_loss: 464.9799 - val_mae: 464.9799\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 463.7472 - mae: 463.7472 - val_loss: 459.0228 - val_mae: 459.0228\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 459.1082 - mae: 459.1082 - val_loss: 454.8877 - val_mae: 454.8877\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 455.3517 - mae: 455.3517 - val_loss: 452.9797 - val_mae: 452.9797\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452.2097 - mae: 452.2097 - val_loss: 447.1790 - val_mae: 447.1790\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 448.3803 - mae: 448.3803 - val_loss: 445.4686 - val_mae: 445.4686\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444.9387 - mae: 444.9387 - val_loss: 442.6641 - val_mae: 442.6641\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 442.5829 - mae: 442.5829 - val_loss: 439.0302 - val_mae: 439.0302\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440.5023 - mae: 440.5023 - val_loss: 437.0677 - val_mae: 437.0677\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.6337 - mae: 438.6337 - val_loss: 434.1494 - val_mae: 434.1494\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436.6530 - mae: 436.6530 - val_loss: 433.7126 - val_mae: 433.7126\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436.1156 - mae: 436.1156 - val_loss: 432.9576 - val_mae: 432.9576\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 434.8500 - mae: 434.8500 - val_loss: 429.8582 - val_mae: 429.8582\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 434.1103 - mae: 434.1103 - val_loss: 430.9154 - val_mae: 430.9154\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 433.5272 - mae: 433.5272 - val_loss: 430.1131 - val_mae: 430.1131\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431.8432 - mae: 431.8432 - val_loss: 432.9880 - val_mae: 432.9880\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.9402 - mae: 430.9402 - val_loss: 431.1078 - val_mae: 431.1078\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.4141 - mae: 430.4141 - val_loss: 428.0900 - val_mae: 428.0900\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429.8840 - mae: 429.8840 - val_loss: 429.2743 - val_mae: 429.2743\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429.4835 - mae: 429.4835 - val_loss: 427.6500 - val_mae: 427.6500\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.9555 - mae: 427.9555 - val_loss: 427.5841 - val_mae: 427.5841\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.4904 - mae: 427.4904 - val_loss: 426.5478 - val_mae: 426.5478\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.1330 - mae: 427.1330 - val_loss: 429.9474 - val_mae: 429.9474\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.7431 - mae: 427.7431 - val_loss: 426.3813 - val_mae: 426.3813\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426.0405 - mae: 426.0405 - val_loss: 424.0838 - val_mae: 424.0838\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.2698 - mae: 425.2698 - val_loss: 425.7002 - val_mae: 425.7002\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426.5477 - mae: 426.5477 - val_loss: 422.2986 - val_mae: 422.2986\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.3391 - mae: 424.3391 - val_loss: 424.4303 - val_mae: 424.4303\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.8499 - mae: 424.8499 - val_loss: 422.9852 - val_mae: 422.9852\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.9904 - mae: 424.9904 - val_loss: 420.7759 - val_mae: 420.7759\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 423.3743 - mae: 423.3743 - val_loss: 419.9732 - val_mae: 419.9732\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.3604 - mae: 424.3604 - val_loss: 420.9372 - val_mae: 420.9372\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.8594 - mae: 422.8594 - val_loss: 421.2932 - val_mae: 421.2932\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.5250 - mae: 423.5250 - val_loss: 422.9470 - val_mae: 422.9470\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.1275 - mae: 423.1275 - val_loss: 421.5446 - val_mae: 421.5446\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.1059 - mae: 423.1059 - val_loss: 420.5312 - val_mae: 420.5312\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.2070 - mae: 423.2070 - val_loss: 423.2645 - val_mae: 423.2645\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.8510 - mae: 422.8510 - val_loss: 420.3187 - val_mae: 420.3187\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.1497 - mae: 422.1497 - val_loss: 419.5641 - val_mae: 419.5641\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.8131 - mae: 421.8131 - val_loss: 418.7535 - val_mae: 418.7535\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.1309 - mae: 422.1309 - val_loss: 417.4445 - val_mae: 417.4445\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.5617 - mae: 421.5617 - val_loss: 420.2220 - val_mae: 420.2220\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.6760 - mae: 420.6760 - val_loss: 422.3041 - val_mae: 422.3041\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.4823 - mae: 420.4823 - val_loss: 419.6492 - val_mae: 419.6492\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.0289 - mae: 421.0289 - val_loss: 416.5955 - val_mae: 416.5955\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.9377 - mae: 420.9377 - val_loss: 416.6119 - val_mae: 416.6119\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.0411 - mae: 420.0411 - val_loss: 416.2097 - val_mae: 416.2097\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.8014 - mae: 420.8014 - val_loss: 418.8842 - val_mae: 418.8842\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.0257 - mae: 420.0257 - val_loss: 417.3775 - val_mae: 417.3775\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.9620 - mae: 419.9620 - val_loss: 416.8337 - val_mae: 416.8337\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.1188 - mae: 419.1188 - val_loss: 420.0585 - val_mae: 420.0585\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.3859 - mae: 419.3859 - val_loss: 418.4652 - val_mae: 418.4652\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.9938 - mae: 418.9938 - val_loss: 417.2764 - val_mae: 417.2764\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.5237 - mae: 418.5237 - val_loss: 414.2119 - val_mae: 414.2119\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.5340 - mae: 418.5340 - val_loss: 415.3866 - val_mae: 415.3866\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.9113 - mae: 417.9113 - val_loss: 416.1013 - val_mae: 416.1013\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.0348 - mae: 418.0348 - val_loss: 416.4447 - val_mae: 416.4447\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.8743 - mae: 417.8743 - val_loss: 414.9040 - val_mae: 414.9040\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.7345 - mae: 417.7345 - val_loss: 414.5572 - val_mae: 414.5572\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.4731 - mae: 416.4731 - val_loss: 413.3446 - val_mae: 413.3446\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.5854 - mae: 416.5854 - val_loss: 419.5269 - val_mae: 419.5269\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.8125 - mae: 415.8125 - val_loss: 414.5994 - val_mae: 414.5994\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.9889 - mae: 415.9889 - val_loss: 413.2851 - val_mae: 413.2851\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.5536 - mae: 415.5536 - val_loss: 416.4263 - val_mae: 416.4263\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.8989 - mae: 415.8989 - val_loss: 411.6805 - val_mae: 411.6805\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.5931 - mae: 415.5931 - val_loss: 415.0231 - val_mae: 415.0231\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.5602 - mae: 415.5602 - val_loss: 412.3807 - val_mae: 412.3807\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.7291 - mae: 414.7291 - val_loss: 414.0056 - val_mae: 414.0056\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.0679 - mae: 415.0679 - val_loss: 413.3456 - val_mae: 413.3456\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.4689 - mae: 414.4689 - val_loss: 411.8780 - val_mae: 411.8780\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.8057 - mae: 413.8057 - val_loss: 411.2184 - val_mae: 411.2184\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.3719 - mae: 413.3719 - val_loss: 410.2163 - val_mae: 410.2163\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.0638 - mae: 414.0638 - val_loss: 412.3573 - val_mae: 412.3573\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.6335 - mae: 413.6335 - val_loss: 411.8944 - val_mae: 411.8944\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.7845 - mae: 413.7845 - val_loss: 412.2407 - val_mae: 412.2407\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.1535 - mae: 413.1535 - val_loss: 412.0099 - val_mae: 412.0099\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.8613 - mae: 412.8613 - val_loss: 410.9670 - val_mae: 410.9670\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.8978 - mae: 412.8978 - val_loss: 411.2688 - val_mae: 411.2688\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.8623 - mae: 412.8623 - val_loss: 410.6370 - val_mae: 410.6370\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.1809 - mae: 413.1809 - val_loss: 414.8997 - val_mae: 414.8997\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.0179 - mae: 413.0179 - val_loss: 410.2413 - val_mae: 410.2413\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.5501 - mae: 412.5501 - val_loss: 412.5991 - val_mae: 412.5991\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6047.9282 - mae: 6047.9282 - val_loss: 6030.1719 - val_mae: 6030.1719\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5742.3291 - mae: 5742.3291 - val_loss: 4718.0195 - val_mae: 4718.0195\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1454.0325 - mae: 1454.0325 - val_loss: 505.4048 - val_mae: 505.4048\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 504.4026 - mae: 504.4026 - val_loss: 502.7946 - val_mae: 502.7946\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 502.8102 - mae: 502.8102 - val_loss: 497.5540 - val_mae: 497.5540\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 501.5598 - mae: 501.5598 - val_loss: 500.8476 - val_mae: 500.8476\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 499.4810 - mae: 499.4810 - val_loss: 495.1518 - val_mae: 495.1518\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 496.7502 - mae: 496.7502 - val_loss: 493.4930 - val_mae: 493.4930\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 492.6850 - mae: 492.6850 - val_loss: 486.7601 - val_mae: 486.7601\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 488.4366 - mae: 488.4366 - val_loss: 483.2039 - val_mae: 483.2039\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482.2004 - mae: 482.2004 - val_loss: 478.2639 - val_mae: 478.2639\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 476.5436 - mae: 476.5436 - val_loss: 469.8803 - val_mae: 469.8803\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 468.1233 - mae: 468.1233 - val_loss: 465.4776 - val_mae: 465.4776\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 463.2557 - mae: 463.2557 - val_loss: 456.4475 - val_mae: 456.4475\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 456.6854 - mae: 456.6854 - val_loss: 450.2122 - val_mae: 450.2122\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452.5824 - mae: 452.5824 - val_loss: 448.3354 - val_mae: 448.3354\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 450.0103 - mae: 450.0103 - val_loss: 448.7602 - val_mae: 448.7602\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 447.6425 - mae: 447.6425 - val_loss: 443.3974 - val_mae: 443.3974\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 445.6857 - mae: 445.6857 - val_loss: 442.6403 - val_mae: 442.6403\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 445.1580 - mae: 445.1580 - val_loss: 443.4045 - val_mae: 443.4045\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441.8402 - mae: 441.8402 - val_loss: 442.4746 - val_mae: 442.4746\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 442.2466 - mae: 442.2466 - val_loss: 441.0263 - val_mae: 441.0263\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440.5680 - mae: 440.5680 - val_loss: 441.9741 - val_mae: 441.9741\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440.5843 - mae: 440.5843 - val_loss: 437.8049 - val_mae: 437.8049\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.5528 - mae: 439.5528 - val_loss: 439.8750 - val_mae: 439.8750\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.5357 - mae: 439.5357 - val_loss: 439.2234 - val_mae: 439.2234\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.9848 - mae: 438.9848 - val_loss: 443.1806 - val_mae: 443.1806\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.0778 - mae: 439.0778 - val_loss: 434.7917 - val_mae: 434.7917\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 437.7651 - mae: 437.7651 - val_loss: 435.7515 - val_mae: 435.7515\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435.7194 - mae: 435.7194 - val_loss: 437.9410 - val_mae: 437.9410\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435.5311 - mae: 435.5311 - val_loss: 431.6003 - val_mae: 431.6003\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 432.7231 - mae: 432.7231 - val_loss: 432.4309 - val_mae: 432.4309\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 432.5744 - mae: 432.5744 - val_loss: 430.6913 - val_mae: 430.6913\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.5429 - mae: 430.5429 - val_loss: 426.6549 - val_mae: 426.6549\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429.3308 - mae: 429.3308 - val_loss: 428.7434 - val_mae: 428.7434\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.7450 - mae: 428.7450 - val_loss: 424.8340 - val_mae: 424.8340\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.1776 - mae: 427.1776 - val_loss: 424.9273 - val_mae: 424.9273\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.8505 - mae: 425.8505 - val_loss: 421.4512 - val_mae: 421.4512\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.3358 - mae: 425.3358 - val_loss: 422.4664 - val_mae: 422.4664\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.2940 - mae: 424.2940 - val_loss: 425.9477 - val_mae: 425.9477\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.0921 - mae: 424.0921 - val_loss: 421.7254 - val_mae: 421.7254\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 423.6833 - mae: 423.6833 - val_loss: 424.8407 - val_mae: 424.8407\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.2452 - mae: 422.2452 - val_loss: 418.8415 - val_mae: 418.8415\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.3419 - mae: 422.3419 - val_loss: 419.1371 - val_mae: 419.1371\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.7779 - mae: 421.7779 - val_loss: 421.4180 - val_mae: 421.4180\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 420.7953 - mae: 420.7953 - val_loss: 418.5404 - val_mae: 418.5404\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.6338 - mae: 420.6338 - val_loss: 416.8803 - val_mae: 416.8803\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.0603 - mae: 420.0603 - val_loss: 416.0562 - val_mae: 416.0562\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 419.1241 - mae: 419.1241 - val_loss: 417.8357 - val_mae: 417.8357\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.3570 - mae: 419.3570 - val_loss: 416.4643 - val_mae: 416.4643\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.1590 - mae: 418.1590 - val_loss: 417.6996 - val_mae: 417.6996\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.4675 - mae: 417.4675 - val_loss: 419.0327 - val_mae: 419.0327\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.9656 - mae: 417.9656 - val_loss: 413.9503 - val_mae: 413.9503\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.4023 - mae: 417.4023 - val_loss: 417.5723 - val_mae: 417.5723\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.0390 - mae: 418.0390 - val_loss: 413.4864 - val_mae: 413.4864\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.4140 - mae: 417.4140 - val_loss: 414.0109 - val_mae: 414.0109\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.7592 - mae: 416.7592 - val_loss: 415.5724 - val_mae: 415.5724\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.3672 - mae: 417.3672 - val_loss: 414.2437 - val_mae: 414.2437\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.9285 - mae: 416.9285 - val_loss: 411.8100 - val_mae: 411.8100\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 416.6794 - mae: 416.6794 - val_loss: 413.2137 - val_mae: 413.2137\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.0905 - mae: 417.0905 - val_loss: 415.3635 - val_mae: 415.3635\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.2087 - mae: 416.2087 - val_loss: 414.2643 - val_mae: 414.2643\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.3376 - mae: 416.3376 - val_loss: 413.0862 - val_mae: 413.0862\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 416.0433 - mae: 416.0433 - val_loss: 417.5357 - val_mae: 417.5357\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 416.2188 - mae: 416.2188 - val_loss: 415.9561 - val_mae: 415.9561\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.8261 - mae: 414.8261 - val_loss: 415.2574 - val_mae: 415.2574\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.8167 - mae: 415.8167 - val_loss: 412.5979 - val_mae: 412.5979\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.4166 - mae: 415.4166 - val_loss: 411.0395 - val_mae: 411.0395\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.7252 - mae: 414.7252 - val_loss: 415.8194 - val_mae: 415.8194\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 415.4609 - mae: 415.4609 - val_loss: 412.4394 - val_mae: 412.4394\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 415.0764 - mae: 415.0764 - val_loss: 413.6758 - val_mae: 413.6758\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 415.2304 - mae: 415.2304 - val_loss: 415.8686 - val_mae: 415.8686\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.7755 - mae: 414.7755 - val_loss: 412.5435 - val_mae: 412.5435\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.5459 - mae: 414.5459 - val_loss: 413.7002 - val_mae: 413.7002\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.7704 - mae: 414.7704 - val_loss: 411.4092 - val_mae: 411.4092\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.4439 - mae: 414.4439 - val_loss: 412.6537 - val_mae: 412.6537\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.5906 - mae: 414.5906 - val_loss: 412.2011 - val_mae: 412.2011\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.4731 - mae: 414.4731 - val_loss: 413.6074 - val_mae: 413.6074\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3928.2703 - mae: 3928.2703 - val_loss: 529.3813 - val_mae: 529.3813\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 507.6178 - mae: 507.6178 - val_loss: 513.6666 - val_mae: 513.6666\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 493.1879 - mae: 493.1879 - val_loss: 501.3580 - val_mae: 501.3580\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 478.3080 - mae: 478.3080 - val_loss: 483.5727 - val_mae: 483.5727\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 464.1364 - mae: 464.1364 - val_loss: 483.8882 - val_mae: 483.8882\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 457.0353 - mae: 457.0353 - val_loss: 451.7470 - val_mae: 451.7470\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 446.6906 - mae: 446.6906 - val_loss: 449.5393 - val_mae: 449.5393\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 439.6008 - mae: 439.6008 - val_loss: 461.1270 - val_mae: 461.1270\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 435.9474 - mae: 435.9474 - val_loss: 437.5216 - val_mae: 437.5216\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431.7258 - mae: 431.7258 - val_loss: 445.1831 - val_mae: 445.1831\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430.1377 - mae: 430.1377 - val_loss: 441.9023 - val_mae: 441.9023\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 425.9369 - mae: 425.9369 - val_loss: 427.2123 - val_mae: 427.2123\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.7195 - mae: 425.7195 - val_loss: 437.0287 - val_mae: 437.0287\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424.5316 - mae: 424.5316 - val_loss: 423.6101 - val_mae: 423.6101\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 422.1290 - mae: 422.1290 - val_loss: 433.2043 - val_mae: 433.2043\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.7401 - mae: 420.7401 - val_loss: 429.9955 - val_mae: 429.9955\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 420.9194 - mae: 420.9194 - val_loss: 430.4161 - val_mae: 430.4161\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419.0771 - mae: 419.0771 - val_loss: 419.3325 - val_mae: 419.3325\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419.1014 - mae: 419.1014 - val_loss: 418.1115 - val_mae: 418.1115\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.0468 - mae: 418.0468 - val_loss: 419.0312 - val_mae: 419.0312\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 418.2890 - mae: 418.2890 - val_loss: 423.6563 - val_mae: 423.6563\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419.0549 - mae: 419.0549 - val_loss: 424.0198 - val_mae: 424.0198\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 416.5561 - mae: 416.5561 - val_loss: 421.7343 - val_mae: 421.7343\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 415.4343 - mae: 415.4343 - val_loss: 424.7059 - val_mae: 424.7059\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 415.1144 - mae: 415.1144 - val_loss: 417.5426 - val_mae: 417.5426\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 414.3030 - mae: 414.3030 - val_loss: 429.8632 - val_mae: 429.8632\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 415.6594 - mae: 415.6594 - val_loss: 411.3965 - val_mae: 411.3965\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.0713 - mae: 415.0713 - val_loss: 412.0004 - val_mae: 412.0004\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.5462 - mae: 413.5462 - val_loss: 420.9201 - val_mae: 420.9201\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.5556 - mae: 414.5556 - val_loss: 416.0861 - val_mae: 416.0861\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.0638 - mae: 413.0638 - val_loss: 422.5014 - val_mae: 422.5014\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.1908 - mae: 414.1908 - val_loss: 413.4224 - val_mae: 413.4224\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 412.5995 - mae: 412.5995 - val_loss: 416.6104 - val_mae: 416.6104\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.8097 - mae: 413.8097 - val_loss: 420.5350 - val_mae: 420.5350\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.0776 - mae: 413.0776 - val_loss: 420.7366 - val_mae: 420.7366\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.0352 - mae: 414.0352 - val_loss: 413.4665 - val_mae: 413.4665\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.2469 - mae: 413.2469 - val_loss: 421.5536 - val_mae: 421.5536\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 3672.3774 - mae: 3672.3774 - val_loss: 519.0880 - val_mae: 519.0880\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 502.9437 - mae: 502.9437 - val_loss: 531.4200 - val_mae: 531.4200\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 493.1798 - mae: 493.1798 - val_loss: 495.6818 - val_mae: 495.6818\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 481.9323 - mae: 481.9323 - val_loss: 501.5091 - val_mae: 501.5091\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 467.2305 - mae: 467.2305 - val_loss: 480.4411 - val_mae: 480.4411\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 455.7390 - mae: 455.7390 - val_loss: 470.2183 - val_mae: 470.2183\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 443.3961 - mae: 443.3961 - val_loss: 466.2610 - val_mae: 466.2610\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 439.3656 - mae: 439.3656 - val_loss: 457.6550 - val_mae: 457.6550\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433.3546 - mae: 433.3546 - val_loss: 436.2430 - val_mae: 436.2430\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430.8041 - mae: 430.8041 - val_loss: 438.8985 - val_mae: 438.8985\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 429.5770 - mae: 429.5770 - val_loss: 427.5135 - val_mae: 427.5135\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 426.3694 - mae: 426.3694 - val_loss: 437.3304 - val_mae: 437.3304\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.2184 - mae: 425.2184 - val_loss: 453.3193 - val_mae: 453.3193\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.0632 - mae: 423.0632 - val_loss: 434.9890 - val_mae: 434.9890\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.1870 - mae: 421.1870 - val_loss: 446.9039 - val_mae: 446.9039\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.6048 - mae: 420.6048 - val_loss: 445.8300 - val_mae: 445.8300\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419.6699 - mae: 419.6699 - val_loss: 438.6119 - val_mae: 438.6119\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 418.7979 - mae: 418.7979 - val_loss: 423.8885 - val_mae: 423.8885\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.6312 - mae: 416.6312 - val_loss: 455.2233 - val_mae: 455.2233\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.6431 - mae: 415.6431 - val_loss: 410.5506 - val_mae: 410.5506\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.0441 - mae: 416.0441 - val_loss: 432.3884 - val_mae: 432.3884\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.8244 - mae: 413.8244 - val_loss: 422.7336 - val_mae: 422.7336\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.1801 - mae: 413.1801 - val_loss: 416.3243 - val_mae: 416.3243\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.4305 - mae: 411.4305 - val_loss: 417.3136 - val_mae: 417.3136\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.5969 - mae: 410.5969 - val_loss: 408.9731 - val_mae: 408.9731\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.9898 - mae: 409.9898 - val_loss: 425.0157 - val_mae: 425.0157\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.1718 - mae: 410.1718 - val_loss: 411.7259 - val_mae: 411.7259\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.6714 - mae: 409.6714 - val_loss: 432.0995 - val_mae: 432.0995\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 410.3180 - mae: 410.3180 - val_loss: 414.1975 - val_mae: 414.1975\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 408.4595 - mae: 408.4595 - val_loss: 416.3846 - val_mae: 416.3846\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 407.4341 - mae: 407.4341 - val_loss: 423.9149 - val_mae: 423.9149\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 406.9692 - mae: 406.9692 - val_loss: 420.7216 - val_mae: 420.7216\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 407.8785 - mae: 407.8785 - val_loss: 419.1922 - val_mae: 419.1922\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.1005 - mae: 407.1005 - val_loss: 427.0698 - val_mae: 427.0698\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 408.0336 - mae: 408.0336 - val_loss: 423.7354 - val_mae: 423.7354\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6042.7227 - mae: 6042.7227 - val_loss: 5985.7563 - val_mae: 5985.7563\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3488.3569 - mae: 3488.3569 - val_loss: 527.3788 - val_mae: 527.3788\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 510.6275 - mae: 510.6275 - val_loss: 499.5397 - val_mae: 499.5397\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 501.9469 - mae: 501.9469 - val_loss: 510.5931 - val_mae: 510.5931\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 497.5534 - mae: 497.5534 - val_loss: 487.0201 - val_mae: 487.0201\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 485.8011 - mae: 485.8011 - val_loss: 484.7289 - val_mae: 484.7289\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 472.7313 - mae: 472.7313 - val_loss: 463.8256 - val_mae: 463.8256\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 461.4407 - mae: 461.4407 - val_loss: 452.9938 - val_mae: 452.9938\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 449.8050 - mae: 449.8050 - val_loss: 449.8087 - val_mae: 449.8087\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442.9468 - mae: 442.9468 - val_loss: 431.9908 - val_mae: 431.9908\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436.3978 - mae: 436.3978 - val_loss: 431.4663 - val_mae: 431.4663\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432.7624 - mae: 432.7624 - val_loss: 430.1860 - val_mae: 430.1860\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 430.2307 - mae: 430.2307 - val_loss: 431.8033 - val_mae: 431.8033\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 427.1707 - mae: 427.1707 - val_loss: 430.8891 - val_mae: 430.8891\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426.3110 - mae: 426.3110 - val_loss: 421.1537 - val_mae: 421.1537\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423.7091 - mae: 423.7091 - val_loss: 417.9802 - val_mae: 417.9802\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.5337 - mae: 421.5337 - val_loss: 416.8599 - val_mae: 416.8599\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.6831 - mae: 419.6831 - val_loss: 420.6562 - val_mae: 420.6562\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.1193 - mae: 420.1193 - val_loss: 416.1648 - val_mae: 416.1648\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.8653 - mae: 417.8653 - val_loss: 415.5476 - val_mae: 415.5476\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.0932 - mae: 418.0932 - val_loss: 414.2516 - val_mae: 414.2516\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.2732 - mae: 415.2732 - val_loss: 416.2704 - val_mae: 416.2704\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.0696 - mae: 416.0696 - val_loss: 413.8749 - val_mae: 413.8749\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 413.9166 - mae: 413.9166 - val_loss: 413.9648 - val_mae: 413.9648\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.0293 - mae: 414.0293 - val_loss: 417.9722 - val_mae: 417.9722\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.8713 - mae: 412.8713 - val_loss: 413.1934 - val_mae: 413.1934\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.2109 - mae: 412.2109 - val_loss: 412.2364 - val_mae: 412.2364\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.8412 - mae: 412.8412 - val_loss: 408.3793 - val_mae: 408.3793\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.4225 - mae: 410.4225 - val_loss: 409.2425 - val_mae: 409.2425\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.0686 - mae: 411.0686 - val_loss: 414.1020 - val_mae: 414.1020\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 410.1969 - mae: 410.1969 - val_loss: 412.2646 - val_mae: 412.2646\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.6466 - mae: 409.6466 - val_loss: 409.7568 - val_mae: 409.7568\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.7525 - mae: 409.7525 - val_loss: 406.7857 - val_mae: 406.7857\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.0275 - mae: 409.0275 - val_loss: 407.5338 - val_mae: 407.5338\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.7888 - mae: 409.7888 - val_loss: 405.3723 - val_mae: 405.3723\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.2464 - mae: 408.2464 - val_loss: 406.3561 - val_mae: 406.3561\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.5445 - mae: 408.5445 - val_loss: 407.1112 - val_mae: 407.1112\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.2164 - mae: 407.2164 - val_loss: 408.3233 - val_mae: 408.3233\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.1385 - mae: 407.1385 - val_loss: 405.4300 - val_mae: 405.4300\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.3530 - mae: 406.3530 - val_loss: 404.2259 - val_mae: 404.2259\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.3867 - mae: 406.3867 - val_loss: 400.9807 - val_mae: 400.9807\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.2497 - mae: 406.2497 - val_loss: 403.8523 - val_mae: 403.8523\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.4746 - mae: 405.4746 - val_loss: 401.7006 - val_mae: 401.7006\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.7586 - mae: 404.7586 - val_loss: 399.8893 - val_mae: 399.8893\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.7712 - mae: 403.7712 - val_loss: 402.0421 - val_mae: 402.0421\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.2937 - mae: 403.2937 - val_loss: 407.0052 - val_mae: 407.0052\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.2894 - mae: 404.2894 - val_loss: 402.7560 - val_mae: 402.7560\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1122 - mae: 404.1122 - val_loss: 406.8347 - val_mae: 406.8347\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1351 - mae: 404.1351 - val_loss: 400.0552 - val_mae: 400.0552\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.1535 - mae: 403.1535 - val_loss: 401.1392 - val_mae: 401.1392\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.7736 - mae: 403.7736 - val_loss: 407.9218 - val_mae: 407.9218\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6677 - mae: 402.6677 - val_loss: 399.1581 - val_mae: 399.1581\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.2393 - mae: 403.2393 - val_loss: 400.3785 - val_mae: 400.3785\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.9093 - mae: 401.9093 - val_loss: 402.6921 - val_mae: 402.6921\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.7146 - mae: 401.7146 - val_loss: 403.6920 - val_mae: 403.6920\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 401.7542 - mae: 401.7542 - val_loss: 403.9642 - val_mae: 403.9642\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 401.6908 - mae: 401.6908 - val_loss: 401.6993 - val_mae: 401.6993\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.7546 - mae: 401.7546 - val_loss: 399.2184 - val_mae: 399.2184\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 401.8008 - mae: 401.8008 - val_loss: 401.8478 - val_mae: 401.8478\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 402.3427 - mae: 402.3427 - val_loss: 397.7560 - val_mae: 397.7560\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.8745 - mae: 400.8745 - val_loss: 399.1927 - val_mae: 399.1927\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.8286 - mae: 401.8286 - val_loss: 400.5986 - val_mae: 400.5986\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.7323 - mae: 399.7323 - val_loss: 400.7112 - val_mae: 400.7112\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.1279 - mae: 401.1279 - val_loss: 398.2165 - val_mae: 398.2165\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.9529 - mae: 400.9529 - val_loss: 399.9268 - val_mae: 399.9268\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.4809 - mae: 401.4809 - val_loss: 400.3236 - val_mae: 400.3236\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.4075 - mae: 401.4075 - val_loss: 401.9266 - val_mae: 401.9266\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.8719 - mae: 401.8719 - val_loss: 397.1246 - val_mae: 397.1246\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 399.8004 - mae: 399.8004 - val_loss: 402.2192 - val_mae: 402.2192\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.0471 - mae: 400.0471 - val_loss: 400.4874 - val_mae: 400.4874\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.5974 - mae: 399.5974 - val_loss: 401.7477 - val_mae: 401.7477\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.0043 - mae: 401.0043 - val_loss: 399.2067 - val_mae: 399.2067\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.4202 - mae: 399.4202 - val_loss: 396.3128 - val_mae: 396.3128\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 400.4697 - mae: 400.4697 - val_loss: 399.0447 - val_mae: 399.0447\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 2s 5ms/step - loss: 400.5470 - mae: 400.5470 - val_loss: 397.8318 - val_mae: 397.8318\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 400.6194 - mae: 400.6194 - val_loss: 399.3238 - val_mae: 399.3238\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 401.0335 - mae: 401.0335 - val_loss: 395.7488 - val_mae: 395.7488\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 2s 5ms/step - loss: 399.5111 - mae: 399.5111 - val_loss: 397.3162 - val_mae: 397.3162\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 399.9710 - mae: 399.9710 - val_loss: 400.9505 - val_mae: 400.9505\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 400.6739 - mae: 400.6739 - val_loss: 399.4314 - val_mae: 399.4314\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 399.9775 - mae: 399.9775 - val_loss: 399.1322 - val_mae: 399.1322\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.3863 - mae: 400.3863 - val_loss: 400.5339 - val_mae: 400.5339\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.8653 - mae: 399.8653 - val_loss: 397.5860 - val_mae: 397.5860\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.1255 - mae: 399.1255 - val_loss: 397.3615 - val_mae: 397.3615\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.8743 - mae: 399.8743 - val_loss: 397.0281 - val_mae: 397.0281\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.5416 - mae: 399.5416 - val_loss: 395.7589 - val_mae: 395.7589\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.2077 - mae: 399.2077 - val_loss: 398.0828 - val_mae: 398.0828\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 5939.8613 - mae: 5939.8613 - val_loss: 5093.8379 - val_mae: 5093.8379\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1170.8452 - mae: 1170.8452 - val_loss: 516.5892 - val_mae: 516.5892\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 512.4477 - mae: 512.4477 - val_loss: 505.8834 - val_mae: 505.8834\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 507.3712 - mae: 507.3712 - val_loss: 501.4158 - val_mae: 501.4158\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 503.3737 - mae: 503.3737 - val_loss: 494.5763 - val_mae: 494.5763\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 493.3879 - mae: 493.3879 - val_loss: 490.7220 - val_mae: 490.7220\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 479.9639 - mae: 479.9639 - val_loss: 469.2016 - val_mae: 469.2016\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 465.7778 - mae: 465.7778 - val_loss: 457.8144 - val_mae: 457.8144\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 456.0523 - mae: 456.0523 - val_loss: 453.7550 - val_mae: 453.7550\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 452.1646 - mae: 452.1646 - val_loss: 453.2065 - val_mae: 453.2065\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 449.0315 - mae: 449.0315 - val_loss: 448.5162 - val_mae: 448.5162\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 445.4724 - mae: 445.4724 - val_loss: 443.7225 - val_mae: 443.7225\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 444.0256 - mae: 444.0256 - val_loss: 437.5265 - val_mae: 437.5265\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 443.1016 - mae: 443.1016 - val_loss: 437.2714 - val_mae: 437.2714\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442.3730 - mae: 442.3730 - val_loss: 438.7258 - val_mae: 438.7258\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 440.0024 - mae: 440.0024 - val_loss: 436.0111 - val_mae: 436.0111\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437.4563 - mae: 437.4563 - val_loss: 438.0705 - val_mae: 438.0705\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 435.3560 - mae: 435.3560 - val_loss: 435.0548 - val_mae: 435.0548\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 433.4396 - mae: 433.4396 - val_loss: 430.6960 - val_mae: 430.6960\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 431.0500 - mae: 431.0500 - val_loss: 425.1778 - val_mae: 425.1778\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 428.7812 - mae: 428.7812 - val_loss: 426.6366 - val_mae: 426.6366\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426.6427 - mae: 426.6427 - val_loss: 425.1508 - val_mae: 425.1508\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.3832 - mae: 424.3832 - val_loss: 426.0988 - val_mae: 426.0988\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.3824 - mae: 424.3824 - val_loss: 432.0229 - val_mae: 432.0229\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422.8548 - mae: 422.8548 - val_loss: 425.3939 - val_mae: 425.3939\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.7903 - mae: 421.7903 - val_loss: 417.9822 - val_mae: 417.9822\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.4135 - mae: 419.4135 - val_loss: 415.5788 - val_mae: 415.5788\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.4803 - mae: 417.4803 - val_loss: 419.0201 - val_mae: 419.0201\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.2189 - mae: 417.2189 - val_loss: 413.2734 - val_mae: 413.2734\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.7625 - mae: 414.7625 - val_loss: 412.9782 - val_mae: 412.9782\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413.7036 - mae: 413.7036 - val_loss: 407.2670 - val_mae: 407.2670\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.5812 - mae: 412.5812 - val_loss: 412.2878 - val_mae: 412.2878\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.9419 - mae: 411.9419 - val_loss: 409.7487 - val_mae: 409.7487\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.2375 - mae: 411.2375 - val_loss: 409.9231 - val_mae: 409.9231\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.5505 - mae: 408.5505 - val_loss: 404.6652 - val_mae: 404.6652\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.5578 - mae: 408.5578 - val_loss: 403.3304 - val_mae: 403.3304\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.0848 - mae: 408.0848 - val_loss: 409.6218 - val_mae: 409.6218\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.2334 - mae: 408.2334 - val_loss: 410.4112 - val_mae: 410.4112\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.4333 - mae: 406.4333 - val_loss: 414.0824 - val_mae: 414.0824\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.5869 - mae: 405.5869 - val_loss: 403.9472 - val_mae: 403.9472\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.1086 - mae: 406.1086 - val_loss: 402.3027 - val_mae: 402.3027\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.3290 - mae: 405.3290 - val_loss: 407.1657 - val_mae: 407.1657\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.1722 - mae: 406.1722 - val_loss: 407.2754 - val_mae: 407.2754\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.5405 - mae: 404.5405 - val_loss: 408.7070 - val_mae: 408.7070\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.3311 - mae: 404.3311 - val_loss: 404.2592 - val_mae: 404.2592\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1017 - mae: 404.1017 - val_loss: 404.5340 - val_mae: 404.5340\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.3123 - mae: 404.3123 - val_loss: 411.8170 - val_mae: 411.8170\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1147 - mae: 404.1147 - val_loss: 399.5584 - val_mae: 399.5584\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.5341 - mae: 404.5341 - val_loss: 400.2492 - val_mae: 400.2492\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.5845 - mae: 403.5845 - val_loss: 404.2775 - val_mae: 404.2775\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.4329 - mae: 403.4329 - val_loss: 403.8734 - val_mae: 403.8734\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.5986 - mae: 402.5986 - val_loss: 401.1960 - val_mae: 401.1960\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.1420 - mae: 403.1420 - val_loss: 404.6870 - val_mae: 404.6870\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.7384 - mae: 402.7384 - val_loss: 399.5267 - val_mae: 399.5267\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.5276 - mae: 402.5276 - val_loss: 405.2985 - val_mae: 405.2985\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.8803 - mae: 402.8803 - val_loss: 404.7988 - val_mae: 404.7988\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.4999 - mae: 401.4999 - val_loss: 401.0387 - val_mae: 401.0387\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.3438 - mae: 402.3438 - val_loss: 403.1550 - val_mae: 403.1550\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.6651 - mae: 400.6651 - val_loss: 401.0914 - val_mae: 401.0914\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.3432 - mae: 401.3432 - val_loss: 400.8805 - val_mae: 400.8805\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.7787 - mae: 400.7787 - val_loss: 394.8021 - val_mae: 394.8021\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.4261 - mae: 400.4261 - val_loss: 404.0966 - val_mae: 404.0966\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.9081 - mae: 400.9081 - val_loss: 401.2016 - val_mae: 401.2016\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.8524 - mae: 400.8524 - val_loss: 409.9893 - val_mae: 409.9893\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.3635 - mae: 401.3635 - val_loss: 399.4050 - val_mae: 399.4050\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.6976 - mae: 400.6976 - val_loss: 403.3383 - val_mae: 403.3383\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.3519 - mae: 400.3519 - val_loss: 400.8527 - val_mae: 400.8527\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 400.5660 - mae: 400.5660 - val_loss: 401.8250 - val_mae: 401.8250\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.1149 - mae: 400.1149 - val_loss: 399.7830 - val_mae: 399.7830\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.7875 - mae: 399.7875 - val_loss: 398.7545 - val_mae: 398.7545\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.4171 - mae: 399.4171 - val_loss: 398.5251 - val_mae: 398.5251\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6049.8101 - mae: 6049.8101 - val_loss: 6040.6719 - val_mae: 6040.6719\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5972.6733 - mae: 5972.6733 - val_loss: 5786.3994 - val_mae: 5786.3994\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4098.4526 - mae: 4098.4526 - val_loss: 747.9313 - val_mae: 747.9313\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.8958 - mae: 534.8958 - val_loss: 500.4328 - val_mae: 500.4328\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 497.5851 - mae: 497.5851 - val_loss: 490.9506 - val_mae: 490.9506\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 491.7897 - mae: 491.7897 - val_loss: 488.7249 - val_mae: 488.7249\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 487.7120 - mae: 487.7120 - val_loss: 483.2168 - val_mae: 483.2168\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 483.8168 - mae: 483.8168 - val_loss: 479.6172 - val_mae: 479.6172\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482.4376 - mae: 482.4376 - val_loss: 478.0283 - val_mae: 478.0283\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 478.4074 - mae: 478.4074 - val_loss: 479.0946 - val_mae: 479.0946\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 478.8596 - mae: 478.8596 - val_loss: 473.2950 - val_mae: 473.2950\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 475.3147 - mae: 475.3147 - val_loss: 474.1543 - val_mae: 474.1543\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 471.9395 - mae: 471.9395 - val_loss: 467.4137 - val_mae: 467.4137\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 470.0095 - mae: 470.0095 - val_loss: 466.3047 - val_mae: 466.3047\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 466.6723 - mae: 466.6723 - val_loss: 465.2158 - val_mae: 465.2158\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 464.4006 - mae: 464.4006 - val_loss: 461.1100 - val_mae: 461.1100\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 461.0167 - mae: 461.0167 - val_loss: 457.7050 - val_mae: 457.7050\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 458.8579 - mae: 458.8579 - val_loss: 458.5715 - val_mae: 458.5715\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 457.5888 - mae: 457.5888 - val_loss: 456.8303 - val_mae: 456.8303\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 454.9608 - mae: 454.9608 - val_loss: 451.9056 - val_mae: 451.9056\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 452.6715 - mae: 452.6715 - val_loss: 448.9949 - val_mae: 448.9949\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 449.6033 - mae: 449.6033 - val_loss: 447.9280 - val_mae: 447.9280\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 447.6373 - mae: 447.6373 - val_loss: 444.5769 - val_mae: 444.5769\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444.7986 - mae: 444.7986 - val_loss: 440.3568 - val_mae: 440.3568\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 443.3887 - mae: 443.3887 - val_loss: 439.9267 - val_mae: 439.9267\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441.1233 - mae: 441.1233 - val_loss: 437.3467 - val_mae: 437.3467\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 438.3874 - mae: 438.3874 - val_loss: 436.6500 - val_mae: 436.6500\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436.0471 - mae: 436.0471 - val_loss: 432.5851 - val_mae: 432.5851\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 434.2608 - mae: 434.2608 - val_loss: 430.1031 - val_mae: 430.1031\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431.5512 - mae: 431.5512 - val_loss: 428.5264 - val_mae: 428.5264\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.5123 - mae: 430.5123 - val_loss: 424.6473 - val_mae: 424.6473\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.2599 - mae: 428.2599 - val_loss: 424.4226 - val_mae: 424.4226\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 425.8795 - mae: 425.8795 - val_loss: 425.1181 - val_mae: 425.1181\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.4534 - mae: 425.4534 - val_loss: 421.8917 - val_mae: 421.8917\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.0311 - mae: 423.0311 - val_loss: 421.9773 - val_mae: 421.9773\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 421.9611 - mae: 421.9611 - val_loss: 419.5223 - val_mae: 419.5223\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.6998 - mae: 420.6998 - val_loss: 417.5217 - val_mae: 417.5217\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.2892 - mae: 419.2892 - val_loss: 420.4876 - val_mae: 420.4876\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.6646 - mae: 417.6646 - val_loss: 417.4265 - val_mae: 417.4265\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.7498 - mae: 417.7498 - val_loss: 412.2823 - val_mae: 412.2823\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.2052 - mae: 416.2052 - val_loss: 412.1533 - val_mae: 412.1533\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.8623 - mae: 415.8623 - val_loss: 411.6523 - val_mae: 411.6523\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.7658 - mae: 414.7658 - val_loss: 411.1454 - val_mae: 411.1454\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.7880 - mae: 413.7880 - val_loss: 412.0698 - val_mae: 412.0698\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.5727 - mae: 413.5727 - val_loss: 410.6154 - val_mae: 410.6154\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.2821 - mae: 412.2821 - val_loss: 409.8849 - val_mae: 409.8849\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.0002 - mae: 412.0002 - val_loss: 411.7967 - val_mae: 411.7967\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.3885 - mae: 412.3885 - val_loss: 408.7189 - val_mae: 408.7189\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 410.8005 - mae: 410.8005 - val_loss: 409.5593 - val_mae: 409.5593\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.0589 - mae: 410.0589 - val_loss: 408.4614 - val_mae: 408.4614\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.3297 - mae: 409.3297 - val_loss: 406.8370 - val_mae: 406.8370\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 409.4084 - mae: 409.4084 - val_loss: 407.1351 - val_mae: 407.1351\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 408.9421 - mae: 408.9421 - val_loss: 405.3150 - val_mae: 405.3150\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 408.7584 - mae: 408.7584 - val_loss: 407.8422 - val_mae: 407.8422\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.5263 - mae: 407.5263 - val_loss: 405.5125 - val_mae: 405.5125\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 408.1194 - mae: 408.1194 - val_loss: 408.5069 - val_mae: 408.5069\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 407.3828 - mae: 407.3828 - val_loss: 404.4884 - val_mae: 404.4884\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.6022 - mae: 407.6022 - val_loss: 405.6455 - val_mae: 405.6455\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 407.3739 - mae: 407.3739 - val_loss: 405.5517 - val_mae: 405.5517\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 406.9079 - mae: 406.9079 - val_loss: 405.0525 - val_mae: 405.0525\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.8192 - mae: 406.8192 - val_loss: 404.3436 - val_mae: 404.3436\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 406.7018 - mae: 406.7018 - val_loss: 406.9848 - val_mae: 406.9848\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.2748 - mae: 407.2748 - val_loss: 402.4712 - val_mae: 402.4712\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.6667 - mae: 405.6667 - val_loss: 406.1250 - val_mae: 406.1250\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 406.2057 - mae: 406.2057 - val_loss: 403.3811 - val_mae: 403.3811\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 405.2928 - mae: 405.2928 - val_loss: 407.2351 - val_mae: 407.2351\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.1655 - mae: 406.1655 - val_loss: 405.0380 - val_mae: 405.0380\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.5670 - mae: 405.5670 - val_loss: 404.2286 - val_mae: 404.2286\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.6293 - mae: 405.6293 - val_loss: 403.3793 - val_mae: 403.3793\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 405.3537 - mae: 405.3537 - val_loss: 404.1959 - val_mae: 404.1959\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 405.1233 - mae: 405.1233 - val_loss: 406.3928 - val_mae: 406.3928\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 404.2358 - mae: 404.2358 - val_loss: 403.2766 - val_mae: 403.2766\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.5496 - mae: 404.5496 - val_loss: 402.5600 - val_mae: 402.5600\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6046.9678 - mae: 6046.9678 - val_loss: 6027.6934 - val_mae: 6027.6934\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 5728.5005 - mae: 5728.5005 - val_loss: 4686.1421 - val_mae: 4686.1421\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1474.9189 - mae: 1474.9189 - val_loss: 508.2909 - val_mae: 508.2909\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 505.2892 - mae: 505.2892 - val_loss: 503.3055 - val_mae: 503.3055\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 499.5247 - mae: 499.5247 - val_loss: 495.0155 - val_mae: 495.0155\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 495.0980 - mae: 495.0980 - val_loss: 488.0697 - val_mae: 488.0697\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 487.3738 - mae: 487.3738 - val_loss: 487.2895 - val_mae: 487.2895\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 481.7823 - mae: 481.7823 - val_loss: 477.9915 - val_mae: 477.9915\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 476.5317 - mae: 476.5317 - val_loss: 470.4368 - val_mae: 470.4368\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 473.1917 - mae: 473.1917 - val_loss: 472.5620 - val_mae: 472.5620\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 471.0985 - mae: 471.0985 - val_loss: 466.5455 - val_mae: 466.5455\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 466.8576 - mae: 466.8576 - val_loss: 469.9118 - val_mae: 469.9118\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 463.4942 - mae: 463.4942 - val_loss: 465.8581 - val_mae: 465.8581\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 460.5645 - mae: 460.5645 - val_loss: 455.9243 - val_mae: 455.9243\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 456.0960 - mae: 456.0960 - val_loss: 451.1233 - val_mae: 451.1233\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452.7360 - mae: 452.7360 - val_loss: 453.8605 - val_mae: 453.8605\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 449.2960 - mae: 449.2960 - val_loss: 445.8712 - val_mae: 445.8712\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 447.5411 - mae: 447.5411 - val_loss: 446.9206 - val_mae: 446.9206\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 446.2631 - mae: 446.2631 - val_loss: 445.6272 - val_mae: 445.6272\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444.6725 - mae: 444.6725 - val_loss: 443.5216 - val_mae: 443.5216\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444.0345 - mae: 444.0345 - val_loss: 440.3690 - val_mae: 440.3690\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 442.4481 - mae: 442.4481 - val_loss: 440.0181 - val_mae: 440.0181\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441.3534 - mae: 441.3534 - val_loss: 441.1731 - val_mae: 441.1731\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440.8347 - mae: 440.8347 - val_loss: 435.7744 - val_mae: 435.7744\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.0577 - mae: 439.0577 - val_loss: 441.2032 - val_mae: 441.2032\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.9648 - mae: 439.9648 - val_loss: 434.5776 - val_mae: 434.5776\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.5549 - mae: 438.5549 - val_loss: 441.6848 - val_mae: 441.6848\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438.4399 - mae: 438.4399 - val_loss: 442.5784 - val_mae: 442.5784\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 437.3359 - mae: 437.3359 - val_loss: 438.5092 - val_mae: 438.5092\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436.9838 - mae: 436.9838 - val_loss: 434.6585 - val_mae: 434.6585\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436.9520 - mae: 436.9520 - val_loss: 435.0099 - val_mae: 435.0099\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435.0711 - mae: 435.0711 - val_loss: 431.8528 - val_mae: 431.8528\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 432.3488 - mae: 432.3488 - val_loss: 430.9922 - val_mae: 430.9922\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.6488 - mae: 430.6488 - val_loss: 428.7415 - val_mae: 428.7415\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.9113 - mae: 428.9113 - val_loss: 424.7743 - val_mae: 424.7743\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.5948 - mae: 427.5948 - val_loss: 426.9579 - val_mae: 426.9579\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.9598 - mae: 425.9598 - val_loss: 424.3564 - val_mae: 424.3564\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.7007 - mae: 424.7007 - val_loss: 423.7959 - val_mae: 423.7959\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.4897 - mae: 424.4897 - val_loss: 422.5764 - val_mae: 422.5764\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.3640 - mae: 423.3640 - val_loss: 419.0492 - val_mae: 419.0492\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.3096 - mae: 422.3096 - val_loss: 419.2293 - val_mae: 419.2293\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.2443 - mae: 421.2443 - val_loss: 418.6190 - val_mae: 418.6190\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.3688 - mae: 420.3688 - val_loss: 416.5687 - val_mae: 416.5687\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.6651 - mae: 418.6651 - val_loss: 415.0337 - val_mae: 415.0337\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.2568 - mae: 418.2568 - val_loss: 414.2122 - val_mae: 414.2122\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.0919 - mae: 417.0919 - val_loss: 415.1540 - val_mae: 415.1540\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 415.6114 - mae: 415.6114 - val_loss: 415.7042 - val_mae: 415.7042\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 415.5975 - mae: 415.5975 - val_loss: 412.6442 - val_mae: 412.6442\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 415.1010 - mae: 415.1010 - val_loss: 412.5744 - val_mae: 412.5744\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 414.2776 - mae: 414.2776 - val_loss: 412.9641 - val_mae: 412.9641\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.8515 - mae: 412.8515 - val_loss: 414.4243 - val_mae: 414.4243\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.5249 - mae: 413.5249 - val_loss: 412.5070 - val_mae: 412.5070\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 412.8845 - mae: 412.8845 - val_loss: 408.4656 - val_mae: 408.4656\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.6091 - mae: 412.6091 - val_loss: 410.4825 - val_mae: 410.4825\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.6487 - mae: 411.6487 - val_loss: 411.7163 - val_mae: 411.7163\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.6063 - mae: 412.6063 - val_loss: 415.9674 - val_mae: 415.9674\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.6488 - mae: 411.6488 - val_loss: 408.8031 - val_mae: 408.8031\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.9588 - mae: 411.9588 - val_loss: 410.3361 - val_mae: 410.3361\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.6712 - mae: 411.6712 - val_loss: 411.6164 - val_mae: 411.6164\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.5695 - mae: 410.5695 - val_loss: 410.7247 - val_mae: 410.7247\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.6941 - mae: 411.6941 - val_loss: 409.0851 - val_mae: 409.0851\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 410.5399 - mae: 410.5399 - val_loss: 407.6714 - val_mae: 407.6714\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.1657 - mae: 410.1657 - val_loss: 409.4209 - val_mae: 409.4209\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 410.6396 - mae: 410.6396 - val_loss: 410.6730 - val_mae: 410.6730\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 409.8822 - mae: 409.8822 - val_loss: 407.0691 - val_mae: 407.0691\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.5177 - mae: 410.5177 - val_loss: 407.1162 - val_mae: 407.1162\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.8205 - mae: 409.8205 - val_loss: 406.4317 - val_mae: 406.4317\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 409.6342 - mae: 409.6342 - val_loss: 409.4588 - val_mae: 409.4588\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.5483 - mae: 409.5483 - val_loss: 408.0596 - val_mae: 408.0596\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 409.2653 - mae: 409.2653 - val_loss: 406.0549 - val_mae: 406.0549\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 409.0538 - mae: 409.0538 - val_loss: 406.2296 - val_mae: 406.2296\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.4853 - mae: 408.4853 - val_loss: 405.1069 - val_mae: 405.1069\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 408.9681 - mae: 408.9681 - val_loss: 404.5396 - val_mae: 404.5396\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.6660 - mae: 408.6660 - val_loss: 408.8005 - val_mae: 408.8005\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.4823 - mae: 408.4823 - val_loss: 406.8036 - val_mae: 406.8036\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.9680 - mae: 407.9680 - val_loss: 408.6700 - val_mae: 408.6700\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 408.4757 - mae: 408.4757 - val_loss: 406.7480 - val_mae: 406.7480\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.0524 - mae: 407.0524 - val_loss: 407.8605 - val_mae: 407.8605\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.0144 - mae: 408.0144 - val_loss: 409.5677 - val_mae: 409.5677\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.5620 - mae: 407.5620 - val_loss: 404.1080 - val_mae: 404.1080\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.6225 - mae: 407.6225 - val_loss: 405.4527 - val_mae: 405.4527\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 406.6269 - mae: 406.6269 - val_loss: 403.2931 - val_mae: 403.2931\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.0194 - mae: 406.0194 - val_loss: 404.9277 - val_mae: 404.9277\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.6440 - mae: 406.6440 - val_loss: 406.3768 - val_mae: 406.3768\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.4800 - mae: 406.4800 - val_loss: 405.8852 - val_mae: 405.8852\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.5496 - mae: 406.5496 - val_loss: 405.0488 - val_mae: 405.0488\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.4340 - mae: 405.4340 - val_loss: 404.4551 - val_mae: 404.4551\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.0346 - mae: 406.0346 - val_loss: 408.1602 - val_mae: 408.1602\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.2512 - mae: 406.2512 - val_loss: 408.3298 - val_mae: 408.3298\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.4504 - mae: 406.4504 - val_loss: 402.2783 - val_mae: 402.2783\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 405.5047 - mae: 405.5047 - val_loss: 405.1282 - val_mae: 405.1282\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 405.7298 - mae: 405.7298 - val_loss: 402.1260 - val_mae: 402.1260\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.6730 - mae: 405.6730 - val_loss: 404.1432 - val_mae: 404.1432\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.1424 - mae: 406.1424 - val_loss: 405.2658 - val_mae: 405.2658\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.2953 - mae: 405.2953 - val_loss: 403.3850 - val_mae: 403.3850\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 405.6962 - mae: 405.6962 - val_loss: 402.6259 - val_mae: 402.6259\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.5979 - mae: 404.5979 - val_loss: 404.6988 - val_mae: 404.6988\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 405.2701 - mae: 405.2701 - val_loss: 408.3423 - val_mae: 408.3423\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.2954 - mae: 405.2954 - val_loss: 400.8307 - val_mae: 400.8307\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.1675 - mae: 404.1675 - val_loss: 405.8759 - val_mae: 405.8759\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.5857 - mae: 404.5857 - val_loss: 405.9742 - val_mae: 405.9742\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 404.0107 - mae: 404.0107 - val_loss: 403.7080 - val_mae: 403.7080\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.9909 - mae: 404.9909 - val_loss: 402.6937 - val_mae: 402.6937\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 404.7065 - mae: 404.7065 - val_loss: 400.9836 - val_mae: 400.9836\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405.0579 - mae: 405.0579 - val_loss: 401.0389 - val_mae: 401.0389\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 404.7645 - mae: 404.7645 - val_loss: 402.9124 - val_mae: 402.9124\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.9199 - mae: 404.9199 - val_loss: 404.1578 - val_mae: 404.1578\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.0383 - mae: 404.0383 - val_loss: 402.2759 - val_mae: 402.2759\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.1740 - mae: 404.1740 - val_loss: 403.0754 - val_mae: 403.0754\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4218.3223 - mae: 4218.3223 - val_loss: 546.5771 - val_mae: 546.5771\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 516.7042 - mae: 516.7042 - val_loss: 534.1859 - val_mae: 534.1859\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 505.4048 - mae: 505.4048 - val_loss: 508.3809 - val_mae: 508.3809\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 483.9054 - mae: 483.9054 - val_loss: 492.8905 - val_mae: 492.8905\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 465.5274 - mae: 465.5274 - val_loss: 458.4267 - val_mae: 458.4267\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 452.8738 - mae: 452.8738 - val_loss: 473.8002 - val_mae: 473.8002\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 443.3919 - mae: 443.3919 - val_loss: 456.0310 - val_mae: 456.0310\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436.9405 - mae: 436.9405 - val_loss: 434.1092 - val_mae: 434.1092\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432.8412 - mae: 432.8412 - val_loss: 447.3966 - val_mae: 447.3966\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429.0120 - mae: 429.0120 - val_loss: 432.1680 - val_mae: 432.1680\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428.2604 - mae: 428.2604 - val_loss: 425.9895 - val_mae: 425.9895\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 426.7501 - mae: 426.7501 - val_loss: 424.0504 - val_mae: 424.0504\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.0721 - mae: 425.0721 - val_loss: 429.5246 - val_mae: 429.5246\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421.8983 - mae: 421.8983 - val_loss: 421.8111 - val_mae: 421.8111\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.0671 - mae: 420.0671 - val_loss: 415.2622 - val_mae: 415.2622\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 419.2359 - mae: 419.2359 - val_loss: 452.6182 - val_mae: 452.6182\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 418.1463 - mae: 418.1463 - val_loss: 444.8696 - val_mae: 444.8696\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 416.6591 - mae: 416.6591 - val_loss: 425.5583 - val_mae: 425.5583\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.9232 - mae: 414.9232 - val_loss: 408.8451 - val_mae: 408.8451\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.4561 - mae: 414.4561 - val_loss: 428.0911 - val_mae: 428.0911\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.5938 - mae: 413.5938 - val_loss: 410.5135 - val_mae: 410.5135\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.1101 - mae: 414.1101 - val_loss: 421.5991 - val_mae: 421.5991\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.0572 - mae: 413.0572 - val_loss: 428.8123 - val_mae: 428.8123\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.1986 - mae: 412.1986 - val_loss: 426.1003 - val_mae: 426.1003\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.0200 - mae: 413.0200 - val_loss: 444.2708 - val_mae: 444.2708\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.0555 - mae: 411.0555 - val_loss: 402.0146 - val_mae: 402.0146\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.7029 - mae: 411.7029 - val_loss: 408.2048 - val_mae: 408.2048\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.1356 - mae: 410.1356 - val_loss: 405.4462 - val_mae: 405.4462\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.5755 - mae: 410.5755 - val_loss: 422.2726 - val_mae: 422.2726\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.2354 - mae: 411.2354 - val_loss: 434.6961 - val_mae: 434.6961\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.7747 - mae: 409.7747 - val_loss: 413.5689 - val_mae: 413.5689\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.8923 - mae: 408.8923 - val_loss: 419.3949 - val_mae: 419.3949\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.8763 - mae: 409.8763 - val_loss: 415.3365 - val_mae: 415.3365\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410.2137 - mae: 410.2137 - val_loss: 408.4356 - val_mae: 408.4356\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.7939 - mae: 408.7939 - val_loss: 411.3823 - val_mae: 411.3823\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.6337 - mae: 407.6337 - val_loss: 407.6917 - val_mae: 407.6917\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3778.2761 - mae: 3778.2761 - val_loss: 515.4064 - val_mae: 515.4064\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 508.4406 - mae: 508.4406 - val_loss: 497.4056 - val_mae: 497.4056\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 488.8181 - mae: 488.8181 - val_loss: 487.5994 - val_mae: 487.5994\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 470.2780 - mae: 470.2780 - val_loss: 479.8779 - val_mae: 479.8779\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 456.7191 - mae: 456.7191 - val_loss: 468.9390 - val_mae: 468.9390\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 449.7088 - mae: 449.7088 - val_loss: 469.2358 - val_mae: 469.2358\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442.6335 - mae: 442.6335 - val_loss: 445.9172 - val_mae: 445.9172\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 440.3145 - mae: 440.3145 - val_loss: 440.4883 - val_mae: 440.4883\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436.7831 - mae: 436.7831 - val_loss: 430.0212 - val_mae: 430.0212\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433.8223 - mae: 433.8223 - val_loss: 451.1519 - val_mae: 451.1519\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430.3791 - mae: 430.3791 - val_loss: 463.8201 - val_mae: 463.8201\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428.8325 - mae: 428.8325 - val_loss: 425.6339 - val_mae: 425.6339\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425.8735 - mae: 425.8735 - val_loss: 452.7120 - val_mae: 452.7120\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424.4129 - mae: 424.4129 - val_loss: 431.8637 - val_mae: 431.8637\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423.5201 - mae: 423.5201 - val_loss: 434.2174 - val_mae: 434.2174\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420.9160 - mae: 420.9160 - val_loss: 432.3488 - val_mae: 432.3488\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 418.6176 - mae: 418.6176 - val_loss: 428.8125 - val_mae: 428.8125\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 417.2730 - mae: 417.2730 - val_loss: 414.3395 - val_mae: 414.3395\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 415.7981 - mae: 415.7981 - val_loss: 418.9004 - val_mae: 418.9004\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416.1164 - mae: 416.1164 - val_loss: 447.6943 - val_mae: 447.6943\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.9808 - mae: 414.9808 - val_loss: 412.0959 - val_mae: 412.0959\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414.5143 - mae: 414.5143 - val_loss: 432.2216 - val_mae: 432.2216\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413.0203 - mae: 413.0203 - val_loss: 401.9157 - val_mae: 401.9157\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 412.1382 - mae: 412.1382 - val_loss: 415.8150 - val_mae: 415.8150\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.8558 - mae: 411.8558 - val_loss: 408.5175 - val_mae: 408.5175\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.4531 - mae: 411.4531 - val_loss: 420.4537 - val_mae: 420.4537\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411.9702 - mae: 411.9702 - val_loss: 435.7632 - val_mae: 435.7632\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.9760 - mae: 409.9760 - val_loss: 413.7598 - val_mae: 413.7598\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.7877 - mae: 408.7877 - val_loss: 403.2357 - val_mae: 403.2357\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409.2328 - mae: 409.2328 - val_loss: 405.4588 - val_mae: 405.4588\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 408.0934 - mae: 408.0934 - val_loss: 414.7186 - val_mae: 414.7186\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.1530 - mae: 407.1530 - val_loss: 424.7398 - val_mae: 424.7398\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407.0870 - mae: 407.0870 - val_loss: 421.7807 - val_mae: 421.7807\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6054.5630 - mae: 6054.5630 - val_loss: 6054.5024 - val_mae: 6054.5024\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6045.3335 - mae: 6045.3335 - val_loss: 6001.4834 - val_mae: 6001.4834\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3675.8564 - mae: 3675.8564 - val_loss: 526.5003 - val_mae: 526.5003\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 510.8065 - mae: 510.8065 - val_loss: 500.6062 - val_mae: 500.6062\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 498.6550 - mae: 498.6550 - val_loss: 493.7432 - val_mae: 493.7432\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 486.1414 - mae: 486.1414 - val_loss: 485.6080 - val_mae: 485.6080\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 476.4939 - mae: 476.4939 - val_loss: 470.4901 - val_mae: 470.4901\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 469.8839 - mae: 469.8839 - val_loss: 469.5516 - val_mae: 469.5516\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 464.9646 - mae: 464.9646 - val_loss: 461.9050 - val_mae: 461.9050\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 458.9164 - mae: 458.9164 - val_loss: 458.1879 - val_mae: 458.1879\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 453.7521 - mae: 453.7521 - val_loss: 452.5991 - val_mae: 452.5991\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 447.9642 - mae: 447.9642 - val_loss: 452.2137 - val_mae: 452.2137\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 443.3338 - mae: 443.3338 - val_loss: 448.2004 - val_mae: 448.2004\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439.7257 - mae: 439.7257 - val_loss: 433.5152 - val_mae: 433.5152\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 435.2495 - mae: 435.2495 - val_loss: 429.9295 - val_mae: 429.9295\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429.6022 - mae: 429.6022 - val_loss: 429.3576 - val_mae: 429.3576\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425.9879 - mae: 425.9879 - val_loss: 422.0056 - val_mae: 422.0056\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423.2885 - mae: 423.2885 - val_loss: 423.9789 - val_mae: 423.9789\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.4011 - mae: 419.4011 - val_loss: 416.4075 - val_mae: 416.4075\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.5300 - mae: 418.5300 - val_loss: 416.7766 - val_mae: 416.7766\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.9743 - mae: 416.9743 - val_loss: 420.5497 - val_mae: 420.5497\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.9570 - mae: 416.9570 - val_loss: 413.4157 - val_mae: 413.4157\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.8723 - mae: 412.8723 - val_loss: 411.6615 - val_mae: 411.6615\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.2296 - mae: 414.2296 - val_loss: 412.9841 - val_mae: 412.9841\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.9068 - mae: 411.9068 - val_loss: 412.2845 - val_mae: 412.2845\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.8830 - mae: 410.8830 - val_loss: 412.2032 - val_mae: 412.2032\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.8592 - mae: 410.8592 - val_loss: 409.5236 - val_mae: 409.5236\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.8328 - mae: 409.8328 - val_loss: 412.8500 - val_mae: 412.8500\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.6085 - mae: 408.6085 - val_loss: 410.5677 - val_mae: 410.5677\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.1226 - mae: 409.1226 - val_loss: 406.3745 - val_mae: 406.3745\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.5779 - mae: 407.5779 - val_loss: 405.6736 - val_mae: 405.6736\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.0315 - mae: 408.0315 - val_loss: 407.1109 - val_mae: 407.1109\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.6234 - mae: 406.6234 - val_loss: 405.1275 - val_mae: 405.1275\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.9300 - mae: 406.9300 - val_loss: 412.1446 - val_mae: 412.1446\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.2640 - mae: 406.2640 - val_loss: 403.0143 - val_mae: 403.0143\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.5649 - mae: 405.5649 - val_loss: 408.5529 - val_mae: 408.5529\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.7069 - mae: 406.7069 - val_loss: 403.2840 - val_mae: 403.2840\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.9698 - mae: 404.9698 - val_loss: 406.8576 - val_mae: 406.8576\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.9327 - mae: 405.9327 - val_loss: 403.7846 - val_mae: 403.7846\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.1197 - mae: 404.1197 - val_loss: 408.6645 - val_mae: 408.6645\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.1836 - mae: 405.1836 - val_loss: 403.0271 - val_mae: 403.0271\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.2557 - mae: 405.2557 - val_loss: 403.7089 - val_mae: 403.7089\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.3373 - mae: 403.3373 - val_loss: 399.6518 - val_mae: 399.6518\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.3617 - mae: 404.3617 - val_loss: 404.2542 - val_mae: 404.2542\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.6682 - mae: 403.6682 - val_loss: 406.1854 - val_mae: 406.1854\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.9921 - mae: 403.9921 - val_loss: 404.8074 - val_mae: 404.8074\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.2674 - mae: 403.2674 - val_loss: 399.9940 - val_mae: 399.9940\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.9842 - mae: 402.9842 - val_loss: 402.0217 - val_mae: 402.0217\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.8008 - mae: 403.8008 - val_loss: 403.2077 - val_mae: 403.2077\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.2187 - mae: 403.2187 - val_loss: 399.0458 - val_mae: 399.0458\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.4939 - mae: 402.4939 - val_loss: 403.3339 - val_mae: 403.3339\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.5394 - mae: 402.5394 - val_loss: 402.9551 - val_mae: 402.9551\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.5777 - mae: 401.5777 - val_loss: 403.7007 - val_mae: 403.7007\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.6588 - mae: 401.6588 - val_loss: 400.8948 - val_mae: 400.8948\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.5419 - mae: 402.5419 - val_loss: 396.7617 - val_mae: 396.7617\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.0124 - mae: 402.0124 - val_loss: 402.1182 - val_mae: 402.1182\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.3202 - mae: 401.3202 - val_loss: 401.1555 - val_mae: 401.1555\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.2745 - mae: 401.2745 - val_loss: 402.6607 - val_mae: 402.6607\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.2990 - mae: 401.2990 - val_loss: 404.7068 - val_mae: 404.7068\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.1418 - mae: 402.1418 - val_loss: 400.1052 - val_mae: 400.1052\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.6629 - mae: 400.6629 - val_loss: 395.9836 - val_mae: 395.9836\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.0779 - mae: 401.0779 - val_loss: 398.5647 - val_mae: 398.5647\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.9553 - mae: 400.9553 - val_loss: 401.5968 - val_mae: 401.5968\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.3986 - mae: 399.3986 - val_loss: 399.4262 - val_mae: 399.4262\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.1360 - mae: 401.1360 - val_loss: 398.7462 - val_mae: 398.7462\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.7781 - mae: 400.7781 - val_loss: 396.8788 - val_mae: 396.8788\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.2781 - mae: 399.2781 - val_loss: 399.7175 - val_mae: 399.7175\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.1016 - mae: 400.1016 - val_loss: 397.0095 - val_mae: 397.0095\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.4570 - mae: 399.4570 - val_loss: 400.8527 - val_mae: 400.8527\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.4352 - mae: 398.4352 - val_loss: 396.0597 - val_mae: 396.0597\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.6143 - mae: 398.6143 - val_loss: 396.7242 - val_mae: 396.7242\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6028.5806 - mae: 6028.5806 - val_loss: 5856.1362 - val_mae: 5856.1362\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2209.2666 - mae: 2209.2666 - val_loss: 504.6091 - val_mae: 504.6091\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 503.3064 - mae: 503.3064 - val_loss: 504.1253 - val_mae: 504.1253\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 497.2474 - mae: 497.2474 - val_loss: 492.4958 - val_mae: 492.4958\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 492.2488 - mae: 492.2488 - val_loss: 486.9606 - val_mae: 486.9606\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 489.8357 - mae: 489.8357 - val_loss: 486.5695 - val_mae: 486.5695\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 487.3979 - mae: 487.3979 - val_loss: 481.6638 - val_mae: 481.6638\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 483.0136 - mae: 483.0136 - val_loss: 479.7221 - val_mae: 479.7221\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 478.5053 - mae: 478.5053 - val_loss: 480.9613 - val_mae: 480.9613\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 475.2117 - mae: 475.2117 - val_loss: 469.2600 - val_mae: 469.2600\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 466.3045 - mae: 466.3045 - val_loss: 457.9261 - val_mae: 457.9261\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 460.4984 - mae: 460.4984 - val_loss: 459.6899 - val_mae: 459.6899\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 454.4964 - mae: 454.4964 - val_loss: 449.1741 - val_mae: 449.1741\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 448.4462 - mae: 448.4462 - val_loss: 447.0328 - val_mae: 447.0328\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 445.3386 - mae: 445.3386 - val_loss: 447.0476 - val_mae: 447.0476\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 443.0702 - mae: 443.0702 - val_loss: 438.7475 - val_mae: 438.7475\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 441.0335 - mae: 441.0335 - val_loss: 439.5080 - val_mae: 439.5080\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438.5721 - mae: 438.5721 - val_loss: 436.8967 - val_mae: 436.8967\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438.7693 - mae: 438.7693 - val_loss: 435.8876 - val_mae: 435.8876\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436.2763 - mae: 436.2763 - val_loss: 431.6447 - val_mae: 431.6447\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436.6738 - mae: 436.6738 - val_loss: 431.1754 - val_mae: 431.1754\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 434.1885 - mae: 434.1885 - val_loss: 433.1537 - val_mae: 433.1537\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432.3426 - mae: 432.3426 - val_loss: 428.9396 - val_mae: 428.9396\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 430.6116 - mae: 430.6116 - val_loss: 426.9358 - val_mae: 426.9358\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 428.6306 - mae: 428.6306 - val_loss: 429.5945 - val_mae: 429.5945\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 428.1175 - mae: 428.1175 - val_loss: 428.3947 - val_mae: 428.3947\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 426.0190 - mae: 426.0190 - val_loss: 422.0302 - val_mae: 422.0302\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423.9395 - mae: 423.9395 - val_loss: 417.4825 - val_mae: 417.4825\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424.6412 - mae: 424.6412 - val_loss: 421.8617 - val_mae: 421.8617\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.0814 - mae: 421.0814 - val_loss: 427.5953 - val_mae: 427.5953\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.5953 - mae: 421.5953 - val_loss: 422.1332 - val_mae: 422.1332\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.5022 - mae: 420.5022 - val_loss: 420.1060 - val_mae: 420.1060\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.3570 - mae: 420.3570 - val_loss: 420.8599 - val_mae: 420.8599\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 419.5350 - mae: 419.5350 - val_loss: 420.7654 - val_mae: 420.7654\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418.3697 - mae: 418.3697 - val_loss: 419.7896 - val_mae: 419.7896\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.6550 - mae: 417.6550 - val_loss: 413.6146 - val_mae: 413.6146\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.2818 - mae: 417.2818 - val_loss: 415.1405 - val_mae: 415.1405\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.2896 - mae: 417.2896 - val_loss: 418.0184 - val_mae: 418.0184\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.6208 - mae: 417.6208 - val_loss: 418.7802 - val_mae: 418.7802\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 415.3423 - mae: 415.3423 - val_loss: 411.8410 - val_mae: 411.8410\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.3336 - mae: 416.3336 - val_loss: 411.8032 - val_mae: 411.8032\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413.8491 - mae: 413.8491 - val_loss: 410.5769 - val_mae: 410.5769\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.0951 - mae: 414.0951 - val_loss: 411.8786 - val_mae: 411.8786\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.5003 - mae: 412.5003 - val_loss: 419.5237 - val_mae: 419.5237\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.3432 - mae: 412.3432 - val_loss: 409.5256 - val_mae: 409.5256\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412.1958 - mae: 412.1958 - val_loss: 410.9428 - val_mae: 410.9428\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.9634 - mae: 410.9634 - val_loss: 409.0753 - val_mae: 409.0753\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.2377 - mae: 411.2377 - val_loss: 410.1348 - val_mae: 410.1348\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.6518 - mae: 411.6518 - val_loss: 407.1471 - val_mae: 407.1471\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410.5455 - mae: 410.5455 - val_loss: 409.5781 - val_mae: 409.5781\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.8708 - mae: 409.8708 - val_loss: 405.7064 - val_mae: 405.7064\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.6851 - mae: 409.6851 - val_loss: 412.5977 - val_mae: 412.5977\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.8343 - mae: 408.8343 - val_loss: 406.6665 - val_mae: 406.6665\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.4928 - mae: 408.4928 - val_loss: 409.9069 - val_mae: 409.9069\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408.3706 - mae: 408.3706 - val_loss: 408.1409 - val_mae: 408.1409\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.5189 - mae: 407.5189 - val_loss: 404.0361 - val_mae: 404.0361\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.1835 - mae: 407.1835 - val_loss: 406.4529 - val_mae: 406.4529\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.1655 - mae: 407.1655 - val_loss: 405.9085 - val_mae: 405.9085\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.9179 - mae: 406.9179 - val_loss: 407.2211 - val_mae: 407.2211\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.7302 - mae: 406.7302 - val_loss: 410.4521 - val_mae: 410.4521\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.6181 - mae: 406.6181 - val_loss: 402.8237 - val_mae: 402.8237\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.4905 - mae: 405.4905 - val_loss: 402.8511 - val_mae: 402.8511\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.8714 - mae: 404.8714 - val_loss: 402.8218 - val_mae: 402.8218\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.4040 - mae: 405.4040 - val_loss: 401.0342 - val_mae: 401.0342\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.8914 - mae: 405.8914 - val_loss: 405.1836 - val_mae: 405.1836\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405.1703 - mae: 405.1703 - val_loss: 407.8174 - val_mae: 407.8174\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.6470 - mae: 404.6470 - val_loss: 406.9438 - val_mae: 406.9438\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.9016 - mae: 403.9016 - val_loss: 401.6391 - val_mae: 401.6391\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.3363 - mae: 404.3363 - val_loss: 399.7062 - val_mae: 399.7062\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.3001 - mae: 404.3001 - val_loss: 398.4041 - val_mae: 398.4041\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.5523 - mae: 402.5523 - val_loss: 409.5528 - val_mae: 409.5528\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.5194 - mae: 403.5194 - val_loss: 398.1534 - val_mae: 398.1534\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.6328 - mae: 403.6328 - val_loss: 403.7347 - val_mae: 403.7347\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.0416 - mae: 403.0416 - val_loss: 404.0803 - val_mae: 404.0803\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.9055 - mae: 402.9055 - val_loss: 400.9984 - val_mae: 400.9984\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6708 - mae: 402.6708 - val_loss: 399.8580 - val_mae: 399.8580\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.1826 - mae: 402.1826 - val_loss: 398.2501 - val_mae: 398.2501\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.4205 - mae: 401.4205 - val_loss: 400.5013 - val_mae: 400.5013\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.3511 - mae: 402.3511 - val_loss: 399.2495 - val_mae: 399.2495\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.5167 - mae: 402.5167 - val_loss: 396.5264 - val_mae: 396.5264\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6343 - mae: 402.6343 - val_loss: 401.6883 - val_mae: 401.6883\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.9641 - mae: 401.9641 - val_loss: 397.1877 - val_mae: 397.1877\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.1337 - mae: 401.1337 - val_loss: 401.4665 - val_mae: 401.4665\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.7384 - mae: 402.7384 - val_loss: 403.5312 - val_mae: 403.5312\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.1745 - mae: 402.1745 - val_loss: 404.2797 - val_mae: 404.2797\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.0556 - mae: 401.0556 - val_loss: 399.4999 - val_mae: 399.4999\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.7587 - mae: 401.7587 - val_loss: 399.3694 - val_mae: 399.3694\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.7673 - mae: 401.7673 - val_loss: 395.8046 - val_mae: 395.8046\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.9326 - mae: 401.9326 - val_loss: 402.5504 - val_mae: 402.5504\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.2609 - mae: 401.2609 - val_loss: 400.0125 - val_mae: 400.0125\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.3708 - mae: 401.3708 - val_loss: 402.8072 - val_mae: 402.8072\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.3788 - mae: 401.3788 - val_loss: 401.3319 - val_mae: 401.3319\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.9575 - mae: 400.9575 - val_loss: 403.3373 - val_mae: 403.3373\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.8211 - mae: 400.8211 - val_loss: 399.4439 - val_mae: 399.4439\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.8249 - mae: 400.8249 - val_loss: 397.6627 - val_mae: 397.6627\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.1568 - mae: 400.1568 - val_loss: 401.1735 - val_mae: 401.1735\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.8511 - mae: 400.8511 - val_loss: 398.0330 - val_mae: 398.0330\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.9069 - mae: 399.9069 - val_loss: 399.3961 - val_mae: 399.3961\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6050.8721 - mae: 6050.8721 - val_loss: 6043.7803 - val_mae: 6043.7803\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5993.2437 - mae: 5993.2437 - val_loss: 5855.7354 - val_mae: 5855.7354\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4551.5337 - mae: 4551.5337 - val_loss: 1239.3685 - val_mae: 1239.3685\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594.9312 - mae: 594.9312 - val_loss: 493.3878 - val_mae: 493.3878\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 495.4658 - mae: 495.4658 - val_loss: 490.2937 - val_mae: 490.2937\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 493.1319 - mae: 493.1319 - val_loss: 494.0575 - val_mae: 494.0575\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 491.6334 - mae: 491.6334 - val_loss: 491.6444 - val_mae: 491.6444\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 491.0699 - mae: 491.0699 - val_loss: 489.1698 - val_mae: 489.1698\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 490.9818 - mae: 490.9818 - val_loss: 486.4691 - val_mae: 486.4691\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 488.1418 - mae: 488.1418 - val_loss: 486.2719 - val_mae: 486.2719\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 488.5887 - mae: 488.5887 - val_loss: 483.6762 - val_mae: 483.6762\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 485.7137 - mae: 485.7137 - val_loss: 483.2444 - val_mae: 483.2444\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 482.9184 - mae: 482.9184 - val_loss: 478.5456 - val_mae: 478.5456\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 478.3107 - mae: 478.3107 - val_loss: 477.7485 - val_mae: 477.7485\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 477.2722 - mae: 477.2722 - val_loss: 473.3436 - val_mae: 473.3436\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 473.4248 - mae: 473.4248 - val_loss: 470.2463 - val_mae: 470.2463\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 471.7032 - mae: 471.7032 - val_loss: 469.9237 - val_mae: 469.9237\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 469.1697 - mae: 469.1697 - val_loss: 464.6266 - val_mae: 464.6266\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 466.4466 - mae: 466.4466 - val_loss: 468.1163 - val_mae: 468.1163\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 465.6386 - mae: 465.6386 - val_loss: 464.0892 - val_mae: 464.0892\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 462.4439 - mae: 462.4439 - val_loss: 461.2820 - val_mae: 461.2820\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 459.7432 - mae: 459.7432 - val_loss: 459.7209 - val_mae: 459.7209\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 456.2491 - mae: 456.2491 - val_loss: 455.5095 - val_mae: 455.5095\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 453.3312 - mae: 453.3312 - val_loss: 451.3301 - val_mae: 451.3301\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 451.2971 - mae: 451.2971 - val_loss: 452.7350 - val_mae: 452.7350\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 449.9352 - mae: 449.9352 - val_loss: 449.4518 - val_mae: 449.4518\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 448.0002 - mae: 448.0002 - val_loss: 444.1172 - val_mae: 444.1172\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 446.7739 - mae: 446.7739 - val_loss: 444.4767 - val_mae: 444.4767\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 446.2220 - mae: 446.2220 - val_loss: 444.3100 - val_mae: 444.3100\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444.4083 - mae: 444.4083 - val_loss: 442.4906 - val_mae: 442.4906\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 443.5147 - mae: 443.5147 - val_loss: 444.6350 - val_mae: 444.6350\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 443.4001 - mae: 443.4001 - val_loss: 444.0361 - val_mae: 444.0361\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 442.5091 - mae: 442.5091 - val_loss: 441.4997 - val_mae: 441.4997\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441.2797 - mae: 441.2797 - val_loss: 439.2797 - val_mae: 439.2797\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440.8643 - mae: 440.8643 - val_loss: 436.4391 - val_mae: 436.4391\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440.8978 - mae: 440.8978 - val_loss: 437.9839 - val_mae: 437.9839\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 440.3916 - mae: 440.3916 - val_loss: 437.6988 - val_mae: 437.6988\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 440.6457 - mae: 440.6457 - val_loss: 436.8552 - val_mae: 436.8552\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.5017 - mae: 439.5017 - val_loss: 438.0780 - val_mae: 438.0780\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.5223 - mae: 439.5223 - val_loss: 436.7212 - val_mae: 436.7212\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.6562 - mae: 439.6562 - val_loss: 435.9652 - val_mae: 435.9652\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 438.2130 - mae: 438.2130 - val_loss: 437.2972 - val_mae: 437.2972\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 437.1892 - mae: 437.1892 - val_loss: 437.1356 - val_mae: 437.1356\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436.8791 - mae: 436.8791 - val_loss: 435.6082 - val_mae: 435.6082\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436.1149 - mae: 436.1149 - val_loss: 434.2988 - val_mae: 434.2988\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436.4240 - mae: 436.4240 - val_loss: 431.5418 - val_mae: 431.5418\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 435.0527 - mae: 435.0527 - val_loss: 433.0258 - val_mae: 433.0258\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 434.4931 - mae: 434.4931 - val_loss: 431.8860 - val_mae: 431.8860\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431.8041 - mae: 431.8041 - val_loss: 428.4099 - val_mae: 428.4099\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.0323 - mae: 430.0323 - val_loss: 424.1226 - val_mae: 424.1226\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 427.1493 - mae: 427.1493 - val_loss: 424.6708 - val_mae: 424.6708\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 425.9240 - mae: 425.9240 - val_loss: 424.1415 - val_mae: 424.1415\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.1429 - mae: 425.1429 - val_loss: 425.3015 - val_mae: 425.3015\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424.6386 - mae: 424.6386 - val_loss: 421.0793 - val_mae: 421.0793\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 423.0382 - mae: 423.0382 - val_loss: 423.1391 - val_mae: 423.1391\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422.0458 - mae: 422.0458 - val_loss: 420.4404 - val_mae: 420.4404\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421.2256 - mae: 421.2256 - val_loss: 418.2051 - val_mae: 418.2051\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.2927 - mae: 420.2927 - val_loss: 419.6211 - val_mae: 419.6211\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.6994 - mae: 419.6994 - val_loss: 418.0551 - val_mae: 418.0551\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 420.1060 - mae: 420.1060 - val_loss: 419.0022 - val_mae: 419.0022\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.7834 - mae: 417.7834 - val_loss: 415.8389 - val_mae: 415.8389\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.6057 - mae: 417.6057 - val_loss: 418.2018 - val_mae: 418.2018\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.9357 - mae: 416.9357 - val_loss: 415.1436 - val_mae: 415.1436\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.6739 - mae: 416.6739 - val_loss: 417.3083 - val_mae: 417.3083\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416.0746 - mae: 416.0746 - val_loss: 414.6294 - val_mae: 414.6294\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.7116 - mae: 415.7116 - val_loss: 412.9802 - val_mae: 412.9802\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 414.9877 - mae: 414.9877 - val_loss: 412.4653 - val_mae: 412.4653\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.7287 - mae: 414.7287 - val_loss: 414.9258 - val_mae: 414.9258\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.3383 - mae: 414.3383 - val_loss: 411.7633 - val_mae: 411.7633\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.4238 - mae: 413.4238 - val_loss: 415.1153 - val_mae: 415.1153\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.8426 - mae: 413.8426 - val_loss: 411.7362 - val_mae: 411.7362\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 413.0462 - mae: 413.0462 - val_loss: 412.1660 - val_mae: 412.1660\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 412.7126 - mae: 412.7126 - val_loss: 409.8621 - val_mae: 409.8621\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 412.2643 - mae: 412.2643 - val_loss: 408.9716 - val_mae: 408.9716\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412.0447 - mae: 412.0447 - val_loss: 410.0196 - val_mae: 410.0196\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 411.6045 - mae: 411.6045 - val_loss: 409.0072 - val_mae: 409.0072\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 411.3575 - mae: 411.3575 - val_loss: 408.6125 - val_mae: 408.6125\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 410.8860 - mae: 410.8860 - val_loss: 408.5328 - val_mae: 408.5328\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.3346 - mae: 411.3346 - val_loss: 409.0927 - val_mae: 409.0927\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 411.0305 - mae: 411.0305 - val_loss: 408.2817 - val_mae: 408.2817\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 409.6165 - mae: 409.6165 - val_loss: 408.9320 - val_mae: 408.9320\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 409.9552 - mae: 409.9552 - val_loss: 406.4283 - val_mae: 406.4283\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 409.2765 - mae: 409.2765 - val_loss: 408.9189 - val_mae: 408.9189\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 410.1053 - mae: 410.1053 - val_loss: 406.8739 - val_mae: 406.8739\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.4049 - mae: 409.4049 - val_loss: 407.0338 - val_mae: 407.0338\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409.2649 - mae: 409.2649 - val_loss: 407.3026 - val_mae: 407.3026\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 408.7914 - mae: 408.7914 - val_loss: 405.5259 - val_mae: 405.5259\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 408.9302 - mae: 408.9302 - val_loss: 406.5091 - val_mae: 406.5091\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 408.9174 - mae: 408.9174 - val_loss: 404.9095 - val_mae: 404.9095\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.5569 - mae: 408.5569 - val_loss: 408.4608 - val_mae: 408.4608\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 407.6920 - mae: 407.6920 - val_loss: 407.4755 - val_mae: 407.4755\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.5379 - mae: 408.5379 - val_loss: 405.6049 - val_mae: 405.6049\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.0345 - mae: 408.0345 - val_loss: 407.1707 - val_mae: 407.1707\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 408.4022 - mae: 408.4022 - val_loss: 405.7881 - val_mae: 405.7881\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.8305 - mae: 407.8305 - val_loss: 406.2701 - val_mae: 406.2701\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 407.1896 - mae: 407.1896 - val_loss: 406.5754 - val_mae: 406.5754\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.9603 - mae: 406.9603 - val_loss: 407.0913 - val_mae: 407.0913\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 407.0922 - mae: 407.0922 - val_loss: 408.2828 - val_mae: 408.2828\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.6938 - mae: 407.6938 - val_loss: 405.4666 - val_mae: 405.4666\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6044.4619 - mae: 6044.4619 - val_loss: 6018.0518 - val_mae: 6018.0518\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5599.9409 - mae: 5599.9409 - val_loss: 4124.0068 - val_mae: 4124.0068\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1125.5190 - mae: 1125.5190 - val_loss: 499.9662 - val_mae: 499.9662\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 498.4586 - mae: 498.4586 - val_loss: 495.3185 - val_mae: 495.3185\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 495.3875 - mae: 495.3875 - val_loss: 491.7320 - val_mae: 491.7320\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 489.4833 - mae: 489.4833 - val_loss: 482.3499 - val_mae: 482.3499\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 484.5417 - mae: 484.5417 - val_loss: 482.0865 - val_mae: 482.0865\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 479.9215 - mae: 479.9215 - val_loss: 476.3770 - val_mae: 476.3770\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 477.4387 - mae: 477.4387 - val_loss: 473.1462 - val_mae: 473.1462\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 472.6383 - mae: 472.6383 - val_loss: 470.2400 - val_mae: 470.2400\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 467.6812 - mae: 467.6812 - val_loss: 463.4724 - val_mae: 463.4724\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 463.5643 - mae: 463.5643 - val_loss: 459.6471 - val_mae: 459.6471\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 458.6161 - mae: 458.6161 - val_loss: 452.9903 - val_mae: 452.9903\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 454.8759 - mae: 454.8759 - val_loss: 455.8988 - val_mae: 455.8988\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 452.6714 - mae: 452.6714 - val_loss: 448.8151 - val_mae: 448.8151\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 449.3130 - mae: 449.3130 - val_loss: 444.2238 - val_mae: 444.2238\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 446.5666 - mae: 446.5666 - val_loss: 444.1166 - val_mae: 444.1166\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 443.6092 - mae: 443.6092 - val_loss: 439.5305 - val_mae: 439.5305\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 440.1165 - mae: 440.1165 - val_loss: 439.4267 - val_mae: 439.4267\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439.9252 - mae: 439.9252 - val_loss: 439.1165 - val_mae: 439.1165\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 436.5483 - mae: 436.5483 - val_loss: 437.9985 - val_mae: 437.9985\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 435.1895 - mae: 435.1895 - val_loss: 436.5159 - val_mae: 436.5159\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 433.8181 - mae: 433.8181 - val_loss: 431.3566 - val_mae: 431.3566\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 433.2010 - mae: 433.2010 - val_loss: 431.8950 - val_mae: 431.8950\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 432.1512 - mae: 432.1512 - val_loss: 429.0560 - val_mae: 429.0560\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 431.6140 - mae: 431.6140 - val_loss: 427.2985 - val_mae: 427.2985\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429.6705 - mae: 429.6705 - val_loss: 427.8424 - val_mae: 427.8424\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430.1002 - mae: 430.1002 - val_loss: 426.3727 - val_mae: 426.3727\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.6401 - mae: 428.6401 - val_loss: 429.0734 - val_mae: 429.0734\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428.6686 - mae: 428.6686 - val_loss: 426.1761 - val_mae: 426.1761\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 426.5891 - mae: 426.5891 - val_loss: 424.6804 - val_mae: 424.6804\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426.1024 - mae: 426.1024 - val_loss: 421.0579 - val_mae: 421.0579\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425.9269 - mae: 425.9269 - val_loss: 422.8802 - val_mae: 422.8802\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 423.7014 - mae: 423.7014 - val_loss: 421.5790 - val_mae: 421.5790\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 423.0441 - mae: 423.0441 - val_loss: 418.5209 - val_mae: 418.5209\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 420.9308 - mae: 420.9308 - val_loss: 420.3472 - val_mae: 420.3472\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 420.8010 - mae: 420.8010 - val_loss: 421.7992 - val_mae: 421.7992\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419.7739 - mae: 419.7739 - val_loss: 416.5549 - val_mae: 416.5549\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 418.6016 - mae: 418.6016 - val_loss: 417.9789 - val_mae: 417.9789\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 418.4710 - mae: 418.4710 - val_loss: 415.8181 - val_mae: 415.8181\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417.8379 - mae: 417.8379 - val_loss: 413.4670 - val_mae: 413.4670\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415.6711 - mae: 415.6711 - val_loss: 418.7418 - val_mae: 418.7418\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 415.3065 - mae: 415.3065 - val_loss: 413.8539 - val_mae: 413.8539\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414.6732 - mae: 414.6732 - val_loss: 410.5337 - val_mae: 410.5337\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 413.4356 - mae: 413.4356 - val_loss: 413.0590 - val_mae: 413.0590\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413.2783 - mae: 413.2783 - val_loss: 411.0969 - val_mae: 411.0969\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 412.9776 - mae: 412.9776 - val_loss: 409.8348 - val_mae: 409.8348\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.3718 - mae: 411.3718 - val_loss: 409.4948 - val_mae: 409.4948\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 411.2538 - mae: 411.2538 - val_loss: 410.7784 - val_mae: 410.7784\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410.9645 - mae: 410.9645 - val_loss: 409.1577 - val_mae: 409.1577\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 410.0311 - mae: 410.0311 - val_loss: 411.5798 - val_mae: 411.5798\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 409.1125 - mae: 409.1125 - val_loss: 409.6530 - val_mae: 409.6530\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.7155 - mae: 408.7155 - val_loss: 405.2887 - val_mae: 405.2887\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.0900 - mae: 408.0900 - val_loss: 408.6287 - val_mae: 408.6287\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 408.3927 - mae: 408.3927 - val_loss: 405.9327 - val_mae: 405.9327\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.5600 - mae: 407.5600 - val_loss: 411.9265 - val_mae: 411.9265\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408.0026 - mae: 408.0026 - val_loss: 404.3440 - val_mae: 404.3440\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.5600 - mae: 407.5600 - val_loss: 406.6797 - val_mae: 406.6797\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.9231 - mae: 407.9231 - val_loss: 405.4763 - val_mae: 405.4763\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.5937 - mae: 407.5937 - val_loss: 403.7129 - val_mae: 403.7129\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.7769 - mae: 406.7769 - val_loss: 408.7581 - val_mae: 408.7581\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.3805 - mae: 406.3805 - val_loss: 402.8901 - val_mae: 402.8901\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406.3157 - mae: 406.3157 - val_loss: 404.5807 - val_mae: 404.5807\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 407.0673 - mae: 407.0673 - val_loss: 405.1374 - val_mae: 405.1374\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 405.6729 - mae: 405.6729 - val_loss: 404.2649 - val_mae: 404.2649\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 405.1669 - mae: 405.1669 - val_loss: 403.9986 - val_mae: 403.9986\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 405.9215 - mae: 405.9215 - val_loss: 401.0572 - val_mae: 401.0572\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.8659 - mae: 404.8659 - val_loss: 402.3713 - val_mae: 402.3713\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.8900 - mae: 403.8900 - val_loss: 403.8709 - val_mae: 403.8709\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 404.6776 - mae: 404.6776 - val_loss: 403.3500 - val_mae: 403.3500\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.3277 - mae: 404.3277 - val_loss: 400.7305 - val_mae: 400.7305\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.0609 - mae: 404.0609 - val_loss: 401.8090 - val_mae: 401.8090\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.4610 - mae: 403.4610 - val_loss: 403.6078 - val_mae: 403.6078\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.5748 - mae: 403.5748 - val_loss: 400.0824 - val_mae: 400.0824\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 404.3418 - mae: 404.3418 - val_loss: 404.1997 - val_mae: 404.1997\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.6038 - mae: 403.6038 - val_loss: 399.4524 - val_mae: 399.4524\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402.7121 - mae: 402.7121 - val_loss: 402.1318 - val_mae: 402.1318\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.6756 - mae: 401.6756 - val_loss: 401.6946 - val_mae: 401.6946\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.6676 - mae: 403.6676 - val_loss: 400.8307 - val_mae: 400.8307\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403.0414 - mae: 403.0414 - val_loss: 400.1091 - val_mae: 400.1091\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 403.1510 - mae: 403.1510 - val_loss: 398.6989 - val_mae: 398.6989\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 402.0060 - mae: 402.0060 - val_loss: 399.9656 - val_mae: 399.9656\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.3490 - mae: 401.3490 - val_loss: 403.0050 - val_mae: 403.0050\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401.8771 - mae: 401.8771 - val_loss: 400.8488 - val_mae: 400.8488\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 402.5344 - mae: 402.5344 - val_loss: 398.1232 - val_mae: 398.1232\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 401.6488 - mae: 401.6488 - val_loss: 401.8092 - val_mae: 401.8092\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 401.6665 - mae: 401.6665 - val_loss: 400.2477 - val_mae: 400.2477\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 401.7082 - mae: 401.7082 - val_loss: 400.3865 - val_mae: 400.3865\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 402.0375 - mae: 402.0375 - val_loss: 398.1685 - val_mae: 398.1685\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 400.6740 - mae: 400.6740 - val_loss: 400.4074 - val_mae: 400.4074\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 400.8246 - mae: 400.8246 - val_loss: 397.6458 - val_mae: 397.6458\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399.6778 - mae: 399.6778 - val_loss: 398.6698 - val_mae: 398.6698\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 400.5824 - mae: 400.5824 - val_loss: 399.9168 - val_mae: 399.9168\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 400.2825 - mae: 400.2825 - val_loss: 396.9552 - val_mae: 396.9552\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 399.6013 - mae: 399.6013 - val_loss: 400.2256 - val_mae: 400.2256\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 400.6299 - mae: 400.6299 - val_loss: 398.8708 - val_mae: 398.8708\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 400.2985 - mae: 400.2985 - val_loss: 397.8027 - val_mae: 397.8027\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 400.0287 - mae: 400.0287 - val_loss: 396.3665 - val_mae: 396.3665\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399.8694 - mae: 399.8694 - val_loss: 398.0702 - val_mae: 398.0702\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399.0781 - mae: 399.0781 - val_loss: 397.5249 - val_mae: 397.5249\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 399.3554 - mae: 399.3554 - val_loss: 399.8163 - val_mae: 399.8163\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399.8597 - mae: 399.8597 - val_loss: 397.0721 - val_mae: 397.0721\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 399.4075 - mae: 399.4075 - val_loss: 395.1607 - val_mae: 395.1607\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 5ms/step - loss: 399.1313 - mae: 399.1313 - val_loss: 397.4773 - val_mae: 397.4773\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 399.1000 - mae: 399.1000 - val_loss: 398.4726 - val_mae: 398.4726\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 398.3846 - mae: 398.3846 - val_loss: 397.5793 - val_mae: 397.5793\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 400.2354 - mae: 400.2354 - val_loss: 397.5797 - val_mae: 397.5797\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 399.9057 - mae: 399.9057 - val_loss: 395.7765 - val_mae: 395.7765\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 398.9295 - mae: 398.9295 - val_loss: 402.0226 - val_mae: 402.0226\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399.1323 - mae: 399.1323 - val_loss: 395.6316 - val_mae: 395.6316\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398.4666 - mae: 398.4666 - val_loss: 398.8333 - val_mae: 398.8333\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 398.6367 - mae: 398.6367 - val_loss: 401.1379 - val_mae: 401.1379\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397.8663 - mae: 397.8663 - val_loss: 397.6986 - val_mae: 397.6986\n"
     ]
    }
   ],
   "source": [
    "# MBGD - mae + sgd\n",
    "\n",
    "result34_dict = {\n",
    "    'units': [],\n",
    "    'batch_size': [],\n",
    "    'learning_rate': [],\n",
    "    'minimum_mae_error': []\n",
    "}\n",
    "\n",
    "for units in para_dict['hidden_units']:\n",
    "    for b_size in para_dict['batch_size']:\n",
    "        for rate in para_dict['learning_rate'][0]:\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "            optimizer = SGD(learning_rate = rate)\n",
    "\n",
    "            model = create_model(columns = x_columns, units = units, optimizer = optimizer)\n",
    "\n",
    "            best_model = model.fit(\n",
    "                x_train, y_train,\n",
    "                validation_data = (x_test, y_test),\n",
    "                batch_size = b_size,\n",
    "                epochs = 250,\n",
    "                callbacks = [early_stopping]\n",
    "            )\n",
    "\n",
    "            min_mae = early_stopping.best\n",
    "\n",
    "            result34_dict['units'].append(units)\n",
    "            result34_dict['batch_size'].append(b_size)\n",
    "            result34_dict['learning_rate'].append(rate)\n",
    "            result34_dict['minimum_mae_error'].append(min_mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>minimum_mae_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>404.279297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>396.241150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>409.937469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>395.671204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>410.216339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>411.039459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>411.396545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>408.973145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>395.748810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>394.802124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>402.471191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>400.830719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>402.014618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>401.915710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>395.983612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>395.804626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>404.909515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>395.160706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  batch_size  learning_rate  minimum_mae_error\n",
       "0       7          16          0.008         404.279297\n",
       "1       7          16          0.010         396.241150\n",
       "2       7          32          0.008         409.937469\n",
       "3       7          32          0.010         395.671204\n",
       "4       7          64          0.008         410.216339\n",
       "5       7          64          0.010         411.039459\n",
       "6       8          16          0.008         411.396545\n",
       "7       8          16          0.010         408.973145\n",
       "8       8          32          0.008         395.748810\n",
       "9       8          32          0.010         394.802124\n",
       "10      8          64          0.008         402.471191\n",
       "11      8          64          0.010         400.830719\n",
       "12      9          16          0.008         402.014618\n",
       "13      9          16          0.010         401.915710\n",
       "14      9          32          0.008         395.983612\n",
       "15      9          32          0.010         395.804626\n",
       "16      9          64          0.008         404.909515\n",
       "17      9          64          0.010         395.160706"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result34_sgd_df = pd.DataFrame(result34_dict)\n",
    "\n",
    "result34_sgd_df.to_csv('result34_sgd.csv')\n",
    "\n",
    "result34_sgd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "864/864 [==============================] - 3s 2ms/step - loss: 33110492.0000 - mae: 5601.7036 - val_loss: 23047608.0000 - val_mae: 4679.1060\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 13786377.0000 - mae: 3399.6885 - val_loss: 6947805.5000 - val_mae: 2209.1384\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4022923.2500 - mae: 1492.8394 - val_loss: 2210352.7500 - val_mae: 1018.3155\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1566429.7500 - mae: 859.0269 - val_loss: 1158334.5000 - val_mae: 755.7100\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 974296.9375 - mae: 701.4128 - val_loss: 830775.0625 - val_mae: 652.3266\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 743593.1875 - mae: 620.5467 - val_loss: 664161.0625 - val_mae: 590.4376\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 621445.1250 - mae: 573.5768 - val_loss: 580070.9375 - val_mae: 555.5349\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558002.5000 - mae: 547.9467 - val_loss: 531914.6875 - val_mae: 537.4653\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 520302.8438 - mae: 532.5598 - val_loss: 501936.3750 - val_mae: 522.8899\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 493920.2500 - mae: 520.4515 - val_loss: 480110.5625 - val_mae: 514.7634\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 475037.4375 - mae: 512.0477 - val_loss: 464108.3438 - val_mae: 503.8857\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 461419.6250 - mae: 504.6501 - val_loss: 453138.2500 - val_mae: 504.0466\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 451761.3750 - mae: 499.4787 - val_loss: 443802.1250 - val_mae: 494.1448\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 444101.1250 - mae: 494.4720 - val_loss: 437934.6875 - val_mae: 492.8520\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437923.9062 - mae: 490.8937 - val_loss: 431941.2188 - val_mae: 486.4030\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432514.2188 - mae: 486.9819 - val_loss: 427976.5312 - val_mae: 485.1302\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 429030.0938 - mae: 484.8633 - val_loss: 423651.2812 - val_mae: 482.5401\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 425604.3750 - mae: 482.9133 - val_loss: 420141.0625 - val_mae: 479.0499\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422325.2188 - mae: 480.6432 - val_loss: 417509.2188 - val_mae: 475.7495\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419375.0000 - mae: 477.8968 - val_loss: 414658.5938 - val_mae: 477.4084\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 416742.9688 - mae: 476.8314 - val_loss: 412083.1562 - val_mae: 473.8669\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 413997.3438 - mae: 475.0050 - val_loss: 409998.0625 - val_mae: 474.0936\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 411896.9688 - mae: 473.7679 - val_loss: 407225.2188 - val_mae: 471.0667\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 409730.7188 - mae: 472.2747 - val_loss: 405491.7812 - val_mae: 468.6826\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407848.1562 - mae: 471.3306 - val_loss: 403593.5625 - val_mae: 467.5452\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 406147.1875 - mae: 470.0825 - val_loss: 403341.3750 - val_mae: 465.7390\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 403975.0312 - mae: 468.4192 - val_loss: 400505.5938 - val_mae: 466.6606\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 402315.8125 - mae: 467.3021 - val_loss: 397563.0000 - val_mae: 463.5254\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 400172.5000 - mae: 465.4503 - val_loss: 396443.8125 - val_mae: 462.2669\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 397932.1875 - mae: 464.3226 - val_loss: 393145.5000 - val_mae: 463.1608\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 394086.7188 - mae: 462.1713 - val_loss: 388208.7812 - val_mae: 458.2024\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 390002.0938 - mae: 458.3047 - val_loss: 385287.0625 - val_mae: 455.3347\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 386446.4062 - mae: 456.1407 - val_loss: 382444.9375 - val_mae: 456.4594\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 383604.4688 - mae: 454.2825 - val_loss: 378480.0625 - val_mae: 452.5152\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 380021.1562 - mae: 451.9227 - val_loss: 376256.5938 - val_mae: 451.9081\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 377163.7812 - mae: 449.9105 - val_loss: 372307.2188 - val_mae: 446.5735\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 374626.5312 - mae: 447.4467 - val_loss: 369883.2812 - val_mae: 446.6800\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 372222.3438 - mae: 446.2495 - val_loss: 367589.9375 - val_mae: 444.0107\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 370025.5312 - mae: 444.7036 - val_loss: 366657.8750 - val_mae: 441.2431\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 368221.4688 - mae: 443.3177 - val_loss: 364318.3125 - val_mae: 443.3190\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 366439.5625 - mae: 441.8958 - val_loss: 361948.7188 - val_mae: 440.1537\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 365404.0938 - mae: 441.9403 - val_loss: 361019.9062 - val_mae: 439.0208\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 363760.6562 - mae: 439.8094 - val_loss: 359660.4688 - val_mae: 436.5063\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 362256.5938 - mae: 439.1459 - val_loss: 357954.5938 - val_mae: 436.0987\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 361217.7188 - mae: 438.0176 - val_loss: 357438.6250 - val_mae: 434.0711\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 359882.6875 - mae: 437.0088 - val_loss: 356271.2188 - val_mae: 437.3694\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358928.9688 - mae: 436.7943 - val_loss: 355447.7812 - val_mae: 436.0049\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 357748.4375 - mae: 436.1949 - val_loss: 354164.8438 - val_mae: 433.4442\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 357051.8125 - mae: 434.5146 - val_loss: 352538.2500 - val_mae: 432.6317\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 355860.4375 - mae: 433.9925 - val_loss: 352712.0625 - val_mae: 434.0861\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 354779.2500 - mae: 433.6729 - val_loss: 351805.3125 - val_mae: 432.8559\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 354657.2500 - mae: 433.0448 - val_loss: 350689.6875 - val_mae: 430.1495\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353671.0625 - mae: 432.4025 - val_loss: 349513.5312 - val_mae: 430.5316\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 352556.1562 - mae: 431.8193 - val_loss: 348756.4062 - val_mae: 430.5856\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 351466.3750 - mae: 431.2585 - val_loss: 348846.1875 - val_mae: 429.8085\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 351167.7500 - mae: 430.7675 - val_loss: 347056.2500 - val_mae: 427.8484\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 350324.5625 - mae: 430.0659 - val_loss: 346596.3125 - val_mae: 429.2104\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348854.5938 - mae: 428.9839 - val_loss: 346490.0312 - val_mae: 426.0405\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348774.8750 - mae: 428.6813 - val_loss: 344640.7188 - val_mae: 426.6514\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347774.5625 - mae: 428.3115 - val_loss: 343775.2812 - val_mae: 425.4233\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 346599.9062 - mae: 427.4177 - val_loss: 343474.8438 - val_mae: 425.0842\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 345999.2188 - mae: 426.4374 - val_loss: 341958.9688 - val_mae: 425.4413\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 344319.8750 - mae: 425.9159 - val_loss: 341530.8125 - val_mae: 423.5813\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 344689.1875 - mae: 425.5033 - val_loss: 340165.8438 - val_mae: 421.9640\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342851.5312 - mae: 424.5519 - val_loss: 341117.5312 - val_mae: 421.1521\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 342040.1250 - mae: 423.7747 - val_loss: 338894.6250 - val_mae: 421.5927\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 341611.1875 - mae: 423.2952 - val_loss: 337836.9062 - val_mae: 420.9526\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 340321.8125 - mae: 422.7097 - val_loss: 337728.5312 - val_mae: 421.1884\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 340128.1562 - mae: 422.3228 - val_loss: 336734.7812 - val_mae: 421.2544\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339631.0625 - mae: 422.7253 - val_loss: 336774.5938 - val_mae: 421.8197\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339227.5625 - mae: 421.9420 - val_loss: 335542.8438 - val_mae: 419.7534\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 338011.8125 - mae: 421.6068 - val_loss: 336083.1562 - val_mae: 419.4655\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 338494.4062 - mae: 421.6655 - val_loss: 335419.5312 - val_mae: 418.5681\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 337816.6562 - mae: 420.9355 - val_loss: 334188.6875 - val_mae: 419.5221\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 337190.1562 - mae: 420.7615 - val_loss: 334574.3438 - val_mae: 417.4872\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 336915.2500 - mae: 419.9230 - val_loss: 334728.7500 - val_mae: 420.9084\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 336331.4375 - mae: 419.9135 - val_loss: 333683.3750 - val_mae: 418.8073\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 335796.5938 - mae: 419.6208 - val_loss: 333094.1562 - val_mae: 418.1056\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 336379.1875 - mae: 419.9932 - val_loss: 332831.6250 - val_mae: 419.0374\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 335706.2188 - mae: 419.4096 - val_loss: 332226.5938 - val_mae: 418.4892\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 335323.7812 - mae: 419.0743 - val_loss: 331774.8438 - val_mae: 416.7357\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334373.8750 - mae: 418.9579 - val_loss: 334187.3125 - val_mae: 415.5124\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334131.2188 - mae: 418.3321 - val_loss: 331660.1875 - val_mae: 418.1100\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 333419.8438 - mae: 418.2433 - val_loss: 330640.9062 - val_mae: 416.1129\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333585.7812 - mae: 417.6562 - val_loss: 329714.4375 - val_mae: 415.8425\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332603.8438 - mae: 417.6000 - val_loss: 329335.7812 - val_mae: 415.5486\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 332660.6562 - mae: 416.7490 - val_loss: 329519.7812 - val_mae: 414.1784\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331937.1875 - mae: 417.1549 - val_loss: 329859.7500 - val_mae: 417.3331\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332040.0000 - mae: 416.7448 - val_loss: 329496.0000 - val_mae: 417.5951\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331947.4062 - mae: 416.5402 - val_loss: 327784.4062 - val_mae: 415.0704\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331189.4062 - mae: 416.1590 - val_loss: 328400.0938 - val_mae: 415.7613\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331001.2500 - mae: 415.9532 - val_loss: 327508.4688 - val_mae: 413.1008\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330559.0625 - mae: 415.7219 - val_loss: 327294.9688 - val_mae: 413.1035\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329889.9688 - mae: 415.5710 - val_loss: 328051.8438 - val_mae: 414.8595\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330334.0625 - mae: 415.6411 - val_loss: 326845.0938 - val_mae: 413.1919\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329464.0000 - mae: 414.9355 - val_loss: 326878.8438 - val_mae: 412.9254\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329074.5625 - mae: 414.5208 - val_loss: 327345.3438 - val_mae: 412.7246\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 329229.0000 - mae: 414.9998 - val_loss: 326024.7500 - val_mae: 411.2608\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 329154.8750 - mae: 414.5807 - val_loss: 325497.5000 - val_mae: 413.6074\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 329059.8125 - mae: 414.4350 - val_loss: 325328.3125 - val_mae: 412.1693\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328412.5625 - mae: 414.0340 - val_loss: 324993.6562 - val_mae: 412.6443\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328323.1250 - mae: 413.6524 - val_loss: 324937.8750 - val_mae: 413.4744\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327758.7812 - mae: 413.7488 - val_loss: 324768.6250 - val_mae: 412.6501\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328089.5625 - mae: 414.1272 - val_loss: 324277.0000 - val_mae: 410.9382\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327339.3438 - mae: 413.8615 - val_loss: 324606.8438 - val_mae: 412.3494\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 327565.8125 - mae: 413.3601 - val_loss: 324441.3125 - val_mae: 410.5180\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327664.4375 - mae: 413.6414 - val_loss: 323846.9375 - val_mae: 411.8658\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327331.1250 - mae: 413.5670 - val_loss: 324531.2188 - val_mae: 411.0627\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327058.3125 - mae: 413.3040 - val_loss: 324195.3750 - val_mae: 410.9723\n",
      "Epoch 110/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327336.5000 - mae: 413.8274 - val_loss: 323604.8750 - val_mae: 409.9439\n",
      "Epoch 111/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326926.4375 - mae: 413.1816 - val_loss: 323764.0625 - val_mae: 412.2987\n",
      "Epoch 112/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326724.4688 - mae: 412.8173 - val_loss: 324371.3438 - val_mae: 413.0993\n",
      "Epoch 113/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327054.5625 - mae: 413.3069 - val_loss: 323376.8125 - val_mae: 411.3264\n",
      "Epoch 114/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326524.3438 - mae: 413.2314 - val_loss: 323861.2500 - val_mae: 411.6234\n",
      "Epoch 115/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 326279.4375 - mae: 412.5357 - val_loss: 324440.8125 - val_mae: 414.4840\n",
      "Epoch 116/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326606.8750 - mae: 413.2736 - val_loss: 323910.6250 - val_mae: 409.8721\n",
      "Epoch 117/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326130.7188 - mae: 412.6787 - val_loss: 323879.4375 - val_mae: 410.9016\n",
      "Epoch 118/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326205.7500 - mae: 412.7137 - val_loss: 323262.1562 - val_mae: 411.3729\n",
      "Epoch 119/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325868.4688 - mae: 412.5921 - val_loss: 323612.4688 - val_mae: 412.9711\n",
      "Epoch 120/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326247.0312 - mae: 412.7412 - val_loss: 323281.5625 - val_mae: 412.5377\n",
      "Epoch 121/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326366.7188 - mae: 412.8390 - val_loss: 322731.1250 - val_mae: 410.6479\n",
      "Epoch 122/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325930.8438 - mae: 412.7722 - val_loss: 322678.5312 - val_mae: 411.3023\n",
      "Epoch 123/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325680.1562 - mae: 412.7151 - val_loss: 322393.4688 - val_mae: 411.2746\n",
      "Epoch 124/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 325788.8438 - mae: 412.4796 - val_loss: 322276.1875 - val_mae: 411.6884\n",
      "Epoch 125/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 325918.1562 - mae: 413.0445 - val_loss: 322987.1562 - val_mae: 411.3653\n",
      "Epoch 126/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325510.1562 - mae: 412.8551 - val_loss: 322741.0938 - val_mae: 409.6749\n",
      "Epoch 127/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 325559.0000 - mae: 412.2099 - val_loss: 324007.4062 - val_mae: 413.8719\n",
      "Epoch 128/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 325522.3125 - mae: 413.2000 - val_loss: 323193.1875 - val_mae: 409.1336\n",
      "Epoch 129/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 325208.5938 - mae: 411.7336 - val_loss: 322744.8125 - val_mae: 412.0559\n",
      "Epoch 130/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 325345.4375 - mae: 412.3676 - val_loss: 322971.0625 - val_mae: 408.8911\n",
      "Epoch 131/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325483.4375 - mae: 412.3580 - val_loss: 322040.3125 - val_mae: 409.7211\n",
      "Epoch 132/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325299.7500 - mae: 412.1984 - val_loss: 322581.8438 - val_mae: 411.4977\n",
      "Epoch 133/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324977.2812 - mae: 412.3006 - val_loss: 322474.1875 - val_mae: 411.4386\n",
      "Epoch 134/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325352.2812 - mae: 412.3636 - val_loss: 322742.9375 - val_mae: 413.2621\n",
      "Epoch 135/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325438.5000 - mae: 412.3052 - val_loss: 321911.4688 - val_mae: 412.2313\n",
      "Epoch 136/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325019.5938 - mae: 412.2360 - val_loss: 322722.7812 - val_mae: 408.2292\n",
      "Epoch 137/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 324406.2500 - mae: 411.8800 - val_loss: 322406.5625 - val_mae: 409.4037\n",
      "Epoch 138/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325128.2812 - mae: 412.2343 - val_loss: 321767.8750 - val_mae: 408.8960\n",
      "Epoch 139/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324526.4688 - mae: 411.5432 - val_loss: 322162.6875 - val_mae: 410.0625\n",
      "Epoch 140/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 324546.6875 - mae: 411.8362 - val_loss: 322059.5938 - val_mae: 410.8999\n",
      "Epoch 141/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 324929.5312 - mae: 411.8387 - val_loss: 321188.0312 - val_mae: 409.6676\n",
      "Epoch 142/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324350.1562 - mae: 411.5111 - val_loss: 322167.8750 - val_mae: 409.3428\n",
      "Epoch 143/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 324219.9062 - mae: 411.6421 - val_loss: 321644.8125 - val_mae: 409.0432\n",
      "Epoch 144/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324812.2188 - mae: 411.8116 - val_loss: 321206.4688 - val_mae: 409.4910\n",
      "Epoch 145/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 324389.9062 - mae: 411.5593 - val_loss: 321406.4062 - val_mae: 410.4943\n",
      "Epoch 146/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324416.9688 - mae: 411.7691 - val_loss: 321083.5000 - val_mae: 410.4013\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 30126616.0000 - mae: 5283.3179 - val_loss: 16561970.0000 - val_mae: 3855.1687\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 7246728.5000 - mae: 2176.6394 - val_loss: 2409947.2500 - val_mae: 961.6182\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 1804366.8750 - mae: 739.1282 - val_loss: 1537299.5000 - val_mae: 656.0952\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1449480.0000 - mae: 631.1538 - val_loss: 1371091.5000 - val_mae: 611.2192\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1326063.6250 - mae: 601.0628 - val_loss: 1279862.2500 - val_mae: 589.2632\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1252734.2500 - mae: 583.3549 - val_loss: 1221873.3750 - val_mae: 577.6440\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1204965.3750 - mae: 572.9892 - val_loss: 1182030.5000 - val_mae: 563.8056\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1171554.0000 - mae: 563.9313 - val_loss: 1153294.5000 - val_mae: 555.8978\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1144791.8750 - mae: 556.8668 - val_loss: 1128509.8750 - val_mae: 550.3657\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1121213.1250 - mae: 550.9722 - val_loss: 1106166.1250 - val_mae: 547.7325\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1100906.5000 - mae: 546.4730 - val_loss: 1087395.7500 - val_mae: 541.1857\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1083914.8750 - mae: 542.2343 - val_loss: 1071115.0000 - val_mae: 537.3530\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1068366.7500 - mae: 538.3453 - val_loss: 1058053.6250 - val_mae: 536.8705\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1056057.6250 - mae: 534.8001 - val_loss: 1046698.4375 - val_mae: 532.6212\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1044865.6875 - mae: 531.6841 - val_loss: 1036107.8750 - val_mae: 530.2803\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1034606.0625 - mae: 529.3157 - val_loss: 1024516.4375 - val_mae: 525.9717\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1023685.6250 - mae: 526.7078 - val_loss: 1016098.9375 - val_mae: 522.4214\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1015196.4375 - mae: 524.2245 - val_loss: 1006575.0000 - val_mae: 522.8127\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1007093.0625 - mae: 522.5159 - val_loss: 1000193.3750 - val_mae: 521.5992\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1000466.8125 - mae: 520.4077 - val_loss: 993737.1250 - val_mae: 519.5143\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 994137.9375 - mae: 518.4788 - val_loss: 988608.2500 - val_mae: 517.1836\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 989325.1250 - mae: 516.5966 - val_loss: 983577.8125 - val_mae: 513.0206\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 984289.0000 - mae: 514.6954 - val_loss: 979218.7500 - val_mae: 514.4245\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 979933.6875 - mae: 513.7765 - val_loss: 975221.5625 - val_mae: 509.5163\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 976232.1875 - mae: 511.6490 - val_loss: 971808.1250 - val_mae: 509.2965\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 972772.6250 - mae: 509.6718 - val_loss: 968787.9375 - val_mae: 511.4758\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 969736.5000 - mae: 508.8517 - val_loss: 965561.0000 - val_mae: 510.1833\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 966773.8125 - mae: 508.0544 - val_loss: 963155.9375 - val_mae: 503.0828\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 963393.1250 - mae: 505.7482 - val_loss: 961134.3125 - val_mae: 506.6345\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 961491.1250 - mae: 504.7901 - val_loss: 957243.5625 - val_mae: 501.5834\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 958716.3750 - mae: 503.5191 - val_loss: 955600.6250 - val_mae: 503.7750\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 956807.3125 - mae: 502.3304 - val_loss: 953962.0625 - val_mae: 502.4418\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 954877.8125 - mae: 502.3628 - val_loss: 950934.3125 - val_mae: 502.6009\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 952734.8125 - mae: 501.1655 - val_loss: 948404.7500 - val_mae: 502.2822\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 949727.2500 - mae: 500.5585 - val_loss: 946713.7500 - val_mae: 496.5980\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 947248.1875 - mae: 499.1240 - val_loss: 942570.1875 - val_mae: 496.1802\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 944151.9375 - mae: 498.5218 - val_loss: 939295.3750 - val_mae: 497.8567\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 940630.3125 - mae: 497.6854 - val_loss: 935796.4375 - val_mae: 496.2180\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 937571.6875 - mae: 496.7198 - val_loss: 932575.5000 - val_mae: 495.6428\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 933875.0000 - mae: 495.9070 - val_loss: 931453.2500 - val_mae: 493.5031\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 931543.1875 - mae: 494.5878 - val_loss: 928475.1250 - val_mae: 496.5638\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 928694.1250 - mae: 494.0765 - val_loss: 923826.3750 - val_mae: 493.3968\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 925188.5625 - mae: 493.5772 - val_loss: 918931.0000 - val_mae: 490.8466\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 917428.3750 - mae: 492.0798 - val_loss: 901199.4375 - val_mae: 489.9849\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 875277.3750 - mae: 489.6372 - val_loss: 841652.1250 - val_mae: 486.2457\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 798774.1250 - mae: 486.3992 - val_loss: 750261.3750 - val_mae: 483.6534\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 720215.1875 - mae: 482.7817 - val_loss: 685860.0625 - val_mae: 480.2456\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 663097.6250 - mae: 478.3485 - val_loss: 636047.5625 - val_mae: 475.6012\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 615298.2500 - mae: 473.4789 - val_loss: 589306.0000 - val_mae: 469.2870\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 575506.3750 - mae: 467.2149 - val_loss: 558258.6250 - val_mae: 466.0120\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550754.0625 - mae: 462.1153 - val_loss: 538697.9375 - val_mae: 461.6208\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534108.5625 - mae: 458.3393 - val_loss: 523971.4375 - val_mae: 457.6469\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 521620.9688 - mae: 454.5841 - val_loss: 512718.4062 - val_mae: 452.4049\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 513908.4375 - mae: 452.3350 - val_loss: 507651.2812 - val_mae: 450.2545\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 509167.8125 - mae: 450.2237 - val_loss: 502168.9062 - val_mae: 448.3201\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 504522.5938 - mae: 448.8008 - val_loss: 499875.8438 - val_mae: 445.5888\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 501432.1875 - mae: 446.6340 - val_loss: 497209.9375 - val_mae: 447.6928\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 499069.4375 - mae: 446.0177 - val_loss: 495046.2188 - val_mae: 441.8375\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 496694.4062 - mae: 444.9893 - val_loss: 492213.4375 - val_mae: 443.6737\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 494747.4375 - mae: 443.7851 - val_loss: 489782.6875 - val_mae: 441.7867\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 485823.3750 - mae: 442.7057 - val_loss: 475642.8750 - val_mae: 441.6024\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 475184.8750 - mae: 441.5284 - val_loss: 467980.9062 - val_mae: 439.8111\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 467838.4375 - mae: 440.4080 - val_loss: 460385.3750 - val_mae: 437.2491\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 461816.7812 - mae: 439.9487 - val_loss: 455320.1562 - val_mae: 438.2747\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 456847.3125 - mae: 438.9721 - val_loss: 451393.5000 - val_mae: 436.2454\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 451872.4062 - mae: 437.6981 - val_loss: 445906.7500 - val_mae: 435.3694\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 447887.5312 - mae: 437.0518 - val_loss: 442345.0000 - val_mae: 433.9837\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 444043.7500 - mae: 435.5003 - val_loss: 439418.2500 - val_mae: 432.9484\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441101.0000 - mae: 434.5241 - val_loss: 437654.2188 - val_mae: 435.1796\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437802.5312 - mae: 434.8014 - val_loss: 434641.2500 - val_mae: 430.7380\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435184.9375 - mae: 433.8397 - val_loss: 431168.0625 - val_mae: 430.5420\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432517.5938 - mae: 432.7775 - val_loss: 430085.9375 - val_mae: 434.1051\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430814.9375 - mae: 432.2455 - val_loss: 427337.8750 - val_mae: 432.1531\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429214.7188 - mae: 431.4557 - val_loss: 425619.3125 - val_mae: 430.5570\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427066.8438 - mae: 430.8954 - val_loss: 424707.4062 - val_mae: 429.9056\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426652.2500 - mae: 430.4841 - val_loss: 423670.5000 - val_mae: 427.2439\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420734.1875 - mae: 429.5587 - val_loss: 409131.3438 - val_mae: 429.4824\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407527.6875 - mae: 428.8143 - val_loss: 397533.6562 - val_mae: 427.5394\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 397489.3125 - mae: 428.5049 - val_loss: 389370.9062 - val_mae: 424.9646\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 388662.3125 - mae: 427.8416 - val_loss: 379440.6875 - val_mae: 426.6877\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 379042.7500 - mae: 427.1481 - val_loss: 371224.7188 - val_mae: 427.2478\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 370884.1250 - mae: 426.3261 - val_loss: 363556.9375 - val_mae: 423.8114\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 364719.0625 - mae: 425.5407 - val_loss: 357645.0625 - val_mae: 424.8742\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358359.7500 - mae: 424.7804 - val_loss: 352293.0312 - val_mae: 423.2239\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353355.5000 - mae: 423.8668 - val_loss: 346893.8438 - val_mae: 420.5397\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348550.4375 - mae: 422.7898 - val_loss: 343572.2188 - val_mae: 422.2190\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 345103.0625 - mae: 422.2198 - val_loss: 340302.7188 - val_mae: 418.7627\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342110.4375 - mae: 421.2912 - val_loss: 337639.1562 - val_mae: 420.0766\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339887.2188 - mae: 421.1540 - val_loss: 336525.5625 - val_mae: 421.7656\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 338062.7500 - mae: 421.1413 - val_loss: 334527.4375 - val_mae: 418.8028\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 336791.4688 - mae: 419.9354 - val_loss: 333429.0625 - val_mae: 419.8244\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 335828.6250 - mae: 419.6285 - val_loss: 335040.0312 - val_mae: 424.1316\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 335160.5625 - mae: 419.9344 - val_loss: 331699.7812 - val_mae: 416.2903\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334840.6562 - mae: 419.2448 - val_loss: 331673.9375 - val_mae: 417.2376\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333945.0312 - mae: 419.0168 - val_loss: 331983.1875 - val_mae: 419.4232\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334288.9062 - mae: 419.4670 - val_loss: 331514.5312 - val_mae: 416.0659\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334459.6250 - mae: 419.1731 - val_loss: 330723.8750 - val_mae: 416.3532\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333627.2188 - mae: 418.7219 - val_loss: 331920.6250 - val_mae: 416.2757\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333445.3438 - mae: 418.8791 - val_loss: 330902.6250 - val_mae: 418.8309\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333493.3125 - mae: 418.9267 - val_loss: 330524.4375 - val_mae: 417.8890\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333183.6562 - mae: 418.8430 - val_loss: 330599.9062 - val_mae: 417.9426\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333385.6250 - mae: 418.8521 - val_loss: 329900.0625 - val_mae: 418.6341\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333260.5938 - mae: 418.8272 - val_loss: 329939.9375 - val_mae: 418.8364\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332356.1250 - mae: 418.4116 - val_loss: 329392.0625 - val_mae: 416.3768\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332011.2812 - mae: 418.4632 - val_loss: 328918.8438 - val_mae: 416.2734\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331555.3125 - mae: 418.1413 - val_loss: 328932.5938 - val_mae: 415.9082\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 332060.9062 - mae: 418.6076 - val_loss: 329648.9688 - val_mae: 415.0807\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331635.1875 - mae: 417.7751 - val_loss: 328001.7188 - val_mae: 414.6671\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331312.5625 - mae: 417.8712 - val_loss: 328234.4062 - val_mae: 414.8821\n",
      "Epoch 110/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331211.5312 - mae: 417.8467 - val_loss: 327591.6875 - val_mae: 414.9513\n",
      "Epoch 111/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330738.6875 - mae: 417.7715 - val_loss: 327868.3125 - val_mae: 415.6284\n",
      "Epoch 112/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330805.5938 - mae: 418.0158 - val_loss: 327668.1875 - val_mae: 417.7253\n",
      "Epoch 113/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330251.1875 - mae: 417.8527 - val_loss: 327607.7188 - val_mae: 415.3904\n",
      "Epoch 114/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330425.1875 - mae: 417.0500 - val_loss: 328113.6250 - val_mae: 418.5052\n",
      "Epoch 115/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330032.9062 - mae: 417.1298 - val_loss: 327555.1562 - val_mae: 416.2169\n",
      "Epoch 116/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329407.1875 - mae: 416.8975 - val_loss: 327414.7500 - val_mae: 415.1523\n",
      "Epoch 117/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329693.5938 - mae: 417.0416 - val_loss: 327591.5938 - val_mae: 415.5968\n",
      "Epoch 118/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329669.8438 - mae: 416.9519 - val_loss: 326916.7500 - val_mae: 415.4684\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 36928312.0000 - mae: 5929.4399 - val_loss: 33310498.0000 - val_mae: 5649.4736\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 27389832.0000 - mae: 5118.5547 - val_loss: 21233858.0000 - val_mae: 4499.9761\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 16099574.0000 - mae: 3819.0305 - val_loss: 11630477.0000 - val_mae: 3138.8811\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 8578798.0000 - mae: 2561.4163 - val_loss: 6060608.5000 - val_mae: 2045.3424\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4493454.5000 - mae: 1669.6741 - val_loss: 3260766.2500 - val_mae: 1355.8230\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2516481.5000 - mae: 1149.7202 - val_loss: 1897693.6250 - val_mae: 977.3459\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1478207.3750 - mae: 864.5712 - val_loss: 1142036.8750 - val_mae: 774.6499\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 951847.2500 - mae: 715.2075 - val_loss: 798897.5000 - val_mae: 665.4463\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 712846.3750 - mae: 628.1601 - val_loss: 642734.6250 - val_mae: 595.6791\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605020.7500 - mae: 575.7037 - val_loss: 570827.2500 - val_mae: 558.0070\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552571.3125 - mae: 547.9717 - val_loss: 533397.6875 - val_mae: 537.6083\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 523345.9375 - mae: 532.1421 - val_loss: 511142.5312 - val_mae: 528.8395\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 504836.0000 - mae: 523.9783 - val_loss: 493837.4062 - val_mae: 517.9515\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 489645.1250 - mae: 515.2629 - val_loss: 480723.9062 - val_mae: 512.0636\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 477253.6250 - mae: 509.2742 - val_loss: 469083.1250 - val_mae: 505.4280\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 466724.1875 - mae: 503.8313 - val_loss: 458823.0312 - val_mae: 499.7909\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 457182.1562 - mae: 498.5797 - val_loss: 450313.5312 - val_mae: 496.1496\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 449290.6250 - mae: 494.5215 - val_loss: 443340.9375 - val_mae: 490.0989\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442363.3438 - mae: 490.6154 - val_loss: 436362.6250 - val_mae: 486.7359\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436205.5312 - mae: 487.1242 - val_loss: 431682.0625 - val_mae: 483.0345\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 431114.3438 - mae: 484.2103 - val_loss: 425896.2500 - val_mae: 481.5750\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425986.3125 - mae: 481.4468 - val_loss: 421688.5625 - val_mae: 479.7432\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 422041.1875 - mae: 479.5411 - val_loss: 416900.1250 - val_mae: 476.4044\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417307.5312 - mae: 475.8698 - val_loss: 412863.8750 - val_mae: 474.2470\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413621.5625 - mae: 474.3206 - val_loss: 409124.0938 - val_mae: 471.2445\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410102.6875 - mae: 471.6991 - val_loss: 406022.1250 - val_mae: 469.7751\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407015.7812 - mae: 469.5878 - val_loss: 402888.4062 - val_mae: 467.7498\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403867.7500 - mae: 467.6361 - val_loss: 399912.9688 - val_mae: 464.8837\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401201.7188 - mae: 465.8543 - val_loss: 397094.2500 - val_mae: 463.3782\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398743.4688 - mae: 464.2151 - val_loss: 394707.3438 - val_mae: 461.5939\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396312.4375 - mae: 462.3859 - val_loss: 392830.4375 - val_mae: 460.7578\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394437.6250 - mae: 461.1339 - val_loss: 390595.1562 - val_mae: 459.0149\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392216.8750 - mae: 459.1853 - val_loss: 388500.1875 - val_mae: 457.4666\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390234.7812 - mae: 457.9193 - val_loss: 386747.1875 - val_mae: 454.5471\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 387822.1562 - mae: 455.7174 - val_loss: 384672.2500 - val_mae: 454.4728\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386285.2500 - mae: 454.7174 - val_loss: 383922.2188 - val_mae: 456.4501\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 384169.2188 - mae: 453.4321 - val_loss: 381038.5938 - val_mae: 452.7910\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382530.9375 - mae: 452.0617 - val_loss: 379245.1250 - val_mae: 451.0767\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 381257.7500 - mae: 451.0295 - val_loss: 378255.0938 - val_mae: 450.9718\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 379149.4375 - mae: 449.7186 - val_loss: 376622.4375 - val_mae: 449.4580\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377842.0625 - mae: 448.8087 - val_loss: 375414.5625 - val_mae: 449.3750\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 376434.4688 - mae: 448.2523 - val_loss: 373844.0000 - val_mae: 445.6687\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 375595.8125 - mae: 447.2663 - val_loss: 372220.3750 - val_mae: 444.4785\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374475.5312 - mae: 446.1946 - val_loss: 371181.2812 - val_mae: 444.9404\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373309.5000 - mae: 445.4669 - val_loss: 370474.4375 - val_mae: 443.8045\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 372658.9688 - mae: 444.6101 - val_loss: 369700.6562 - val_mae: 444.9351\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371277.8438 - mae: 444.7155 - val_loss: 369025.8125 - val_mae: 443.0461\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371001.0000 - mae: 443.8146 - val_loss: 367903.8750 - val_mae: 443.0240\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370161.5000 - mae: 443.6409 - val_loss: 367041.7500 - val_mae: 441.2120\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369447.7188 - mae: 442.7395 - val_loss: 366382.9062 - val_mae: 440.7093\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368754.7500 - mae: 442.4066 - val_loss: 366683.5938 - val_mae: 443.4341\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368158.1875 - mae: 442.0128 - val_loss: 365176.4688 - val_mae: 439.8968\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367432.4688 - mae: 441.3730 - val_loss: 364801.5000 - val_mae: 441.1043\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 366822.4062 - mae: 441.1959 - val_loss: 364117.9375 - val_mae: 438.2159\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366005.7812 - mae: 440.1434 - val_loss: 363554.4688 - val_mae: 439.9584\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365253.0312 - mae: 440.0812 - val_loss: 362650.4375 - val_mae: 437.8418\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364905.3750 - mae: 439.6141 - val_loss: 361819.0312 - val_mae: 437.8801\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363833.0625 - mae: 439.1562 - val_loss: 361164.9062 - val_mae: 436.2237\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363159.2188 - mae: 438.3285 - val_loss: 360671.6250 - val_mae: 436.2826\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362592.2500 - mae: 437.5478 - val_loss: 359824.4062 - val_mae: 437.7642\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361814.2188 - mae: 437.2998 - val_loss: 359279.8125 - val_mae: 436.7693\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361199.0625 - mae: 437.2247 - val_loss: 358597.9688 - val_mae: 434.0711\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360720.2812 - mae: 436.7505 - val_loss: 357798.2812 - val_mae: 436.2054\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359955.2500 - mae: 436.1361 - val_loss: 358803.1875 - val_mae: 439.1388\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359366.5312 - mae: 436.0759 - val_loss: 356397.1250 - val_mae: 434.1984\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 358908.4062 - mae: 435.8290 - val_loss: 355773.3438 - val_mae: 433.3546\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357891.8125 - mae: 434.5958 - val_loss: 355299.9062 - val_mae: 433.3588\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357472.6875 - mae: 434.2665 - val_loss: 355387.7500 - val_mae: 435.2552\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357205.9062 - mae: 434.4269 - val_loss: 354594.7812 - val_mae: 431.6687\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356381.2812 - mae: 433.9250 - val_loss: 353709.4375 - val_mae: 431.1765\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355565.1875 - mae: 433.0763 - val_loss: 353260.9375 - val_mae: 432.4759\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354849.0312 - mae: 432.5830 - val_loss: 352580.0000 - val_mae: 432.2663\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354235.5000 - mae: 432.7219 - val_loss: 351875.3438 - val_mae: 430.6219\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353865.8438 - mae: 432.2310 - val_loss: 351010.8750 - val_mae: 430.0950\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353244.9062 - mae: 432.0346 - val_loss: 349885.2500 - val_mae: 429.5413\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351690.6875 - mae: 430.4420 - val_loss: 349476.1875 - val_mae: 431.9806\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350787.9375 - mae: 430.6656 - val_loss: 348202.2500 - val_mae: 428.9496\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349578.0312 - mae: 430.1113 - val_loss: 346931.7812 - val_mae: 426.5632\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348339.2188 - mae: 429.0417 - val_loss: 345962.6875 - val_mae: 427.3347\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347384.1875 - mae: 428.9998 - val_loss: 344365.3125 - val_mae: 426.2967\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346095.4375 - mae: 427.6102 - val_loss: 344252.2500 - val_mae: 428.9042\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345322.8125 - mae: 427.9503 - val_loss: 342339.7812 - val_mae: 424.9541\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344387.3125 - mae: 426.8574 - val_loss: 341383.5938 - val_mae: 425.6119\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 343261.8438 - mae: 426.1534 - val_loss: 340466.5938 - val_mae: 424.1411\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342256.5312 - mae: 425.6570 - val_loss: 339386.3750 - val_mae: 423.2674\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341379.1562 - mae: 425.0089 - val_loss: 338617.9062 - val_mae: 424.4203\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340710.2500 - mae: 424.8767 - val_loss: 338235.5625 - val_mae: 424.9102\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340345.6250 - mae: 424.5997 - val_loss: 337146.0938 - val_mae: 423.1279\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339122.2188 - mae: 423.6832 - val_loss: 337020.2188 - val_mae: 424.3651\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338765.2500 - mae: 423.5800 - val_loss: 336484.4688 - val_mae: 423.2885\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338173.5312 - mae: 423.6920 - val_loss: 336026.6250 - val_mae: 422.6887\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338111.4375 - mae: 423.5840 - val_loss: 335203.3438 - val_mae: 421.4418\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337280.2812 - mae: 422.8432 - val_loss: 335073.6250 - val_mae: 421.1229\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337000.6562 - mae: 422.5995 - val_loss: 335584.4062 - val_mae: 423.8963\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337211.4062 - mae: 423.0054 - val_loss: 334260.2188 - val_mae: 421.9845\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336498.8750 - mae: 422.5969 - val_loss: 333749.5000 - val_mae: 420.8649\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 335970.9688 - mae: 421.7715 - val_loss: 334498.2500 - val_mae: 423.5442\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335770.0938 - mae: 421.9668 - val_loss: 333553.9062 - val_mae: 422.0849\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335639.2500 - mae: 422.1145 - val_loss: 332893.9688 - val_mae: 419.8766\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335240.7500 - mae: 421.3547 - val_loss: 333278.1875 - val_mae: 422.1945\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335093.0938 - mae: 421.8070 - val_loss: 332999.9062 - val_mae: 419.2110\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334585.9062 - mae: 421.1332 - val_loss: 332533.9688 - val_mae: 420.1379\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334616.0000 - mae: 421.6727 - val_loss: 332294.9062 - val_mae: 418.8086\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334266.5938 - mae: 420.8889 - val_loss: 331989.2500 - val_mae: 418.7021\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334139.2812 - mae: 420.6362 - val_loss: 332160.9062 - val_mae: 421.7972\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 334039.5312 - mae: 420.8418 - val_loss: 331567.4375 - val_mae: 419.9452\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333452.8750 - mae: 420.9250 - val_loss: 331318.2812 - val_mae: 417.7969\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333333.0312 - mae: 420.1918 - val_loss: 330961.4688 - val_mae: 418.6506\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 333082.9375 - mae: 420.0904 - val_loss: 330705.6250 - val_mae: 418.8764\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 333054.4688 - mae: 419.8522 - val_loss: 330791.2188 - val_mae: 419.6219\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 333047.3750 - mae: 420.2268 - val_loss: 330329.2812 - val_mae: 417.7741\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332818.9688 - mae: 419.5392 - val_loss: 330549.2188 - val_mae: 417.7096\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 332491.3125 - mae: 419.7272 - val_loss: 330069.7812 - val_mae: 418.8807\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332203.0000 - mae: 419.4826 - val_loss: 330142.0312 - val_mae: 418.5482\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332214.6250 - mae: 419.7631 - val_loss: 330072.3125 - val_mae: 417.2747\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332252.1562 - mae: 419.1780 - val_loss: 329514.0312 - val_mae: 417.1257\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 331902.3750 - mae: 419.2931 - val_loss: 329623.3750 - val_mae: 419.3552\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331532.3750 - mae: 419.5008 - val_loss: 329821.5938 - val_mae: 416.5835\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331488.8438 - mae: 418.6718 - val_loss: 329162.6562 - val_mae: 418.0485\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331541.9062 - mae: 418.9617 - val_loss: 328950.9375 - val_mae: 416.8805\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331048.3125 - mae: 418.7538 - val_loss: 328592.3125 - val_mae: 417.4153\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330958.5938 - mae: 418.4442 - val_loss: 328550.6250 - val_mae: 415.4102\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 330517.7812 - mae: 417.6902 - val_loss: 328169.7500 - val_mae: 417.5379\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330151.5312 - mae: 417.5739 - val_loss: 327534.8750 - val_mae: 416.9508\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329795.0312 - mae: 417.3096 - val_loss: 327405.4375 - val_mae: 416.3223\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329522.2500 - mae: 417.4009 - val_loss: 327292.0938 - val_mae: 415.3292\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329308.3438 - mae: 416.5650 - val_loss: 327703.8125 - val_mae: 417.9102\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329034.0625 - mae: 417.1298 - val_loss: 326933.4062 - val_mae: 415.8071\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329103.5312 - mae: 416.8514 - val_loss: 326856.4062 - val_mae: 414.8923\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328789.2500 - mae: 416.4953 - val_loss: 326575.9375 - val_mae: 414.1191\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328623.9688 - mae: 416.2546 - val_loss: 326280.7500 - val_mae: 415.1653\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328355.7188 - mae: 416.2667 - val_loss: 326217.3750 - val_mae: 414.1279\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328141.5938 - mae: 416.1002 - val_loss: 326357.1875 - val_mae: 413.6167\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328367.6562 - mae: 416.1159 - val_loss: 325895.8125 - val_mae: 414.2402\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328199.5312 - mae: 416.0737 - val_loss: 325721.0938 - val_mae: 414.8381\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328042.4062 - mae: 416.2002 - val_loss: 325464.6875 - val_mae: 414.3985\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327904.3125 - mae: 416.2179 - val_loss: 325511.6250 - val_mae: 414.2832\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327826.0938 - mae: 415.9899 - val_loss: 325574.5000 - val_mae: 413.9116\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327946.8750 - mae: 416.1391 - val_loss: 325674.9062 - val_mae: 413.3375\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 327550.6250 - mae: 415.2943 - val_loss: 325994.0312 - val_mae: 416.4717\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327784.2812 - mae: 415.9146 - val_loss: 325160.6562 - val_mae: 415.3915\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327853.5312 - mae: 415.7175 - val_loss: 324982.0938 - val_mae: 414.1009\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327217.6875 - mae: 415.5446 - val_loss: 325383.0312 - val_mae: 413.6649\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327523.5312 - mae: 415.7844 - val_loss: 325770.9375 - val_mae: 412.8229\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327157.4375 - mae: 415.2843 - val_loss: 325087.9375 - val_mae: 415.3394\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 327147.7188 - mae: 415.6443 - val_loss: 324876.0938 - val_mae: 414.2596\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327104.3125 - mae: 415.3047 - val_loss: 324666.6250 - val_mae: 413.7789\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326658.7812 - mae: 415.1065 - val_loss: 324915.6875 - val_mae: 414.0179\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326758.7500 - mae: 415.2146 - val_loss: 325302.5312 - val_mae: 412.9387\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326844.2812 - mae: 415.3634 - val_loss: 324617.4062 - val_mae: 412.9112\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326635.3125 - mae: 414.9126 - val_loss: 324255.9688 - val_mae: 413.9252\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 326511.3125 - mae: 414.9978 - val_loss: 324464.3750 - val_mae: 413.9539\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326565.4375 - mae: 415.0925 - val_loss: 324504.4062 - val_mae: 412.9543\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326547.6250 - mae: 415.1161 - val_loss: 324117.3750 - val_mae: 414.0555\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 36234012.0000 - mae: 5870.9028 - val_loss: 31053680.0000 - val_mae: 5453.8696\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 23173304.0000 - mae: 4681.9941 - val_loss: 15420468.0000 - val_mae: 3798.4216\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 9907008.0000 - mae: 2900.5320 - val_loss: 5649830.5000 - val_mae: 2068.8132\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3555083.0000 - mae: 1528.7640 - val_loss: 2168854.5000 - val_mae: 1128.0139\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1630884.8750 - mae: 946.9585 - val_loss: 1269677.8750 - val_mae: 825.9802\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1094666.8750 - mae: 765.3971 - val_loss: 953873.8125 - val_mae: 715.2694\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 869463.9375 - mae: 682.6352 - val_loss: 792436.7500 - val_mae: 653.3917\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 742323.1250 - mae: 633.3296 - val_loss: 691041.4375 - val_mae: 613.5911\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 658169.6250 - mae: 598.8709 - val_loss: 623060.0625 - val_mae: 584.0507\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 601412.5625 - mae: 573.2932 - val_loss: 575675.0000 - val_mae: 562.1711\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 561943.8750 - mae: 553.8712 - val_loss: 543011.1250 - val_mae: 544.8843\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 533850.6875 - mae: 538.6826 - val_loss: 520847.0938 - val_mae: 530.8719\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 2s 6ms/step - loss: 515330.9688 - mae: 527.1697 - val_loss: 503990.4062 - val_mae: 521.7206\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 500890.1562 - mae: 518.9379 - val_loss: 491728.8125 - val_mae: 515.3912\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 489228.4375 - mae: 511.8366 - val_loss: 480494.6562 - val_mae: 508.0140\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 479266.0625 - mae: 506.1417 - val_loss: 471179.0938 - val_mae: 502.0955\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 470004.8125 - mae: 500.7590 - val_loss: 462971.3125 - val_mae: 497.5258\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 462327.8438 - mae: 495.3640 - val_loss: 455455.5000 - val_mae: 492.8949\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 455708.4688 - mae: 491.8766 - val_loss: 448580.8438 - val_mae: 488.5950\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 448471.6562 - mae: 487.8116 - val_loss: 442322.0000 - val_mae: 486.0559\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 442546.0938 - mae: 484.5476 - val_loss: 436288.8125 - val_mae: 481.6075\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 437011.9375 - mae: 481.6390 - val_loss: 431243.2188 - val_mae: 478.0696\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432489.2188 - mae: 479.0407 - val_loss: 426754.5625 - val_mae: 476.1891\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 427674.7812 - mae: 476.3615 - val_loss: 423796.1875 - val_mae: 475.1524\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424306.9375 - mae: 474.8636 - val_loss: 420098.2812 - val_mae: 469.9619\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420859.6875 - mae: 471.9420 - val_loss: 416147.9375 - val_mae: 471.3084\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417847.9062 - mae: 471.0597 - val_loss: 413233.8125 - val_mae: 467.5573\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414779.0938 - mae: 469.1201 - val_loss: 411042.7500 - val_mae: 469.2753\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412479.6562 - mae: 467.5343 - val_loss: 408109.7812 - val_mae: 467.0963\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409910.5938 - mae: 466.1391 - val_loss: 405238.1250 - val_mae: 463.0075\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 407068.8750 - mae: 464.6397 - val_loss: 403524.3125 - val_mae: 465.6609\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 2s 5ms/step - loss: 404842.1562 - mae: 463.6059 - val_loss: 401525.2500 - val_mae: 461.3397\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402658.8750 - mae: 461.8043 - val_loss: 398477.7188 - val_mae: 460.8188\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400873.2500 - mae: 461.0596 - val_loss: 396729.0938 - val_mae: 459.2548\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 399356.8438 - mae: 460.7762 - val_loss: 395279.4688 - val_mae: 457.9096\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 397910.6875 - mae: 459.2055 - val_loss: 394296.7500 - val_mae: 456.4793\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 396408.6562 - mae: 458.5663 - val_loss: 392805.6875 - val_mae: 457.1242\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 394838.0312 - mae: 457.9530 - val_loss: 391570.1562 - val_mae: 456.5536\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 393533.7188 - mae: 457.2063 - val_loss: 390776.1250 - val_mae: 454.5689\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 392437.8750 - mae: 456.0485 - val_loss: 390867.7812 - val_mae: 453.3434\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 392067.5625 - mae: 455.8791 - val_loss: 388322.0000 - val_mae: 455.7759\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390920.0625 - mae: 455.9850 - val_loss: 386971.2812 - val_mae: 453.1048\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 389724.0000 - mae: 454.8121 - val_loss: 386129.8438 - val_mae: 452.7491\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 388269.0000 - mae: 454.2270 - val_loss: 385297.9375 - val_mae: 453.0747\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 387915.3438 - mae: 453.9590 - val_loss: 384092.9062 - val_mae: 451.1047\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 386935.2812 - mae: 453.3417 - val_loss: 383267.3125 - val_mae: 451.7286\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 385763.8750 - mae: 452.5525 - val_loss: 382664.7812 - val_mae: 451.9536\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 385335.9688 - mae: 452.3658 - val_loss: 381762.9375 - val_mae: 453.3055\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 384249.5938 - mae: 452.2246 - val_loss: 380183.5312 - val_mae: 449.7136\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 382974.7500 - mae: 451.6310 - val_loss: 379703.2188 - val_mae: 448.3748\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 382038.7500 - mae: 451.0733 - val_loss: 378424.2812 - val_mae: 448.3973\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 380911.9375 - mae: 450.0843 - val_loss: 378050.8125 - val_mae: 450.9810\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 379948.8438 - mae: 450.3642 - val_loss: 376274.4062 - val_mae: 448.0546\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 379214.0625 - mae: 449.3495 - val_loss: 375361.6562 - val_mae: 446.4131\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 378140.9375 - mae: 448.3366 - val_loss: 374820.0625 - val_mae: 445.3310\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 376810.8438 - mae: 447.7565 - val_loss: 373420.5000 - val_mae: 445.3738\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 375607.0000 - mae: 447.4579 - val_loss: 372942.5312 - val_mae: 444.0779\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 374962.6875 - mae: 446.9055 - val_loss: 372112.7812 - val_mae: 442.8414\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 373793.8438 - mae: 445.9482 - val_loss: 370085.9375 - val_mae: 445.6411\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 372511.8125 - mae: 445.4866 - val_loss: 369112.2500 - val_mae: 443.9446\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371777.8125 - mae: 445.8421 - val_loss: 368447.1875 - val_mae: 443.1437\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370898.5312 - mae: 444.6133 - val_loss: 367066.2188 - val_mae: 443.5683\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369994.1250 - mae: 443.8764 - val_loss: 366537.8438 - val_mae: 443.6576\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368761.9375 - mae: 443.9528 - val_loss: 366907.3750 - val_mae: 440.0857\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 368397.1875 - mae: 443.3427 - val_loss: 365009.0625 - val_mae: 440.8607\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 367512.0938 - mae: 442.3495 - val_loss: 364522.9688 - val_mae: 443.1591\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 366661.6562 - mae: 442.5961 - val_loss: 363943.6250 - val_mae: 441.4813\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366436.3438 - mae: 442.3703 - val_loss: 363379.3125 - val_mae: 442.9628\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365165.0625 - mae: 441.4113 - val_loss: 362612.9375 - val_mae: 439.0120\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 364700.6562 - mae: 441.1539 - val_loss: 361570.3750 - val_mae: 439.5854\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364167.3750 - mae: 440.4510 - val_loss: 360771.5000 - val_mae: 439.6650\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363367.3438 - mae: 439.9419 - val_loss: 359966.3125 - val_mae: 437.6772\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 363138.9688 - mae: 439.9178 - val_loss: 359283.7500 - val_mae: 437.0034\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 362114.3750 - mae: 438.9826 - val_loss: 358719.8438 - val_mae: 438.5443\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 3s 6ms/step - loss: 361416.9062 - mae: 438.7859 - val_loss: 358245.9062 - val_mae: 437.3669\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 360678.0000 - mae: 437.7705 - val_loss: 358474.0312 - val_mae: 438.8995\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 360149.2812 - mae: 437.8919 - val_loss: 357669.9375 - val_mae: 438.2076\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 359930.3125 - mae: 437.5228 - val_loss: 357011.1250 - val_mae: 433.3441\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 2s 5ms/step - loss: 359044.7500 - mae: 436.5074 - val_loss: 355732.1250 - val_mae: 434.0112\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 358322.0625 - mae: 436.3861 - val_loss: 354871.7500 - val_mae: 434.0447\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357569.7500 - mae: 435.6018 - val_loss: 354690.3750 - val_mae: 432.0773\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 356782.0000 - mae: 434.4304 - val_loss: 353666.1562 - val_mae: 434.0571\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 356229.6875 - mae: 434.1838 - val_loss: 353533.9688 - val_mae: 431.2511\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 2s 5ms/step - loss: 355804.9688 - mae: 433.5906 - val_loss: 352455.0312 - val_mae: 433.0624\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 355184.9688 - mae: 433.5325 - val_loss: 351855.8125 - val_mae: 432.8254\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 354905.1250 - mae: 432.8300 - val_loss: 351564.3750 - val_mae: 431.6375\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 354031.5938 - mae: 432.3917 - val_loss: 350608.0938 - val_mae: 430.7402\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 353371.0625 - mae: 431.9817 - val_loss: 350541.6562 - val_mae: 431.4784\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 352747.9375 - mae: 431.2992 - val_loss: 349716.9688 - val_mae: 429.8644\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353004.5938 - mae: 431.1077 - val_loss: 349088.0625 - val_mae: 429.5451\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 351497.5938 - mae: 430.9648 - val_loss: 349587.9375 - val_mae: 427.9915\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 351369.3750 - mae: 429.9941 - val_loss: 348550.6562 - val_mae: 429.0653\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351532.2188 - mae: 430.4925 - val_loss: 348377.8125 - val_mae: 426.6737\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351000.6250 - mae: 430.0045 - val_loss: 347595.8750 - val_mae: 427.7728\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 350368.5312 - mae: 429.0713 - val_loss: 347179.4375 - val_mae: 428.4619\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 349651.9688 - mae: 429.0180 - val_loss: 347769.0000 - val_mae: 426.3071\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349718.8125 - mae: 428.4369 - val_loss: 346639.6562 - val_mae: 428.2738\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 349434.0938 - mae: 428.3020 - val_loss: 346238.6875 - val_mae: 427.4225\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 348973.8125 - mae: 428.0087 - val_loss: 345706.9375 - val_mae: 427.4438\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 348104.2188 - mae: 427.7216 - val_loss: 345598.2812 - val_mae: 426.6436\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 348568.7812 - mae: 427.9143 - val_loss: 345165.0625 - val_mae: 425.5774\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347931.6250 - mae: 427.6019 - val_loss: 345478.6250 - val_mae: 426.7032\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347823.9375 - mae: 427.3092 - val_loss: 345142.2812 - val_mae: 427.4316\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 347421.1875 - mae: 426.6955 - val_loss: 344755.0312 - val_mae: 425.8840\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347133.4688 - mae: 426.7395 - val_loss: 343635.9688 - val_mae: 424.9183\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 345954.1875 - mae: 426.0499 - val_loss: 344478.6875 - val_mae: 424.3044\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 346040.3438 - mae: 425.6962 - val_loss: 344259.3750 - val_mae: 426.1935\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 346553.1250 - mae: 426.0548 - val_loss: 342836.7812 - val_mae: 424.0892\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 345972.1250 - mae: 425.5325 - val_loss: 342644.7500 - val_mae: 423.7487\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 345769.0625 - mae: 425.5652 - val_loss: 342815.6562 - val_mae: 424.3326\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345505.3438 - mae: 425.0862 - val_loss: 342672.9062 - val_mae: 422.9074\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 345399.2500 - mae: 424.7778 - val_loss: 342181.9375 - val_mae: 423.7601\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345126.5938 - mae: 425.3119 - val_loss: 342014.6875 - val_mae: 423.7798\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344584.6875 - mae: 424.6561 - val_loss: 342156.6562 - val_mae: 424.0905\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344585.7812 - mae: 424.7454 - val_loss: 342334.6562 - val_mae: 424.9120\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 344379.1250 - mae: 424.9534 - val_loss: 341715.9062 - val_mae: 423.9615\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344484.4062 - mae: 424.5596 - val_loss: 341489.5000 - val_mae: 423.2238\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343977.4688 - mae: 424.3857 - val_loss: 341121.3125 - val_mae: 422.3901\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344375.6562 - mae: 424.1218 - val_loss: 340428.2188 - val_mae: 421.9871\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343492.2500 - mae: 423.8768 - val_loss: 340473.8125 - val_mae: 422.1659\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343368.2500 - mae: 424.3277 - val_loss: 340649.9062 - val_mae: 421.2639\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 342977.2500 - mae: 423.6748 - val_loss: 340111.4375 - val_mae: 422.3987\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 342909.1250 - mae: 423.6499 - val_loss: 339926.1875 - val_mae: 421.7264\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342170.2188 - mae: 423.5462 - val_loss: 339960.0312 - val_mae: 421.8497\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342695.0312 - mae: 423.7388 - val_loss: 339875.1875 - val_mae: 420.7204\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341929.0625 - mae: 423.5255 - val_loss: 339363.6875 - val_mae: 422.3646\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 341726.1875 - mae: 423.1226 - val_loss: 338474.5000 - val_mae: 422.4784\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341081.9375 - mae: 423.0512 - val_loss: 339517.2812 - val_mae: 424.4749\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340547.8750 - mae: 423.0704 - val_loss: 338077.1250 - val_mae: 420.7583\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 340308.6562 - mae: 422.5681 - val_loss: 338921.1875 - val_mae: 423.1270\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340044.8438 - mae: 423.1133 - val_loss: 338061.7188 - val_mae: 422.0406\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339639.2812 - mae: 422.7911 - val_loss: 338377.6562 - val_mae: 423.2861\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339434.3750 - mae: 422.3405 - val_loss: 337029.8438 - val_mae: 420.2957\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339497.0312 - mae: 422.4653 - val_loss: 336122.0938 - val_mae: 419.8219\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338911.9688 - mae: 422.6417 - val_loss: 335956.5938 - val_mae: 420.7088\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 338168.3750 - mae: 421.9160 - val_loss: 336829.7188 - val_mae: 423.8918\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338029.2188 - mae: 422.4139 - val_loss: 335676.6562 - val_mae: 420.7952\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337840.8125 - mae: 421.6462 - val_loss: 335369.0938 - val_mae: 421.6667\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337615.6250 - mae: 421.9938 - val_loss: 334470.6562 - val_mae: 421.0058\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337166.6250 - mae: 422.2203 - val_loss: 336825.8750 - val_mae: 424.9841\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337185.5938 - mae: 421.9870 - val_loss: 334686.3438 - val_mae: 420.7064\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337007.0938 - mae: 421.6804 - val_loss: 333999.4375 - val_mae: 419.8157\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336615.3438 - mae: 421.3909 - val_loss: 335259.7812 - val_mae: 421.6136\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336441.9688 - mae: 422.2983 - val_loss: 334810.8438 - val_mae: 418.6122\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336363.0625 - mae: 421.4221 - val_loss: 333497.1875 - val_mae: 421.2403\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336182.0000 - mae: 421.4280 - val_loss: 333356.9688 - val_mae: 421.8988\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335684.6250 - mae: 421.2190 - val_loss: 333518.5938 - val_mae: 419.9798\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335678.7188 - mae: 421.2727 - val_loss: 332881.7188 - val_mae: 420.8895\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335061.3125 - mae: 421.2236 - val_loss: 332980.4375 - val_mae: 419.4298\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335042.7812 - mae: 421.0492 - val_loss: 332970.4688 - val_mae: 419.9655\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334557.5312 - mae: 420.9650 - val_loss: 332964.3125 - val_mae: 418.8712\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335177.1875 - mae: 420.9416 - val_loss: 332334.1875 - val_mae: 420.5949\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334981.9688 - mae: 420.5514 - val_loss: 332294.8125 - val_mae: 420.0742\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334509.8750 - mae: 421.1429 - val_loss: 331845.3750 - val_mae: 419.2680\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38185288.0000 - mae: 6023.0000 - val_loss: 37294980.0000 - val_mae: 5952.6704\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 35379092.0000 - mae: 5797.0205 - val_loss: 32996378.0000 - val_mae: 5599.0332\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 30025056.0000 - mae: 5335.8208 - val_loss: 26812460.0000 - val_mae: 5039.2964\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 23495940.0000 - mae: 4701.1050 - val_loss: 20146102.0000 - val_mae: 4339.6089\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 17048552.0000 - mae: 3959.3047 - val_loss: 14065342.0000 - val_mae: 3565.7815\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 11542262.0000 - mae: 3176.7249 - val_loss: 9209275.0000 - val_mae: 2785.7561\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 7386550.0000 - mae: 2423.2383 - val_loss: 5768163.5000 - val_mae: 2074.3767\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 4596896.0000 - mae: 1783.5500 - val_loss: 3596525.5000 - val_mae: 1522.1404\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2930266.7500 - mae: 1326.7783 - val_loss: 2376758.2500 - val_mae: 1157.1373\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2028257.8750 - mae: 1041.3158 - val_loss: 1739939.7500 - val_mae: 946.1348\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1560156.0000 - mae: 886.1833 - val_loss: 1406704.7500 - val_mae: 836.7673\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1303745.2500 - mae: 804.0814 - val_loss: 1209789.2500 - val_mae: 776.1179\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1141746.6250 - mae: 755.0886 - val_loss: 1075314.3750 - val_mae: 734.5485\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1025063.8750 - mae: 718.4351 - val_loss: 974949.5000 - val_mae: 703.3157\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 935476.4375 - mae: 690.5057 - val_loss: 894858.5000 - val_mae: 676.8099\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 864300.2500 - mae: 666.4130 - val_loss: 831109.8125 - val_mae: 654.6135\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 805699.5000 - mae: 645.2518 - val_loss: 777317.2500 - val_mae: 634.4984\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 756677.6250 - mae: 626.0925 - val_loss: 731772.6875 - val_mae: 616.5698\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 714399.8125 - mae: 609.2002 - val_loss: 693620.5625 - val_mae: 599.9259\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 679265.3125 - mae: 593.4258 - val_loss: 661375.9375 - val_mae: 586.0909\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 649976.1875 - mae: 580.7646 - val_loss: 635211.5625 - val_mae: 574.4075\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 625498.3125 - mae: 570.2880 - val_loss: 612383.5625 - val_mae: 564.4684\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604573.2500 - mae: 560.9344 - val_loss: 592981.5000 - val_mae: 556.2179\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 586378.1875 - mae: 552.9753 - val_loss: 575975.0625 - val_mae: 549.1221\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 569788.0625 - mae: 546.2852 - val_loss: 560362.0625 - val_mae: 541.4981\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555194.5625 - mae: 538.9595 - val_loss: 546489.1875 - val_mae: 537.3938\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 542060.4375 - mae: 534.3215 - val_loss: 533851.8125 - val_mae: 530.8633\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530386.5000 - mae: 528.4520 - val_loss: 523268.5625 - val_mae: 525.3528\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 520442.9688 - mae: 523.4564 - val_loss: 513529.4062 - val_mae: 520.9524\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 511407.8438 - mae: 519.8014 - val_loss: 505441.3125 - val_mae: 515.9883\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 503828.5000 - mae: 515.4577 - val_loss: 498077.2188 - val_mae: 513.3076\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 496888.7812 - mae: 512.2766 - val_loss: 491622.7500 - val_mae: 509.8175\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 490867.1875 - mae: 509.3120 - val_loss: 485967.8750 - val_mae: 507.0565\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 485380.5000 - mae: 506.3474 - val_loss: 480654.5625 - val_mae: 504.6802\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 480349.3438 - mae: 504.1788 - val_loss: 475791.0625 - val_mae: 501.6990\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 475570.4375 - mae: 501.3152 - val_loss: 471217.7188 - val_mae: 500.2188\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 471031.6875 - mae: 499.2254 - val_loss: 466761.4688 - val_mae: 497.7853\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 466640.4062 - mae: 497.1635 - val_loss: 462507.9062 - val_mae: 494.3246\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 462853.8438 - mae: 494.7114 - val_loss: 458772.5312 - val_mae: 493.4297\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 458839.6875 - mae: 492.5000 - val_loss: 455112.5312 - val_mae: 490.4979\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 455650.0938 - mae: 490.8120 - val_loss: 451756.9688 - val_mae: 489.5021\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452103.0000 - mae: 488.6857 - val_loss: 448517.5938 - val_mae: 487.2083\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 449064.0625 - mae: 487.2241 - val_loss: 445558.6250 - val_mae: 484.4178\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 6ms/step - loss: 446300.2500 - mae: 485.0650 - val_loss: 442800.6250 - val_mae: 483.0778\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 443416.8125 - mae: 483.6546 - val_loss: 440179.0000 - val_mae: 482.1515\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 441344.2812 - mae: 482.0244 - val_loss: 438073.0625 - val_mae: 482.5121\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 6ms/step - loss: 438497.4062 - mae: 481.0293 - val_loss: 435452.5000 - val_mae: 479.4940\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 436446.1875 - mae: 479.5760 - val_loss: 433490.1250 - val_mae: 478.4687\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 434328.2188 - mae: 478.2872 - val_loss: 431736.8438 - val_mae: 478.0801\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 432687.7188 - mae: 477.9130 - val_loss: 429869.4688 - val_mae: 475.0782\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 430930.7500 - mae: 476.2575 - val_loss: 428154.1875 - val_mae: 475.4833\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 6ms/step - loss: 429124.8750 - mae: 475.5130 - val_loss: 426569.8125 - val_mae: 473.3880\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 427807.3125 - mae: 474.2688 - val_loss: 424904.6250 - val_mae: 473.9500\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 426252.5625 - mae: 473.6112 - val_loss: 423731.0312 - val_mae: 474.3515\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 425048.7500 - mae: 473.4393 - val_loss: 422292.5312 - val_mae: 470.3004\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 423043.5312 - mae: 471.4402 - val_loss: 420392.6562 - val_mae: 470.7827\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 421871.4062 - mae: 471.3873 - val_loss: 419110.1562 - val_mae: 469.8257\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 420518.0000 - mae: 470.2717 - val_loss: 417536.4688 - val_mae: 468.3566\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 418885.5938 - mae: 469.4037 - val_loss: 416273.0625 - val_mae: 468.5684\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 417194.8750 - mae: 468.4734 - val_loss: 415105.1875 - val_mae: 465.6926\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 416120.5312 - mae: 467.1955 - val_loss: 413323.5625 - val_mae: 465.4844\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 414848.4688 - mae: 466.2365 - val_loss: 412070.2812 - val_mae: 465.1854\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 413547.2188 - mae: 465.6873 - val_loss: 411054.6875 - val_mae: 463.7231\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 412491.0625 - mae: 465.0025 - val_loss: 409909.0000 - val_mae: 463.7105\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 411420.5312 - mae: 464.1595 - val_loss: 408688.3125 - val_mae: 462.2560\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 410210.1562 - mae: 463.4464 - val_loss: 407678.8750 - val_mae: 462.8123\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 408917.6562 - mae: 462.4261 - val_loss: 406662.4375 - val_mae: 462.5574\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 407964.7812 - mae: 462.4258 - val_loss: 405934.5312 - val_mae: 459.4019\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 407022.1562 - mae: 461.3355 - val_loss: 404605.5000 - val_mae: 459.4380\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 405951.3438 - mae: 461.1359 - val_loss: 403697.1250 - val_mae: 458.6252\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 405161.9062 - mae: 460.2862 - val_loss: 402721.3125 - val_mae: 459.8186\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 404282.4062 - mae: 459.9740 - val_loss: 401666.6562 - val_mae: 458.3070\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 403514.8750 - mae: 459.0497 - val_loss: 400792.6562 - val_mae: 457.6643\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 402073.9688 - mae: 458.6078 - val_loss: 399918.7188 - val_mae: 457.9567\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 401260.1562 - mae: 458.1557 - val_loss: 399102.2812 - val_mae: 456.9839\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 400709.1562 - mae: 457.4109 - val_loss: 398232.3750 - val_mae: 456.7283\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399819.3438 - mae: 456.8016 - val_loss: 397515.9375 - val_mae: 456.5649\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399113.8438 - mae: 456.7030 - val_loss: 397011.5938 - val_mae: 454.6964\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 398148.1250 - mae: 455.7495 - val_loss: 395871.3750 - val_mae: 454.5555\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 397247.9375 - mae: 455.3475 - val_loss: 395265.5938 - val_mae: 453.5744\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 396607.6562 - mae: 454.6822 - val_loss: 394743.7188 - val_mae: 454.8028\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 395911.7812 - mae: 454.5742 - val_loss: 393961.7812 - val_mae: 453.2080\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 395470.6875 - mae: 453.8574 - val_loss: 392983.5938 - val_mae: 452.5606\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394667.1875 - mae: 453.3607 - val_loss: 392550.0000 - val_mae: 453.5954\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393748.4688 - mae: 452.9446 - val_loss: 391474.0312 - val_mae: 451.4757\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 392946.5000 - mae: 452.4804 - val_loss: 390535.7500 - val_mae: 451.1368\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 392056.5625 - mae: 451.7695 - val_loss: 389832.8438 - val_mae: 450.3594\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391369.6250 - mae: 451.3073 - val_loss: 388844.4688 - val_mae: 449.9581\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 390616.4062 - mae: 450.8503 - val_loss: 388270.7188 - val_mae: 448.7405\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 389633.3125 - mae: 450.2406 - val_loss: 387429.2188 - val_mae: 449.4702\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388940.0938 - mae: 449.9638 - val_loss: 386836.7500 - val_mae: 447.7813\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388098.0000 - mae: 449.2107 - val_loss: 385853.1875 - val_mae: 447.5401\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387354.1562 - mae: 448.8697 - val_loss: 385251.2500 - val_mae: 447.4960\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386478.6875 - mae: 448.4634 - val_loss: 384601.0312 - val_mae: 446.6917\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385966.6562 - mae: 447.7141 - val_loss: 384060.2812 - val_mae: 447.8951\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385511.5000 - mae: 447.6659 - val_loss: 383331.6562 - val_mae: 446.6329\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384865.2812 - mae: 447.3416 - val_loss: 382623.7812 - val_mae: 446.7425\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384226.4062 - mae: 447.0388 - val_loss: 382056.0312 - val_mae: 445.8588\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 383762.8438 - mae: 446.3904 - val_loss: 381560.9375 - val_mae: 445.7478\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 383241.6562 - mae: 446.1728 - val_loss: 380959.0938 - val_mae: 445.1675\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382771.9688 - mae: 446.0886 - val_loss: 380430.1875 - val_mae: 444.7880\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382123.3438 - mae: 445.6727 - val_loss: 379847.0938 - val_mae: 444.1813\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381222.8750 - mae: 444.8803 - val_loss: 379936.6562 - val_mae: 446.0149\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 381081.9688 - mae: 445.1436 - val_loss: 379092.3750 - val_mae: 442.8006\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380614.0312 - mae: 444.3752 - val_loss: 378462.6875 - val_mae: 444.5120\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380019.8438 - mae: 443.9310 - val_loss: 377698.6250 - val_mae: 443.3411\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379359.7188 - mae: 443.8772 - val_loss: 377316.2188 - val_mae: 441.9183\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378825.6875 - mae: 443.4948 - val_loss: 376687.5312 - val_mae: 442.0496\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378507.9062 - mae: 442.9291 - val_loss: 376085.5625 - val_mae: 442.0651\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377676.7188 - mae: 442.6803 - val_loss: 375636.0625 - val_mae: 441.1567\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377298.0938 - mae: 442.1671 - val_loss: 375118.6250 - val_mae: 442.2303\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 376763.5312 - mae: 442.2757 - val_loss: 374519.3438 - val_mae: 440.0464\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376199.5625 - mae: 441.3336 - val_loss: 373827.3125 - val_mae: 440.2667\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375525.2812 - mae: 441.1162 - val_loss: 373442.2500 - val_mae: 439.7355\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375120.3438 - mae: 440.5949 - val_loss: 372951.3750 - val_mae: 439.9419\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374765.3125 - mae: 440.6825 - val_loss: 372574.2500 - val_mae: 438.4812\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374310.2812 - mae: 439.8018 - val_loss: 372047.8125 - val_mae: 439.3756\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 373681.6562 - mae: 439.9356 - val_loss: 371663.0938 - val_mae: 438.6135\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373506.7188 - mae: 439.7837 - val_loss: 371413.0000 - val_mae: 438.1427\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373106.7500 - mae: 439.1576 - val_loss: 371045.1250 - val_mae: 437.4828\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372813.1875 - mae: 439.1653 - val_loss: 370944.2812 - val_mae: 437.0339\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372437.2500 - mae: 438.5440 - val_loss: 370251.9688 - val_mae: 437.3430\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372027.2188 - mae: 438.4617 - val_loss: 369931.3750 - val_mae: 437.7007\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371975.0625 - mae: 438.3810 - val_loss: 369742.4688 - val_mae: 437.4263\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371042.6562 - mae: 438.2324 - val_loss: 370195.4688 - val_mae: 435.5753\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 371268.6562 - mae: 437.6777 - val_loss: 368930.7500 - val_mae: 436.5298\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 370953.1875 - mae: 437.4714 - val_loss: 368797.1562 - val_mae: 437.6455\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370331.5938 - mae: 437.3609 - val_loss: 368629.1875 - val_mae: 437.5322\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370284.1875 - mae: 437.7313 - val_loss: 368213.7812 - val_mae: 435.8008\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369749.6250 - mae: 436.8442 - val_loss: 367959.2188 - val_mae: 435.7023\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369574.8125 - mae: 436.7840 - val_loss: 367625.5312 - val_mae: 435.1649\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369193.5625 - mae: 436.3212 - val_loss: 367308.9062 - val_mae: 436.4436\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 369006.0625 - mae: 436.5413 - val_loss: 366864.4688 - val_mae: 435.1507\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368825.4062 - mae: 436.5550 - val_loss: 366732.1562 - val_mae: 434.7346\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368391.1250 - mae: 435.8679 - val_loss: 366387.4375 - val_mae: 435.1292\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368118.8750 - mae: 435.9170 - val_loss: 366391.8438 - val_mae: 433.6997\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367795.6250 - mae: 435.2723 - val_loss: 365823.2500 - val_mae: 435.0026\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367689.9062 - mae: 435.4753 - val_loss: 365540.5938 - val_mae: 434.6886\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367391.6875 - mae: 435.5513 - val_loss: 365227.7812 - val_mae: 434.7090\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366892.3125 - mae: 434.7517 - val_loss: 365071.5625 - val_mae: 433.2478\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366959.3125 - mae: 434.9488 - val_loss: 364684.2812 - val_mae: 433.5034\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366610.3750 - mae: 434.6136 - val_loss: 364557.3125 - val_mae: 433.3813\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366227.3750 - mae: 434.4674 - val_loss: 364429.9688 - val_mae: 432.5829\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365939.5938 - mae: 433.8732 - val_loss: 364104.7812 - val_mae: 433.6937\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365723.4062 - mae: 434.2507 - val_loss: 363678.1250 - val_mae: 432.8794\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365448.5938 - mae: 433.7590 - val_loss: 363468.4375 - val_mae: 432.5416\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365157.4062 - mae: 433.8557 - val_loss: 363338.3125 - val_mae: 431.9914\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364887.6875 - mae: 433.2422 - val_loss: 363168.4062 - val_mae: 433.7248\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364686.9062 - mae: 433.3309 - val_loss: 362891.9062 - val_mae: 433.5290\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364579.9688 - mae: 433.2458 - val_loss: 362282.9375 - val_mae: 431.6054\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364153.5000 - mae: 433.0454 - val_loss: 361980.0000 - val_mae: 431.9783\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363709.4062 - mae: 432.6986 - val_loss: 361820.0000 - val_mae: 431.9731\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363652.4688 - mae: 432.5767 - val_loss: 361942.6562 - val_mae: 430.8988\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363431.2500 - mae: 432.4147 - val_loss: 361433.4062 - val_mae: 431.3888\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363045.9688 - mae: 432.2177 - val_loss: 361003.1875 - val_mae: 431.6833\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362714.5000 - mae: 432.0416 - val_loss: 361065.4688 - val_mae: 432.4886\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362669.9062 - mae: 431.8896 - val_loss: 361036.4062 - val_mae: 432.4954\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362342.5938 - mae: 431.7821 - val_loss: 360445.6562 - val_mae: 431.0282\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362089.8438 - mae: 431.4147 - val_loss: 360545.0625 - val_mae: 431.6165\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361986.6562 - mae: 431.5963 - val_loss: 360091.3750 - val_mae: 429.9842\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361553.5625 - mae: 431.0841 - val_loss: 359803.3125 - val_mae: 430.9744\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361554.9375 - mae: 431.4593 - val_loss: 360051.7500 - val_mae: 428.9586\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361100.1562 - mae: 430.7721 - val_loss: 359560.3438 - val_mae: 431.3828\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361272.2500 - mae: 430.8307 - val_loss: 359067.5938 - val_mae: 430.2419\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360937.1562 - mae: 431.0174 - val_loss: 358938.2812 - val_mae: 428.8941\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360666.8750 - mae: 430.5057 - val_loss: 358821.0625 - val_mae: 428.9992\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360397.6875 - mae: 430.3762 - val_loss: 358874.2188 - val_mae: 428.1282\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360256.0000 - mae: 430.0683 - val_loss: 358260.4375 - val_mae: 429.2059\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360081.7812 - mae: 430.5109 - val_loss: 358186.4375 - val_mae: 428.4377\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359839.1562 - mae: 430.2177 - val_loss: 358098.0625 - val_mae: 428.4617\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359682.6250 - mae: 429.8232 - val_loss: 357699.8750 - val_mae: 429.1033\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359794.9375 - mae: 429.9240 - val_loss: 357633.5000 - val_mae: 428.7426\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359555.5625 - mae: 430.1840 - val_loss: 357399.0625 - val_mae: 428.2018\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359302.0938 - mae: 429.3407 - val_loss: 357400.1250 - val_mae: 429.4649\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358858.8438 - mae: 429.1647 - val_loss: 357498.0625 - val_mae: 430.3618\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 358860.4688 - mae: 429.2776 - val_loss: 356906.6250 - val_mae: 428.4879\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358866.9688 - mae: 429.3127 - val_loss: 356713.3125 - val_mae: 428.2046\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38064636.0000 - mae: 6014.0225 - val_loss: 36750908.0000 - val_mae: 5913.6763\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 33635128.0000 - mae: 5665.9580 - val_loss: 29856758.0000 - val_mae: 5353.1509\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 25548434.0000 - mae: 4948.5757 - val_loss: 21154430.0000 - val_mae: 4503.0625\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 17220714.0000 - mae: 4023.8828 - val_loss: 13560289.0000 - val_mae: 3529.9646\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 10705071.0000 - mae: 3064.4290 - val_loss: 8176800.0000 - val_mae: 2618.1365\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6352591.5000 - mae: 2237.3225 - val_loss: 4786399.5000 - val_mae: 1887.0103\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3727605.7500 - mae: 1612.5364 - val_loss: 2850991.7500 - val_mae: 1367.4419\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2304409.5000 - mae: 1195.9612 - val_loss: 1868004.5000 - val_mae: 1051.5175\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1609752.3750 - mae: 959.5691 - val_loss: 1398514.3750 - val_mae: 884.5997\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1266706.5000 - mae: 837.4324 - val_loss: 1150508.1250 - val_mae: 795.5807\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1071425.6250 - mae: 766.6187 - val_loss: 993189.1250 - val_mae: 738.4384\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 936184.4375 - mae: 716.6821 - val_loss: 878624.9375 - val_mae: 695.4731\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 834505.5000 - mae: 678.3143 - val_loss: 788006.0625 - val_mae: 661.0200\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 754841.6250 - mae: 647.2195 - val_loss: 718798.9375 - val_mae: 632.9371\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 694453.8125 - mae: 622.3509 - val_loss: 667119.0000 - val_mae: 610.3354\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 649413.6875 - mae: 602.5225 - val_loss: 628451.5000 - val_mae: 592.8147\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615498.1250 - mae: 586.1529 - val_loss: 599008.8125 - val_mae: 578.5162\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589908.3750 - mae: 573.4828 - val_loss: 576359.4375 - val_mae: 567.1282\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 569866.8750 - mae: 563.0263 - val_loss: 558411.2500 - val_mae: 557.2128\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553160.8750 - mae: 553.9441 - val_loss: 543108.3750 - val_mae: 549.4575\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 538912.7500 - mae: 546.4157 - val_loss: 529987.3125 - val_mae: 541.9590\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527108.8125 - mae: 539.6710 - val_loss: 518534.0938 - val_mae: 534.9772\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 516015.8125 - mae: 532.8460 - val_loss: 508495.2188 - val_mae: 529.8265\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 506663.1562 - mae: 528.0737 - val_loss: 499785.1562 - val_mae: 523.5040\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 498450.9375 - mae: 522.9441 - val_loss: 492458.7500 - val_mae: 518.5891\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 491384.2812 - mae: 518.6060 - val_loss: 485549.1875 - val_mae: 515.6752\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 485563.8438 - mae: 514.8790 - val_loss: 480129.6250 - val_mae: 513.9305\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 480002.6250 - mae: 512.1685 - val_loss: 474445.5312 - val_mae: 510.3514\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 474601.8438 - mae: 508.9544 - val_loss: 469439.4688 - val_mae: 506.7015\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 469678.3438 - mae: 506.5145 - val_loss: 464872.0938 - val_mae: 503.8304\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 464864.5938 - mae: 503.8853 - val_loss: 460362.3438 - val_mae: 501.6957\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 460254.1250 - mae: 501.6668 - val_loss: 455623.6250 - val_mae: 499.3674\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 456042.6875 - mae: 499.0913 - val_loss: 451390.7500 - val_mae: 496.1742\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 451849.4062 - mae: 496.9714 - val_loss: 446867.7500 - val_mae: 494.5176\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 447849.5312 - mae: 494.9131 - val_loss: 443094.7500 - val_mae: 492.4850\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 443693.3125 - mae: 492.6115 - val_loss: 439170.6250 - val_mae: 491.0159\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 439896.7812 - mae: 490.8656 - val_loss: 435565.8750 - val_mae: 488.8270\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 436727.2500 - mae: 489.1283 - val_loss: 432121.6250 - val_mae: 488.0945\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 432811.0625 - mae: 487.1069 - val_loss: 428610.1250 - val_mae: 484.6623\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429631.5938 - mae: 485.7696 - val_loss: 425486.1562 - val_mae: 483.4756\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 426792.2500 - mae: 483.9021 - val_loss: 422973.1250 - val_mae: 481.6827\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 424435.5938 - mae: 482.6308 - val_loss: 420428.8750 - val_mae: 480.3182\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 421724.7812 - mae: 480.7733 - val_loss: 418290.3438 - val_mae: 480.1741\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419708.0000 - mae: 479.8177 - val_loss: 416186.5938 - val_mae: 477.2737\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 417635.7500 - mae: 478.3429 - val_loss: 414307.2500 - val_mae: 478.1929\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415758.5000 - mae: 476.9662 - val_loss: 412464.8438 - val_mae: 476.8293\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 414387.6562 - mae: 476.5456 - val_loss: 410556.0938 - val_mae: 474.8587\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 412653.6875 - mae: 475.3715 - val_loss: 409016.4062 - val_mae: 473.3129\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 410742.6250 - mae: 474.3139 - val_loss: 407628.0938 - val_mae: 472.9806\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409619.5312 - mae: 473.4526 - val_loss: 406010.0000 - val_mae: 471.1514\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408017.1875 - mae: 472.3863 - val_loss: 404835.0000 - val_mae: 469.3972\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 406434.8125 - mae: 471.6562 - val_loss: 403698.5625 - val_mae: 468.4264\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405233.8438 - mae: 469.9358 - val_loss: 402125.9062 - val_mae: 469.6901\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 403892.1250 - mae: 469.8442 - val_loss: 400914.3438 - val_mae: 466.6424\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 402515.3438 - mae: 468.3511 - val_loss: 399132.5312 - val_mae: 466.6201\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401526.5625 - mae: 467.8937 - val_loss: 398101.0625 - val_mae: 466.8961\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 399774.6875 - mae: 466.6907 - val_loss: 397155.5625 - val_mae: 466.4971\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 398592.5625 - mae: 466.0060 - val_loss: 395542.1875 - val_mae: 464.9244\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 397622.9375 - mae: 465.0708 - val_loss: 395226.2188 - val_mae: 466.5141\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 396425.6562 - mae: 464.7966 - val_loss: 393439.0625 - val_mae: 464.6162\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394775.7188 - mae: 463.6060 - val_loss: 392180.4375 - val_mae: 462.6026\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393904.5625 - mae: 462.8661 - val_loss: 390801.1250 - val_mae: 461.8857\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 392799.9375 - mae: 462.3950 - val_loss: 389472.1562 - val_mae: 459.9624\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391665.4688 - mae: 461.2187 - val_loss: 389233.5938 - val_mae: 458.0312\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390614.0625 - mae: 460.5861 - val_loss: 386951.6250 - val_mae: 458.2207\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388617.4688 - mae: 459.7219 - val_loss: 386545.2500 - val_mae: 456.3361\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387469.9688 - mae: 458.0128 - val_loss: 385087.8750 - val_mae: 459.2793\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386740.9062 - mae: 458.7253 - val_loss: 383522.0938 - val_mae: 455.7240\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385422.6562 - mae: 457.0342 - val_loss: 382331.8125 - val_mae: 456.4381\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384222.5938 - mae: 457.0449 - val_loss: 381193.1875 - val_mae: 453.6748\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 382678.9688 - mae: 455.3083 - val_loss: 379725.9062 - val_mae: 452.9649\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381286.3750 - mae: 453.9698 - val_loss: 377962.1875 - val_mae: 453.2660\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380081.9688 - mae: 453.7492 - val_loss: 376642.4375 - val_mae: 451.4271\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378714.9688 - mae: 452.4740 - val_loss: 375330.9062 - val_mae: 451.0073\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377076.2812 - mae: 451.3602 - val_loss: 374519.1562 - val_mae: 450.4576\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375951.0000 - mae: 450.4178 - val_loss: 372752.1875 - val_mae: 449.2006\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374650.5938 - mae: 449.7028 - val_loss: 371422.3438 - val_mae: 446.6320\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373278.9062 - mae: 448.5701 - val_loss: 370403.9062 - val_mae: 446.3427\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372015.3438 - mae: 447.4141 - val_loss: 368943.6250 - val_mae: 446.1967\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370756.2812 - mae: 446.5779 - val_loss: 368032.6875 - val_mae: 446.4600\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369727.8438 - mae: 445.8888 - val_loss: 366885.0312 - val_mae: 445.3918\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368499.3750 - mae: 445.4849 - val_loss: 365527.8438 - val_mae: 442.9878\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 367286.8438 - mae: 444.1956 - val_loss: 364888.6250 - val_mae: 441.2344\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366471.9688 - mae: 443.3977 - val_loss: 363539.2500 - val_mae: 441.0428\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365347.9375 - mae: 442.5721 - val_loss: 362642.4688 - val_mae: 441.7346\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 364291.9375 - mae: 442.5968 - val_loss: 361844.0312 - val_mae: 440.2238\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 363911.4062 - mae: 441.4551 - val_loss: 360958.0312 - val_mae: 439.5797\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362871.4688 - mae: 441.1898 - val_loss: 360254.7812 - val_mae: 439.7105\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 362230.3125 - mae: 440.6021 - val_loss: 359420.8438 - val_mae: 439.0008\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 361539.7812 - mae: 439.9197 - val_loss: 358831.7812 - val_mae: 439.7689\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360634.9062 - mae: 439.5541 - val_loss: 358135.6875 - val_mae: 439.3752\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360047.1875 - mae: 439.0780 - val_loss: 357273.3750 - val_mae: 438.5553\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 359417.1875 - mae: 438.2699 - val_loss: 357240.5625 - val_mae: 439.0961\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358802.3125 - mae: 438.2726 - val_loss: 356287.5625 - val_mae: 435.9622\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 358153.6562 - mae: 437.6551 - val_loss: 355852.8750 - val_mae: 435.0179\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357499.3750 - mae: 437.1069 - val_loss: 355045.7812 - val_mae: 435.9073\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 357312.0625 - mae: 437.1304 - val_loss: 354804.0000 - val_mae: 434.8014\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 356821.4375 - mae: 436.6625 - val_loss: 353963.5312 - val_mae: 435.7035\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355927.0938 - mae: 436.1992 - val_loss: 354048.1250 - val_mae: 436.2812\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355851.3438 - mae: 436.0190 - val_loss: 353301.1562 - val_mae: 435.6816\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355217.3438 - mae: 435.6679 - val_loss: 352654.6250 - val_mae: 433.5327\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354667.9375 - mae: 434.7565 - val_loss: 352241.6875 - val_mae: 434.2906\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354817.3125 - mae: 435.4106 - val_loss: 351936.0938 - val_mae: 432.5609\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354068.5312 - mae: 434.4528 - val_loss: 351591.9375 - val_mae: 431.9218\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353575.8750 - mae: 433.9142 - val_loss: 351200.3438 - val_mae: 432.9676\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353480.6562 - mae: 433.8845 - val_loss: 351319.9375 - val_mae: 433.9938\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353341.4375 - mae: 433.9175 - val_loss: 350483.9375 - val_mae: 432.6451\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352692.7812 - mae: 433.9664 - val_loss: 350263.5000 - val_mae: 431.5503\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352825.8438 - mae: 433.0323 - val_loss: 349884.0312 - val_mae: 431.4769\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352030.3750 - mae: 432.8673 - val_loss: 349921.2500 - val_mae: 431.5255\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352297.5312 - mae: 433.0369 - val_loss: 349705.2188 - val_mae: 432.9578\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351501.7812 - mae: 432.4668 - val_loss: 349343.9688 - val_mae: 432.2914\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352225.5938 - mae: 432.6869 - val_loss: 348861.0625 - val_mae: 431.4178\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351350.0000 - mae: 432.4416 - val_loss: 348786.5000 - val_mae: 430.8568\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350760.0312 - mae: 431.7911 - val_loss: 350062.5938 - val_mae: 434.9074\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350988.2812 - mae: 432.8208 - val_loss: 348660.4375 - val_mae: 429.5855\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350700.5625 - mae: 431.6612 - val_loss: 348010.3750 - val_mae: 430.3798\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350144.7812 - mae: 431.3105 - val_loss: 348039.8125 - val_mae: 431.3772\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350087.9688 - mae: 431.9440 - val_loss: 347731.1875 - val_mae: 431.1232\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349910.3750 - mae: 431.4757 - val_loss: 347479.8125 - val_mae: 430.8369\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349878.4375 - mae: 431.6960 - val_loss: 347674.0625 - val_mae: 428.9800\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349278.8750 - mae: 430.5592 - val_loss: 346886.0312 - val_mae: 429.8097\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 349004.1562 - mae: 431.1652 - val_loss: 347234.0938 - val_mae: 430.9672\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348888.8438 - mae: 430.9732 - val_loss: 346480.1875 - val_mae: 429.8575\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348981.0625 - mae: 430.8344 - val_loss: 346291.8438 - val_mae: 430.1950\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348582.5312 - mae: 430.6948 - val_loss: 346475.7812 - val_mae: 428.1064\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348271.0000 - mae: 430.3136 - val_loss: 346041.2812 - val_mae: 429.5582\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348156.6250 - mae: 430.6208 - val_loss: 345518.2500 - val_mae: 429.4849\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 348023.1250 - mae: 430.2268 - val_loss: 345014.5625 - val_mae: 429.0607\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347323.6562 - mae: 430.3700 - val_loss: 345141.0000 - val_mae: 427.2155\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346760.0938 - mae: 429.5269 - val_loss: 344806.8125 - val_mae: 427.1118\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347030.1562 - mae: 429.4951 - val_loss: 344314.4062 - val_mae: 427.4780\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346943.7500 - mae: 429.4684 - val_loss: 344091.2812 - val_mae: 428.3867\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346299.7812 - mae: 429.1248 - val_loss: 343735.5000 - val_mae: 428.2246\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346015.3438 - mae: 429.3459 - val_loss: 343722.1250 - val_mae: 427.4503\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345916.7812 - mae: 428.6498 - val_loss: 343559.3125 - val_mae: 429.2318\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345754.5625 - mae: 429.0527 - val_loss: 343325.1875 - val_mae: 429.2677\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345659.7188 - mae: 428.7144 - val_loss: 342865.5625 - val_mae: 427.5402\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345308.6875 - mae: 428.7306 - val_loss: 342617.6250 - val_mae: 425.9460\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344843.3750 - mae: 428.1666 - val_loss: 342648.9688 - val_mae: 426.8795\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344569.0625 - mae: 428.6646 - val_loss: 343014.7812 - val_mae: 424.8579\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344518.9375 - mae: 427.8882 - val_loss: 341759.2500 - val_mae: 425.4985\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344069.5938 - mae: 427.7018 - val_loss: 341632.7188 - val_mae: 426.5369\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 343597.2500 - mae: 426.7517 - val_loss: 341464.4375 - val_mae: 428.1577\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343409.7188 - mae: 427.1344 - val_loss: 340908.7812 - val_mae: 426.9272\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343300.5312 - mae: 427.3284 - val_loss: 340521.2500 - val_mae: 425.9796\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342690.7812 - mae: 427.0436 - val_loss: 340397.6250 - val_mae: 426.4089\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342533.9375 - mae: 426.2386 - val_loss: 340374.8750 - val_mae: 427.2057\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342632.1875 - mae: 426.2406 - val_loss: 339701.8750 - val_mae: 425.6252\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342472.6875 - mae: 426.6698 - val_loss: 339357.9688 - val_mae: 425.8176\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341708.4375 - mae: 426.2486 - val_loss: 338797.1875 - val_mae: 424.7332\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341154.8438 - mae: 425.7247 - val_loss: 338731.2188 - val_mae: 425.0113\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340334.3438 - mae: 425.9105 - val_loss: 338716.7188 - val_mae: 423.9011\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340715.0000 - mae: 425.2640 - val_loss: 338205.7188 - val_mae: 423.3760\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340381.6250 - mae: 425.3578 - val_loss: 337902.8438 - val_mae: 423.5143\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340273.8438 - mae: 424.9545 - val_loss: 337856.5625 - val_mae: 424.3364\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339904.7188 - mae: 424.9227 - val_loss: 337665.1250 - val_mae: 423.7092\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339527.2188 - mae: 424.6193 - val_loss: 337257.5625 - val_mae: 423.2332\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339773.7500 - mae: 424.7724 - val_loss: 336942.0000 - val_mae: 424.1118\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339036.3438 - mae: 424.6166 - val_loss: 337106.0000 - val_mae: 422.2431\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339249.5938 - mae: 424.1081 - val_loss: 336537.6250 - val_mae: 424.1382\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338976.4375 - mae: 424.3470 - val_loss: 336719.4375 - val_mae: 422.3528\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338716.9062 - mae: 424.1865 - val_loss: 336842.0625 - val_mae: 420.9305\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338562.0625 - mae: 423.9724 - val_loss: 336096.2812 - val_mae: 422.5236\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338251.9375 - mae: 423.6429 - val_loss: 336013.8125 - val_mae: 422.9205\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338701.8750 - mae: 423.9767 - val_loss: 335736.2500 - val_mae: 422.4392\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337988.0312 - mae: 423.9802 - val_loss: 335861.4062 - val_mae: 421.3975\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338210.8438 - mae: 423.7902 - val_loss: 335861.0312 - val_mae: 421.9658\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337742.8750 - mae: 423.1157 - val_loss: 335518.6562 - val_mae: 423.5258\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337598.6875 - mae: 423.8755 - val_loss: 335372.9062 - val_mae: 422.5115\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337291.3125 - mae: 423.3795 - val_loss: 335167.5625 - val_mae: 422.5569\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337394.7188 - mae: 423.0679 - val_loss: 335196.5938 - val_mae: 422.6600\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337135.1250 - mae: 423.0936 - val_loss: 334903.6875 - val_mae: 423.0656\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 32705162.0000 - mae: 5541.6714 - val_loss: 22270086.0000 - val_mae: 4557.1753\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 11098174.0000 - mae: 3010.6770 - val_loss: 3378141.5000 - val_mae: 1542.5590\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1614196.2500 - mae: 931.5461 - val_loss: 888685.5000 - val_mae: 659.6077\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 762588.9375 - mae: 609.8539 - val_loss: 680328.0000 - val_mae: 577.1173\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 644861.6250 - mae: 563.0656 - val_loss: 608495.0625 - val_mae: 549.5584\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590757.2500 - mae: 542.2936 - val_loss: 567013.2500 - val_mae: 533.2110\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554269.6875 - mae: 529.8574 - val_loss: 534172.2500 - val_mae: 522.5852\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 524683.6875 - mae: 521.2578 - val_loss: 508821.3125 - val_mae: 512.1864\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 500746.1562 - mae: 512.6900 - val_loss: 485495.5938 - val_mae: 506.4799\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 479782.9688 - mae: 505.2094 - val_loss: 469598.1250 - val_mae: 497.5031\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 463046.7812 - mae: 498.8115 - val_loss: 452247.8750 - val_mae: 495.5672\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 449714.0312 - mae: 493.0669 - val_loss: 441419.6250 - val_mae: 492.4414\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439090.6875 - mae: 488.1916 - val_loss: 432078.4062 - val_mae: 482.0263\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431255.6562 - mae: 483.3808 - val_loss: 424447.2812 - val_mae: 481.4763\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423889.8438 - mae: 479.0170 - val_loss: 419358.2812 - val_mae: 475.2559\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 419797.0938 - mae: 476.4232 - val_loss: 413193.8750 - val_mae: 470.7891\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414311.6250 - mae: 472.6455 - val_loss: 411612.4375 - val_mae: 475.3698\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 410554.0938 - mae: 470.3453 - val_loss: 405983.1250 - val_mae: 469.4905\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407367.7812 - mae: 468.4889 - val_loss: 401776.0625 - val_mae: 465.6982\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 404245.7188 - mae: 466.1208 - val_loss: 400585.5312 - val_mae: 467.5047\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 401898.1562 - mae: 464.6269 - val_loss: 396774.6875 - val_mae: 462.6148\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 399082.0312 - mae: 462.7753 - val_loss: 394627.3125 - val_mae: 461.0514\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 397424.0000 - mae: 461.6246 - val_loss: 392453.2500 - val_mae: 457.9648\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 395215.8750 - mae: 460.4495 - val_loss: 390403.8125 - val_mae: 456.2023\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 392714.6875 - mae: 459.0521 - val_loss: 390433.0938 - val_mae: 454.5352\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 391439.0938 - mae: 457.9382 - val_loss: 387177.3125 - val_mae: 453.6182\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 389062.1562 - mae: 455.9587 - val_loss: 386126.5625 - val_mae: 457.2284\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 387529.6250 - mae: 455.3105 - val_loss: 383957.8438 - val_mae: 453.2569\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 386379.5312 - mae: 454.7483 - val_loss: 381597.6562 - val_mae: 452.9380\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 384224.3438 - mae: 453.7856 - val_loss: 380534.7188 - val_mae: 450.7089\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 382783.4062 - mae: 452.2170 - val_loss: 379883.2812 - val_mae: 452.2293\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 381904.5625 - mae: 451.6328 - val_loss: 378323.2500 - val_mae: 450.6152\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 380655.7812 - mae: 450.9848 - val_loss: 376763.5625 - val_mae: 448.2833\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 379392.7812 - mae: 449.9706 - val_loss: 375573.2188 - val_mae: 446.6038\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 379039.3750 - mae: 449.8963 - val_loss: 374071.4375 - val_mae: 447.2001\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 377544.4375 - mae: 449.0711 - val_loss: 373894.2812 - val_mae: 446.0601\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 376406.1875 - mae: 448.6246 - val_loss: 372554.3750 - val_mae: 446.5766\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 375916.0000 - mae: 447.6887 - val_loss: 372031.7188 - val_mae: 445.9649\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 374684.2812 - mae: 447.6195 - val_loss: 370783.6875 - val_mae: 445.0737\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 373688.9062 - mae: 446.7283 - val_loss: 370899.6875 - val_mae: 446.7149\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 373386.2500 - mae: 446.8914 - val_loss: 370024.9688 - val_mae: 443.7660\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 373069.7812 - mae: 445.9352 - val_loss: 368892.1250 - val_mae: 444.2799\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 372767.3750 - mae: 445.5273 - val_loss: 367957.0312 - val_mae: 443.7784\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 371652.6875 - mae: 445.1792 - val_loss: 368027.1875 - val_mae: 442.4660\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 370695.1875 - mae: 444.5122 - val_loss: 368026.2812 - val_mae: 445.6689\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 370491.0312 - mae: 444.7918 - val_loss: 366359.2188 - val_mae: 441.4340\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 369901.0312 - mae: 444.4681 - val_loss: 365552.6875 - val_mae: 442.0043\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 368782.7188 - mae: 443.3748 - val_loss: 366276.2188 - val_mae: 441.0473\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 368865.2812 - mae: 443.1900 - val_loss: 365000.6875 - val_mae: 441.5882\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 367661.1875 - mae: 442.5231 - val_loss: 364950.7188 - val_mae: 443.1898\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 367788.6875 - mae: 442.8433 - val_loss: 363449.0312 - val_mae: 440.0994\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 366322.0938 - mae: 442.0724 - val_loss: 363313.4062 - val_mae: 441.7204\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 366197.9375 - mae: 441.8801 - val_loss: 362252.8125 - val_mae: 440.6815\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365194.6875 - mae: 440.8661 - val_loss: 361876.8750 - val_mae: 440.4261\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 364619.0000 - mae: 440.8966 - val_loss: 360672.2188 - val_mae: 439.8682\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363558.0312 - mae: 440.8081 - val_loss: 364319.7812 - val_mae: 436.3404\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363135.4688 - mae: 439.6518 - val_loss: 359470.0000 - val_mae: 439.7911\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 362304.2500 - mae: 439.7706 - val_loss: 359061.4062 - val_mae: 436.0083\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 361715.5312 - mae: 439.1803 - val_loss: 359764.4688 - val_mae: 435.4277\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 361404.4688 - mae: 439.0204 - val_loss: 358151.5938 - val_mae: 435.8733\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 360659.1875 - mae: 438.6372 - val_loss: 356954.3125 - val_mae: 435.0314\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 360006.7812 - mae: 437.6846 - val_loss: 356900.2812 - val_mae: 436.5881\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359787.3438 - mae: 437.7923 - val_loss: 356146.7812 - val_mae: 437.2227\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359228.6562 - mae: 437.4743 - val_loss: 355475.5938 - val_mae: 436.3831\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359081.5938 - mae: 437.1939 - val_loss: 355920.0000 - val_mae: 433.6379\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358005.8125 - mae: 435.8295 - val_loss: 355724.4375 - val_mae: 437.3485\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 358513.8438 - mae: 436.8406 - val_loss: 354821.0312 - val_mae: 436.2907\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 357564.6562 - mae: 436.1651 - val_loss: 354132.4062 - val_mae: 434.4352\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 357655.3750 - mae: 436.3249 - val_loss: 353358.4375 - val_mae: 433.7589\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 356226.0312 - mae: 435.3200 - val_loss: 354086.9688 - val_mae: 431.8646\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 356650.5312 - mae: 435.5006 - val_loss: 353127.9062 - val_mae: 433.4963\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 356068.0625 - mae: 435.0652 - val_loss: 352741.4688 - val_mae: 433.4328\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 355934.0000 - mae: 435.3145 - val_loss: 351667.0625 - val_mae: 433.8583\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 354287.1562 - mae: 434.2476 - val_loss: 351796.9062 - val_mae: 433.9263\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 354923.6562 - mae: 434.7547 - val_loss: 351505.2812 - val_mae: 433.8058\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 354288.3438 - mae: 434.5963 - val_loss: 350337.2188 - val_mae: 432.5162\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353511.6562 - mae: 433.8925 - val_loss: 351844.0312 - val_mae: 430.7019\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353257.7812 - mae: 433.3533 - val_loss: 350255.3125 - val_mae: 433.1743\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353180.5000 - mae: 433.2267 - val_loss: 349533.1562 - val_mae: 431.9215\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 352794.8750 - mae: 433.2307 - val_loss: 349935.5000 - val_mae: 430.2791\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 351750.3125 - mae: 432.0831 - val_loss: 348559.3750 - val_mae: 429.9172\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 351155.8125 - mae: 432.0796 - val_loss: 348322.7500 - val_mae: 432.2826\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 350959.1562 - mae: 432.0830 - val_loss: 347727.7188 - val_mae: 430.5999\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 350163.2188 - mae: 431.5769 - val_loss: 346425.8750 - val_mae: 429.7507\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 349153.6250 - mae: 430.7890 - val_loss: 347468.1875 - val_mae: 429.0481\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 349213.5312 - mae: 430.6378 - val_loss: 346315.4375 - val_mae: 429.7108\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348766.7188 - mae: 430.9319 - val_loss: 345952.0938 - val_mae: 427.8001\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347945.9062 - mae: 429.8976 - val_loss: 346320.0625 - val_mae: 431.3502\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348017.9375 - mae: 429.9046 - val_loss: 344794.9375 - val_mae: 426.8815\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347498.5938 - mae: 429.3141 - val_loss: 344312.1250 - val_mae: 425.9476\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 346546.3750 - mae: 428.8767 - val_loss: 343653.8125 - val_mae: 428.9572\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 345879.3750 - mae: 428.1855 - val_loss: 342976.7812 - val_mae: 427.6181\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 344914.2188 - mae: 427.6093 - val_loss: 342138.9062 - val_mae: 426.3107\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 344787.2812 - mae: 427.3994 - val_loss: 341608.5312 - val_mae: 424.2069\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 344242.2500 - mae: 427.1420 - val_loss: 341859.5312 - val_mae: 425.0777\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 344142.7812 - mae: 426.5345 - val_loss: 340288.9062 - val_mae: 425.9018\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343894.2812 - mae: 426.6729 - val_loss: 339683.8750 - val_mae: 424.8880\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343153.2500 - mae: 426.1324 - val_loss: 339439.8438 - val_mae: 424.9245\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342396.3125 - mae: 425.4124 - val_loss: 339898.3750 - val_mae: 424.5588\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342633.0938 - mae: 425.4330 - val_loss: 339254.2812 - val_mae: 422.4548\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 342583.3750 - mae: 425.1475 - val_loss: 338683.5312 - val_mae: 423.3292\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 341568.7188 - mae: 424.5154 - val_loss: 339008.2812 - val_mae: 421.3171\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 341335.6875 - mae: 424.1501 - val_loss: 338514.3438 - val_mae: 423.9251\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 340923.2812 - mae: 423.9603 - val_loss: 338532.9688 - val_mae: 424.9985\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 340863.8125 - mae: 424.3413 - val_loss: 337870.4688 - val_mae: 420.9976\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 340757.9062 - mae: 423.7112 - val_loss: 337252.5312 - val_mae: 421.6472\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 340113.4062 - mae: 422.6985 - val_loss: 337032.2500 - val_mae: 421.9651\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339945.1875 - mae: 423.4938 - val_loss: 336714.2500 - val_mae: 419.7739\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339716.3125 - mae: 422.6801 - val_loss: 336510.6250 - val_mae: 421.4945\n",
      "Epoch 110/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339387.3125 - mae: 422.4343 - val_loss: 335884.0625 - val_mae: 420.3022\n",
      "Epoch 111/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 338879.3125 - mae: 422.4452 - val_loss: 336211.5312 - val_mae: 419.5995\n",
      "Epoch 112/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 338266.8125 - mae: 422.0143 - val_loss: 336615.6875 - val_mae: 420.3357\n",
      "Epoch 113/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339102.5625 - mae: 421.9092 - val_loss: 335471.3750 - val_mae: 420.4133\n",
      "Epoch 114/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 338491.2500 - mae: 422.0002 - val_loss: 334471.5000 - val_mae: 419.8603\n",
      "Epoch 115/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 337797.1562 - mae: 421.9731 - val_loss: 336226.0625 - val_mae: 417.8949\n",
      "Epoch 116/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 337121.4062 - mae: 420.5421 - val_loss: 334836.7188 - val_mae: 418.8197\n",
      "Epoch 117/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 337394.5000 - mae: 420.7598 - val_loss: 334055.8125 - val_mae: 420.7813\n",
      "Epoch 118/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 336784.9688 - mae: 420.5975 - val_loss: 333252.2500 - val_mae: 418.6504\n",
      "Epoch 119/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 336476.0625 - mae: 420.2320 - val_loss: 332814.6875 - val_mae: 417.5563\n",
      "Epoch 120/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 335958.9375 - mae: 419.8189 - val_loss: 332591.8750 - val_mae: 418.3213\n",
      "Epoch 121/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 335901.9062 - mae: 419.6396 - val_loss: 332066.7188 - val_mae: 418.5262\n",
      "Epoch 122/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334653.5312 - mae: 419.0503 - val_loss: 333290.2500 - val_mae: 420.4880\n",
      "Epoch 123/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334331.7812 - mae: 419.0365 - val_loss: 332005.2812 - val_mae: 417.4190\n",
      "Epoch 124/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334650.9688 - mae: 418.4744 - val_loss: 331085.7500 - val_mae: 414.8828\n",
      "Epoch 125/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333703.0312 - mae: 418.0244 - val_loss: 331745.5312 - val_mae: 416.5847\n",
      "Epoch 126/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334407.9688 - mae: 418.4170 - val_loss: 330430.9062 - val_mae: 415.3036\n",
      "Epoch 127/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333816.5625 - mae: 417.7477 - val_loss: 330362.4375 - val_mae: 417.6121\n",
      "Epoch 128/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333516.1562 - mae: 417.8795 - val_loss: 330494.0312 - val_mae: 417.4115\n",
      "Epoch 129/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333005.8750 - mae: 417.7807 - val_loss: 329976.1562 - val_mae: 415.0170\n",
      "Epoch 130/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333331.3750 - mae: 417.4008 - val_loss: 329215.7812 - val_mae: 415.2772\n",
      "Epoch 131/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332809.0938 - mae: 417.0551 - val_loss: 330074.8750 - val_mae: 418.0395\n",
      "Epoch 132/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332369.9375 - mae: 417.2793 - val_loss: 329039.1250 - val_mae: 416.0247\n",
      "Epoch 133/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332668.5000 - mae: 417.4584 - val_loss: 328641.9688 - val_mae: 416.4114\n",
      "Epoch 134/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331815.8125 - mae: 416.6161 - val_loss: 329160.3125 - val_mae: 415.6696\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 29484388.0000 - mae: 5228.4116 - val_loss: 14266081.0000 - val_mae: 3625.2122\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 5532947.5000 - mae: 1934.5372 - val_loss: 1548740.7500 - val_mae: 885.5579\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1069668.6250 - mae: 715.8870 - val_loss: 825172.9375 - val_mae: 631.4424\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 733522.1250 - mae: 597.6785 - val_loss: 661294.2500 - val_mae: 572.4330\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 628632.4375 - mae: 556.8641 - val_loss: 598449.3125 - val_mae: 540.9879\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584713.5000 - mae: 535.9501 - val_loss: 568432.5625 - val_mae: 526.4803\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 561944.6250 - mae: 523.9622 - val_loss: 548454.1250 - val_mae: 517.7861\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545252.0000 - mae: 514.2189 - val_loss: 534364.0000 - val_mae: 507.8083\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533336.1875 - mae: 507.0253 - val_loss: 522661.3125 - val_mae: 502.2752\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 522717.0312 - mae: 500.3630 - val_loss: 514288.6562 - val_mae: 495.6386\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 513785.5000 - mae: 494.3234 - val_loss: 507571.9375 - val_mae: 491.7433\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 506501.3750 - mae: 489.8165 - val_loss: 499490.1875 - val_mae: 486.7509\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 499595.2500 - mae: 485.1733 - val_loss: 494562.5000 - val_mae: 485.3535\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 493679.0938 - mae: 480.9638 - val_loss: 486573.9062 - val_mae: 476.7739\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 488191.6875 - mae: 477.2745 - val_loss: 481038.6875 - val_mae: 473.7868\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 482550.7500 - mae: 472.6532 - val_loss: 477168.2500 - val_mae: 469.2399\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 477951.7812 - mae: 469.3681 - val_loss: 471740.8750 - val_mae: 464.3966\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 473574.0000 - mae: 466.4376 - val_loss: 467539.7812 - val_mae: 462.4617\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 469693.0000 - mae: 463.0577 - val_loss: 465149.9062 - val_mae: 460.4240\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 467841.5938 - mae: 462.1988 - val_loss: 461849.4062 - val_mae: 456.5221\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 463705.1250 - mae: 458.9908 - val_loss: 460305.7188 - val_mae: 454.4983\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 461687.7500 - mae: 456.9435 - val_loss: 459995.4375 - val_mae: 460.4958\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 459326.6250 - mae: 456.1546 - val_loss: 455053.3125 - val_mae: 454.7097\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 457647.4062 - mae: 454.6566 - val_loss: 452695.0312 - val_mae: 451.5504\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 455614.5625 - mae: 453.2147 - val_loss: 451826.3438 - val_mae: 450.7401\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 453886.9062 - mae: 451.3062 - val_loss: 450152.4062 - val_mae: 452.7436\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 452828.0000 - mae: 450.7660 - val_loss: 448331.7812 - val_mae: 447.8714\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 450550.0312 - mae: 449.2808 - val_loss: 447439.6250 - val_mae: 446.3849\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 449459.2188 - mae: 448.6133 - val_loss: 445830.2812 - val_mae: 444.2003\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 448435.1250 - mae: 448.3962 - val_loss: 443039.1875 - val_mae: 445.0108\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 446867.1875 - mae: 446.9238 - val_loss: 442895.1875 - val_mae: 446.2211\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 445157.0938 - mae: 445.9533 - val_loss: 441714.8750 - val_mae: 445.2012\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 444330.8438 - mae: 444.6721 - val_loss: 439354.1875 - val_mae: 442.1199\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 442780.3125 - mae: 444.0694 - val_loss: 438648.8438 - val_mae: 442.0237\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 441106.9688 - mae: 442.3873 - val_loss: 438430.1875 - val_mae: 443.1750\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 439919.8125 - mae: 441.8180 - val_loss: 435601.9688 - val_mae: 437.5774\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437570.3750 - mae: 439.9026 - val_loss: 433710.8125 - val_mae: 438.7845\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 437334.4375 - mae: 439.1356 - val_loss: 434690.1875 - val_mae: 435.7533\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 436112.1250 - mae: 438.7629 - val_loss: 433245.7188 - val_mae: 435.2224\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435578.1562 - mae: 438.5096 - val_loss: 432083.0938 - val_mae: 434.6642\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 435090.6250 - mae: 438.1493 - val_loss: 430988.5312 - val_mae: 436.2244\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433351.6562 - mae: 437.4421 - val_loss: 432338.3750 - val_mae: 439.6085\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 433460.4062 - mae: 437.3549 - val_loss: 430297.9688 - val_mae: 436.5041\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432581.7188 - mae: 436.4106 - val_loss: 428509.0312 - val_mae: 435.0529\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432507.8750 - mae: 436.5217 - val_loss: 429205.7188 - val_mae: 436.5002\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 432000.0625 - mae: 436.4337 - val_loss: 428412.5938 - val_mae: 432.6061\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 431495.3750 - mae: 435.6715 - val_loss: 427158.8750 - val_mae: 433.2784\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430793.2188 - mae: 435.0478 - val_loss: 426869.8750 - val_mae: 433.7421\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430604.4688 - mae: 435.6595 - val_loss: 425921.8750 - val_mae: 431.9404\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 430013.7188 - mae: 434.3013 - val_loss: 426191.5938 - val_mae: 434.7394\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429200.8750 - mae: 434.6736 - val_loss: 427585.4688 - val_mae: 431.8995\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429736.8125 - mae: 435.0038 - val_loss: 426998.3750 - val_mae: 431.7169\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 429088.4062 - mae: 434.1009 - val_loss: 425719.1250 - val_mae: 433.6141\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428386.7812 - mae: 434.0042 - val_loss: 425567.6562 - val_mae: 431.8982\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428302.7500 - mae: 433.7705 - val_loss: 424686.3750 - val_mae: 430.1763\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427947.0000 - mae: 433.5746 - val_loss: 424322.6562 - val_mae: 434.8246\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427129.3750 - mae: 433.9039 - val_loss: 425163.1250 - val_mae: 430.5851\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 427477.2500 - mae: 433.1360 - val_loss: 423085.1875 - val_mae: 431.3513\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426735.1875 - mae: 433.3821 - val_loss: 423730.5938 - val_mae: 431.4881\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426587.2188 - mae: 432.9761 - val_loss: 423166.4688 - val_mae: 430.1706\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 426309.7500 - mae: 433.2545 - val_loss: 423243.0938 - val_mae: 431.3133\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425855.3750 - mae: 432.8243 - val_loss: 423607.9062 - val_mae: 434.5097\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424815.1562 - mae: 432.5989 - val_loss: 423169.8125 - val_mae: 431.7043\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425297.2500 - mae: 433.2379 - val_loss: 420897.8438 - val_mae: 429.8641\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424805.1250 - mae: 432.6050 - val_loss: 422472.3125 - val_mae: 432.6885\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 425225.6250 - mae: 432.4674 - val_loss: 420163.3750 - val_mae: 430.8286\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424037.3125 - mae: 432.9147 - val_loss: 422095.7500 - val_mae: 428.9082\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 424164.7188 - mae: 431.3872 - val_loss: 420506.6875 - val_mae: 431.3793\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423203.7812 - mae: 431.2886 - val_loss: 420249.4688 - val_mae: 429.7054\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423537.7812 - mae: 431.6935 - val_loss: 419938.9688 - val_mae: 431.8567\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 423367.1250 - mae: 431.5604 - val_loss: 419354.5938 - val_mae: 428.7477\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422478.7188 - mae: 431.1564 - val_loss: 420196.8125 - val_mae: 427.6959\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422640.0000 - mae: 431.1091 - val_loss: 419106.6875 - val_mae: 431.0915\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422143.4375 - mae: 431.4700 - val_loss: 418965.2188 - val_mae: 429.1743\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421912.3125 - mae: 431.3545 - val_loss: 420507.4375 - val_mae: 426.7314\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422087.3750 - mae: 430.7262 - val_loss: 419083.4375 - val_mae: 429.0379\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 422014.1562 - mae: 430.8739 - val_loss: 418884.4688 - val_mae: 431.0475\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 421372.6875 - mae: 431.0985 - val_loss: 418741.1875 - val_mae: 429.4914\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421453.5625 - mae: 430.4876 - val_loss: 417857.5000 - val_mae: 428.8931\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421343.4062 - mae: 430.2719 - val_loss: 418241.2500 - val_mae: 429.6078\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 421429.0000 - mae: 430.4307 - val_loss: 417578.0938 - val_mae: 427.7078\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 420804.9375 - mae: 430.2833 - val_loss: 418300.0000 - val_mae: 427.9057\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 421106.5938 - mae: 430.0431 - val_loss: 416889.5938 - val_mae: 430.2031\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 420861.2188 - mae: 430.0796 - val_loss: 416975.0938 - val_mae: 429.5134\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420556.5938 - mae: 429.6866 - val_loss: 416555.0938 - val_mae: 428.5946\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 36823248.0000 - mae: 5913.1846 - val_loss: 32780826.0000 - val_mae: 5583.8691\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 26091124.0000 - mae: 4957.8555 - val_loss: 19088156.0000 - val_mae: 4228.7251\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 13153684.0000 - mae: 3418.5632 - val_loss: 8099195.0000 - val_mae: 2608.2244\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 5073341.5000 - mae: 1929.9008 - val_loss: 2890558.7500 - val_mae: 1356.3176\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1954145.8750 - mae: 1046.2975 - val_loss: 1350333.1250 - val_mae: 840.3215\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1112593.0000 - mae: 762.2939 - val_loss: 942147.7500 - val_mae: 707.2265\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 848817.1875 - mae: 676.1752 - val_loss: 766883.0000 - val_mae: 646.1307\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 714758.5000 - mae: 624.6815 - val_loss: 665102.1875 - val_mae: 603.6608\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 634078.3750 - mae: 590.3043 - val_loss: 602029.3750 - val_mae: 575.4547\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 582856.2500 - mae: 567.0079 - val_loss: 560946.1875 - val_mae: 556.3841\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 548164.8125 - mae: 550.4637 - val_loss: 531860.6250 - val_mae: 541.1959\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 522709.8438 - mae: 536.7358 - val_loss: 508879.7188 - val_mae: 528.3875\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 501540.5938 - mae: 524.3317 - val_loss: 490370.0000 - val_mae: 520.5355\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 484808.0312 - mae: 515.0281 - val_loss: 474660.2812 - val_mae: 510.1093\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 470896.3125 - mae: 506.1530 - val_loss: 462307.3438 - val_mae: 500.3932\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 460008.9688 - mae: 498.6681 - val_loss: 452308.5625 - val_mae: 494.0493\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 451359.5312 - mae: 492.4318 - val_loss: 444615.6562 - val_mae: 488.7713\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 444079.1250 - mae: 487.6049 - val_loss: 438374.5312 - val_mae: 485.3729\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 438037.5625 - mae: 483.1079 - val_loss: 432249.9375 - val_mae: 479.0742\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432766.4062 - mae: 478.8837 - val_loss: 427534.4688 - val_mae: 476.5631\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 428053.5625 - mae: 475.7044 - val_loss: 423668.5000 - val_mae: 474.7247\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 424117.2812 - mae: 473.1591 - val_loss: 419700.9688 - val_mae: 471.5569\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420885.5000 - mae: 470.4081 - val_loss: 416223.3750 - val_mae: 468.8159\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417805.0000 - mae: 468.1751 - val_loss: 413483.1250 - val_mae: 466.4337\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414752.0938 - mae: 465.8757 - val_loss: 411394.5000 - val_mae: 462.5646\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 412457.7188 - mae: 464.6582 - val_loss: 409118.2812 - val_mae: 461.2905\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410465.3438 - mae: 462.7130 - val_loss: 406887.4062 - val_mae: 461.1315\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408287.7188 - mae: 461.8450 - val_loss: 404822.5000 - val_mae: 460.1175\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406223.7500 - mae: 460.0486 - val_loss: 402836.1562 - val_mae: 459.3644\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404428.3438 - mae: 458.8903 - val_loss: 401570.3750 - val_mae: 460.0697\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402705.4062 - mae: 458.2190 - val_loss: 399175.4062 - val_mae: 455.7867\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400968.0000 - mae: 456.2220 - val_loss: 397715.0312 - val_mae: 453.3750\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399137.3750 - mae: 455.5463 - val_loss: 395904.7188 - val_mae: 453.1729\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397442.9375 - mae: 454.2460 - val_loss: 394259.2812 - val_mae: 451.8282\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396334.8438 - mae: 453.0811 - val_loss: 392625.2500 - val_mae: 451.1348\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394551.2812 - mae: 451.6885 - val_loss: 392206.0625 - val_mae: 453.0228\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393466.3438 - mae: 451.0331 - val_loss: 390378.3438 - val_mae: 451.9018\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391944.0312 - mae: 450.2023 - val_loss: 388525.9375 - val_mae: 447.5772\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390599.3438 - mae: 449.0923 - val_loss: 387350.0312 - val_mae: 447.9895\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389498.7500 - mae: 448.6364 - val_loss: 386269.7188 - val_mae: 447.7112\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388097.9688 - mae: 447.8020 - val_loss: 385304.5312 - val_mae: 446.2112\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386950.6875 - mae: 446.4217 - val_loss: 383971.4688 - val_mae: 445.3297\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 385932.0000 - mae: 446.3889 - val_loss: 382905.2812 - val_mae: 443.9268\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 385082.7188 - mae: 445.2324 - val_loss: 381400.0625 - val_mae: 442.8020\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 383283.9688 - mae: 444.1286 - val_loss: 380682.6250 - val_mae: 444.6753\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382383.7812 - mae: 443.4998 - val_loss: 379331.6562 - val_mae: 443.4852\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 381100.5938 - mae: 443.0952 - val_loss: 378171.8438 - val_mae: 441.5220\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 380505.2188 - mae: 442.3641 - val_loss: 376784.0000 - val_mae: 440.8227\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 378677.1875 - mae: 441.5242 - val_loss: 376344.0625 - val_mae: 438.4898\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377197.1250 - mae: 440.6674 - val_loss: 375272.5938 - val_mae: 439.9131\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 376537.0312 - mae: 440.1081 - val_loss: 373793.8750 - val_mae: 440.2376\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374997.5312 - mae: 439.6282 - val_loss: 372929.5938 - val_mae: 439.6615\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374721.3750 - mae: 439.2599 - val_loss: 371558.2188 - val_mae: 437.0021\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373504.7500 - mae: 438.2200 - val_loss: 370168.4688 - val_mae: 436.5754\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 372192.7500 - mae: 438.0419 - val_loss: 370811.8438 - val_mae: 434.3100\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371482.1562 - mae: 436.5469 - val_loss: 368760.9375 - val_mae: 436.0199\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370739.6562 - mae: 436.7639 - val_loss: 367371.6562 - val_mae: 435.0264\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369477.4062 - mae: 435.9259 - val_loss: 366941.6875 - val_mae: 435.5037\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368647.1250 - mae: 435.3987 - val_loss: 366520.6875 - val_mae: 433.1465\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368147.4375 - mae: 434.9038 - val_loss: 365362.8125 - val_mae: 432.7252\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367594.7812 - mae: 434.7994 - val_loss: 364722.3750 - val_mae: 431.5525\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366710.4375 - mae: 433.5150 - val_loss: 363775.9062 - val_mae: 432.2707\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365982.0312 - mae: 433.7938 - val_loss: 363318.4375 - val_mae: 432.2781\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365248.4375 - mae: 433.0499 - val_loss: 363916.4062 - val_mae: 430.6109\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364866.6875 - mae: 433.0089 - val_loss: 361862.7812 - val_mae: 430.7059\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364314.1562 - mae: 432.2683 - val_loss: 361757.0938 - val_mae: 431.1996\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363893.8750 - mae: 432.5002 - val_loss: 361151.7812 - val_mae: 429.7186\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363315.2812 - mae: 431.7886 - val_loss: 360320.0625 - val_mae: 430.0665\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362755.6250 - mae: 431.0319 - val_loss: 360270.7500 - val_mae: 431.2624\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362255.8125 - mae: 431.1624 - val_loss: 359424.9688 - val_mae: 429.9930\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361757.8125 - mae: 430.9160 - val_loss: 358853.4375 - val_mae: 429.0690\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361019.4688 - mae: 430.7631 - val_loss: 359282.4375 - val_mae: 428.2516\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360763.1250 - mae: 430.7062 - val_loss: 358298.3750 - val_mae: 429.8208\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360202.2500 - mae: 429.6257 - val_loss: 357543.8125 - val_mae: 427.7905\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360086.0938 - mae: 429.9100 - val_loss: 357021.2500 - val_mae: 428.2450\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359369.8750 - mae: 429.8084 - val_loss: 356960.8750 - val_mae: 428.8088\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358879.5312 - mae: 429.0976 - val_loss: 356177.1250 - val_mae: 427.7899\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358153.3125 - mae: 429.0557 - val_loss: 356385.5625 - val_mae: 426.7656\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358142.2500 - mae: 428.6473 - val_loss: 355539.6875 - val_mae: 427.8965\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357923.7500 - mae: 428.9923 - val_loss: 356741.6250 - val_mae: 425.6114\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357423.2812 - mae: 428.4883 - val_loss: 356001.4375 - val_mae: 425.6164\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357452.5938 - mae: 428.4847 - val_loss: 354556.8438 - val_mae: 428.4463\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356724.1562 - mae: 428.1595 - val_loss: 354142.8438 - val_mae: 426.6329\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356540.6250 - mae: 427.9745 - val_loss: 353796.5000 - val_mae: 426.3486\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356156.3750 - mae: 427.7515 - val_loss: 353888.1250 - val_mae: 426.7728\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356032.9375 - mae: 427.6747 - val_loss: 353507.3750 - val_mae: 427.0459\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355666.2188 - mae: 427.5288 - val_loss: 353063.4688 - val_mae: 426.8091\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355124.5938 - mae: 426.9605 - val_loss: 352740.0000 - val_mae: 427.2695\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355123.0625 - mae: 427.3941 - val_loss: 352169.4375 - val_mae: 426.0144\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354638.6562 - mae: 427.2740 - val_loss: 351585.8750 - val_mae: 425.3763\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354026.5938 - mae: 426.7761 - val_loss: 352261.5000 - val_mae: 424.6389\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353836.9062 - mae: 426.7145 - val_loss: 350891.9688 - val_mae: 424.5622\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353471.5938 - mae: 426.3827 - val_loss: 350485.4062 - val_mae: 425.5753\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352554.6562 - mae: 425.9222 - val_loss: 350461.5000 - val_mae: 425.4411\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352446.4375 - mae: 425.6599 - val_loss: 349677.8438 - val_mae: 425.8014\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351899.0938 - mae: 425.8824 - val_loss: 349581.2500 - val_mae: 425.4823\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351510.0312 - mae: 425.7149 - val_loss: 349050.8750 - val_mae: 423.1158\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351023.0938 - mae: 425.2886 - val_loss: 348899.0938 - val_mae: 425.6026\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350440.7500 - mae: 425.1238 - val_loss: 348473.2812 - val_mae: 425.2143\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350437.2500 - mae: 424.6484 - val_loss: 347599.8750 - val_mae: 423.5742\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350271.2188 - mae: 425.0476 - val_loss: 347653.3438 - val_mae: 422.3924\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349619.1875 - mae: 424.7171 - val_loss: 347269.9375 - val_mae: 423.3437\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349554.4375 - mae: 424.4885 - val_loss: 346889.5938 - val_mae: 423.6349\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349555.8438 - mae: 424.5841 - val_loss: 346630.2500 - val_mae: 422.8228\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348970.6250 - mae: 424.2691 - val_loss: 346820.6250 - val_mae: 424.8969\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348648.5938 - mae: 424.4166 - val_loss: 346159.4375 - val_mae: 423.2983\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348458.6562 - mae: 424.4750 - val_loss: 346022.8438 - val_mae: 423.6125\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347989.0000 - mae: 424.1636 - val_loss: 345529.1250 - val_mae: 422.0021\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347580.5312 - mae: 423.3938 - val_loss: 345300.6562 - val_mae: 423.0435\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347553.0312 - mae: 423.8596 - val_loss: 345098.1250 - val_mae: 422.0363\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347238.7500 - mae: 423.3598 - val_loss: 344842.5938 - val_mae: 422.8084\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347160.2812 - mae: 423.4677 - val_loss: 344759.0000 - val_mae: 423.0049\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346814.7500 - mae: 423.3503 - val_loss: 344833.3438 - val_mae: 420.8524\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346783.6250 - mae: 422.9164 - val_loss: 344441.5000 - val_mae: 421.0720\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346416.8750 - mae: 422.5247 - val_loss: 344757.2500 - val_mae: 424.5764\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346431.4375 - mae: 423.2884 - val_loss: 343747.9688 - val_mae: 422.0529\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346051.9375 - mae: 423.0952 - val_loss: 343818.5938 - val_mae: 421.4238\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345597.6875 - mae: 422.8351 - val_loss: 344035.6250 - val_mae: 419.8480\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345635.0000 - mae: 422.4206 - val_loss: 343266.4062 - val_mae: 421.5176\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345517.0312 - mae: 422.9001 - val_loss: 343803.4688 - val_mae: 420.1110\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345557.4062 - mae: 422.1087 - val_loss: 343561.7188 - val_mae: 421.8963\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345522.6562 - mae: 422.7119 - val_loss: 343081.1562 - val_mae: 422.3786\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345275.9688 - mae: 422.2486 - val_loss: 343083.8438 - val_mae: 422.3820\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345026.5000 - mae: 422.2814 - val_loss: 342818.5312 - val_mae: 421.9577\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344954.5938 - mae: 422.1190 - val_loss: 342397.5312 - val_mae: 422.0995\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344409.8750 - mae: 422.1316 - val_loss: 342022.4375 - val_mae: 420.4922\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344131.5938 - mae: 421.9302 - val_loss: 341552.9688 - val_mae: 421.1721\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343704.7812 - mae: 421.8825 - val_loss: 341443.7188 - val_mae: 419.3833\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343322.2188 - mae: 421.2173 - val_loss: 340870.0625 - val_mae: 420.4593\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342732.6875 - mae: 421.2019 - val_loss: 340450.6250 - val_mae: 420.3913\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342787.9375 - mae: 421.3381 - val_loss: 340519.4375 - val_mae: 419.4317\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342648.4062 - mae: 421.2447 - val_loss: 340404.0625 - val_mae: 418.9111\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342046.4062 - mae: 421.0651 - val_loss: 339682.6875 - val_mae: 419.4595\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341850.9688 - mae: 420.9979 - val_loss: 339525.8438 - val_mae: 419.8777\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341805.8438 - mae: 420.9098 - val_loss: 339485.9688 - val_mae: 419.7005\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341585.1875 - mae: 420.9814 - val_loss: 339315.1875 - val_mae: 419.1123\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341192.1562 - mae: 420.2737 - val_loss: 338786.0312 - val_mae: 419.6056\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341159.7812 - mae: 420.4896 - val_loss: 338638.6250 - val_mae: 418.3436\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340923.8125 - mae: 420.3191 - val_loss: 338317.8125 - val_mae: 420.1086\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340382.4375 - mae: 420.0990 - val_loss: 337940.1250 - val_mae: 419.6036\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340335.9688 - mae: 420.0398 - val_loss: 338028.8438 - val_mae: 419.9385\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339690.4688 - mae: 419.6942 - val_loss: 337701.0312 - val_mae: 419.9109\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339482.7188 - mae: 420.0610 - val_loss: 337694.4062 - val_mae: 420.1626\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339096.6250 - mae: 419.6528 - val_loss: 336953.1875 - val_mae: 417.4998\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338851.6250 - mae: 419.6737 - val_loss: 336995.5000 - val_mae: 416.9673\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338816.5000 - mae: 419.3730 - val_loss: 336120.0625 - val_mae: 418.0628\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338321.6250 - mae: 418.6437 - val_loss: 336306.1250 - val_mae: 419.0032\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338296.3438 - mae: 419.2348 - val_loss: 335574.7500 - val_mae: 418.0779\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338115.2500 - mae: 419.3588 - val_loss: 335641.3750 - val_mae: 417.7137\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337919.2500 - mae: 419.0871 - val_loss: 335577.8125 - val_mae: 416.7694\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337554.1250 - mae: 418.7958 - val_loss: 335180.3438 - val_mae: 416.6292\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337204.5938 - mae: 418.3250 - val_loss: 334693.7500 - val_mae: 417.6206\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336500.0000 - mae: 418.2187 - val_loss: 333997.3125 - val_mae: 416.5688\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336066.8438 - mae: 418.0795 - val_loss: 334033.8125 - val_mae: 418.8424\n",
      "Epoch 155/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335652.3750 - mae: 417.5946 - val_loss: 332703.1250 - val_mae: 415.5996\n",
      "Epoch 156/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334764.6875 - mae: 417.5379 - val_loss: 332377.2812 - val_mae: 416.8993\n",
      "Epoch 157/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334593.1562 - mae: 416.6914 - val_loss: 331756.5625 - val_mae: 416.6066\n",
      "Epoch 158/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333674.0000 - mae: 416.7092 - val_loss: 331902.0938 - val_mae: 415.2107\n",
      "Epoch 159/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 333417.4375 - mae: 416.9563 - val_loss: 332059.9375 - val_mae: 413.8630\n",
      "Epoch 160/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333373.5000 - mae: 416.5220 - val_loss: 330191.1875 - val_mae: 415.1250\n",
      "Epoch 161/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332358.8750 - mae: 416.0778 - val_loss: 330797.2500 - val_mae: 413.3167\n",
      "Epoch 162/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332006.0625 - mae: 415.4199 - val_loss: 330467.6562 - val_mae: 417.0287\n",
      "Epoch 163/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331990.0625 - mae: 416.1265 - val_loss: 329256.0000 - val_mae: 413.7940\n",
      "Epoch 164/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331496.5000 - mae: 415.3043 - val_loss: 329132.6562 - val_mae: 415.2670\n",
      "Epoch 165/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331192.0312 - mae: 415.8269 - val_loss: 328653.4688 - val_mae: 413.8842\n",
      "Epoch 166/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330997.5938 - mae: 414.8474 - val_loss: 329184.5312 - val_mae: 416.4856\n",
      "Epoch 167/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330907.0312 - mae: 415.3928 - val_loss: 328491.8438 - val_mae: 414.6624\n",
      "Epoch 168/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330740.0938 - mae: 415.0960 - val_loss: 328029.8750 - val_mae: 413.8031\n",
      "Epoch 169/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330144.8438 - mae: 414.9221 - val_loss: 328258.8750 - val_mae: 413.5774\n",
      "Epoch 170/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329857.8125 - mae: 414.9855 - val_loss: 328022.4062 - val_mae: 413.3051\n",
      "Epoch 171/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 329875.5000 - mae: 414.6298 - val_loss: 327462.4375 - val_mae: 414.2157\n",
      "Epoch 172/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 329809.1562 - mae: 414.7232 - val_loss: 327291.5312 - val_mae: 413.0531\n",
      "Epoch 173/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 329486.7812 - mae: 414.8075 - val_loss: 327610.4062 - val_mae: 414.4874\n",
      "Epoch 174/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 329300.3438 - mae: 414.5591 - val_loss: 326909.3750 - val_mae: 412.9186\n",
      "Epoch 175/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329294.7188 - mae: 414.6190 - val_loss: 326654.2188 - val_mae: 413.0282\n",
      "Epoch 176/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328759.3125 - mae: 414.2740 - val_loss: 326400.1562 - val_mae: 412.4728\n",
      "Epoch 177/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328949.4062 - mae: 414.1473 - val_loss: 326509.6875 - val_mae: 413.4684\n",
      "Epoch 178/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328803.0938 - mae: 414.3350 - val_loss: 326048.6875 - val_mae: 412.3953\n",
      "Epoch 179/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328115.5625 - mae: 413.7961 - val_loss: 326037.2812 - val_mae: 413.5066\n",
      "Epoch 180/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327926.1875 - mae: 413.8565 - val_loss: 326596.8438 - val_mae: 411.7243\n",
      "Epoch 181/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328121.3438 - mae: 413.7408 - val_loss: 326238.7188 - val_mae: 411.0620\n",
      "Epoch 182/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327707.9375 - mae: 413.5599 - val_loss: 325119.6250 - val_mae: 412.5695\n",
      "Epoch 183/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327304.0625 - mae: 413.6085 - val_loss: 325557.2500 - val_mae: 413.4082\n",
      "Epoch 184/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327539.6562 - mae: 413.6903 - val_loss: 325075.6250 - val_mae: 412.6458\n",
      "Epoch 185/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327298.7500 - mae: 413.3211 - val_loss: 324909.0938 - val_mae: 411.5227\n",
      "Epoch 186/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327012.5312 - mae: 413.0958 - val_loss: 324613.5625 - val_mae: 411.4211\n",
      "Epoch 187/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326767.2188 - mae: 413.1921 - val_loss: 324713.8750 - val_mae: 412.0577\n",
      "Epoch 188/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326411.9688 - mae: 413.0364 - val_loss: 324584.5000 - val_mae: 410.9519\n",
      "Epoch 189/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326452.1562 - mae: 412.9950 - val_loss: 324385.6875 - val_mae: 410.4304\n",
      "Epoch 190/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326312.8750 - mae: 412.4690 - val_loss: 324304.7188 - val_mae: 413.7427\n",
      "Epoch 191/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326217.8125 - mae: 413.4223 - val_loss: 323861.3125 - val_mae: 411.4767\n",
      "Epoch 192/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326042.7188 - mae: 412.9227 - val_loss: 323676.0000 - val_mae: 410.7972\n",
      "Epoch 193/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326006.2812 - mae: 412.8938 - val_loss: 323687.3438 - val_mae: 410.4159\n",
      "Epoch 194/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325492.8438 - mae: 412.4442 - val_loss: 323625.6250 - val_mae: 412.6932\n",
      "Epoch 195/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325449.4062 - mae: 412.2703 - val_loss: 323191.9375 - val_mae: 412.5089\n",
      "Epoch 196/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325623.1875 - mae: 412.5896 - val_loss: 323337.2812 - val_mae: 412.5430\n",
      "Epoch 197/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324838.2188 - mae: 412.6632 - val_loss: 323230.3438 - val_mae: 409.8806\n",
      "Epoch 198/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324824.7500 - mae: 412.1258 - val_loss: 322728.3438 - val_mae: 410.9463\n",
      "Epoch 199/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324906.6562 - mae: 412.3045 - val_loss: 322707.8750 - val_mae: 411.5413\n",
      "Epoch 200/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324943.3125 - mae: 412.1751 - val_loss: 322607.8750 - val_mae: 411.3251\n",
      "Epoch 201/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324814.5312 - mae: 412.3133 - val_loss: 323022.0000 - val_mae: 410.2926\n",
      "Epoch 202/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325072.9062 - mae: 412.4911 - val_loss: 322434.0625 - val_mae: 410.3599\n",
      "Epoch 203/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324837.8125 - mae: 412.2296 - val_loss: 322352.1875 - val_mae: 411.4130\n",
      "Epoch 204/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324550.6250 - mae: 412.2271 - val_loss: 322460.5312 - val_mae: 410.1589\n",
      "Epoch 205/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324490.7812 - mae: 412.4449 - val_loss: 322341.2812 - val_mae: 411.6298\n",
      "Epoch 206/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324696.5625 - mae: 412.7016 - val_loss: 322398.8438 - val_mae: 411.7862\n",
      "Epoch 207/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324437.2188 - mae: 412.0350 - val_loss: 321972.4375 - val_mae: 410.0496\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 35811392.0000 - mae: 5824.5122 - val_loss: 30114440.0000 - val_mae: 5330.5332\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 21981740.0000 - mae: 4463.3896 - val_loss: 14211448.0000 - val_mae: 3499.9392\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 8816413.0000 - mae: 2574.5991 - val_loss: 4735343.0000 - val_mae: 1755.2928\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2909688.5000 - mae: 1250.4158 - val_loss: 1789470.1250 - val_mae: 902.1356\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1424904.6250 - mae: 780.5977 - val_loss: 1183886.6250 - val_mae: 706.4531\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1063791.1250 - mae: 669.1093 - val_loss: 955788.7500 - val_mae: 640.8876\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 883966.6250 - mae: 621.9763 - val_loss: 812250.9375 - val_mae: 604.8712\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 760756.1250 - mae: 591.9319 - val_loss: 707270.2500 - val_mae: 577.9327\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 670466.8125 - mae: 568.0403 - val_loss: 631256.5625 - val_mae: 556.9992\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603730.0000 - mae: 548.5245 - val_loss: 575234.6250 - val_mae: 541.1266\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555635.5625 - mae: 533.1746 - val_loss: 532992.3125 - val_mae: 526.6120\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 520480.5938 - mae: 520.6153 - val_loss: 503804.4375 - val_mae: 514.7843\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 496120.0312 - mae: 511.0541 - val_loss: 483926.0000 - val_mae: 503.9211\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 478678.0312 - mae: 502.2765 - val_loss: 468681.7188 - val_mae: 500.2108\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 466145.6562 - mae: 497.1784 - val_loss: 457283.2812 - val_mae: 491.1129\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 455695.5000 - mae: 491.9802 - val_loss: 448393.6562 - val_mae: 488.3094\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 448100.3125 - mae: 488.0490 - val_loss: 441074.0938 - val_mae: 485.4064\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 441052.9375 - mae: 484.4826 - val_loss: 434967.4375 - val_mae: 481.6605\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 434807.4375 - mae: 480.8484 - val_loss: 428717.6562 - val_mae: 479.3585\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 428725.3438 - mae: 477.9541 - val_loss: 423266.3438 - val_mae: 474.0245\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423478.5000 - mae: 474.5808 - val_loss: 417660.9062 - val_mae: 469.9916\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 418462.6250 - mae: 471.2876 - val_loss: 413281.8438 - val_mae: 467.6603\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414011.9688 - mae: 468.3175 - val_loss: 410305.6875 - val_mae: 469.5491\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 410573.0000 - mae: 466.7753 - val_loss: 405636.5312 - val_mae: 465.5928\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406953.9688 - mae: 464.3870 - val_loss: 402940.9375 - val_mae: 465.2839\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403630.0625 - mae: 462.7182 - val_loss: 399368.3438 - val_mae: 459.7843\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400814.6562 - mae: 460.6930 - val_loss: 397034.0938 - val_mae: 458.0180\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398668.3125 - mae: 459.3278 - val_loss: 393922.4062 - val_mae: 456.7902\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396362.6562 - mae: 458.1846 - val_loss: 392055.7188 - val_mae: 455.1310\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393824.2500 - mae: 456.6513 - val_loss: 390072.9062 - val_mae: 454.3931\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391821.0312 - mae: 455.1580 - val_loss: 387410.4375 - val_mae: 453.1063\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389848.1562 - mae: 453.4423 - val_loss: 385913.8750 - val_mae: 452.4124\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 387633.8750 - mae: 452.2759 - val_loss: 384603.5000 - val_mae: 452.7992\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386098.9062 - mae: 451.7985 - val_loss: 382577.8125 - val_mae: 448.5652\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 384868.3125 - mae: 450.1336 - val_loss: 381439.7500 - val_mae: 450.4120\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 383387.3438 - mae: 450.0744 - val_loss: 379665.8438 - val_mae: 447.0064\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382142.6250 - mae: 448.6258 - val_loss: 379444.6562 - val_mae: 446.2326\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 381247.5312 - mae: 448.0764 - val_loss: 378402.1875 - val_mae: 445.1599\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 380063.9062 - mae: 446.8206 - val_loss: 376554.7500 - val_mae: 445.8398\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 379188.8750 - mae: 446.8604 - val_loss: 376006.5625 - val_mae: 444.2417\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 378007.2500 - mae: 445.5653 - val_loss: 374983.5312 - val_mae: 445.1326\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377292.6562 - mae: 445.5261 - val_loss: 373803.1562 - val_mae: 443.5837\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 376262.3438 - mae: 444.8914 - val_loss: 373075.5312 - val_mae: 443.6745\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 375982.4688 - mae: 444.8321 - val_loss: 371981.0625 - val_mae: 441.1673\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374966.8438 - mae: 443.6547 - val_loss: 371619.7500 - val_mae: 440.5279\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374034.6562 - mae: 443.3237 - val_loss: 370629.8750 - val_mae: 441.3333\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373522.1250 - mae: 442.9652 - val_loss: 370121.2812 - val_mae: 440.2877\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 372850.0938 - mae: 442.0783 - val_loss: 369793.5312 - val_mae: 442.1156\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371950.6250 - mae: 442.1570 - val_loss: 370107.1250 - val_mae: 439.5072\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371184.4688 - mae: 441.0079 - val_loss: 369036.9062 - val_mae: 442.9754\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 370518.4688 - mae: 441.1817 - val_loss: 367686.1250 - val_mae: 437.9789\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369592.8125 - mae: 440.5029 - val_loss: 366508.5000 - val_mae: 439.4417\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368988.9688 - mae: 439.9530 - val_loss: 365694.4375 - val_mae: 438.3443\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368194.2812 - mae: 439.4373 - val_loss: 365114.0625 - val_mae: 438.9728\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367249.5312 - mae: 438.5478 - val_loss: 364969.0625 - val_mae: 437.7178\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366650.9062 - mae: 438.5474 - val_loss: 363969.7188 - val_mae: 435.3528\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366004.3125 - mae: 437.5490 - val_loss: 362927.7500 - val_mae: 437.0143\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365962.3750 - mae: 437.5346 - val_loss: 362108.1875 - val_mae: 435.2152\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364761.0312 - mae: 437.1100 - val_loss: 362075.1562 - val_mae: 434.4766\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364309.0000 - mae: 436.7740 - val_loss: 361123.4062 - val_mae: 435.1434\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363680.7188 - mae: 436.5997 - val_loss: 360799.0000 - val_mae: 433.9641\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363312.2500 - mae: 436.0325 - val_loss: 360509.6562 - val_mae: 434.9623\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362668.9062 - mae: 435.3145 - val_loss: 360094.3750 - val_mae: 433.9561\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362428.5625 - mae: 435.0949 - val_loss: 359414.5000 - val_mae: 435.0399\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361819.1875 - mae: 435.0063 - val_loss: 358741.7812 - val_mae: 434.2254\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361836.3125 - mae: 434.8430 - val_loss: 358925.7188 - val_mae: 435.5633\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360962.2500 - mae: 434.2366 - val_loss: 358031.3438 - val_mae: 431.1345\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360450.3750 - mae: 434.0972 - val_loss: 357066.5312 - val_mae: 432.6510\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359649.5312 - mae: 433.6874 - val_loss: 357146.5938 - val_mae: 433.7202\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358838.1875 - mae: 432.9047 - val_loss: 356888.1562 - val_mae: 430.0215\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358646.5000 - mae: 432.4065 - val_loss: 355507.6875 - val_mae: 431.5029\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357720.8750 - mae: 432.7595 - val_loss: 354920.6875 - val_mae: 430.1708\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357262.8438 - mae: 431.7032 - val_loss: 354630.6250 - val_mae: 431.1251\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357067.0312 - mae: 431.8324 - val_loss: 353772.5625 - val_mae: 430.6650\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356566.7500 - mae: 431.3479 - val_loss: 353345.8750 - val_mae: 429.7182\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355752.8125 - mae: 431.0550 - val_loss: 352947.2812 - val_mae: 429.3571\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355265.2500 - mae: 431.0077 - val_loss: 352089.3125 - val_mae: 429.4985\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354689.5938 - mae: 430.2217 - val_loss: 351875.9688 - val_mae: 428.9063\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354474.2812 - mae: 430.3900 - val_loss: 351213.2500 - val_mae: 428.9093\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353412.1875 - mae: 429.4135 - val_loss: 350489.3438 - val_mae: 428.2096\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352603.6562 - mae: 429.3467 - val_loss: 350542.0625 - val_mae: 428.8704\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352627.6875 - mae: 429.0246 - val_loss: 349315.6875 - val_mae: 426.6780\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351833.3750 - mae: 428.3770 - val_loss: 349143.5312 - val_mae: 428.4626\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351251.0312 - mae: 428.1317 - val_loss: 348709.0625 - val_mae: 427.7597\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350542.3750 - mae: 428.0506 - val_loss: 348164.5938 - val_mae: 425.8168\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350415.5625 - mae: 427.3121 - val_loss: 347096.1562 - val_mae: 424.4479\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349041.8750 - mae: 426.7792 - val_loss: 346640.1875 - val_mae: 425.2665\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348967.2812 - mae: 426.3372 - val_loss: 345571.8750 - val_mae: 423.4206\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347851.1562 - mae: 425.7534 - val_loss: 344997.2500 - val_mae: 423.6862\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347122.8125 - mae: 424.8338 - val_loss: 344197.1875 - val_mae: 424.5074\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346389.8438 - mae: 425.1071 - val_loss: 343527.9688 - val_mae: 423.5383\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345897.7188 - mae: 424.4101 - val_loss: 342181.9062 - val_mae: 422.7971\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344282.6250 - mae: 424.0568 - val_loss: 342115.9062 - val_mae: 421.0472\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343971.6562 - mae: 423.0163 - val_loss: 340621.0312 - val_mae: 420.1252\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342892.1562 - mae: 422.2002 - val_loss: 340363.3750 - val_mae: 420.1967\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342207.5625 - mae: 421.8070 - val_loss: 339380.4375 - val_mae: 418.8705\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341550.0938 - mae: 421.4452 - val_loss: 338475.9375 - val_mae: 419.6216\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340960.3750 - mae: 420.3331 - val_loss: 338202.9062 - val_mae: 421.1694\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340373.7500 - mae: 420.7674 - val_loss: 337622.1250 - val_mae: 418.5551\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339987.0625 - mae: 419.9693 - val_loss: 338525.3438 - val_mae: 417.5309\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339547.1562 - mae: 419.7629 - val_loss: 336317.7812 - val_mae: 419.5164\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338712.0000 - mae: 419.4749 - val_loss: 336783.5000 - val_mae: 420.7171\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338359.8125 - mae: 419.0372 - val_loss: 336108.2188 - val_mae: 418.9708\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338316.6562 - mae: 419.0171 - val_loss: 335872.1250 - val_mae: 419.7515\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337658.0625 - mae: 418.9882 - val_loss: 335010.3125 - val_mae: 417.4995\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337368.0312 - mae: 418.4745 - val_loss: 334936.1875 - val_mae: 415.4155\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337174.2500 - mae: 418.6956 - val_loss: 334629.1562 - val_mae: 415.6616\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337063.1250 - mae: 418.1725 - val_loss: 333473.8438 - val_mae: 416.4194\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336757.5000 - mae: 417.9709 - val_loss: 333572.3125 - val_mae: 417.3612\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336556.0000 - mae: 417.8767 - val_loss: 333858.2500 - val_mae: 418.3756\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335920.4375 - mae: 417.3747 - val_loss: 333670.1250 - val_mae: 416.0575\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335548.0938 - mae: 417.5612 - val_loss: 333233.5938 - val_mae: 417.4918\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335361.1562 - mae: 417.0099 - val_loss: 332536.1875 - val_mae: 416.1824\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335508.2812 - mae: 417.0047 - val_loss: 332069.5625 - val_mae: 415.4982\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334852.5625 - mae: 416.8093 - val_loss: 331912.5625 - val_mae: 415.6133\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335146.0625 - mae: 416.9441 - val_loss: 332244.1875 - val_mae: 414.4374\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334648.5312 - mae: 416.8055 - val_loss: 332589.0000 - val_mae: 414.9102\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334665.0000 - mae: 416.2366 - val_loss: 331454.8125 - val_mae: 414.6428\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334410.8438 - mae: 416.2266 - val_loss: 331895.7500 - val_mae: 414.1681\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333973.4688 - mae: 416.0147 - val_loss: 330998.3125 - val_mae: 415.3230\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333535.6250 - mae: 415.9850 - val_loss: 331447.4062 - val_mae: 414.7505\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333701.4375 - mae: 415.9537 - val_loss: 331691.9062 - val_mae: 416.7822\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333800.2500 - mae: 415.9090 - val_loss: 331185.7188 - val_mae: 414.8703\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333523.9688 - mae: 415.8526 - val_loss: 330931.7500 - val_mae: 415.7825\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333612.0312 - mae: 415.7469 - val_loss: 330837.7500 - val_mae: 413.8772\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333211.4688 - mae: 415.4499 - val_loss: 330209.3438 - val_mae: 415.2494\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332317.2500 - mae: 415.4412 - val_loss: 331659.9688 - val_mae: 415.7685\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333176.8438 - mae: 415.3570 - val_loss: 329983.7188 - val_mae: 414.4541\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332453.5625 - mae: 415.5991 - val_loss: 330238.4375 - val_mae: 412.6805\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332606.5312 - mae: 414.9761 - val_loss: 330508.6875 - val_mae: 413.8264\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332571.9375 - mae: 415.0437 - val_loss: 330761.9062 - val_mae: 416.9250\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332232.7188 - mae: 415.2588 - val_loss: 329546.7500 - val_mae: 413.6316\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332255.4062 - mae: 415.2188 - val_loss: 329546.7500 - val_mae: 414.5601\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332130.3438 - mae: 415.1374 - val_loss: 329279.1250 - val_mae: 413.0529\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331997.3125 - mae: 414.6203 - val_loss: 329261.9688 - val_mae: 414.3615\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331840.9375 - mae: 414.9763 - val_loss: 329120.7188 - val_mae: 413.4339\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331522.6562 - mae: 414.8719 - val_loss: 329133.7500 - val_mae: 413.1570\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331355.8750 - mae: 414.0086 - val_loss: 330057.1250 - val_mae: 417.0641\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331444.7500 - mae: 415.3040 - val_loss: 328871.3438 - val_mae: 412.4944\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331311.2188 - mae: 414.5269 - val_loss: 328400.6875 - val_mae: 412.8483\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331245.0938 - mae: 414.2480 - val_loss: 328301.1250 - val_mae: 412.9835\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 331456.8438 - mae: 414.6422 - val_loss: 328929.8750 - val_mae: 414.4777\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330799.2812 - mae: 414.3665 - val_loss: 328469.1250 - val_mae: 413.9977\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330713.1250 - mae: 414.6932 - val_loss: 328010.7812 - val_mae: 412.7878\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330644.0000 - mae: 414.1739 - val_loss: 327974.0625 - val_mae: 413.0273\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330398.3125 - mae: 414.8115 - val_loss: 327879.5312 - val_mae: 411.5370\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330190.8125 - mae: 414.2256 - val_loss: 327671.2812 - val_mae: 412.0552\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330280.2188 - mae: 414.0221 - val_loss: 327094.3438 - val_mae: 412.4487\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329759.8438 - mae: 413.5724 - val_loss: 327589.0312 - val_mae: 414.5866\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329837.0312 - mae: 414.0953 - val_loss: 326699.4062 - val_mae: 411.8053\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329067.0938 - mae: 413.9879 - val_loss: 326700.7500 - val_mae: 413.5438\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329143.6875 - mae: 413.7759 - val_loss: 325805.0938 - val_mae: 412.0254\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328182.0938 - mae: 413.7033 - val_loss: 325614.5000 - val_mae: 411.4691\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328407.0312 - mae: 413.4257 - val_loss: 325245.4062 - val_mae: 411.8241\n",
      "Epoch 155/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327394.7188 - mae: 413.0875 - val_loss: 326254.0312 - val_mae: 413.0820\n",
      "Epoch 156/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327267.5312 - mae: 413.0964 - val_loss: 325552.8125 - val_mae: 413.9481\n",
      "Epoch 157/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327390.7500 - mae: 413.4965 - val_loss: 324535.2500 - val_mae: 410.9011\n",
      "Epoch 158/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326778.0312 - mae: 412.6725 - val_loss: 324544.9062 - val_mae: 410.5833\n",
      "Epoch 159/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326959.2500 - mae: 412.8978 - val_loss: 323723.0625 - val_mae: 410.7384\n",
      "Epoch 160/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326566.0312 - mae: 412.9475 - val_loss: 323888.0938 - val_mae: 410.7804\n",
      "Epoch 161/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326275.7812 - mae: 412.1242 - val_loss: 323543.6250 - val_mae: 409.9310\n",
      "Epoch 162/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326107.7188 - mae: 412.5371 - val_loss: 324299.0312 - val_mae: 409.8645\n",
      "Epoch 163/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325675.8438 - mae: 412.3512 - val_loss: 323214.6562 - val_mae: 410.2876\n",
      "Epoch 164/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325836.0938 - mae: 412.0126 - val_loss: 323042.5000 - val_mae: 411.3144\n",
      "Epoch 165/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325575.3438 - mae: 412.1684 - val_loss: 322711.0625 - val_mae: 410.3387\n",
      "Epoch 166/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325043.7812 - mae: 412.1850 - val_loss: 323072.1250 - val_mae: 408.7868\n",
      "Epoch 167/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324949.1250 - mae: 411.3188 - val_loss: 324364.5938 - val_mae: 409.4365\n",
      "Epoch 168/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325242.9375 - mae: 411.3512 - val_loss: 322943.2188 - val_mae: 412.9144\n",
      "Epoch 169/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324820.4688 - mae: 412.0822 - val_loss: 322715.7812 - val_mae: 408.6231\n",
      "Epoch 170/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324307.4062 - mae: 410.9162 - val_loss: 321894.0000 - val_mae: 411.1218\n",
      "Epoch 171/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324475.2500 - mae: 411.4487 - val_loss: 321472.6875 - val_mae: 410.0567\n",
      "Epoch 172/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323848.0938 - mae: 411.3807 - val_loss: 322383.1562 - val_mae: 408.7506\n",
      "Epoch 173/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324123.3125 - mae: 411.1431 - val_loss: 321968.4688 - val_mae: 411.3108\n",
      "Epoch 174/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323575.5000 - mae: 410.7191 - val_loss: 321910.2188 - val_mae: 407.9254\n",
      "Epoch 175/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323923.0312 - mae: 410.5985 - val_loss: 321387.1562 - val_mae: 410.3511\n",
      "Epoch 176/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323956.1562 - mae: 411.1443 - val_loss: 321334.0938 - val_mae: 408.7326\n",
      "Epoch 177/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 323475.9375 - mae: 410.7680 - val_loss: 321447.3750 - val_mae: 411.8008\n",
      "Epoch 178/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323160.1250 - mae: 410.6110 - val_loss: 321918.6875 - val_mae: 409.0958\n",
      "Epoch 179/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323154.5312 - mae: 410.9680 - val_loss: 320421.3438 - val_mae: 409.2343\n",
      "Epoch 180/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323334.0625 - mae: 410.8564 - val_loss: 320866.0625 - val_mae: 408.4879\n",
      "Epoch 181/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323187.6562 - mae: 410.5150 - val_loss: 320282.4375 - val_mae: 409.0581\n",
      "Epoch 182/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322916.2188 - mae: 410.2281 - val_loss: 320915.7500 - val_mae: 410.5846\n",
      "Epoch 183/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322998.3125 - mae: 410.7258 - val_loss: 320696.5000 - val_mae: 410.2968\n",
      "Epoch 184/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 322830.8438 - mae: 410.4270 - val_loss: 320395.3438 - val_mae: 407.5309\n",
      "Epoch 185/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322364.3125 - mae: 410.1555 - val_loss: 320777.1250 - val_mae: 407.2225\n",
      "Epoch 186/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323002.8750 - mae: 410.3678 - val_loss: 319973.7500 - val_mae: 409.1803\n",
      "Epoch 187/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322281.0312 - mae: 410.1006 - val_loss: 319652.5938 - val_mae: 408.4937\n",
      "Epoch 188/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322156.8125 - mae: 409.8554 - val_loss: 320225.3750 - val_mae: 407.8686\n",
      "Epoch 189/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322523.7500 - mae: 410.0484 - val_loss: 319074.7812 - val_mae: 408.4469\n",
      "Epoch 190/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321965.5000 - mae: 409.5157 - val_loss: 319162.8438 - val_mae: 408.1601\n",
      "Epoch 191/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321977.4062 - mae: 409.6275 - val_loss: 319359.8750 - val_mae: 409.2457\n",
      "Epoch 192/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322148.5000 - mae: 409.8704 - val_loss: 318913.3750 - val_mae: 408.6284\n",
      "Epoch 193/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321869.0625 - mae: 409.8495 - val_loss: 318944.3438 - val_mae: 407.5927\n",
      "Epoch 194/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321800.0312 - mae: 409.5859 - val_loss: 319028.0938 - val_mae: 409.3206\n",
      "Epoch 195/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 321700.8438 - mae: 409.9694 - val_loss: 320174.4375 - val_mae: 406.2016\n",
      "Epoch 196/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 321495.1562 - mae: 409.2360 - val_loss: 319481.1875 - val_mae: 410.4129\n",
      "Epoch 197/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 321592.3438 - mae: 409.9536 - val_loss: 318806.4375 - val_mae: 407.5855\n",
      "Epoch 198/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321621.3750 - mae: 409.2560 - val_loss: 318442.2500 - val_mae: 407.9065\n",
      "Epoch 199/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321019.5938 - mae: 408.8363 - val_loss: 319202.2812 - val_mae: 409.7203\n",
      "Epoch 200/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321252.6875 - mae: 409.6904 - val_loss: 318687.5938 - val_mae: 406.8208\n",
      "Epoch 201/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321087.7188 - mae: 409.3376 - val_loss: 318314.3750 - val_mae: 408.0148\n",
      "Epoch 202/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320767.2500 - mae: 409.1590 - val_loss: 318281.5625 - val_mae: 408.2702\n",
      "Epoch 203/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321212.3750 - mae: 409.6729 - val_loss: 318171.0938 - val_mae: 406.6411\n",
      "Epoch 204/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320515.5312 - mae: 408.9164 - val_loss: 318432.7500 - val_mae: 407.7078\n",
      "Epoch 205/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321312.4688 - mae: 408.9019 - val_loss: 318091.8750 - val_mae: 408.9270\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38178644.0000 - mae: 6022.9370 - val_loss: 37220668.0000 - val_mae: 5948.5044\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 34958784.0000 - mae: 5768.5776 - val_loss: 32149984.0000 - val_mae: 5539.2100\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 28736292.0000 - mae: 5237.5254 - val_loss: 25092892.0000 - val_mae: 4899.5015\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 21449084.0000 - mae: 4517.4785 - val_loss: 17850460.0000 - val_mae: 4112.4463\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 14691266.0000 - mae: 3696.5007 - val_loss: 11736443.0000 - val_mae: 3272.3572\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 9364628.0000 - mae: 2871.0967 - val_loss: 7243851.0000 - val_mae: 2479.7417\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5676662.5000 - mae: 2141.8928 - val_loss: 4324431.5000 - val_mae: 1822.4580\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3400067.0000 - mae: 1564.9941 - val_loss: 2630129.2500 - val_mae: 1333.9218\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2142959.7500 - mae: 1172.7185 - val_loss: 1744573.1250 - val_mae: 1035.9121\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1501266.7500 - mae: 947.8827 - val_loss: 1298923.3750 - val_mae: 874.2888\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1171485.8750 - mae: 827.0703 - val_loss: 1059591.7500 - val_mae: 784.9856\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 984398.0625 - mae: 755.7357 - val_loss: 914203.6875 - val_mae: 727.2690\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 864174.2500 - mae: 706.1061 - val_loss: 814714.2500 - val_mae: 684.7101\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 779581.0625 - mae: 668.9767 - val_loss: 743361.9375 - val_mae: 652.6069\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 717662.1875 - mae: 640.6742 - val_loss: 690363.9375 - val_mae: 628.1052\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 671180.8125 - mae: 619.0320 - val_loss: 649640.2500 - val_mae: 608.5927\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 634919.8750 - mae: 601.3671 - val_loss: 617544.3750 - val_mae: 593.2422\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606307.8125 - mae: 587.0219 - val_loss: 591759.2500 - val_mae: 580.3896\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582217.3125 - mae: 574.9441 - val_loss: 569265.9375 - val_mae: 568.3379\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561379.1250 - mae: 563.4692 - val_loss: 550246.5000 - val_mae: 557.9768\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544042.1875 - mae: 554.3927 - val_loss: 534003.0000 - val_mae: 549.3679\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528661.5000 - mae: 546.0861 - val_loss: 519402.7500 - val_mae: 540.4982\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 514985.8438 - mae: 537.9691 - val_loss: 506856.0625 - val_mae: 533.3146\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 503277.3125 - mae: 531.4637 - val_loss: 495721.3125 - val_mae: 527.3669\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 492609.6562 - mae: 525.2117 - val_loss: 485738.9375 - val_mae: 522.1722\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 483343.7812 - mae: 520.0335 - val_loss: 477005.4375 - val_mae: 516.5257\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 475087.2812 - mae: 514.2859 - val_loss: 469426.3750 - val_mae: 512.1741\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 468000.8750 - mae: 510.8311 - val_loss: 462560.8750 - val_mae: 507.5041\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 461711.4375 - mae: 506.5571 - val_loss: 456565.7188 - val_mae: 504.0564\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 455890.3125 - mae: 503.4062 - val_loss: 451638.8438 - val_mae: 499.6652\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 450762.5625 - mae: 500.0958 - val_loss: 446357.7500 - val_mae: 497.3653\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 445998.4062 - mae: 497.0030 - val_loss: 441495.8125 - val_mae: 494.8809\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441739.3438 - mae: 494.4009 - val_loss: 437070.7812 - val_mae: 492.0401\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 436945.1562 - mae: 491.8661 - val_loss: 432705.5000 - val_mae: 489.5731\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 432937.1250 - mae: 489.0266 - val_loss: 429223.5000 - val_mae: 488.9205\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 428929.7812 - mae: 487.2244 - val_loss: 425111.9688 - val_mae: 484.2432\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 425567.5000 - mae: 484.6652 - val_loss: 421506.2188 - val_mae: 482.5197\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 422028.1250 - mae: 482.3802 - val_loss: 418595.7500 - val_mae: 479.6753\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 419077.1250 - mae: 480.0180 - val_loss: 415585.7812 - val_mae: 478.9617\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 416223.4062 - mae: 478.2755 - val_loss: 413201.6875 - val_mae: 478.2213\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413610.4688 - mae: 476.6670 - val_loss: 410478.5625 - val_mae: 475.1368\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 411189.5000 - mae: 474.9438 - val_loss: 408079.7500 - val_mae: 473.9825\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 408937.5938 - mae: 473.9814 - val_loss: 406603.9688 - val_mae: 471.4928\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 407013.3750 - mae: 472.0540 - val_loss: 403731.7812 - val_mae: 470.7114\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 404675.5938 - mae: 470.2729 - val_loss: 401763.0000 - val_mae: 468.4318\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 402886.1250 - mae: 469.6908 - val_loss: 399651.1875 - val_mae: 467.5053\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 401081.0625 - mae: 468.0408 - val_loss: 398126.4375 - val_mae: 465.9948\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399338.1875 - mae: 466.6271 - val_loss: 396486.0625 - val_mae: 464.7599\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 397734.6250 - mae: 465.7287 - val_loss: 394859.6250 - val_mae: 464.0785\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 396222.2500 - mae: 464.2502 - val_loss: 393275.6875 - val_mae: 463.5635\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 394778.0312 - mae: 463.5047 - val_loss: 392005.6250 - val_mae: 462.0230\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 393105.5625 - mae: 462.6663 - val_loss: 391044.1875 - val_mae: 460.2285\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 391792.0312 - mae: 461.3608 - val_loss: 389847.4688 - val_mae: 462.6171\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390594.4375 - mae: 460.8432 - val_loss: 388301.2188 - val_mae: 459.9644\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389693.2500 - mae: 460.2763 - val_loss: 386867.0625 - val_mae: 458.6989\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388419.6250 - mae: 459.0801 - val_loss: 386021.1250 - val_mae: 459.2774\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387218.5000 - mae: 458.6209 - val_loss: 384763.5938 - val_mae: 457.0416\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 386280.2812 - mae: 457.6357 - val_loss: 383829.0000 - val_mae: 457.3313\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385076.4062 - mae: 456.8531 - val_loss: 382455.0312 - val_mae: 455.5958\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 383779.6562 - mae: 456.0551 - val_loss: 381527.3125 - val_mae: 455.8149\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 383013.4062 - mae: 455.3433 - val_loss: 380413.6875 - val_mae: 454.7516\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 381661.8125 - mae: 454.2256 - val_loss: 379413.0312 - val_mae: 454.2575\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 380678.0938 - mae: 454.0449 - val_loss: 378318.8750 - val_mae: 451.8239\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 379785.6562 - mae: 452.7196 - val_loss: 377115.3125 - val_mae: 451.6635\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378711.4062 - mae: 452.5565 - val_loss: 376132.1875 - val_mae: 450.3505\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377427.1562 - mae: 451.2520 - val_loss: 375143.7188 - val_mae: 450.7225\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376594.8438 - mae: 451.2408 - val_loss: 374635.3125 - val_mae: 448.0598\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375267.6250 - mae: 449.6438 - val_loss: 372880.2188 - val_mae: 448.2431\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 373915.7500 - mae: 448.6838 - val_loss: 372113.1875 - val_mae: 450.2226\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 372639.0938 - mae: 448.7757 - val_loss: 370228.9688 - val_mae: 446.6245\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 371680.7812 - mae: 447.6526 - val_loss: 368937.4375 - val_mae: 446.5691\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 370200.2188 - mae: 447.1281 - val_loss: 367740.5625 - val_mae: 445.1901\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 369262.2812 - mae: 446.0543 - val_loss: 366660.0000 - val_mae: 445.3179\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 368271.0938 - mae: 445.7835 - val_loss: 365584.0625 - val_mae: 444.4068\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 367214.5938 - mae: 445.2943 - val_loss: 364361.2500 - val_mae: 443.4661\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 366042.5938 - mae: 444.1223 - val_loss: 363913.7500 - val_mae: 441.4590\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 364673.4688 - mae: 443.1577 - val_loss: 362710.5938 - val_mae: 441.6317\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 363938.5938 - mae: 442.8810 - val_loss: 362085.8750 - val_mae: 443.7165\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 362919.8750 - mae: 442.7350 - val_loss: 360613.7500 - val_mae: 440.7237\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 362088.8125 - mae: 441.8742 - val_loss: 359819.1875 - val_mae: 441.1082\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 361193.0312 - mae: 441.1989 - val_loss: 358637.3750 - val_mae: 440.5626\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 360137.5938 - mae: 440.9996 - val_loss: 357539.5625 - val_mae: 439.2036\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 358980.8125 - mae: 439.7429 - val_loss: 356721.9375 - val_mae: 439.1190\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 358347.3438 - mae: 439.7635 - val_loss: 355860.7500 - val_mae: 437.4042\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 357577.6250 - mae: 438.7237 - val_loss: 355039.6562 - val_mae: 437.6752\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 356691.1250 - mae: 438.3983 - val_loss: 354509.8750 - val_mae: 438.0369\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 356113.5625 - mae: 438.1394 - val_loss: 353668.9688 - val_mae: 437.9493\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 355225.7188 - mae: 437.8551 - val_loss: 352883.7500 - val_mae: 435.9089\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354627.1250 - mae: 436.9130 - val_loss: 352284.5312 - val_mae: 435.8470\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 353711.2500 - mae: 436.5240 - val_loss: 351554.3125 - val_mae: 435.0447\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 353287.9062 - mae: 436.3812 - val_loss: 350943.9375 - val_mae: 435.1690\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 352517.9062 - mae: 435.7328 - val_loss: 350458.6562 - val_mae: 433.9419\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 351844.5625 - mae: 435.5906 - val_loss: 350007.8438 - val_mae: 435.2964\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351341.2188 - mae: 435.0347 - val_loss: 349369.3750 - val_mae: 433.5196\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 350860.9375 - mae: 434.7117 - val_loss: 348643.7188 - val_mae: 434.2327\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 350431.2500 - mae: 434.6670 - val_loss: 348416.4688 - val_mae: 434.5041\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 349662.6875 - mae: 434.6675 - val_loss: 348708.1562 - val_mae: 431.1030\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 349422.9375 - mae: 433.5463 - val_loss: 347126.0312 - val_mae: 433.0472\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348843.8750 - mae: 433.2867 - val_loss: 346556.0625 - val_mae: 432.3038\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 348099.5000 - mae: 433.3275 - val_loss: 346262.2188 - val_mae: 431.6644\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347573.3438 - mae: 432.7226 - val_loss: 345646.3438 - val_mae: 430.6003\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 347479.0312 - mae: 432.5950 - val_loss: 345937.6250 - val_mae: 429.7657\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346597.5000 - mae: 431.4445 - val_loss: 344903.5000 - val_mae: 431.5711\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 346173.6875 - mae: 431.7195 - val_loss: 344533.8438 - val_mae: 432.0326\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346150.2500 - mae: 432.0217 - val_loss: 343849.6875 - val_mae: 430.1409\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 345391.2812 - mae: 430.7052 - val_loss: 343967.6562 - val_mae: 432.4717\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345006.6250 - mae: 431.2201 - val_loss: 342823.7500 - val_mae: 430.1364\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 344426.6875 - mae: 430.9833 - val_loss: 342677.8438 - val_mae: 429.2403\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 344207.3125 - mae: 430.1083 - val_loss: 342140.6250 - val_mae: 429.2101\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 343809.2500 - mae: 430.0831 - val_loss: 341666.4062 - val_mae: 429.5988\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 343739.0312 - mae: 430.4154 - val_loss: 341408.4688 - val_mae: 428.9102\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342991.2188 - mae: 429.8331 - val_loss: 341323.6875 - val_mae: 427.8556\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342572.8125 - mae: 429.1300 - val_loss: 341085.3750 - val_mae: 430.3477\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 342456.5625 - mae: 429.2742 - val_loss: 340348.5938 - val_mae: 428.8126\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342160.9375 - mae: 429.2215 - val_loss: 340119.9688 - val_mae: 427.0948\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 341550.9375 - mae: 428.4312 - val_loss: 339702.6875 - val_mae: 427.5707\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 341651.5312 - mae: 428.4161 - val_loss: 339463.3750 - val_mae: 427.9557\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341211.0312 - mae: 428.4847 - val_loss: 339236.6875 - val_mae: 426.4460\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340783.4688 - mae: 428.2894 - val_loss: 339392.3125 - val_mae: 427.7623\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340159.5625 - mae: 427.3452 - val_loss: 339269.9375 - val_mae: 428.7353\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340368.7500 - mae: 428.0212 - val_loss: 338367.6875 - val_mae: 427.0880\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 340134.3125 - mae: 427.5536 - val_loss: 338259.6562 - val_mae: 427.3592\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339668.1562 - mae: 427.0803 - val_loss: 338019.8750 - val_mae: 427.3041\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339595.2812 - mae: 427.5460 - val_loss: 338025.7812 - val_mae: 425.0728\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339548.4062 - mae: 427.1375 - val_loss: 337481.1562 - val_mae: 425.3080\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339039.9375 - mae: 426.4252 - val_loss: 337527.8750 - val_mae: 425.5712\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 339051.2812 - mae: 426.5024 - val_loss: 337192.6250 - val_mae: 425.1896\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338883.3125 - mae: 426.5229 - val_loss: 337441.2812 - val_mae: 427.7748\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 338582.0000 - mae: 426.4538 - val_loss: 336566.7188 - val_mae: 424.8485\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338470.5938 - mae: 426.1479 - val_loss: 336342.0312 - val_mae: 425.4660\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338291.3750 - mae: 425.9297 - val_loss: 336435.7500 - val_mae: 426.0946\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 338080.4062 - mae: 425.8917 - val_loss: 336058.1250 - val_mae: 424.7978\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337975.0938 - mae: 425.7761 - val_loss: 335887.5625 - val_mae: 425.0473\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337273.7500 - mae: 425.6169 - val_loss: 335841.0938 - val_mae: 424.1932\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337546.3125 - mae: 425.5209 - val_loss: 335999.5312 - val_mae: 423.1433\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 337420.9688 - mae: 424.8793 - val_loss: 335347.4375 - val_mae: 424.6887\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337049.7500 - mae: 425.3953 - val_loss: 335217.1250 - val_mae: 424.3265\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337147.1875 - mae: 424.9693 - val_loss: 335001.5625 - val_mae: 423.8018\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336789.0938 - mae: 424.6876 - val_loss: 334752.8750 - val_mae: 423.5754\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336613.2500 - mae: 424.6484 - val_loss: 335043.7812 - val_mae: 423.7885\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 336453.0312 - mae: 424.7329 - val_loss: 334567.4375 - val_mae: 423.3924\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336350.6875 - mae: 424.5107 - val_loss: 334843.5000 - val_mae: 422.5434\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 336003.5000 - mae: 424.1754 - val_loss: 334273.9062 - val_mae: 423.7951\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335873.0312 - mae: 424.6206 - val_loss: 333957.7812 - val_mae: 422.8656\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335662.5938 - mae: 424.0113 - val_loss: 333877.6562 - val_mae: 422.6814\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335826.7812 - mae: 424.0615 - val_loss: 333715.7500 - val_mae: 422.3418\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335264.9062 - mae: 423.4880 - val_loss: 333673.4062 - val_mae: 424.1108\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 335190.6875 - mae: 424.0295 - val_loss: 333217.5625 - val_mae: 422.3228\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334771.3750 - mae: 423.5300 - val_loss: 333066.0938 - val_mae: 422.4581\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334975.5625 - mae: 423.3284 - val_loss: 333101.7188 - val_mae: 423.6179\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334632.5625 - mae: 423.4751 - val_loss: 332714.8750 - val_mae: 421.9127\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 334334.4375 - mae: 422.9498 - val_loss: 333247.5625 - val_mae: 424.1042\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 334251.6250 - mae: 423.3086 - val_loss: 332363.2188 - val_mae: 421.4736\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 333947.3125 - mae: 422.6123 - val_loss: 332491.0000 - val_mae: 422.3718\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 334179.7188 - mae: 422.7087 - val_loss: 332060.3750 - val_mae: 422.1777\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 333812.0312 - mae: 422.7712 - val_loss: 331699.1250 - val_mae: 421.7361\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 333521.9375 - mae: 422.4366 - val_loss: 331694.2500 - val_mae: 420.9198\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 333276.7812 - mae: 422.4221 - val_loss: 331735.9688 - val_mae: 419.8750\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333024.6250 - mae: 422.0329 - val_loss: 331590.6875 - val_mae: 419.9638\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333114.6562 - mae: 421.6879 - val_loss: 331018.1875 - val_mae: 420.7804\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 332741.9062 - mae: 421.8102 - val_loss: 331054.6562 - val_mae: 421.7331\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 332571.6875 - mae: 421.7175 - val_loss: 330509.2188 - val_mae: 420.0797\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332344.6562 - mae: 421.2850 - val_loss: 330336.3750 - val_mae: 419.8339\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 332020.2812 - mae: 421.1273 - val_loss: 330782.3125 - val_mae: 418.1429\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 331797.3438 - mae: 420.6241 - val_loss: 329983.4375 - val_mae: 419.3644\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 331599.7188 - mae: 420.1807 - val_loss: 329842.9375 - val_mae: 420.2722\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331365.9375 - mae: 420.6616 - val_loss: 329667.4688 - val_mae: 418.8358\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 331304.6562 - mae: 420.3353 - val_loss: 329156.9688 - val_mae: 418.9186\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 331252.4375 - mae: 420.0687 - val_loss: 329217.9688 - val_mae: 420.0674\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330854.5312 - mae: 420.2925 - val_loss: 329723.5938 - val_mae: 418.0106\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 330532.0625 - mae: 419.2106 - val_loss: 329170.5938 - val_mae: 419.5991\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 330598.6250 - mae: 419.7589 - val_loss: 328679.7188 - val_mae: 418.2134\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330211.6250 - mae: 419.0520 - val_loss: 328693.7812 - val_mae: 419.4978\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330248.0938 - mae: 419.1665 - val_loss: 329116.7812 - val_mae: 420.7564\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329982.3750 - mae: 419.1127 - val_loss: 328226.0312 - val_mae: 417.9408\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329972.3125 - mae: 418.8907 - val_loss: 327991.7812 - val_mae: 417.7013\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329791.0625 - mae: 418.5861 - val_loss: 327884.3125 - val_mae: 418.2575\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329499.5312 - mae: 418.7075 - val_loss: 328115.6250 - val_mae: 417.7719\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 329554.5312 - mae: 418.3600 - val_loss: 327903.7812 - val_mae: 418.6426\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 329483.8750 - mae: 418.3964 - val_loss: 327396.1250 - val_mae: 417.0377\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329235.9688 - mae: 418.2124 - val_loss: 327308.1562 - val_mae: 416.4860\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328984.1250 - mae: 417.7708 - val_loss: 327049.2188 - val_mae: 416.5845\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328831.3750 - mae: 417.7328 - val_loss: 327172.1250 - val_mae: 418.3690\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328459.9688 - mae: 418.0921 - val_loss: 327058.1875 - val_mae: 416.0789\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328555.2812 - mae: 417.6597 - val_loss: 326634.8438 - val_mae: 415.4152\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 328245.9062 - mae: 417.2294 - val_loss: 326353.9688 - val_mae: 416.6752\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 328036.8125 - mae: 417.4461 - val_loss: 326310.8750 - val_mae: 414.8924\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327625.6250 - mae: 416.4029 - val_loss: 326293.1250 - val_mae: 417.4743\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 327450.9688 - mae: 416.9922 - val_loss: 326258.7812 - val_mae: 417.3985\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327902.4375 - mae: 417.5192 - val_loss: 325704.5625 - val_mae: 415.4034\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 1s 5ms/step - loss: 327368.9375 - mae: 416.6835 - val_loss: 325539.8750 - val_mae: 416.0072\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 327363.2188 - mae: 416.6171 - val_loss: 325418.3125 - val_mae: 415.8971\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327014.3438 - mae: 416.0992 - val_loss: 325187.7188 - val_mae: 415.2937\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 326768.7500 - mae: 416.2668 - val_loss: 325186.6562 - val_mae: 415.8694\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 326555.7188 - mae: 416.2876 - val_loss: 325054.5625 - val_mae: 414.4423\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 326685.9688 - mae: 415.7676 - val_loss: 324733.8438 - val_mae: 414.9590\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 326565.6562 - mae: 415.9180 - val_loss: 324571.3750 - val_mae: 414.4319\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326436.9375 - mae: 415.6038 - val_loss: 324515.5312 - val_mae: 414.4478\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326020.0625 - mae: 415.2198 - val_loss: 324496.7500 - val_mae: 414.9843\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 326050.8438 - mae: 415.5041 - val_loss: 324267.0625 - val_mae: 414.5956\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326070.6250 - mae: 415.3282 - val_loss: 324205.0000 - val_mae: 414.9828\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325906.3750 - mae: 415.2684 - val_loss: 324620.5938 - val_mae: 416.4421\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325815.8750 - mae: 415.3691 - val_loss: 324051.5000 - val_mae: 413.6854\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325200.6250 - mae: 414.6656 - val_loss: 324308.9688 - val_mae: 415.4645\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325494.3750 - mae: 415.1302 - val_loss: 324619.8125 - val_mae: 412.1390\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325582.2812 - mae: 414.6975 - val_loss: 323552.9375 - val_mae: 413.0109\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325253.3438 - mae: 414.7076 - val_loss: 323533.1250 - val_mae: 413.6599\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325386.4688 - mae: 414.4614 - val_loss: 323420.4375 - val_mae: 414.5217\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325057.5625 - mae: 414.4711 - val_loss: 323573.7812 - val_mae: 414.5190\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324873.8438 - mae: 414.6639 - val_loss: 323348.2812 - val_mae: 413.5438\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324917.0625 - mae: 414.1765 - val_loss: 323457.6250 - val_mae: 414.7967\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324810.1562 - mae: 414.3039 - val_loss: 323433.3438 - val_mae: 414.7654\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324804.7500 - mae: 413.8811 - val_loss: 322928.6875 - val_mae: 413.5233\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324775.8750 - mae: 414.3065 - val_loss: 322871.6875 - val_mae: 412.7878\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324546.5000 - mae: 414.0425 - val_loss: 322962.9062 - val_mae: 414.1673\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 37888032.0000 - mae: 6000.9478 - val_loss: 36348108.0000 - val_mae: 5882.8335\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 33028792.0000 - mae: 5613.2666 - val_loss: 28974894.0000 - val_mae: 5267.6724\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 24429910.0000 - mae: 4825.5981 - val_loss: 19810490.0000 - val_mae: 4336.5259\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 15741343.0000 - mae: 3813.1560 - val_loss: 11995648.0000 - val_mae: 3277.9014\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 9141439.0000 - mae: 2772.9707 - val_loss: 6662701.5000 - val_mae: 2292.1814\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 4975240.0000 - mae: 1900.4348 - val_loss: 3583766.5000 - val_mae: 1546.3647\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2740178.5000 - mae: 1303.6909 - val_loss: 2085271.2500 - val_mae: 1104.8376\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1726801.0000 - mae: 991.1744 - val_loss: 1452316.7500 - val_mae: 904.9180\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1296747.2500 - mae: 853.2796 - val_loss: 1168505.6250 - val_mae: 809.8851\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1083486.0000 - mae: 779.6320 - val_loss: 1004372.8750 - val_mae: 752.1450\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 946578.7500 - mae: 730.5611 - val_loss: 887926.5000 - val_mae: 708.2041\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 844592.5000 - mae: 690.5233 - val_loss: 799792.6875 - val_mae: 672.5654\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 766589.1250 - mae: 657.6277 - val_loss: 731236.8125 - val_mae: 642.6631\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 706697.7500 - mae: 631.1398 - val_loss: 678939.3125 - val_mae: 618.4072\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 660207.0625 - mae: 608.5490 - val_loss: 638125.1250 - val_mae: 598.3553\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 623551.4375 - mae: 590.7269 - val_loss: 604976.1250 - val_mae: 582.4609\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593056.3125 - mae: 575.5847 - val_loss: 577221.0625 - val_mae: 567.6470\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 568061.3750 - mae: 561.9617 - val_loss: 554744.8125 - val_mae: 555.9783\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 547515.3750 - mae: 551.2397 - val_loss: 535805.6875 - val_mae: 546.4825\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 529906.7500 - mae: 541.9997 - val_loss: 520240.5000 - val_mae: 538.2307\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 515098.5000 - mae: 534.6603 - val_loss: 505865.7188 - val_mae: 528.0099\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 502162.9062 - mae: 526.0266 - val_loss: 493697.8125 - val_mae: 522.2109\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 490962.0938 - mae: 520.0027 - val_loss: 483587.6250 - val_mae: 515.7726\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 481395.0938 - mae: 514.1829 - val_loss: 474484.8750 - val_mae: 509.5117\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 473041.6250 - mae: 508.5501 - val_loss: 466332.7500 - val_mae: 505.4029\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 465028.6875 - mae: 504.3820 - val_loss: 459626.1250 - val_mae: 499.7693\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 458837.5312 - mae: 499.7120 - val_loss: 453264.0312 - val_mae: 497.1623\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 453263.5000 - mae: 496.7728 - val_loss: 447929.0938 - val_mae: 493.4831\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 447683.3438 - mae: 493.2083 - val_loss: 443034.6562 - val_mae: 491.5610\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 443173.4688 - mae: 490.7996 - val_loss: 438341.6875 - val_mae: 487.4743\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 438931.2188 - mae: 487.8976 - val_loss: 434215.5312 - val_mae: 485.0030\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 434548.4688 - mae: 484.9261 - val_loss: 430583.5000 - val_mae: 484.7272\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 430293.7812 - mae: 483.0731 - val_loss: 426227.0938 - val_mae: 479.1041\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 426671.8438 - mae: 480.0453 - val_loss: 422103.2500 - val_mae: 477.8727\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 422957.1875 - mae: 477.9611 - val_loss: 418804.2500 - val_mae: 474.8012\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 419128.0000 - mae: 475.8307 - val_loss: 415202.3438 - val_mae: 472.8127\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 415964.2812 - mae: 473.1365 - val_loss: 413592.1875 - val_mae: 474.4706\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 413622.0312 - mae: 472.7540 - val_loss: 410987.1875 - val_mae: 468.2977\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 411523.6562 - mae: 470.4078 - val_loss: 407849.7188 - val_mae: 469.5524\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 409476.6562 - mae: 469.8057 - val_loss: 405790.7188 - val_mae: 466.8297\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 407169.4688 - mae: 468.0528 - val_loss: 404172.2812 - val_mae: 465.4661\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 405166.0938 - mae: 466.5358 - val_loss: 401974.6562 - val_mae: 466.3837\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 403229.1250 - mae: 466.0905 - val_loss: 400149.3438 - val_mae: 462.5606\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 401263.5312 - mae: 464.1354 - val_loss: 398236.4688 - val_mae: 462.8272\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 399396.1875 - mae: 463.3225 - val_loss: 396156.3438 - val_mae: 461.6877\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 397823.2188 - mae: 462.4378 - val_loss: 394770.5625 - val_mae: 459.5737\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 396533.8750 - mae: 461.1168 - val_loss: 393118.0938 - val_mae: 460.2999\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 394908.8438 - mae: 460.6662 - val_loss: 391737.9062 - val_mae: 458.8139\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 393285.2188 - mae: 459.5027 - val_loss: 390499.3750 - val_mae: 457.7709\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 392232.7188 - mae: 459.1929 - val_loss: 389515.1562 - val_mae: 456.3682\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 390990.4375 - mae: 457.9447 - val_loss: 388155.9062 - val_mae: 457.0175\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 390050.5000 - mae: 458.3515 - val_loss: 387185.0625 - val_mae: 455.4161\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 389248.5625 - mae: 457.0729 - val_loss: 386050.6562 - val_mae: 455.2902\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 387796.4375 - mae: 456.2231 - val_loss: 385159.1562 - val_mae: 454.9993\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387258.4375 - mae: 455.9497 - val_loss: 384213.8750 - val_mae: 454.8002\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 385679.4062 - mae: 454.9325 - val_loss: 383058.7188 - val_mae: 454.0993\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 384873.1562 - mae: 454.8221 - val_loss: 382165.9375 - val_mae: 453.0328\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 383826.4062 - mae: 453.8082 - val_loss: 381184.3750 - val_mae: 452.8875\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 383017.1875 - mae: 453.9541 - val_loss: 380248.0000 - val_mae: 451.2607\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 382098.9375 - mae: 452.3729 - val_loss: 379603.9375 - val_mae: 452.2584\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 381202.9375 - mae: 452.7315 - val_loss: 378596.6875 - val_mae: 450.3307\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 380515.9062 - mae: 451.6015 - val_loss: 377786.6875 - val_mae: 451.4850\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 379628.8438 - mae: 451.6888 - val_loss: 376869.8125 - val_mae: 450.3958\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 378601.2500 - mae: 451.1824 - val_loss: 376535.9375 - val_mae: 448.0108\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 378005.8750 - mae: 450.4375 - val_loss: 375371.8438 - val_mae: 448.4876\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 377229.2188 - mae: 449.8265 - val_loss: 375579.6875 - val_mae: 451.4258\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 376634.0000 - mae: 449.9495 - val_loss: 374220.6250 - val_mae: 447.0253\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 376221.7188 - mae: 449.2378 - val_loss: 373537.6562 - val_mae: 448.9071\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 375173.1875 - mae: 448.8472 - val_loss: 372652.4375 - val_mae: 447.8054\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 374632.6250 - mae: 448.5377 - val_loss: 372253.0000 - val_mae: 448.4336\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 373793.4375 - mae: 448.6641 - val_loss: 371389.8750 - val_mae: 446.3208\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 373302.0000 - mae: 447.5011 - val_loss: 370625.8750 - val_mae: 446.0536\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 372600.5312 - mae: 447.4158 - val_loss: 369758.1250 - val_mae: 445.8083\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 371923.5938 - mae: 446.9276 - val_loss: 369526.0312 - val_mae: 444.8596\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 371080.5312 - mae: 446.5968 - val_loss: 368531.3750 - val_mae: 444.4782\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 370328.6562 - mae: 446.0104 - val_loss: 367775.9375 - val_mae: 443.5896\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 369752.7500 - mae: 446.1249 - val_loss: 367279.4688 - val_mae: 444.2408\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 368912.7812 - mae: 445.2587 - val_loss: 366633.2188 - val_mae: 444.3983\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 368169.8438 - mae: 444.8403 - val_loss: 365883.2812 - val_mae: 442.4097\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 367632.9375 - mae: 444.1461 - val_loss: 364990.3125 - val_mae: 442.3670\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 366885.7500 - mae: 444.2242 - val_loss: 364607.0312 - val_mae: 441.7127\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 366245.8125 - mae: 443.2975 - val_loss: 363956.7500 - val_mae: 441.2272\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365622.9375 - mae: 443.1816 - val_loss: 363102.4375 - val_mae: 441.9687\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 364888.4062 - mae: 442.1475 - val_loss: 362659.7188 - val_mae: 441.9882\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 364461.1875 - mae: 442.2831 - val_loss: 361910.4375 - val_mae: 440.3990\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 363805.7812 - mae: 441.4908 - val_loss: 361632.4688 - val_mae: 441.4135\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 363149.4062 - mae: 441.2299 - val_loss: 360987.8438 - val_mae: 439.0387\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 363104.1250 - mae: 440.5910 - val_loss: 360386.3750 - val_mae: 439.5750\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 362080.0312 - mae: 440.3037 - val_loss: 359692.0625 - val_mae: 439.2274\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 361710.1875 - mae: 440.1780 - val_loss: 358992.1875 - val_mae: 439.1425\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 360833.5625 - mae: 439.7116 - val_loss: 358764.3125 - val_mae: 437.5329\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 360386.5938 - mae: 439.2003 - val_loss: 358457.6562 - val_mae: 437.6472\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 5ms/step - loss: 359974.8438 - mae: 438.8148 - val_loss: 357343.8125 - val_mae: 437.3414\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 359124.1562 - mae: 438.4223 - val_loss: 356514.5938 - val_mae: 436.6442\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 358163.3438 - mae: 437.2409 - val_loss: 356020.9375 - val_mae: 437.7065\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 357531.7812 - mae: 437.4841 - val_loss: 354936.3125 - val_mae: 436.2159\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 356684.0938 - mae: 437.2815 - val_loss: 354228.6562 - val_mae: 434.6341\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 356232.9375 - mae: 436.2688 - val_loss: 353708.5000 - val_mae: 436.4306\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 355283.1562 - mae: 436.3621 - val_loss: 352898.1250 - val_mae: 433.3436\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 354328.9375 - mae: 434.9200 - val_loss: 352219.5312 - val_mae: 435.6211\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 353876.5312 - mae: 435.0785 - val_loss: 351055.6250 - val_mae: 433.8327\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 352798.0000 - mae: 434.6213 - val_loss: 350448.3125 - val_mae: 433.5245\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 351958.7812 - mae: 433.8369 - val_loss: 349899.1562 - val_mae: 431.9064\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 351208.1250 - mae: 433.3911 - val_loss: 349124.2812 - val_mae: 432.1447\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 350689.8125 - mae: 433.1183 - val_loss: 348393.6250 - val_mae: 430.2647\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 349880.7812 - mae: 432.2225 - val_loss: 347398.5000 - val_mae: 431.9140\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348893.3125 - mae: 432.0496 - val_loss: 346742.8438 - val_mae: 430.8727\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348398.9062 - mae: 431.5189 - val_loss: 345890.0625 - val_mae: 429.2408\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 347848.9062 - mae: 431.1997 - val_loss: 345378.2812 - val_mae: 428.6982\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 347179.3438 - mae: 430.6456 - val_loss: 344439.9062 - val_mae: 429.1082\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 346379.2188 - mae: 429.7566 - val_loss: 343963.3125 - val_mae: 428.1097\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 345633.0312 - mae: 429.6034 - val_loss: 343426.3750 - val_mae: 428.0341\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 345141.1562 - mae: 429.0175 - val_loss: 342946.2812 - val_mae: 426.1005\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 344717.2188 - mae: 428.2431 - val_loss: 342053.2812 - val_mae: 426.2984\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 344126.8438 - mae: 428.1995 - val_loss: 341723.9375 - val_mae: 427.3960\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 343469.4062 - mae: 428.0127 - val_loss: 341414.2188 - val_mae: 425.7721\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 343007.4375 - mae: 426.9852 - val_loss: 341260.8438 - val_mae: 427.5424\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342557.0000 - mae: 426.9272 - val_loss: 340441.0312 - val_mae: 425.0680\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342562.6562 - mae: 426.5573 - val_loss: 340423.2188 - val_mae: 424.3978\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342145.3438 - mae: 426.2351 - val_loss: 339560.2500 - val_mae: 425.1953\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 341723.7500 - mae: 425.8604 - val_loss: 339218.6250 - val_mae: 424.4908\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 341379.8125 - mae: 425.7671 - val_loss: 338744.0625 - val_mae: 424.5467\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340567.0938 - mae: 425.4669 - val_loss: 338323.1562 - val_mae: 423.8530\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340550.6562 - mae: 425.1042 - val_loss: 338125.5000 - val_mae: 423.5760\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340152.7812 - mae: 424.9122 - val_loss: 337788.4375 - val_mae: 424.0352\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339891.8438 - mae: 424.4413 - val_loss: 338000.9688 - val_mae: 425.4127\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339372.0312 - mae: 424.3356 - val_loss: 337440.5625 - val_mae: 424.6363\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339233.7812 - mae: 424.7965 - val_loss: 336925.8125 - val_mae: 423.2292\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339072.5625 - mae: 424.1757 - val_loss: 336942.3750 - val_mae: 421.2278\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 338535.9062 - mae: 423.4868 - val_loss: 336677.2812 - val_mae: 422.1675\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 338384.8438 - mae: 423.8063 - val_loss: 336037.1562 - val_mae: 422.1512\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337778.6562 - mae: 423.2264 - val_loss: 335999.7500 - val_mae: 421.4949\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337766.7188 - mae: 422.8564 - val_loss: 335938.0000 - val_mae: 423.3137\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337543.6562 - mae: 423.0298 - val_loss: 335297.5312 - val_mae: 421.5152\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337284.6562 - mae: 423.1895 - val_loss: 335128.7188 - val_mae: 421.3835\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337028.4062 - mae: 422.5691 - val_loss: 334686.2500 - val_mae: 421.0235\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336993.4688 - mae: 422.6624 - val_loss: 334590.2812 - val_mae: 420.9610\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336215.1250 - mae: 422.0358 - val_loss: 334654.6562 - val_mae: 420.8832\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336071.7812 - mae: 421.9085 - val_loss: 334271.3750 - val_mae: 419.6308\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335809.2500 - mae: 421.8953 - val_loss: 333816.0000 - val_mae: 420.9858\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335745.4688 - mae: 421.6594 - val_loss: 333727.0625 - val_mae: 421.2629\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 335933.4688 - mae: 422.0050 - val_loss: 333151.9688 - val_mae: 420.7833\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 335121.6875 - mae: 421.4627 - val_loss: 333400.7188 - val_mae: 421.2699\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335054.8750 - mae: 421.0975 - val_loss: 333072.8750 - val_mae: 421.7211\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 334590.2812 - mae: 421.3412 - val_loss: 332915.0625 - val_mae: 420.6887\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 334563.3750 - mae: 421.1854 - val_loss: 332402.3750 - val_mae: 419.3268\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 334285.9062 - mae: 420.8907 - val_loss: 332443.6250 - val_mae: 420.3766\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 334243.3125 - mae: 420.6856 - val_loss: 332073.1562 - val_mae: 419.2610\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 333941.6250 - mae: 420.8840 - val_loss: 331705.0000 - val_mae: 419.1764\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333493.2500 - mae: 420.1947 - val_loss: 332164.1875 - val_mae: 421.3976\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 333575.6875 - mae: 420.5328 - val_loss: 331451.0625 - val_mae: 418.3355\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333432.9375 - mae: 420.1198 - val_loss: 331111.7500 - val_mae: 418.5526\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333535.3125 - mae: 420.1629 - val_loss: 330842.6875 - val_mae: 418.7977\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333029.1562 - mae: 419.8498 - val_loss: 330671.5625 - val_mae: 418.6956\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332772.5312 - mae: 419.4502 - val_loss: 330644.3125 - val_mae: 417.6947\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332538.8750 - mae: 419.3903 - val_loss: 330206.3125 - val_mae: 418.2901\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332252.8125 - mae: 419.5539 - val_loss: 330206.2188 - val_mae: 418.8694\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 332278.0625 - mae: 419.4777 - val_loss: 330042.2812 - val_mae: 417.7365\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331971.6562 - mae: 419.1142 - val_loss: 329887.1875 - val_mae: 417.9816\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331742.7188 - mae: 418.8424 - val_loss: 329906.1250 - val_mae: 417.6010\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331720.1250 - mae: 419.0231 - val_loss: 329368.2500 - val_mae: 417.6972\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 331349.9062 - mae: 419.0152 - val_loss: 329363.1250 - val_mae: 418.0329\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331110.7812 - mae: 418.7902 - val_loss: 329971.0000 - val_mae: 415.6003\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331145.1875 - mae: 418.2249 - val_loss: 329038.8750 - val_mae: 418.4450\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330766.1562 - mae: 418.3226 - val_loss: 328938.4375 - val_mae: 418.5785\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330781.1250 - mae: 418.4400 - val_loss: 328570.4375 - val_mae: 416.1467\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330648.1875 - mae: 418.3910 - val_loss: 328306.4688 - val_mae: 416.2921\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330176.5625 - mae: 417.7872 - val_loss: 328406.1875 - val_mae: 416.9231\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330150.7812 - mae: 417.8119 - val_loss: 328466.8750 - val_mae: 416.8117\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 330156.7812 - mae: 418.3330 - val_loss: 327798.1875 - val_mae: 416.7317\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329918.3750 - mae: 417.8618 - val_loss: 327992.6562 - val_mae: 416.5706\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329906.2188 - mae: 417.8212 - val_loss: 327682.7812 - val_mae: 416.3088\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329420.6875 - mae: 417.7290 - val_loss: 327363.3750 - val_mae: 416.4966\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 31174544.0000 - mae: 5400.6509 - val_loss: 18135196.0000 - val_mae: 4111.1392\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 8050036.0000 - mae: 2465.7190 - val_loss: 2279445.5000 - val_mae: 1155.3157\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 1314804.0000 - mae: 815.8202 - val_loss: 901213.2500 - val_mae: 660.5038\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 795988.4375 - mae: 618.0654 - val_loss: 722304.1250 - val_mae: 587.7311\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 691079.6875 - mae: 573.1334 - val_loss: 658259.6875 - val_mae: 559.0479\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 641457.8125 - mae: 551.6274 - val_loss: 619992.9375 - val_mae: 541.9444\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610365.3750 - mae: 539.3084 - val_loss: 593851.0625 - val_mae: 532.4402\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588255.6250 - mae: 530.5079 - val_loss: 574054.4375 - val_mae: 524.8431\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 569175.9375 - mae: 523.2869 - val_loss: 555832.9375 - val_mae: 516.9450\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552568.6875 - mae: 516.4147 - val_loss: 541030.8750 - val_mae: 512.4537\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538000.2500 - mae: 511.4240 - val_loss: 526902.8125 - val_mae: 505.7225\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 525060.6250 - mae: 504.8138 - val_loss: 514915.3438 - val_mae: 502.4359\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 513482.1250 - mae: 499.9088 - val_loss: 504594.5312 - val_mae: 496.7889\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 503481.9375 - mae: 496.5468 - val_loss: 496588.5312 - val_mae: 495.6420\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 495796.5625 - mae: 493.7484 - val_loss: 488860.6875 - val_mae: 488.6479\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 488488.8438 - mae: 490.4607 - val_loss: 480930.8438 - val_mae: 486.1736\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 481640.3438 - mae: 488.5474 - val_loss: 474614.6875 - val_mae: 485.8663\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 475168.0312 - mae: 485.4161 - val_loss: 467958.1250 - val_mae: 483.7581\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 468864.7812 - mae: 483.7584 - val_loss: 463195.1562 - val_mae: 483.0731\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 463248.7188 - mae: 481.3610 - val_loss: 456618.4062 - val_mae: 477.7010\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 456320.9062 - mae: 479.5705 - val_loss: 455099.5625 - val_mae: 475.6086\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 452149.3438 - mae: 477.5107 - val_loss: 445369.8750 - val_mae: 475.5197\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 445816.0312 - mae: 474.8997 - val_loss: 439769.7500 - val_mae: 474.3793\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 440439.6250 - mae: 473.5142 - val_loss: 433332.4688 - val_mae: 469.3971\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 433835.1875 - mae: 470.1386 - val_loss: 427766.0312 - val_mae: 469.3686\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 428094.4062 - mae: 468.6378 - val_loss: 422447.3750 - val_mae: 466.6796\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 421916.6875 - mae: 466.5682 - val_loss: 414481.0312 - val_mae: 463.5002\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 414395.6250 - mae: 462.7137 - val_loss: 408107.9688 - val_mae: 459.4236\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 407898.3750 - mae: 460.4757 - val_loss: 401607.0312 - val_mae: 455.8291\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 401853.8125 - mae: 457.1194 - val_loss: 395621.3125 - val_mae: 453.9261\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 396864.9062 - mae: 455.0233 - val_loss: 390847.6562 - val_mae: 451.6783\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 392447.7812 - mae: 453.2371 - val_loss: 387413.3438 - val_mae: 450.9043\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 388854.6250 - mae: 451.8885 - val_loss: 385423.3750 - val_mae: 453.8304\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 385415.2500 - mae: 450.2567 - val_loss: 380158.9375 - val_mae: 447.1986\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 381561.7188 - mae: 447.9419 - val_loss: 377497.5938 - val_mae: 447.6096\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 379032.5625 - mae: 446.8213 - val_loss: 374802.7812 - val_mae: 444.9763\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 376881.9062 - mae: 445.6042 - val_loss: 372075.6250 - val_mae: 443.0771\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 373854.2812 - mae: 444.3802 - val_loss: 370239.0312 - val_mae: 440.9581\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 371298.4688 - mae: 442.3572 - val_loss: 366554.1875 - val_mae: 439.6616\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 368702.0312 - mae: 441.1509 - val_loss: 363814.8750 - val_mae: 438.5274\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 365683.8125 - mae: 439.3934 - val_loss: 362428.1562 - val_mae: 439.7760\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 363703.9062 - mae: 438.5082 - val_loss: 360149.2812 - val_mae: 437.8748\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 361757.0938 - mae: 437.2336 - val_loss: 357866.5312 - val_mae: 434.1304\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 359615.0938 - mae: 436.0192 - val_loss: 355662.4688 - val_mae: 433.7738\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 357157.8438 - mae: 434.6393 - val_loss: 354571.8125 - val_mae: 430.7877\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 355735.6562 - mae: 433.6380 - val_loss: 351722.7812 - val_mae: 431.1364\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 353580.4375 - mae: 432.1763 - val_loss: 350527.6562 - val_mae: 428.7336\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 352130.6875 - mae: 430.7589 - val_loss: 350622.1250 - val_mae: 433.2834\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 350960.9688 - mae: 430.2994 - val_loss: 347065.0312 - val_mae: 427.3355\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 348613.5625 - mae: 429.0742 - val_loss: 347097.8750 - val_mae: 426.4116\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 347566.4062 - mae: 428.5410 - val_loss: 343958.1875 - val_mae: 426.3142\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 345908.4688 - mae: 427.2032 - val_loss: 342975.1562 - val_mae: 424.8737\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 344743.0000 - mae: 426.2697 - val_loss: 341356.9688 - val_mae: 426.4566\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 343259.9062 - mae: 425.8153 - val_loss: 340387.9062 - val_mae: 424.8698\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 342261.5625 - mae: 424.9173 - val_loss: 338869.7812 - val_mae: 423.7361\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 341214.8125 - mae: 424.6205 - val_loss: 337662.9688 - val_mae: 423.3528\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339778.4375 - mae: 423.9314 - val_loss: 337396.1250 - val_mae: 423.4302\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 339179.4062 - mae: 423.6455 - val_loss: 336565.5938 - val_mae: 420.4057\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 338098.3438 - mae: 422.4433 - val_loss: 335427.0625 - val_mae: 422.2072\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 337264.4688 - mae: 422.1150 - val_loss: 334630.6250 - val_mae: 418.7921\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 336577.0625 - mae: 421.1180 - val_loss: 333409.3750 - val_mae: 420.1248\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 335725.7812 - mae: 421.1634 - val_loss: 331881.8750 - val_mae: 418.9211\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 334674.1250 - mae: 420.7530 - val_loss: 331863.9375 - val_mae: 419.4016\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333732.1875 - mae: 420.1938 - val_loss: 330739.1875 - val_mae: 416.7394\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 333290.5000 - mae: 419.5531 - val_loss: 331255.5938 - val_mae: 421.1717\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 332555.8125 - mae: 419.3993 - val_loss: 329353.2812 - val_mae: 417.8747\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331495.0000 - mae: 419.1402 - val_loss: 328820.6875 - val_mae: 417.4669\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 331170.0312 - mae: 418.5074 - val_loss: 328295.3438 - val_mae: 416.1963\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330244.2500 - mae: 418.1034 - val_loss: 327373.4375 - val_mae: 415.5290\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329911.6250 - mae: 417.7097 - val_loss: 326858.6250 - val_mae: 416.2209\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329166.0625 - mae: 417.2403 - val_loss: 326450.2812 - val_mae: 417.7429\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328692.5000 - mae: 416.9644 - val_loss: 325460.5312 - val_mae: 415.7757\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328014.1250 - mae: 416.5838 - val_loss: 325632.6250 - val_mae: 414.7352\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328084.8750 - mae: 416.4487 - val_loss: 324384.7188 - val_mae: 415.4283\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 327188.7188 - mae: 416.2381 - val_loss: 324355.6875 - val_mae: 414.6360\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326623.9688 - mae: 415.5559 - val_loss: 323755.7188 - val_mae: 414.0036\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326830.0938 - mae: 415.4684 - val_loss: 323314.8125 - val_mae: 412.5679\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326042.0000 - mae: 415.1414 - val_loss: 322706.0938 - val_mae: 413.2489\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325533.5625 - mae: 415.0679 - val_loss: 322644.9688 - val_mae: 411.4848\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324795.3750 - mae: 414.1528 - val_loss: 322796.7188 - val_mae: 414.5602\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324723.0938 - mae: 414.4427 - val_loss: 322371.1250 - val_mae: 415.0846\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324741.2812 - mae: 414.2641 - val_loss: 321259.9688 - val_mae: 413.1303\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 323822.2188 - mae: 413.5808 - val_loss: 321327.4375 - val_mae: 412.6520\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 323817.9688 - mae: 413.7317 - val_loss: 320320.5938 - val_mae: 411.7827\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 323225.0312 - mae: 413.7189 - val_loss: 319983.8438 - val_mae: 411.3970\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 322906.6250 - mae: 413.1932 - val_loss: 320584.9062 - val_mae: 414.5065\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 322572.4688 - mae: 413.1835 - val_loss: 319360.0625 - val_mae: 411.2413\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 322072.5938 - mae: 412.5204 - val_loss: 320085.0000 - val_mae: 412.0599\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 321663.7812 - mae: 412.6329 - val_loss: 319892.2188 - val_mae: 413.1096\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 321434.8750 - mae: 412.9219 - val_loss: 319055.6562 - val_mae: 412.4183\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 321097.6562 - mae: 411.7983 - val_loss: 318772.6562 - val_mae: 409.4124\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 320522.9375 - mae: 411.7695 - val_loss: 319235.1250 - val_mae: 409.9169\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 320534.0312 - mae: 411.7263 - val_loss: 318025.4688 - val_mae: 410.9305\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 320006.3750 - mae: 411.8813 - val_loss: 318204.1875 - val_mae: 408.3564\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 320046.5312 - mae: 411.8226 - val_loss: 318412.5000 - val_mae: 408.0190\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 319519.2188 - mae: 410.6003 - val_loss: 317165.8750 - val_mae: 411.1592\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 319697.7812 - mae: 411.4646 - val_loss: 316478.7188 - val_mae: 409.0576\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 318906.3125 - mae: 410.5130 - val_loss: 317348.7812 - val_mae: 408.5519\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 319371.5625 - mae: 411.0335 - val_loss: 315968.7500 - val_mae: 408.5349\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 319065.1250 - mae: 410.1905 - val_loss: 316240.0312 - val_mae: 411.1873\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 318319.9375 - mae: 410.5619 - val_loss: 315419.7188 - val_mae: 407.2594\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 318217.7812 - mae: 409.8041 - val_loss: 315200.2500 - val_mae: 408.7723\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 318077.0312 - mae: 410.4450 - val_loss: 315680.5000 - val_mae: 407.8894\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 317972.3750 - mae: 409.9099 - val_loss: 314665.9062 - val_mae: 407.7710\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 317586.3125 - mae: 409.6411 - val_loss: 314877.2500 - val_mae: 407.4414\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 317304.8438 - mae: 409.3715 - val_loss: 314551.6875 - val_mae: 408.4351\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 316977.9062 - mae: 409.0344 - val_loss: 315622.4688 - val_mae: 411.3262\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 317483.8438 - mae: 409.6800 - val_loss: 314637.6875 - val_mae: 406.5075\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 316890.3438 - mae: 409.3242 - val_loss: 314260.0000 - val_mae: 408.7128\n",
      "Epoch 110/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 316927.6250 - mae: 409.3825 - val_loss: 315965.4062 - val_mae: 405.0493\n",
      "Epoch 111/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 316794.6875 - mae: 408.8883 - val_loss: 313687.8750 - val_mae: 407.3024\n",
      "Epoch 112/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 316760.4688 - mae: 408.9670 - val_loss: 313973.6562 - val_mae: 408.6901\n",
      "Epoch 113/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 316061.6562 - mae: 408.2592 - val_loss: 313578.3438 - val_mae: 406.7271\n",
      "Epoch 114/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315866.0625 - mae: 408.3031 - val_loss: 313281.5938 - val_mae: 407.3694\n",
      "Epoch 115/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315289.5938 - mae: 408.0828 - val_loss: 313695.7812 - val_mae: 408.3190\n",
      "Epoch 116/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315915.5625 - mae: 408.4563 - val_loss: 313632.7812 - val_mae: 408.9348\n",
      "Epoch 117/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315676.8750 - mae: 408.0208 - val_loss: 313031.1250 - val_mae: 407.9972\n",
      "Epoch 118/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315365.9375 - mae: 407.8599 - val_loss: 312744.5938 - val_mae: 405.6611\n",
      "Epoch 119/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315076.1562 - mae: 407.7982 - val_loss: 312679.5938 - val_mae: 407.6968\n",
      "Epoch 120/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315133.9688 - mae: 407.9587 - val_loss: 312549.7812 - val_mae: 405.6561\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 28505764.0000 - mae: 5117.2969 - val_loss: 12304709.0000 - val_mae: 3329.3059\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4409423.5000 - mae: 1627.3752 - val_loss: 1363922.1250 - val_mae: 743.3038\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1149256.8750 - mae: 674.6474 - val_loss: 1033426.8125 - val_mae: 635.0373\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 988025.3750 - mae: 620.0388 - val_loss: 942537.9375 - val_mae: 602.3447\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 914001.8125 - mae: 593.4570 - val_loss: 881028.5625 - val_mae: 581.8779\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 860505.4375 - mae: 573.2241 - val_loss: 832838.8750 - val_mae: 561.4579\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 818762.6875 - mae: 555.5551 - val_loss: 797409.8750 - val_mae: 547.7061\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 788265.2500 - mae: 542.6713 - val_loss: 775188.6250 - val_mae: 537.3293\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 766165.1875 - mae: 532.0952 - val_loss: 752431.6250 - val_mae: 526.3091\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 748325.2500 - mae: 523.2511 - val_loss: 738300.8125 - val_mae: 520.7314\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 734680.5000 - mae: 516.0967 - val_loss: 723812.5000 - val_mae: 510.8150\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 722391.1875 - mae: 509.3728 - val_loss: 713878.7500 - val_mae: 505.0431\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 713126.5000 - mae: 504.1418 - val_loss: 705126.9375 - val_mae: 500.2296\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 705077.3750 - mae: 499.8948 - val_loss: 698814.2500 - val_mae: 499.7491\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 698021.2500 - mae: 495.3596 - val_loss: 690730.3125 - val_mae: 491.8508\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 691384.6875 - mae: 491.1813 - val_loss: 684930.1250 - val_mae: 490.3041\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 686080.3125 - mae: 488.6306 - val_loss: 679770.4375 - val_mae: 483.1693\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 681908.5000 - mae: 485.6682 - val_loss: 675243.0000 - val_mae: 483.4567\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 677632.1875 - mae: 483.7390 - val_loss: 672650.5000 - val_mae: 480.6790\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 674305.3750 - mae: 481.6590 - val_loss: 668751.8750 - val_mae: 479.0980\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 671011.8750 - mae: 480.3440 - val_loss: 666244.6250 - val_mae: 476.8676\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 667891.2500 - mae: 478.5950 - val_loss: 664811.0625 - val_mae: 476.9854\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 666551.5000 - mae: 477.7444 - val_loss: 660808.3125 - val_mae: 474.0751\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 664426.8125 - mae: 476.5942 - val_loss: 659134.7500 - val_mae: 472.3138\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 661860.3125 - mae: 474.7915 - val_loss: 657702.2500 - val_mae: 473.9062\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 659638.1875 - mae: 473.6658 - val_loss: 656524.5000 - val_mae: 473.4699\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 657849.2500 - mae: 472.3936 - val_loss: 655859.0625 - val_mae: 476.1517\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 656010.0625 - mae: 472.1301 - val_loss: 651458.5625 - val_mae: 469.9454\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 653770.1250 - mae: 469.8809 - val_loss: 649052.0000 - val_mae: 468.8419\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 651496.3750 - mae: 468.4300 - val_loss: 646455.6875 - val_mae: 467.3250\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 648984.0625 - mae: 466.8883 - val_loss: 643935.1250 - val_mae: 463.9771\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 646444.0000 - mae: 465.3592 - val_loss: 642898.9375 - val_mae: 463.1494\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 644593.5625 - mae: 464.2942 - val_loss: 642050.3125 - val_mae: 461.0373\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 643228.5000 - mae: 462.9605 - val_loss: 640035.4375 - val_mae: 461.3982\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 641618.8125 - mae: 461.8742 - val_loss: 638419.3125 - val_mae: 460.8405\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 640158.1250 - mae: 461.2627 - val_loss: 636388.4375 - val_mae: 460.0888\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 638458.3125 - mae: 460.0904 - val_loss: 634275.6250 - val_mae: 458.6780\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 636711.7500 - mae: 459.2534 - val_loss: 631773.0625 - val_mae: 455.9587\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 634550.5000 - mae: 457.7870 - val_loss: 630281.3750 - val_mae: 457.2254\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 632008.9375 - mae: 456.5994 - val_loss: 627065.9375 - val_mae: 453.6294\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 630370.9375 - mae: 455.3835 - val_loss: 624988.3125 - val_mae: 453.2068\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 627472.0625 - mae: 454.1219 - val_loss: 624261.8125 - val_mae: 451.4237\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 626595.3125 - mae: 453.5094 - val_loss: 621223.2500 - val_mae: 452.7238\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 624602.1875 - mae: 453.0202 - val_loss: 619761.4375 - val_mae: 449.0676\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 622524.1875 - mae: 451.3595 - val_loss: 619277.6875 - val_mae: 450.7186\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 622175.8750 - mae: 451.3241 - val_loss: 617196.6250 - val_mae: 449.0925\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 620786.8750 - mae: 450.7132 - val_loss: 615626.8125 - val_mae: 449.2407\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 618634.0625 - mae: 450.1360 - val_loss: 614837.9375 - val_mae: 448.7974\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 605934.6250 - mae: 449.1584 - val_loss: 585586.0000 - val_mae: 451.3947\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 561642.7500 - mae: 448.3504 - val_loss: 534263.4375 - val_mae: 445.6499\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 517603.0938 - mae: 446.1310 - val_loss: 494619.5312 - val_mae: 441.9559\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 480344.5000 - mae: 443.3891 - val_loss: 460050.1875 - val_mae: 440.7797\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 447884.5625 - mae: 441.6999 - val_loss: 431369.5000 - val_mae: 437.3197\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 420105.6875 - mae: 438.9736 - val_loss: 406190.3438 - val_mae: 434.0069\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 396366.6562 - mae: 435.4251 - val_loss: 383106.1250 - val_mae: 431.2377\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 379395.1250 - mae: 432.7190 - val_loss: 369063.2188 - val_mae: 429.7439\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 367380.1875 - mae: 429.6443 - val_loss: 359239.8750 - val_mae: 426.9330\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 359577.8438 - mae: 427.4662 - val_loss: 352277.3750 - val_mae: 423.4861\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 353659.6250 - mae: 424.5673 - val_loss: 348998.2188 - val_mae: 420.7279\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 351132.9688 - mae: 422.1960 - val_loss: 345432.9062 - val_mae: 419.8646\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 347045.1875 - mae: 420.5529 - val_loss: 344422.5000 - val_mae: 419.1765\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 346154.6562 - mae: 419.3519 - val_loss: 341509.2500 - val_mae: 416.3239\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 344131.0625 - mae: 418.4023 - val_loss: 340216.5625 - val_mae: 415.6088\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 342917.0938 - mae: 417.5046 - val_loss: 337965.3125 - val_mae: 413.9217\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 340514.7500 - mae: 416.7907 - val_loss: 335878.4062 - val_mae: 413.9258\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 339181.1250 - mae: 416.0907 - val_loss: 334492.6250 - val_mae: 413.6163\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 337702.1562 - mae: 415.2209 - val_loss: 334101.4062 - val_mae: 415.7148\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 336252.1250 - mae: 414.7925 - val_loss: 332300.9375 - val_mae: 413.1967\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 334171.4688 - mae: 413.8487 - val_loss: 330555.7812 - val_mae: 412.4077\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 333365.3750 - mae: 413.8963 - val_loss: 329390.7812 - val_mae: 411.9311\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 332638.5938 - mae: 413.4365 - val_loss: 327355.9688 - val_mae: 410.9395\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 330992.1250 - mae: 412.8871 - val_loss: 327883.7812 - val_mae: 413.7639\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 329615.4375 - mae: 412.6922 - val_loss: 326737.7188 - val_mae: 407.9807\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328361.6562 - mae: 411.5239 - val_loss: 325196.6875 - val_mae: 409.5686\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 328210.6250 - mae: 411.4051 - val_loss: 324247.9062 - val_mae: 411.7038\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326990.3438 - mae: 411.3498 - val_loss: 324931.4062 - val_mae: 407.0266\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 326325.4688 - mae: 410.5792 - val_loss: 323005.6875 - val_mae: 406.6277\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 325167.0000 - mae: 410.4626 - val_loss: 321641.2812 - val_mae: 407.1884\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324359.0312 - mae: 409.8475 - val_loss: 321127.8125 - val_mae: 408.6494\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 324206.8125 - mae: 410.3715 - val_loss: 319747.6250 - val_mae: 406.7574\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 322863.8438 - mae: 409.2990 - val_loss: 320359.5938 - val_mae: 409.2596\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 322275.5000 - mae: 409.3333 - val_loss: 318802.0312 - val_mae: 406.9831\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 321931.7500 - mae: 408.7459 - val_loss: 317358.9375 - val_mae: 406.7164\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 321335.0938 - mae: 408.8848 - val_loss: 318117.2188 - val_mae: 409.3364\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 320378.2188 - mae: 408.8506 - val_loss: 317311.5000 - val_mae: 406.4586\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 319983.0625 - mae: 408.0449 - val_loss: 316357.8750 - val_mae: 406.0788\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 319576.9375 - mae: 408.3440 - val_loss: 316274.5312 - val_mae: 406.3268\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 319075.1562 - mae: 407.9395 - val_loss: 315070.1875 - val_mae: 406.0769\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 318667.9062 - mae: 407.8574 - val_loss: 315060.3438 - val_mae: 407.2119\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 317885.6875 - mae: 407.4069 - val_loss: 315851.5938 - val_mae: 407.2618\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 318167.9062 - mae: 407.3561 - val_loss: 316381.1562 - val_mae: 409.3343\n",
      "Epoch 92/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 317537.9062 - mae: 407.7169 - val_loss: 315660.8125 - val_mae: 402.8586\n",
      "Epoch 93/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 316846.5938 - mae: 406.2919 - val_loss: 315545.1562 - val_mae: 410.5184\n",
      "Epoch 94/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 316502.1562 - mae: 406.7836 - val_loss: 313682.5625 - val_mae: 405.1089\n",
      "Epoch 95/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 316750.6562 - mae: 406.8204 - val_loss: 312665.6250 - val_mae: 403.1007\n",
      "Epoch 96/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315337.1562 - mae: 406.1935 - val_loss: 314297.6250 - val_mae: 401.7543\n",
      "Epoch 97/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315975.2188 - mae: 405.4889 - val_loss: 311745.4688 - val_mae: 403.3719\n",
      "Epoch 98/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315640.3125 - mae: 406.3119 - val_loss: 311893.5000 - val_mae: 402.9092\n",
      "Epoch 99/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315296.0625 - mae: 405.4323 - val_loss: 313098.0625 - val_mae: 405.0948\n",
      "Epoch 100/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 315033.3438 - mae: 405.9622 - val_loss: 311100.0625 - val_mae: 404.3598\n",
      "Epoch 101/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 314762.7188 - mae: 405.6827 - val_loss: 311890.5000 - val_mae: 401.2946\n",
      "Epoch 102/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 313918.9375 - mae: 405.1349 - val_loss: 310921.7188 - val_mae: 403.5144\n",
      "Epoch 103/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 314048.5938 - mae: 405.3145 - val_loss: 311094.2812 - val_mae: 403.6987\n",
      "Epoch 104/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 313702.1562 - mae: 404.3968 - val_loss: 310902.6562 - val_mae: 405.3474\n",
      "Epoch 105/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 313979.5312 - mae: 405.0428 - val_loss: 310522.1875 - val_mae: 400.9796\n",
      "Epoch 106/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 313354.3125 - mae: 404.5239 - val_loss: 310572.5312 - val_mae: 402.3270\n",
      "Epoch 107/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 312935.4062 - mae: 404.5789 - val_loss: 310814.7500 - val_mae: 404.7553\n",
      "Epoch 108/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 312486.9688 - mae: 404.2897 - val_loss: 309759.9375 - val_mae: 401.1789\n",
      "Epoch 109/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 312903.0938 - mae: 404.4821 - val_loss: 309258.5938 - val_mae: 403.4308\n",
      "Epoch 110/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 312747.3750 - mae: 404.1970 - val_loss: 310009.8125 - val_mae: 401.3286\n",
      "Epoch 111/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 312676.5312 - mae: 404.0421 - val_loss: 308929.8125 - val_mae: 401.6692\n",
      "Epoch 112/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 312103.7812 - mae: 403.8217 - val_loss: 310737.6875 - val_mae: 402.0581\n",
      "Epoch 113/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 312181.9688 - mae: 403.8124 - val_loss: 308504.0312 - val_mae: 400.8016\n",
      "Epoch 114/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 311526.5938 - mae: 403.4465 - val_loss: 310844.3125 - val_mae: 405.8831\n",
      "Epoch 115/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 312044.6250 - mae: 404.3343 - val_loss: 307844.7500 - val_mae: 400.4192\n",
      "Epoch 116/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 311500.1562 - mae: 403.6345 - val_loss: 308782.4375 - val_mae: 401.6263\n",
      "Epoch 117/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 311612.7812 - mae: 403.5295 - val_loss: 308268.3125 - val_mae: 401.5487\n",
      "Epoch 118/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 311405.4375 - mae: 403.7956 - val_loss: 307621.3438 - val_mae: 400.8286\n",
      "Epoch 119/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310923.7500 - mae: 402.9994 - val_loss: 308954.2500 - val_mae: 404.2219\n",
      "Epoch 120/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310880.5312 - mae: 403.0983 - val_loss: 309653.3750 - val_mae: 404.5654\n",
      "Epoch 121/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 311276.6562 - mae: 403.6700 - val_loss: 307628.8438 - val_mae: 400.5103\n",
      "Epoch 122/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310872.9062 - mae: 403.4269 - val_loss: 307192.5000 - val_mae: 399.6656\n",
      "Epoch 123/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310593.2188 - mae: 402.9628 - val_loss: 307393.5000 - val_mae: 401.7541\n",
      "Epoch 124/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310212.6562 - mae: 402.9227 - val_loss: 308843.3750 - val_mae: 400.7406\n",
      "Epoch 125/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310537.3750 - mae: 402.4153 - val_loss: 308150.5625 - val_mae: 403.0458\n",
      "Epoch 126/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309589.3438 - mae: 402.1023 - val_loss: 308385.5000 - val_mae: 402.9770\n",
      "Epoch 127/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310285.0938 - mae: 403.2460 - val_loss: 309284.6875 - val_mae: 403.8939\n",
      "Epoch 128/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310389.6562 - mae: 403.3594 - val_loss: 307658.5000 - val_mae: 399.0485\n",
      "Epoch 129/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310480.8125 - mae: 402.5587 - val_loss: 306708.9062 - val_mae: 401.1893\n",
      "Epoch 130/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310154.4062 - mae: 402.8767 - val_loss: 306456.4062 - val_mae: 399.9515\n",
      "Epoch 131/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310494.8438 - mae: 402.7421 - val_loss: 306563.1875 - val_mae: 401.1197\n",
      "Epoch 132/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310219.3438 - mae: 402.4504 - val_loss: 307351.8125 - val_mae: 399.3961\n",
      "Epoch 133/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309850.0938 - mae: 402.8142 - val_loss: 307455.8438 - val_mae: 400.2208\n",
      "Epoch 134/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 310007.5625 - mae: 402.7662 - val_loss: 307799.4375 - val_mae: 402.1105\n",
      "Epoch 135/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309536.8125 - mae: 403.0152 - val_loss: 309497.7812 - val_mae: 398.3674\n",
      "Epoch 136/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309102.7188 - mae: 402.4036 - val_loss: 307402.4375 - val_mae: 401.9623\n",
      "Epoch 137/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309543.4375 - mae: 402.5588 - val_loss: 307277.8438 - val_mae: 398.2610\n",
      "Epoch 138/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309299.8750 - mae: 401.8699 - val_loss: 306442.5938 - val_mae: 401.0081\n",
      "Epoch 139/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309091.3750 - mae: 402.5276 - val_loss: 306976.6250 - val_mae: 401.4731\n",
      "Epoch 140/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309237.8750 - mae: 401.7013 - val_loss: 305513.5312 - val_mae: 399.5746\n",
      "Epoch 141/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 309037.0000 - mae: 402.2311 - val_loss: 306182.0312 - val_mae: 401.5706\n",
      "Epoch 142/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 308599.9375 - mae: 401.9713 - val_loss: 306276.6562 - val_mae: 401.4435\n",
      "Epoch 143/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 308702.5312 - mae: 401.8214 - val_loss: 306399.9062 - val_mae: 399.2375\n",
      "Epoch 144/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 308834.2188 - mae: 402.2295 - val_loss: 306504.1875 - val_mae: 399.6199\n",
      "Epoch 145/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 308338.3125 - mae: 401.4771 - val_loss: 305730.5312 - val_mae: 400.4782\n",
      "Epoch 146/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 308713.1250 - mae: 401.9760 - val_loss: 304815.3750 - val_mae: 399.6331\n",
      "Epoch 147/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 308901.8125 - mae: 401.2765 - val_loss: 305164.9062 - val_mae: 400.4884\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 36536920.0000 - mae: 5887.3560 - val_loss: 32005408.0000 - val_mae: 5511.3979\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 24706100.0000 - mae: 4812.0757 - val_loss: 17179564.0000 - val_mae: 4004.7476\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 11183631.0000 - mae: 3126.9587 - val_loss: 6347814.0000 - val_mae: 2265.5715\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3873227.7500 - mae: 1622.0060 - val_loss: 2223244.7500 - val_mae: 1133.5138\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1594962.5000 - mae: 923.3264 - val_loss: 1187345.0000 - val_mae: 789.8816\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1010420.1250 - mae: 729.6207 - val_loss: 873934.7500 - val_mae: 680.9639\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 797991.6875 - mae: 649.8835 - val_loss: 732257.5000 - val_mae: 622.4410\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 692977.9375 - mae: 605.0728 - val_loss: 654362.8125 - val_mae: 587.5530\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 631191.5000 - mae: 577.6028 - val_loss: 604887.3750 - val_mae: 565.8448\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589056.9375 - mae: 558.8046 - val_loss: 568712.0625 - val_mae: 549.6918\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557250.5000 - mae: 544.2719 - val_loss: 540647.5625 - val_mae: 536.2821\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531988.3750 - mae: 531.7933 - val_loss: 518100.8125 - val_mae: 526.0934\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 511348.9062 - mae: 522.2421 - val_loss: 499186.0312 - val_mae: 517.3812\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 493833.6875 - mae: 514.0521 - val_loss: 482927.1875 - val_mae: 508.0049\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 479130.3125 - mae: 506.4361 - val_loss: 469412.1875 - val_mae: 502.3730\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 466278.6250 - mae: 500.2014 - val_loss: 457039.2188 - val_mae: 496.2173\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 455132.1562 - mae: 494.6895 - val_loss: 446906.0312 - val_mae: 490.0622\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 445083.6562 - mae: 489.3990 - val_loss: 438444.5938 - val_mae: 486.1928\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436990.3125 - mae: 485.3238 - val_loss: 429994.6562 - val_mae: 482.7859\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 429393.3125 - mae: 482.2938 - val_loss: 424399.6250 - val_mae: 477.0222\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423412.8750 - mae: 478.8265 - val_loss: 417906.3750 - val_mae: 475.9758\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 418020.3125 - mae: 476.3388 - val_loss: 413247.8438 - val_mae: 474.4272\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 413566.6562 - mae: 473.3019 - val_loss: 408318.9062 - val_mae: 471.1182\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409060.9375 - mae: 471.0766 - val_loss: 404188.2812 - val_mae: 468.8552\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405242.0938 - mae: 468.7734 - val_loss: 400646.6562 - val_mae: 466.4176\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401618.7812 - mae: 466.9916 - val_loss: 398072.3438 - val_mae: 463.3833\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399394.8125 - mae: 465.0337 - val_loss: 395894.1875 - val_mae: 461.5169\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396704.4375 - mae: 463.5347 - val_loss: 392704.0000 - val_mae: 462.5785\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 394169.6875 - mae: 461.7243 - val_loss: 390387.3750 - val_mae: 460.4125\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391896.2812 - mae: 461.1195 - val_loss: 388966.7500 - val_mae: 458.4435\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390147.0312 - mae: 459.6422 - val_loss: 386619.2812 - val_mae: 458.1942\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388095.2812 - mae: 458.0118 - val_loss: 384929.3438 - val_mae: 456.9097\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386408.1562 - mae: 457.6093 - val_loss: 383634.8125 - val_mae: 453.8816\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 384743.2188 - mae: 455.8282 - val_loss: 381213.3438 - val_mae: 454.6221\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382769.5312 - mae: 454.8471 - val_loss: 379359.9062 - val_mae: 453.9378\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 381292.2188 - mae: 453.4194 - val_loss: 377718.6875 - val_mae: 451.9842\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 379329.9375 - mae: 452.4543 - val_loss: 376340.3125 - val_mae: 449.2616\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377263.8125 - mae: 450.7718 - val_loss: 374088.5625 - val_mae: 448.4048\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 375127.8438 - mae: 449.1650 - val_loss: 371821.7812 - val_mae: 448.3694\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 373247.7812 - mae: 448.1018 - val_loss: 369859.9688 - val_mae: 447.5853\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 371558.0000 - mae: 447.1457 - val_loss: 368195.2188 - val_mae: 445.3267\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 369993.3750 - mae: 446.4000 - val_loss: 366831.0312 - val_mae: 442.9248\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368017.9688 - mae: 444.8967 - val_loss: 365744.3438 - val_mae: 443.1710\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367206.0625 - mae: 444.1998 - val_loss: 364279.4688 - val_mae: 443.2511\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366243.3438 - mae: 443.5067 - val_loss: 363032.8125 - val_mae: 442.3878\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364784.0312 - mae: 442.4015 - val_loss: 362095.6562 - val_mae: 443.1081\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 363183.9375 - mae: 441.6227 - val_loss: 360639.5000 - val_mae: 441.4167\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 362020.4375 - mae: 441.1474 - val_loss: 358979.3750 - val_mae: 437.9751\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360516.6875 - mae: 439.7475 - val_loss: 357423.8750 - val_mae: 438.4061\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359190.8125 - mae: 438.9005 - val_loss: 355992.8750 - val_mae: 436.6636\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357617.6250 - mae: 438.1195 - val_loss: 354732.2188 - val_mae: 435.6115\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 356292.5000 - mae: 436.6329 - val_loss: 353870.7500 - val_mae: 436.1020\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355822.6250 - mae: 436.6350 - val_loss: 352380.5938 - val_mae: 433.9780\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354171.3438 - mae: 435.7512 - val_loss: 351837.0625 - val_mae: 433.3629\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352951.5000 - mae: 434.3763 - val_loss: 350275.0938 - val_mae: 433.8109\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 352042.2188 - mae: 433.9903 - val_loss: 349074.7500 - val_mae: 432.8177\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 350916.3750 - mae: 433.4187 - val_loss: 348265.3125 - val_mae: 433.0733\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349808.8750 - mae: 432.2886 - val_loss: 347042.2500 - val_mae: 430.7137\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348934.9375 - mae: 431.6546 - val_loss: 346686.5000 - val_mae: 432.9461\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 347840.6250 - mae: 431.1698 - val_loss: 344836.2500 - val_mae: 429.7079\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346706.0312 - mae: 430.2880 - val_loss: 343704.6562 - val_mae: 428.6045\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345570.9688 - mae: 429.8143 - val_loss: 343295.2500 - val_mae: 427.5559\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345272.2500 - mae: 428.8944 - val_loss: 342117.1250 - val_mae: 427.6026\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 344097.6250 - mae: 428.0172 - val_loss: 341093.2188 - val_mae: 426.2631\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343038.0312 - mae: 427.7587 - val_loss: 340367.3438 - val_mae: 425.6238\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342501.4688 - mae: 427.3004 - val_loss: 339938.6250 - val_mae: 424.0953\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341961.8438 - mae: 426.5022 - val_loss: 339004.8750 - val_mae: 424.3877\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341065.3750 - mae: 426.2721 - val_loss: 338175.3750 - val_mae: 424.6487\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340334.3125 - mae: 425.4329 - val_loss: 337884.9375 - val_mae: 423.2807\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339521.1875 - mae: 424.8829 - val_loss: 338411.3750 - val_mae: 422.3182\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339399.4688 - mae: 424.7515 - val_loss: 336510.4375 - val_mae: 423.6950\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338443.6875 - mae: 423.8839 - val_loss: 336223.3750 - val_mae: 423.2818\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338181.2500 - mae: 423.6673 - val_loss: 336215.2188 - val_mae: 420.5198\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337584.9688 - mae: 423.3245 - val_loss: 335693.2812 - val_mae: 424.7990\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336932.8438 - mae: 423.2691 - val_loss: 334647.9375 - val_mae: 420.0090\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336138.2188 - mae: 422.0076 - val_loss: 334442.5000 - val_mae: 419.3117\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 335144.3438 - mae: 421.3026 - val_loss: 332720.4375 - val_mae: 419.0697\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334595.3125 - mae: 420.9081 - val_loss: 331551.9062 - val_mae: 419.1638\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333485.7188 - mae: 420.0925 - val_loss: 331314.3750 - val_mae: 420.4818\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333161.9375 - mae: 420.3539 - val_loss: 330714.7500 - val_mae: 418.2774\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332830.2812 - mae: 420.0309 - val_loss: 329992.5000 - val_mae: 418.5504\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332030.0938 - mae: 419.3905 - val_loss: 330251.0938 - val_mae: 420.0035\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331857.8125 - mae: 419.1772 - val_loss: 328863.7188 - val_mae: 417.6741\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331275.2188 - mae: 419.1533 - val_loss: 328632.1250 - val_mae: 418.1825\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 330978.5938 - mae: 418.5686 - val_loss: 328161.8750 - val_mae: 416.7133\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 330539.0938 - mae: 418.4825 - val_loss: 327485.4375 - val_mae: 416.6230\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329981.4688 - mae: 417.7754 - val_loss: 327299.3750 - val_mae: 417.5801\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329588.7812 - mae: 418.0716 - val_loss: 326983.7812 - val_mae: 417.1482\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 329025.5312 - mae: 417.5803 - val_loss: 326631.7188 - val_mae: 416.7816\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328684.7188 - mae: 417.3154 - val_loss: 326217.5938 - val_mae: 415.4581\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 328317.7812 - mae: 416.7994 - val_loss: 326246.8750 - val_mae: 417.3053\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 328073.6250 - mae: 417.0233 - val_loss: 325738.8438 - val_mae: 415.1973\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327589.5938 - mae: 416.7758 - val_loss: 326025.6562 - val_mae: 414.4028\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327623.5312 - mae: 416.5320 - val_loss: 325263.1250 - val_mae: 416.8570\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327287.4688 - mae: 416.8076 - val_loss: 325154.8750 - val_mae: 415.0939\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 326974.2188 - mae: 416.0428 - val_loss: 324716.0938 - val_mae: 415.9906\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 327043.0000 - mae: 416.0674 - val_loss: 324201.4688 - val_mae: 413.8709\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 326000.9688 - mae: 415.6714 - val_loss: 324724.8750 - val_mae: 413.1814\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 326438.6875 - mae: 415.7111 - val_loss: 323699.0625 - val_mae: 413.6745\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325752.1250 - mae: 415.5822 - val_loss: 323623.0625 - val_mae: 412.9798\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325734.1562 - mae: 415.5355 - val_loss: 323169.3750 - val_mae: 413.7845\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325529.1875 - mae: 415.4448 - val_loss: 322886.7188 - val_mae: 413.7458\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 325056.7812 - mae: 414.7863 - val_loss: 322871.0938 - val_mae: 413.8208\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324769.9688 - mae: 414.7592 - val_loss: 322936.3125 - val_mae: 414.0381\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324867.1562 - mae: 414.5830 - val_loss: 322675.8438 - val_mae: 414.9166\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324206.4375 - mae: 414.7995 - val_loss: 322666.1875 - val_mae: 415.3280\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324479.1250 - mae: 414.7445 - val_loss: 321848.8750 - val_mae: 412.1944\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 324112.5312 - mae: 414.0965 - val_loss: 321694.1250 - val_mae: 412.8821\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 324006.5312 - mae: 414.3280 - val_loss: 321597.2500 - val_mae: 411.5754\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323398.5625 - mae: 413.8400 - val_loss: 321673.3750 - val_mae: 412.5165\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 323622.5938 - mae: 413.9091 - val_loss: 321080.4375 - val_mae: 412.9863\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323404.2500 - mae: 413.9681 - val_loss: 321019.5000 - val_mae: 412.0401\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 323289.6562 - mae: 413.4485 - val_loss: 320721.1875 - val_mae: 412.1568\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 323127.5625 - mae: 413.6537 - val_loss: 321066.7188 - val_mae: 412.3806\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322670.3125 - mae: 413.3083 - val_loss: 320776.9375 - val_mae: 411.4244\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322360.3438 - mae: 413.3619 - val_loss: 320581.0625 - val_mae: 411.6959\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322557.3750 - mae: 412.6370 - val_loss: 321195.7188 - val_mae: 414.1987\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 322136.0312 - mae: 412.8015 - val_loss: 320274.8750 - val_mae: 411.5300\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322235.3125 - mae: 412.7589 - val_loss: 319721.5625 - val_mae: 411.4448\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 322072.8750 - mae: 412.9924 - val_loss: 319898.2500 - val_mae: 411.8603\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321837.7500 - mae: 412.2072 - val_loss: 319651.0000 - val_mae: 412.4111\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321730.9688 - mae: 412.9345 - val_loss: 319430.6562 - val_mae: 411.6561\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321671.4375 - mae: 412.6914 - val_loss: 319152.1875 - val_mae: 410.3027\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321462.0938 - mae: 412.2268 - val_loss: 319348.7500 - val_mae: 410.3325\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321183.0312 - mae: 412.0824 - val_loss: 319482.4688 - val_mae: 411.2904\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321379.5625 - mae: 412.1585 - val_loss: 319214.6562 - val_mae: 411.4741\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321349.3750 - mae: 412.0575 - val_loss: 318649.4688 - val_mae: 410.9075\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320891.9062 - mae: 412.1191 - val_loss: 319680.3438 - val_mae: 410.0670\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 321147.0000 - mae: 412.0852 - val_loss: 319019.5312 - val_mae: 409.0551\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320630.9375 - mae: 411.5988 - val_loss: 320570.4375 - val_mae: 414.4475\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320737.5938 - mae: 411.3468 - val_loss: 318490.5000 - val_mae: 411.3016\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 320685.0000 - mae: 411.9264 - val_loss: 318576.4062 - val_mae: 409.6337\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320721.9375 - mae: 411.3688 - val_loss: 318205.0312 - val_mae: 411.1872\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320256.6250 - mae: 411.4277 - val_loss: 318381.4688 - val_mae: 409.4850\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320341.0938 - mae: 411.2159 - val_loss: 318033.1250 - val_mae: 410.3024\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320130.6562 - mae: 411.2443 - val_loss: 318350.8125 - val_mae: 408.9164\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320290.1562 - mae: 411.2418 - val_loss: 318065.9688 - val_mae: 410.2596\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 320012.9062 - mae: 410.8727 - val_loss: 317812.0625 - val_mae: 410.6596\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319947.7812 - mae: 411.4095 - val_loss: 317902.1250 - val_mae: 409.8391\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319992.2188 - mae: 411.2163 - val_loss: 317527.5312 - val_mae: 408.7013\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 319830.8438 - mae: 410.4479 - val_loss: 317792.0938 - val_mae: 411.3031\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319727.0312 - mae: 410.9279 - val_loss: 317437.6875 - val_mae: 408.7767\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319704.0312 - mae: 410.9499 - val_loss: 317100.1875 - val_mae: 408.9345\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319214.1250 - mae: 411.0189 - val_loss: 318043.2188 - val_mae: 408.1133\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319565.8438 - mae: 410.6488 - val_loss: 317287.5625 - val_mae: 408.6283\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 319302.7188 - mae: 410.3762 - val_loss: 317456.9688 - val_mae: 409.5021\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318923.4375 - mae: 410.2104 - val_loss: 316976.6875 - val_mae: 409.6471\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319065.3438 - mae: 410.3403 - val_loss: 316978.4688 - val_mae: 408.9023\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 319262.9688 - mae: 410.3745 - val_loss: 316674.5312 - val_mae: 408.3078\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318824.6875 - mae: 409.9462 - val_loss: 316416.1875 - val_mae: 408.0107\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 318645.6250 - mae: 409.6067 - val_loss: 316253.4375 - val_mae: 408.8228\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318500.0625 - mae: 409.7086 - val_loss: 316427.8125 - val_mae: 407.8094\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 318220.2500 - mae: 409.3885 - val_loss: 316499.1250 - val_mae: 408.1741\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318218.7812 - mae: 409.6133 - val_loss: 316367.6250 - val_mae: 409.8815\n",
      "Epoch 155/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 318073.6250 - mae: 409.1492 - val_loss: 316001.3750 - val_mae: 407.8368\n",
      "Epoch 156/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317932.3750 - mae: 409.4674 - val_loss: 317094.1250 - val_mae: 406.5728\n",
      "Epoch 157/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 318096.3125 - mae: 409.0609 - val_loss: 315484.8125 - val_mae: 407.8549\n",
      "Epoch 158/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317857.1562 - mae: 409.1737 - val_loss: 315597.5625 - val_mae: 407.2250\n",
      "Epoch 159/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317813.2812 - mae: 409.3720 - val_loss: 315371.1562 - val_mae: 407.4601\n",
      "Epoch 160/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 317568.6250 - mae: 408.7245 - val_loss: 315429.2812 - val_mae: 407.6033\n",
      "Epoch 161/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 317476.8750 - mae: 408.9722 - val_loss: 315601.5938 - val_mae: 406.9453\n",
      "Epoch 162/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317655.7812 - mae: 409.2190 - val_loss: 315441.2188 - val_mae: 406.3733\n",
      "Epoch 163/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317139.3125 - mae: 408.4242 - val_loss: 315472.0625 - val_mae: 407.4820\n",
      "Epoch 164/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 317392.4062 - mae: 408.6409 - val_loss: 314683.9688 - val_mae: 406.5260\n",
      "Epoch 165/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317210.3750 - mae: 409.0324 - val_loss: 315566.9688 - val_mae: 405.8900\n",
      "Epoch 166/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 316994.0312 - mae: 408.0052 - val_loss: 315101.6562 - val_mae: 406.6776\n",
      "Epoch 167/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 317047.1875 - mae: 408.5101 - val_loss: 314648.7188 - val_mae: 407.5995\n",
      "Epoch 168/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316924.4062 - mae: 408.3751 - val_loss: 314351.8750 - val_mae: 405.9967\n",
      "Epoch 169/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316650.7500 - mae: 408.1709 - val_loss: 315650.7500 - val_mae: 405.4165\n",
      "Epoch 170/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316232.7188 - mae: 407.6807 - val_loss: 314771.5938 - val_mae: 405.3640\n",
      "Epoch 171/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316411.5938 - mae: 407.8609 - val_loss: 314763.0312 - val_mae: 405.5282\n",
      "Epoch 172/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316747.0000 - mae: 408.0919 - val_loss: 314484.9688 - val_mae: 405.6747\n",
      "Epoch 173/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 316437.3750 - mae: 407.8671 - val_loss: 314554.6562 - val_mae: 407.3708\n",
      "Epoch 174/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316281.1250 - mae: 408.2002 - val_loss: 313960.6562 - val_mae: 406.0071\n",
      "Epoch 175/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 316377.2188 - mae: 408.1429 - val_loss: 313901.7500 - val_mae: 406.6700\n",
      "Epoch 176/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316235.7188 - mae: 407.7501 - val_loss: 313778.6562 - val_mae: 406.4046\n",
      "Epoch 177/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316049.6875 - mae: 407.6743 - val_loss: 313960.2188 - val_mae: 406.0890\n",
      "Epoch 178/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316304.7812 - mae: 407.7277 - val_loss: 314152.6250 - val_mae: 404.9054\n",
      "Epoch 179/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315911.3438 - mae: 407.7259 - val_loss: 314306.3125 - val_mae: 407.3740\n",
      "Epoch 180/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 315879.1562 - mae: 407.1786 - val_loss: 313676.4688 - val_mae: 406.6131\n",
      "Epoch 181/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315851.4375 - mae: 407.8290 - val_loss: 313580.7500 - val_mae: 406.0734\n",
      "Epoch 182/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315536.3125 - mae: 407.3599 - val_loss: 314876.8438 - val_mae: 408.9881\n",
      "Epoch 183/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 316031.8125 - mae: 407.8869 - val_loss: 313736.1250 - val_mae: 405.1089\n",
      "Epoch 184/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315962.2500 - mae: 407.5862 - val_loss: 313696.0000 - val_mae: 405.6346\n",
      "Epoch 185/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315577.4062 - mae: 407.2202 - val_loss: 314128.4375 - val_mae: 404.4496\n",
      "Epoch 186/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315837.0938 - mae: 407.3625 - val_loss: 313568.6250 - val_mae: 405.1403\n",
      "Epoch 187/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 315510.1562 - mae: 406.9414 - val_loss: 313605.7188 - val_mae: 405.0484\n",
      "Epoch 188/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315600.1250 - mae: 407.4458 - val_loss: 313788.5625 - val_mae: 406.0544\n",
      "Epoch 189/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315477.8125 - mae: 406.9774 - val_loss: 313729.1250 - val_mae: 404.8735\n",
      "Epoch 190/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315425.3125 - mae: 406.8443 - val_loss: 313110.3438 - val_mae: 406.3582\n",
      "Epoch 191/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315249.2500 - mae: 407.1517 - val_loss: 313368.2812 - val_mae: 405.7029\n",
      "Epoch 192/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315471.8438 - mae: 407.1821 - val_loss: 313873.9062 - val_mae: 404.4543\n",
      "Epoch 193/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315481.6250 - mae: 406.9553 - val_loss: 313195.5938 - val_mae: 406.1393\n",
      "Epoch 194/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 315111.7500 - mae: 407.1031 - val_loss: 314075.0938 - val_mae: 404.5709\n",
      "Epoch 195/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 315540.5000 - mae: 406.8529 - val_loss: 312825.3125 - val_mae: 406.3008\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 35537488.0000 - mae: 5807.0444 - val_loss: 28881342.0000 - val_mae: 5246.9985\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 19542428.0000 - mae: 4250.9331 - val_loss: 11023857.0000 - val_mae: 3154.2173\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6083863.0000 - mae: 2178.9885 - val_loss: 2789284.2500 - val_mae: 1379.0472\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1679961.2500 - mae: 1000.0685 - val_loss: 1071067.5000 - val_mae: 773.3955\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 897510.3125 - mae: 702.3840 - val_loss: 782795.2500 - val_mae: 655.0081\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 730469.0625 - mae: 629.8748 - val_loss: 682036.6250 - val_mae: 609.5934\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 653414.1875 - mae: 595.4558 - val_loss: 621223.0000 - val_mae: 581.1284\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601907.0625 - mae: 572.3273 - val_loss: 577057.6875 - val_mae: 560.3297\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563550.0625 - mae: 554.1412 - val_loss: 543385.3125 - val_mae: 543.8033\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533802.6250 - mae: 539.5219 - val_loss: 517404.4062 - val_mae: 530.2049\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 509070.4688 - mae: 526.8356 - val_loss: 494078.6875 - val_mae: 519.5516\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 488192.9062 - mae: 516.1186 - val_loss: 475409.4062 - val_mae: 509.9724\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 470856.4688 - mae: 506.1910 - val_loss: 461059.1562 - val_mae: 501.9689\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 458183.6250 - mae: 498.8188 - val_loss: 448862.5938 - val_mae: 494.9561\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 447834.1875 - mae: 492.7223 - val_loss: 439365.5938 - val_mae: 488.0944\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 438852.9688 - mae: 487.4174 - val_loss: 431568.6562 - val_mae: 483.0724\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 431841.5938 - mae: 483.0648 - val_loss: 425932.5938 - val_mae: 478.2522\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 425972.6875 - mae: 479.3980 - val_loss: 420000.1562 - val_mae: 476.2318\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 420863.6250 - mae: 476.3388 - val_loss: 415783.4375 - val_mae: 475.8053\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416409.1562 - mae: 474.3676 - val_loss: 411093.6250 - val_mae: 470.3002\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 412149.2812 - mae: 470.5151 - val_loss: 407090.0938 - val_mae: 469.2047\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 408639.7188 - mae: 468.7374 - val_loss: 404309.0312 - val_mae: 465.1140\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 405192.0000 - mae: 466.5050 - val_loss: 400925.8125 - val_mae: 466.8245\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401443.5625 - mae: 464.4882 - val_loss: 397379.9375 - val_mae: 462.8146\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398842.6562 - mae: 462.6916 - val_loss: 395919.4375 - val_mae: 464.1490\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 396480.0000 - mae: 461.4200 - val_loss: 391688.9062 - val_mae: 458.0112\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393846.1250 - mae: 458.9390 - val_loss: 388728.7500 - val_mae: 456.6483\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391097.9375 - mae: 456.7092 - val_loss: 386231.8750 - val_mae: 454.4883\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 388539.5938 - mae: 455.5302 - val_loss: 384110.5000 - val_mae: 452.6290\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 386906.5625 - mae: 454.2686 - val_loss: 381986.4375 - val_mae: 451.1246\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 384578.7812 - mae: 452.3094 - val_loss: 380859.3750 - val_mae: 451.8818\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 382700.4062 - mae: 451.2185 - val_loss: 379703.5000 - val_mae: 448.8780\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 381008.3438 - mae: 450.5010 - val_loss: 376946.3438 - val_mae: 447.9471\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 379546.6875 - mae: 449.1005 - val_loss: 375434.1562 - val_mae: 447.1113\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 377504.5938 - mae: 447.7277 - val_loss: 375873.5312 - val_mae: 450.7823\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 375987.8438 - mae: 446.8875 - val_loss: 372209.9375 - val_mae: 446.2149\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 374719.6875 - mae: 445.7326 - val_loss: 370525.8438 - val_mae: 444.6621\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 373357.9688 - mae: 444.8224 - val_loss: 369048.3750 - val_mae: 443.4788\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 371609.8750 - mae: 443.5324 - val_loss: 367377.2500 - val_mae: 441.1161\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 370000.2500 - mae: 442.0700 - val_loss: 366197.2188 - val_mae: 440.2534\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 368856.1250 - mae: 441.1844 - val_loss: 366015.1250 - val_mae: 441.1470\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 367710.8750 - mae: 440.3991 - val_loss: 364167.9375 - val_mae: 439.5577\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 366816.6250 - mae: 439.6018 - val_loss: 362917.5938 - val_mae: 438.1709\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 365262.0000 - mae: 438.7600 - val_loss: 363230.3125 - val_mae: 438.3966\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 364737.8750 - mae: 439.1834 - val_loss: 362951.6250 - val_mae: 434.7519\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 364048.4688 - mae: 437.9854 - val_loss: 359915.4688 - val_mae: 435.1407\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 362554.6250 - mae: 436.7310 - val_loss: 359695.5938 - val_mae: 434.3022\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 361476.0312 - mae: 436.2738 - val_loss: 359683.9062 - val_mae: 433.0118\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360872.0312 - mae: 435.4339 - val_loss: 358477.5312 - val_mae: 437.4450\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 360240.8750 - mae: 435.4799 - val_loss: 357585.1875 - val_mae: 433.9088\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 359080.4688 - mae: 434.2737 - val_loss: 355918.8750 - val_mae: 431.5441\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 358515.5312 - mae: 434.2981 - val_loss: 354814.5625 - val_mae: 431.5906\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 357602.8125 - mae: 433.5207 - val_loss: 354919.1562 - val_mae: 431.8888\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 357085.9375 - mae: 432.5167 - val_loss: 353889.6875 - val_mae: 433.5488\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355804.5312 - mae: 432.4279 - val_loss: 352823.5938 - val_mae: 430.8275\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 355363.8125 - mae: 431.8217 - val_loss: 351949.7812 - val_mae: 430.8324\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 354980.2188 - mae: 431.5832 - val_loss: 351624.1250 - val_mae: 428.8539\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 354169.3125 - mae: 431.5862 - val_loss: 350309.4688 - val_mae: 428.8438\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 353049.0312 - mae: 430.2065 - val_loss: 351078.7500 - val_mae: 431.6597\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 353106.7188 - mae: 430.1815 - val_loss: 349519.3125 - val_mae: 427.0200\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351933.4688 - mae: 429.7953 - val_loss: 349982.4062 - val_mae: 426.6960\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351788.8438 - mae: 429.0674 - val_loss: 348414.7500 - val_mae: 427.4790\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 351524.5625 - mae: 429.2684 - val_loss: 348170.6250 - val_mae: 428.3579\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350837.6250 - mae: 428.6537 - val_loss: 348329.4688 - val_mae: 428.4291\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350246.1875 - mae: 428.7097 - val_loss: 347698.4062 - val_mae: 425.7917\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 350140.2188 - mae: 428.2959 - val_loss: 346880.1562 - val_mae: 425.8206\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 349631.6875 - mae: 427.8305 - val_loss: 346613.4375 - val_mae: 425.8452\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349176.6250 - mae: 427.0694 - val_loss: 346659.7812 - val_mae: 426.4573\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 349141.8750 - mae: 427.7095 - val_loss: 345470.2812 - val_mae: 426.0858\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348650.0625 - mae: 426.8679 - val_loss: 346118.0312 - val_mae: 428.2101\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 348321.7812 - mae: 426.6150 - val_loss: 344893.1562 - val_mae: 425.6064\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347723.3750 - mae: 426.6424 - val_loss: 344574.5938 - val_mae: 425.5235\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 347576.0938 - mae: 426.2750 - val_loss: 345244.3438 - val_mae: 422.5765\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 346981.3438 - mae: 425.5886 - val_loss: 345528.7812 - val_mae: 422.5003\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346892.8750 - mae: 425.6195 - val_loss: 344209.2812 - val_mae: 422.4676\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346428.6562 - mae: 425.0626 - val_loss: 342982.2812 - val_mae: 422.6917\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346120.0000 - mae: 425.3282 - val_loss: 343039.0625 - val_mae: 422.4925\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 346109.9688 - mae: 425.0945 - val_loss: 342265.1875 - val_mae: 422.7913\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345565.1562 - mae: 424.3322 - val_loss: 342451.7500 - val_mae: 425.0008\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 345065.8750 - mae: 424.9984 - val_loss: 341935.4375 - val_mae: 424.3211\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 344707.0625 - mae: 423.9319 - val_loss: 341979.5312 - val_mae: 423.0033\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344004.6875 - mae: 424.2683 - val_loss: 343657.0312 - val_mae: 421.2697\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 344443.0625 - mae: 423.8546 - val_loss: 340664.7812 - val_mae: 421.5002\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343756.8125 - mae: 423.5551 - val_loss: 341075.5625 - val_mae: 423.3855\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343864.2812 - mae: 423.6184 - val_loss: 341007.5938 - val_mae: 424.0450\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342977.5000 - mae: 422.7148 - val_loss: 340135.0000 - val_mae: 421.2517\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 343367.6875 - mae: 423.0107 - val_loss: 339937.7188 - val_mae: 421.8580\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342703.0312 - mae: 423.3661 - val_loss: 340052.4062 - val_mae: 420.0988\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342676.3125 - mae: 422.8222 - val_loss: 339108.5000 - val_mae: 420.5930\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 342003.0000 - mae: 421.7860 - val_loss: 340324.4688 - val_mae: 424.6817\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341955.8750 - mae: 422.5147 - val_loss: 338318.6250 - val_mae: 421.2428\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341754.1250 - mae: 422.2692 - val_loss: 338371.7188 - val_mae: 421.0579\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 341465.0625 - mae: 421.4967 - val_loss: 339013.9688 - val_mae: 423.3321\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340842.5000 - mae: 421.7136 - val_loss: 338296.8125 - val_mae: 420.0637\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 341096.4062 - mae: 421.3512 - val_loss: 337338.0938 - val_mae: 419.3417\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 340153.2812 - mae: 420.7965 - val_loss: 338316.8438 - val_mae: 422.8528\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 340087.3750 - mae: 421.1248 - val_loss: 337107.2500 - val_mae: 420.6087\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339503.9688 - mae: 420.5665 - val_loss: 336547.2500 - val_mae: 417.7186\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 339484.1875 - mae: 420.3101 - val_loss: 336542.2188 - val_mae: 419.8440\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 339152.5312 - mae: 419.9530 - val_loss: 335814.9375 - val_mae: 419.2292\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 338801.8750 - mae: 420.3486 - val_loss: 335288.7812 - val_mae: 418.3190\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 338583.5938 - mae: 419.5919 - val_loss: 335839.8438 - val_mae: 419.8868\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 337961.3438 - mae: 419.6266 - val_loss: 335500.4688 - val_mae: 419.6067\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 338194.4688 - mae: 419.5312 - val_loss: 334698.7188 - val_mae: 417.4191\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 337823.1562 - mae: 419.0737 - val_loss: 335101.9688 - val_mae: 416.0967\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337051.9375 - mae: 418.5134 - val_loss: 334068.3438 - val_mae: 416.0615\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 337357.0312 - mae: 418.7258 - val_loss: 334535.7812 - val_mae: 418.1304\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 336914.6875 - mae: 418.7571 - val_loss: 334212.8125 - val_mae: 418.2128\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336271.9688 - mae: 418.4016 - val_loss: 333938.8125 - val_mae: 418.5452\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 336505.0000 - mae: 418.3022 - val_loss: 333297.9375 - val_mae: 417.2921\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336319.5312 - mae: 418.6046 - val_loss: 333780.0625 - val_mae: 416.2728\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336041.0000 - mae: 417.9042 - val_loss: 333147.7812 - val_mae: 415.9007\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 336181.6875 - mae: 417.7994 - val_loss: 333415.0625 - val_mae: 417.4430\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335652.3125 - mae: 418.3057 - val_loss: 332881.4062 - val_mae: 416.3117\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 335830.6562 - mae: 418.3625 - val_loss: 332464.8750 - val_mae: 414.7155\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 335223.5312 - mae: 417.5990 - val_loss: 332281.4375 - val_mae: 416.6440\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334913.0000 - mae: 417.8997 - val_loss: 332098.8438 - val_mae: 416.6462\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334696.0312 - mae: 417.6165 - val_loss: 331711.0625 - val_mae: 415.1601\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334643.5938 - mae: 417.4760 - val_loss: 331468.0938 - val_mae: 416.3811\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 334213.9375 - mae: 416.8685 - val_loss: 331792.4688 - val_mae: 418.0546\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333831.7812 - mae: 416.7955 - val_loss: 332323.0625 - val_mae: 418.6391\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 334478.3125 - mae: 417.1762 - val_loss: 330782.9688 - val_mae: 415.9194\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333819.0000 - mae: 417.2971 - val_loss: 331331.6562 - val_mae: 414.9379\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333415.0938 - mae: 417.0581 - val_loss: 331041.5000 - val_mae: 413.7735\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 333363.0625 - mae: 416.4097 - val_loss: 330686.9062 - val_mae: 414.8962\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333608.5625 - mae: 416.8232 - val_loss: 330274.4688 - val_mae: 416.0723\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333046.9375 - mae: 417.3085 - val_loss: 330068.6250 - val_mae: 414.6881\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332818.9688 - mae: 415.8572 - val_loss: 329929.7188 - val_mae: 415.3195\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 332867.6562 - mae: 416.2583 - val_loss: 330189.4688 - val_mae: 416.9556\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 333137.3125 - mae: 416.6404 - val_loss: 329428.4688 - val_mae: 414.0775\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332440.8438 - mae: 416.3029 - val_loss: 330204.5938 - val_mae: 412.9900\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332367.0000 - mae: 415.8721 - val_loss: 329678.2188 - val_mae: 414.4349\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332427.6250 - mae: 416.1410 - val_loss: 329276.7188 - val_mae: 413.1894\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331801.0312 - mae: 415.7936 - val_loss: 330134.7812 - val_mae: 416.7469\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332533.5000 - mae: 416.2672 - val_loss: 329690.3750 - val_mae: 416.8076\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 332094.9062 - mae: 415.4490 - val_loss: 329582.6875 - val_mae: 416.1280\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 332395.7188 - mae: 416.2091 - val_loss: 328473.4062 - val_mae: 413.1259\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331763.8750 - mae: 415.6617 - val_loss: 328780.5938 - val_mae: 414.4488\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331607.7188 - mae: 415.8634 - val_loss: 329502.5938 - val_mae: 414.0935\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331328.7188 - mae: 415.6892 - val_loss: 328371.7188 - val_mae: 413.8062\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 331549.8750 - mae: 415.4443 - val_loss: 328408.7812 - val_mae: 413.3654\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38152084.0000 - mae: 6021.3955 - val_loss: 36987232.0000 - val_mae: 5932.9561\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 34338104.0000 - mae: 5724.8369 - val_loss: 31104156.0000 - val_mae: 5462.3389\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 27289136.0000 - mae: 5118.7085 - val_loss: 23303694.0000 - val_mae: 4737.0723\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 19525368.0000 - mae: 4315.0103 - val_loss: 15882917.0000 - val_mae: 3871.5320\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 12847374.0000 - mae: 3426.8145 - val_loss: 10086079.0000 - val_mae: 2984.6743\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 7976620.5000 - mae: 2582.8215 - val_loss: 6121525.0000 - val_mae: 2202.3594\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 4784012.5000 - mae: 1887.5438 - val_loss: 3644670.5000 - val_mae: 1604.2914\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2876304.5000 - mae: 1394.8574 - val_loss: 2239568.0000 - val_mae: 1215.3608\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1839798.8750 - mae: 1087.8927 - val_loss: 1515992.7500 - val_mae: 975.5157\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1320689.8750 - mae: 899.3016 - val_loss: 1158466.3750 - val_mae: 834.3019\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1056183.0000 - mae: 791.1698 - val_loss: 965728.0000 - val_mae: 754.2981\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 905011.7500 - mae: 727.8990 - val_loss: 846859.4375 - val_mae: 702.9572\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 805419.5000 - mae: 684.2228 - val_loss: 763807.6875 - val_mae: 664.5335\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 733338.6875 - mae: 649.9923 - val_loss: 701774.0000 - val_mae: 634.3763\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 679093.8750 - mae: 622.7629 - val_loss: 654226.1250 - val_mae: 610.5681\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 637453.1875 - mae: 601.3169 - val_loss: 617282.0625 - val_mae: 590.9679\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 604284.5625 - mae: 583.5623 - val_loss: 587784.4375 - val_mae: 573.9099\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 577782.4375 - mae: 568.5309 - val_loss: 564432.6875 - val_mae: 560.4789\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556596.0000 - mae: 555.8143 - val_loss: 545282.5625 - val_mae: 549.4911\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 539616.2500 - mae: 546.1707 - val_loss: 530204.7500 - val_mae: 541.2191\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 526160.4375 - mae: 538.1299 - val_loss: 518295.3750 - val_mae: 533.8181\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 515518.5000 - mae: 532.2518 - val_loss: 508543.7500 - val_mae: 528.2264\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 506928.0000 - mae: 526.9393 - val_loss: 500482.6875 - val_mae: 523.5139\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 499300.6250 - mae: 522.7750 - val_loss: 493558.8125 - val_mae: 519.6643\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 492962.5312 - mae: 519.0663 - val_loss: 487694.3750 - val_mae: 517.5372\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 487099.5938 - mae: 516.2724 - val_loss: 482143.7812 - val_mae: 513.2913\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 481866.4062 - mae: 513.2596 - val_loss: 477028.4062 - val_mae: 510.3289\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 476922.6875 - mae: 510.6926 - val_loss: 472554.3438 - val_mae: 508.8441\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 472897.4375 - mae: 508.4676 - val_loss: 468547.6875 - val_mae: 507.1711\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 468583.6562 - mae: 506.1555 - val_loss: 464349.3125 - val_mae: 504.5017\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 464723.9062 - mae: 504.1783 - val_loss: 460705.5625 - val_mae: 502.7709\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 461404.4688 - mae: 502.4228 - val_loss: 457418.5000 - val_mae: 501.8588\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 458026.0625 - mae: 500.3071 - val_loss: 454070.1875 - val_mae: 499.1852\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 454790.8438 - mae: 499.0839 - val_loss: 451200.4688 - val_mae: 496.2346\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 452142.2188 - mae: 496.6782 - val_loss: 448454.3438 - val_mae: 496.5467\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 449237.8438 - mae: 495.4888 - val_loss: 445512.9062 - val_mae: 494.1924\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 446354.0938 - mae: 493.7969 - val_loss: 442835.6250 - val_mae: 491.9900\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 444155.0000 - mae: 492.7643 - val_loss: 440589.0000 - val_mae: 490.0981\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 441681.6875 - mae: 491.2097 - val_loss: 438276.9375 - val_mae: 488.9897\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 439529.5312 - mae: 489.9856 - val_loss: 436125.3438 - val_mae: 488.5768\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 437536.6562 - mae: 488.5349 - val_loss: 433901.4062 - val_mae: 486.5905\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 435413.4688 - mae: 486.9667 - val_loss: 431868.8750 - val_mae: 485.8265\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 433111.2812 - mae: 486.0847 - val_loss: 429821.5000 - val_mae: 483.9476\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 431387.0312 - mae: 484.8444 - val_loss: 428010.2500 - val_mae: 482.3484\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 429404.5000 - mae: 483.6529 - val_loss: 426205.6875 - val_mae: 481.5338\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 427780.3125 - mae: 482.1147 - val_loss: 424611.6250 - val_mae: 480.7109\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 425835.6250 - mae: 480.7084 - val_loss: 423119.4688 - val_mae: 480.6097\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 424556.1250 - mae: 480.2062 - val_loss: 421974.9688 - val_mae: 480.2810\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 423222.2812 - mae: 479.5750 - val_loss: 420812.3438 - val_mae: 476.4926\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 421895.7188 - mae: 478.6849 - val_loss: 418834.3750 - val_mae: 476.1927\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 420370.6875 - mae: 477.2200 - val_loss: 417584.1250 - val_mae: 475.9592\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 419069.7812 - mae: 476.5326 - val_loss: 416530.4688 - val_mae: 476.7841\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 417737.3438 - mae: 475.9423 - val_loss: 415154.1875 - val_mae: 474.8759\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 416311.3438 - mae: 475.2762 - val_loss: 413459.7188 - val_mae: 472.9153\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 414888.1875 - mae: 474.1450 - val_loss: 412170.0938 - val_mae: 471.5967\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 413951.8438 - mae: 472.9981 - val_loss: 410528.5312 - val_mae: 471.4276\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 412448.4062 - mae: 472.3751 - val_loss: 409126.4062 - val_mae: 470.2073\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 410589.3438 - mae: 471.0925 - val_loss: 408371.0625 - val_mae: 468.1809\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 409502.9062 - mae: 469.6845 - val_loss: 405909.3125 - val_mae: 467.9120\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 407570.0312 - mae: 468.3744 - val_loss: 404437.0312 - val_mae: 466.9593\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 406075.5312 - mae: 468.2853 - val_loss: 402754.1875 - val_mae: 465.6618\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 404236.7812 - mae: 466.6077 - val_loss: 401236.2812 - val_mae: 464.0082\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 402778.2500 - mae: 465.3175 - val_loss: 399602.4062 - val_mae: 463.7926\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 401079.8125 - mae: 464.0717 - val_loss: 398673.0625 - val_mae: 464.8000\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 399426.5938 - mae: 463.8672 - val_loss: 397741.6562 - val_mae: 460.3150\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 398399.0625 - mae: 462.1952 - val_loss: 395092.6250 - val_mae: 461.9891\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 396753.6562 - mae: 461.9596 - val_loss: 393699.8750 - val_mae: 458.9229\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 395028.5312 - mae: 459.9597 - val_loss: 392170.1875 - val_mae: 458.2012\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 393395.3125 - mae: 459.5997 - val_loss: 391091.3750 - val_mae: 457.0165\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 392475.7188 - mae: 458.7331 - val_loss: 389367.5938 - val_mae: 457.1505\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 391196.4688 - mae: 457.9636 - val_loss: 388346.1250 - val_mae: 455.4616\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 389899.5625 - mae: 456.9732 - val_loss: 386972.0938 - val_mae: 455.7367\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 388500.6250 - mae: 456.5398 - val_loss: 386064.5938 - val_mae: 455.7952\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387612.2812 - mae: 455.5995 - val_loss: 384807.9062 - val_mae: 453.5708\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 386297.7500 - mae: 454.8022 - val_loss: 383833.7812 - val_mae: 453.3320\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 385426.5625 - mae: 453.8033 - val_loss: 382735.5625 - val_mae: 452.5880\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 384200.2188 - mae: 453.8963 - val_loss: 381880.1250 - val_mae: 452.0630\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 383724.1562 - mae: 452.8117 - val_loss: 380617.2188 - val_mae: 451.7050\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 382233.8438 - mae: 451.7561 - val_loss: 380040.8438 - val_mae: 449.3017\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 381341.2500 - mae: 451.4526 - val_loss: 378566.7500 - val_mae: 450.5367\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380468.7500 - mae: 451.0409 - val_loss: 378420.7812 - val_mae: 451.9788\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 379549.7500 - mae: 450.6932 - val_loss: 376768.5312 - val_mae: 448.4792\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 378328.0312 - mae: 449.8039 - val_loss: 375980.5000 - val_mae: 449.5820\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377399.3125 - mae: 449.4551 - val_loss: 374882.0312 - val_mae: 448.5134\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 376729.9688 - mae: 448.8197 - val_loss: 373936.6875 - val_mae: 447.4767\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 375808.9688 - mae: 448.4561 - val_loss: 373312.0312 - val_mae: 447.3279\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 374817.5625 - mae: 447.6343 - val_loss: 372503.4375 - val_mae: 447.1905\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373999.2188 - mae: 447.1575 - val_loss: 371504.5312 - val_mae: 446.5365\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 373184.6562 - mae: 446.6179 - val_loss: 370884.0625 - val_mae: 444.5419\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 372363.8750 - mae: 446.0934 - val_loss: 369783.1875 - val_mae: 444.3723\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 371628.3438 - mae: 445.5587 - val_loss: 369124.5938 - val_mae: 444.7182\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 370533.3125 - mae: 444.9919 - val_loss: 368416.5938 - val_mae: 443.2392\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369917.9375 - mae: 444.4230 - val_loss: 367959.7812 - val_mae: 442.3812\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 369235.5000 - mae: 443.7075 - val_loss: 366999.9688 - val_mae: 442.4501\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 368585.0625 - mae: 443.5140 - val_loss: 366349.8750 - val_mae: 442.1793\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 368244.7812 - mae: 443.1620 - val_loss: 365497.2812 - val_mae: 441.6723\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 367146.8438 - mae: 442.5652 - val_loss: 364896.9375 - val_mae: 440.8692\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 366584.0000 - mae: 442.3317 - val_loss: 364493.5000 - val_mae: 439.5034\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 366163.6562 - mae: 441.4244 - val_loss: 363597.0625 - val_mae: 440.4921\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365236.5000 - mae: 441.4680 - val_loss: 364156.6250 - val_mae: 438.0691\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 365142.9375 - mae: 440.7526 - val_loss: 362752.4688 - val_mae: 439.3511\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 364421.7500 - mae: 440.3424 - val_loss: 362114.5938 - val_mae: 439.0010\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 363891.1250 - mae: 440.0663 - val_loss: 361817.2188 - val_mae: 438.3144\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 363305.3438 - mae: 439.8290 - val_loss: 361225.3750 - val_mae: 439.4668\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 363036.6562 - mae: 439.6943 - val_loss: 360717.0938 - val_mae: 438.6707\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 362423.0938 - mae: 439.2312 - val_loss: 359937.4062 - val_mae: 437.9131\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 361634.3438 - mae: 438.6146 - val_loss: 359843.2500 - val_mae: 439.1997\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 361464.4062 - mae: 438.7386 - val_loss: 359147.1875 - val_mae: 436.3045\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 360707.3125 - mae: 437.4866 - val_loss: 358585.8750 - val_mae: 437.1469\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 360496.2188 - mae: 438.0922 - val_loss: 358735.1562 - val_mae: 436.1923\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 360193.2500 - mae: 437.1713 - val_loss: 357677.3438 - val_mae: 436.2911\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 359672.0625 - mae: 437.1094 - val_loss: 357794.6562 - val_mae: 437.9091\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 359079.0938 - mae: 436.9811 - val_loss: 357031.3750 - val_mae: 435.0099\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 358809.0625 - mae: 436.2706 - val_loss: 356634.1562 - val_mae: 435.6611\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 358168.7500 - mae: 436.2988 - val_loss: 356751.2188 - val_mae: 433.1647\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 357917.9062 - mae: 435.4167 - val_loss: 355608.7812 - val_mae: 434.6826\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 357321.8125 - mae: 435.3341 - val_loss: 355464.7500 - val_mae: 435.3569\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 357229.1250 - mae: 435.2783 - val_loss: 354703.4375 - val_mae: 433.6807\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 356875.3125 - mae: 434.8162 - val_loss: 354443.0312 - val_mae: 434.3361\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 356500.8438 - mae: 435.0152 - val_loss: 354112.8438 - val_mae: 432.7207\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 355851.9375 - mae: 434.0365 - val_loss: 353720.7188 - val_mae: 432.3350\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 355527.5938 - mae: 433.8842 - val_loss: 353392.4375 - val_mae: 432.1670\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 355142.4062 - mae: 433.6981 - val_loss: 352921.2812 - val_mae: 432.0373\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 354897.1875 - mae: 433.3246 - val_loss: 352639.9688 - val_mae: 432.3840\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 354501.1250 - mae: 433.0237 - val_loss: 352324.7188 - val_mae: 432.7552\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 354220.6875 - mae: 432.8564 - val_loss: 351775.0000 - val_mae: 431.1581\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 353716.4375 - mae: 432.4099 - val_loss: 351403.2812 - val_mae: 431.5090\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 353164.4688 - mae: 431.8804 - val_loss: 351319.2812 - val_mae: 431.9807\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 353161.5312 - mae: 432.3251 - val_loss: 350726.1562 - val_mae: 430.9179\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 352537.1562 - mae: 431.9329 - val_loss: 350731.6875 - val_mae: 429.2642\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 352436.8125 - mae: 431.4352 - val_loss: 350017.1562 - val_mae: 429.6422\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 352108.7500 - mae: 431.0293 - val_loss: 349788.5000 - val_mae: 429.4830\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351873.2812 - mae: 431.1180 - val_loss: 349535.3750 - val_mae: 429.0009\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 351353.5312 - mae: 430.6114 - val_loss: 349159.5312 - val_mae: 429.8098\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 351106.8438 - mae: 430.6098 - val_loss: 348917.3750 - val_mae: 428.8265\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 350555.1875 - mae: 430.0015 - val_loss: 348634.0625 - val_mae: 429.3091\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 350676.3750 - mae: 430.0126 - val_loss: 348402.4062 - val_mae: 429.6559\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 350180.3750 - mae: 429.7527 - val_loss: 348288.7812 - val_mae: 427.7669\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 350059.3125 - mae: 429.6537 - val_loss: 347977.5625 - val_mae: 429.4104\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 349711.8750 - mae: 429.8208 - val_loss: 347935.5000 - val_mae: 426.9977\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 349486.5000 - mae: 429.2123 - val_loss: 347620.7500 - val_mae: 428.7748\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 349149.7188 - mae: 428.4999 - val_loss: 347325.9688 - val_mae: 428.5475\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348909.0625 - mae: 429.3547 - val_loss: 347810.5000 - val_mae: 426.2217\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348894.4688 - mae: 428.1970 - val_loss: 346549.4062 - val_mae: 427.5411\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348535.9375 - mae: 428.2259 - val_loss: 346326.3125 - val_mae: 427.1967\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348476.0312 - mae: 428.4624 - val_loss: 346073.9688 - val_mae: 426.5258\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 347878.4062 - mae: 428.0135 - val_loss: 346006.1875 - val_mae: 425.8886\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348215.8438 - mae: 427.9092 - val_loss: 345743.3125 - val_mae: 427.7598\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 347687.3750 - mae: 428.0986 - val_loss: 345897.4375 - val_mae: 425.5506\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 347378.8125 - mae: 427.4515 - val_loss: 345285.0625 - val_mae: 426.8707\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 347192.8438 - mae: 427.7158 - val_loss: 345010.9375 - val_mae: 426.2514\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 347197.6562 - mae: 427.3153 - val_loss: 344910.3438 - val_mae: 425.9036\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 346702.2812 - mae: 427.0423 - val_loss: 344761.2188 - val_mae: 427.0567\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 346473.3750 - mae: 427.1964 - val_loss: 344664.6250 - val_mae: 424.9214\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 346556.7188 - mae: 426.9591 - val_loss: 344355.5000 - val_mae: 425.0125\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 346013.2500 - mae: 426.6075 - val_loss: 344182.9688 - val_mae: 425.6678\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 346032.5625 - mae: 426.6197 - val_loss: 343780.4375 - val_mae: 425.0980\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 345699.4688 - mae: 426.5598 - val_loss: 343711.5625 - val_mae: 425.7106\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 345464.5312 - mae: 426.2456 - val_loss: 343532.6875 - val_mae: 425.0894\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 345417.1562 - mae: 426.4277 - val_loss: 343586.5625 - val_mae: 424.7690\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 345029.4375 - mae: 426.0981 - val_loss: 343123.7500 - val_mae: 424.5151\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 345022.0000 - mae: 426.1165 - val_loss: 342684.6562 - val_mae: 424.2406\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 344767.1875 - mae: 425.7572 - val_loss: 342497.6250 - val_mae: 424.1601\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 344624.5312 - mae: 425.7713 - val_loss: 342451.0000 - val_mae: 423.4811\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 344699.9375 - mae: 425.7133 - val_loss: 342212.1250 - val_mae: 423.7696\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 344102.7812 - mae: 425.1553 - val_loss: 342216.4375 - val_mae: 424.5340\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 344211.2188 - mae: 425.0472 - val_loss: 342004.7188 - val_mae: 425.0843\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 344041.2500 - mae: 425.5878 - val_loss: 341748.0312 - val_mae: 424.6572\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 343587.0625 - mae: 425.0579 - val_loss: 341613.5000 - val_mae: 423.7901\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 343612.1250 - mae: 424.9744 - val_loss: 341515.5000 - val_mae: 423.7559\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 343285.2188 - mae: 424.6283 - val_loss: 341181.5938 - val_mae: 424.1691\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 343400.7812 - mae: 424.9939 - val_loss: 341279.0000 - val_mae: 423.8603\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342968.2188 - mae: 424.5801 - val_loss: 340927.4688 - val_mae: 423.4763\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342727.9688 - mae: 424.4012 - val_loss: 340931.1250 - val_mae: 423.9781\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342871.8125 - mae: 424.4192 - val_loss: 340737.1250 - val_mae: 422.4319\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 342637.1875 - mae: 424.1860 - val_loss: 340532.7812 - val_mae: 423.3608\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342338.5312 - mae: 424.4002 - val_loss: 340294.7812 - val_mae: 423.4873\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342007.4688 - mae: 424.3258 - val_loss: 340271.0312 - val_mae: 421.6902\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342082.8750 - mae: 423.6497 - val_loss: 339963.8750 - val_mae: 422.5478\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 341986.2188 - mae: 423.8413 - val_loss: 340111.8750 - val_mae: 424.2360\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341850.0938 - mae: 424.0538 - val_loss: 339982.2812 - val_mae: 421.1630\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 341568.8438 - mae: 423.3485 - val_loss: 339482.4375 - val_mae: 422.1674\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 341410.9062 - mae: 423.6231 - val_loss: 339293.9688 - val_mae: 421.4974\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 341128.8438 - mae: 423.0479 - val_loss: 338920.6562 - val_mae: 421.7426\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340654.5312 - mae: 423.0831 - val_loss: 339190.0312 - val_mae: 421.2654\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340666.4062 - mae: 422.6797 - val_loss: 339149.1250 - val_mae: 420.5592\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 340816.8125 - mae: 422.7270 - val_loss: 338312.6250 - val_mae: 420.5525\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 340155.2188 - mae: 422.5039 - val_loss: 338582.6250 - val_mae: 419.6050\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 340188.9062 - mae: 422.2363 - val_loss: 337849.0000 - val_mae: 420.8077\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 339838.6250 - mae: 422.5549 - val_loss: 337783.6562 - val_mae: 420.1114\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339670.0312 - mae: 421.6852 - val_loss: 337613.7500 - val_mae: 421.4702\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 339434.1875 - mae: 422.2087 - val_loss: 337230.5312 - val_mae: 420.7482\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 339318.0938 - mae: 421.8123 - val_loss: 337396.7812 - val_mae: 419.6972\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 338998.8438 - mae: 421.5095 - val_loss: 337292.5625 - val_mae: 421.6506\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339192.2812 - mae: 422.2098 - val_loss: 337032.4688 - val_mae: 419.7293\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 339059.8750 - mae: 421.7021 - val_loss: 337018.2500 - val_mae: 421.7301\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338758.5312 - mae: 421.5491 - val_loss: 336700.7500 - val_mae: 421.2253\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338706.5625 - mae: 421.8046 - val_loss: 337197.0938 - val_mae: 418.9817\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 338290.3125 - mae: 420.9117 - val_loss: 336695.5938 - val_mae: 421.1838\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 338366.2500 - mae: 421.1111 - val_loss: 336750.7500 - val_mae: 421.9720\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 338111.5625 - mae: 421.2132 - val_loss: 336292.0000 - val_mae: 419.5774\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 337951.6875 - mae: 421.3092 - val_loss: 335974.2188 - val_mae: 419.0305\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337885.5000 - mae: 420.6891 - val_loss: 335673.8125 - val_mae: 420.6028\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337585.9688 - mae: 420.4334 - val_loss: 335556.0000 - val_mae: 420.4049\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337237.5000 - mae: 420.5454 - val_loss: 335577.0312 - val_mae: 418.1615\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 337054.8125 - mae: 420.3654 - val_loss: 334618.7500 - val_mae: 418.9258\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336033.9688 - mae: 419.3700 - val_loss: 335849.9688 - val_mae: 423.0803\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336217.0000 - mae: 420.6477 - val_loss: 334612.5625 - val_mae: 417.2293\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335637.0312 - mae: 419.5092 - val_loss: 333425.4062 - val_mae: 418.1306\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335485.9062 - mae: 420.0478 - val_loss: 333074.0312 - val_mae: 417.6316\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 335110.5938 - mae: 419.3489 - val_loss: 332910.6875 - val_mae: 416.9489\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 334631.6562 - mae: 419.2054 - val_loss: 332490.9688 - val_mae: 416.6325\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 334062.7812 - mae: 418.8396 - val_loss: 331933.5625 - val_mae: 418.3727\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333452.8125 - mae: 418.5033 - val_loss: 331377.1875 - val_mae: 417.8996\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 333131.9688 - mae: 418.2279 - val_loss: 330916.3125 - val_mae: 417.6874\n",
      "Epoch 216/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332577.2500 - mae: 418.0957 - val_loss: 330513.6875 - val_mae: 417.2211\n",
      "Epoch 217/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 332243.4062 - mae: 417.6207 - val_loss: 330012.8750 - val_mae: 416.8743\n",
      "Epoch 218/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 332028.9688 - mae: 418.0132 - val_loss: 329689.8750 - val_mae: 416.9996\n",
      "Epoch 219/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 331274.9375 - mae: 417.2323 - val_loss: 329376.4062 - val_mae: 415.7876\n",
      "Epoch 220/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 331026.7500 - mae: 417.3213 - val_loss: 329502.9688 - val_mae: 414.4828\n",
      "Epoch 221/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 331009.8125 - mae: 416.8283 - val_loss: 328965.0938 - val_mae: 414.8203\n",
      "Epoch 222/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 330378.8438 - mae: 416.7151 - val_loss: 328875.5938 - val_mae: 415.6968\n",
      "Epoch 223/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 330180.9062 - mae: 416.7143 - val_loss: 328254.2500 - val_mae: 414.4024\n",
      "Epoch 224/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329993.6562 - mae: 416.0922 - val_loss: 328525.2812 - val_mae: 417.2678\n",
      "Epoch 225/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 329586.9062 - mae: 416.4907 - val_loss: 327757.5625 - val_mae: 414.4801\n",
      "Epoch 226/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329317.3125 - mae: 415.7372 - val_loss: 327819.3438 - val_mae: 417.0170\n",
      "Epoch 227/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 329313.3125 - mae: 416.4243 - val_loss: 327080.0312 - val_mae: 414.3818\n",
      "Epoch 228/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328873.9688 - mae: 415.6569 - val_loss: 326819.7500 - val_mae: 414.2770\n",
      "Epoch 229/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328768.3438 - mae: 415.7559 - val_loss: 326577.1250 - val_mae: 415.1283\n",
      "Epoch 230/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 328352.4062 - mae: 415.4592 - val_loss: 326436.0625 - val_mae: 414.9693\n",
      "Epoch 231/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 328192.7188 - mae: 415.5790 - val_loss: 326232.8750 - val_mae: 413.4020\n",
      "Epoch 232/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327817.7188 - mae: 414.8767 - val_loss: 325774.4062 - val_mae: 414.3106\n",
      "Epoch 233/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 327305.5625 - mae: 414.9828 - val_loss: 325602.7500 - val_mae: 413.7043\n",
      "Epoch 234/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327170.3438 - mae: 414.7548 - val_loss: 325461.4062 - val_mae: 412.8122\n",
      "Epoch 235/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 327096.1250 - mae: 414.3704 - val_loss: 324795.4062 - val_mae: 413.6897\n",
      "Epoch 236/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 327009.5312 - mae: 414.7170 - val_loss: 324546.0312 - val_mae: 413.0812\n",
      "Epoch 237/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 326542.0625 - mae: 414.2352 - val_loss: 324323.5938 - val_mae: 412.9729\n",
      "Epoch 238/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 326234.1250 - mae: 414.1246 - val_loss: 324269.9375 - val_mae: 413.7312\n",
      "Epoch 239/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 325846.1250 - mae: 414.2560 - val_loss: 323953.7812 - val_mae: 413.0271\n",
      "Epoch 240/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325899.5938 - mae: 413.7435 - val_loss: 323856.1875 - val_mae: 414.1359\n",
      "Epoch 241/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 325364.0938 - mae: 413.5806 - val_loss: 323610.9062 - val_mae: 413.5659\n",
      "Epoch 242/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 325331.0938 - mae: 413.8994 - val_loss: 323256.0938 - val_mae: 411.8488\n",
      "Epoch 243/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325068.1250 - mae: 413.5232 - val_loss: 323206.2500 - val_mae: 411.7227\n",
      "Epoch 244/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 324903.8438 - mae: 413.1310 - val_loss: 322715.0938 - val_mae: 412.6342\n",
      "Epoch 245/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 324733.4062 - mae: 413.4136 - val_loss: 322627.7188 - val_mae: 410.9802\n",
      "Epoch 246/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324441.4688 - mae: 412.8095 - val_loss: 322448.9062 - val_mae: 412.6620\n",
      "Epoch 247/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 324366.6250 - mae: 413.1808 - val_loss: 322246.6250 - val_mae: 412.3929\n",
      "Epoch 248/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324137.1250 - mae: 412.6362 - val_loss: 321865.3438 - val_mae: 412.1349\n",
      "Epoch 249/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 323843.3125 - mae: 412.4173 - val_loss: 322545.8750 - val_mae: 413.5948\n",
      "Epoch 250/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 323686.2188 - mae: 413.0102 - val_loss: 321780.3125 - val_mae: 411.6475\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 37878748.0000 - mae: 5999.6880 - val_loss: 36200588.0000 - val_mae: 5868.3740\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 32599724.0000 - mae: 5569.3374 - val_loss: 28312572.0000 - val_mae: 5195.1689\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 23575776.0000 - mae: 4720.0566 - val_loss: 18844278.0000 - val_mae: 4200.3213\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 14786468.0000 - mae: 3655.6008 - val_loss: 11100589.0000 - val_mae: 3106.2593\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 8414877.0000 - mae: 2618.5930 - val_loss: 6136833.5000 - val_mae: 2161.3708\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 4670208.0000 - mae: 1805.1986 - val_loss: 3496028.5000 - val_mae: 1495.5292\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2816127.5000 - mae: 1297.1132 - val_loss: 2289069.2500 - val_mae: 1139.7505\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 1982659.1250 - mae: 1047.7928 - val_loss: 1728595.6250 - val_mae: 972.1690\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1556598.8750 - mae: 918.7932 - val_loss: 1402815.2500 - val_mae: 871.2885\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1285613.0000 - mae: 832.8445 - val_loss: 1176096.1250 - val_mae: 794.8159\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1091695.6250 - mae: 764.6592 - val_loss: 1007457.5000 - val_mae: 734.6048\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 942026.3750 - mae: 709.7490 - val_loss: 876580.7500 - val_mae: 683.6713\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 827006.3750 - mae: 663.6938 - val_loss: 776686.2500 - val_mae: 643.3609\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 740002.1875 - mae: 627.7700 - val_loss: 701912.8750 - val_mae: 613.6861\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 675290.8125 - mae: 602.8341 - val_loss: 645333.1875 - val_mae: 591.2819\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 626387.3750 - mae: 583.6611 - val_loss: 604115.1875 - val_mae: 574.4520\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 589776.7500 - mae: 568.6586 - val_loss: 571887.8750 - val_mae: 561.1707\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 561447.7500 - mae: 557.1528 - val_loss: 547020.0625 - val_mae: 550.7872\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 539178.9375 - mae: 547.5644 - val_loss: 526724.3750 - val_mae: 542.5932\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 520150.0625 - mae: 539.6602 - val_loss: 509465.2812 - val_mae: 535.1099\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 504979.3750 - mae: 532.8633 - val_loss: 495331.9688 - val_mae: 528.4716\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 491682.2188 - mae: 525.9507 - val_loss: 483347.5312 - val_mae: 523.1989\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 480494.7812 - mae: 521.1233 - val_loss: 473140.5938 - val_mae: 516.5680\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 470685.0000 - mae: 515.2823 - val_loss: 463968.7500 - val_mae: 513.3679\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 462327.0938 - mae: 510.8563 - val_loss: 455678.0312 - val_mae: 507.8145\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 454737.4062 - mae: 506.7165 - val_loss: 449335.5938 - val_mae: 501.7518\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 448048.2188 - mae: 502.0085 - val_loss: 442624.2812 - val_mae: 498.9866\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 442499.4062 - mae: 498.4075 - val_loss: 436976.9062 - val_mae: 495.0963\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 436996.2188 - mae: 495.1071 - val_loss: 432555.2500 - val_mae: 491.5857\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 432597.1562 - mae: 491.8973 - val_loss: 428055.3125 - val_mae: 489.7470\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 428683.7188 - mae: 489.3488 - val_loss: 424639.0625 - val_mae: 485.7972\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 425193.9688 - mae: 486.4476 - val_loss: 421668.3438 - val_mae: 482.8859\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 421893.0000 - mae: 484.2242 - val_loss: 417442.4375 - val_mae: 481.8597\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 418476.3125 - mae: 481.8086 - val_loss: 414641.4375 - val_mae: 479.5699\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 415723.7188 - mae: 480.0632 - val_loss: 411588.1250 - val_mae: 477.7288\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 412565.0625 - mae: 477.8502 - val_loss: 408824.1875 - val_mae: 476.2912\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 409443.4688 - mae: 475.6335 - val_loss: 406813.5000 - val_mae: 472.3774\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 407476.7812 - mae: 473.6459 - val_loss: 403511.5625 - val_mae: 471.4012\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 404712.6562 - mae: 471.7300 - val_loss: 401207.7812 - val_mae: 470.3521\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 402417.2500 - mae: 469.7777 - val_loss: 398704.5000 - val_mae: 467.8572\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 400141.4375 - mae: 468.0309 - val_loss: 396482.5625 - val_mae: 466.9967\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 398219.0625 - mae: 467.0359 - val_loss: 394142.8125 - val_mae: 464.5622\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 395987.7812 - mae: 465.0138 - val_loss: 392685.6875 - val_mae: 464.3613\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 393828.0938 - mae: 463.6387 - val_loss: 390642.6250 - val_mae: 462.4129\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 392162.0312 - mae: 462.6617 - val_loss: 388970.9062 - val_mae: 461.4083\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 390417.3750 - mae: 461.1004 - val_loss: 387524.1250 - val_mae: 461.2921\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 388790.5000 - mae: 460.6283 - val_loss: 385553.5000 - val_mae: 459.4410\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 387385.7500 - mae: 459.7270 - val_loss: 385119.7500 - val_mae: 455.5789\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 385673.9062 - mae: 458.2399 - val_loss: 382603.4688 - val_mae: 456.7693\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 384257.9688 - mae: 457.1712 - val_loss: 381444.2500 - val_mae: 456.1317\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 383175.5625 - mae: 456.4658 - val_loss: 380262.0000 - val_mae: 455.1628\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 382249.0625 - mae: 455.9063 - val_loss: 379036.8125 - val_mae: 452.9288\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 380798.5000 - mae: 454.8717 - val_loss: 377873.2500 - val_mae: 453.5360\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 380250.2812 - mae: 454.3112 - val_loss: 377173.7188 - val_mae: 454.4277\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 379131.9062 - mae: 454.3388 - val_loss: 375580.9062 - val_mae: 451.4192\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 377333.0625 - mae: 452.5582 - val_loss: 375193.3438 - val_mae: 450.2415\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 376653.6875 - mae: 452.3132 - val_loss: 374168.8438 - val_mae: 448.9005\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 375453.5312 - mae: 451.3544 - val_loss: 373494.5625 - val_mae: 448.2610\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 374634.1562 - mae: 449.7256 - val_loss: 372283.9375 - val_mae: 450.3731\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 373869.9062 - mae: 449.9897 - val_loss: 371752.3750 - val_mae: 450.5653\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 372853.4688 - mae: 449.6630 - val_loss: 371330.0625 - val_mae: 450.6043\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 371926.0938 - mae: 448.6823 - val_loss: 369757.5625 - val_mae: 448.3743\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 371260.2188 - mae: 448.4629 - val_loss: 368861.4375 - val_mae: 445.6653\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 370633.7500 - mae: 447.3319 - val_loss: 367768.3750 - val_mae: 446.2427\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 369633.5938 - mae: 446.8703 - val_loss: 367136.5625 - val_mae: 445.2831\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 369152.7812 - mae: 446.4674 - val_loss: 366385.6250 - val_mae: 445.8280\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 368458.5312 - mae: 445.7221 - val_loss: 365826.4375 - val_mae: 444.0445\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 367754.0625 - mae: 445.1644 - val_loss: 364859.6250 - val_mae: 444.0920\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 366614.3438 - mae: 444.9801 - val_loss: 363964.1875 - val_mae: 442.9709\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 365969.9688 - mae: 443.6890 - val_loss: 364360.2812 - val_mae: 445.3147\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 365529.0625 - mae: 444.1998 - val_loss: 362641.5312 - val_mae: 440.7289\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 364324.1250 - mae: 441.9813 - val_loss: 362725.4062 - val_mae: 443.3202\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 363881.9062 - mae: 442.5225 - val_loss: 360997.0312 - val_mae: 440.7632\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 363189.0000 - mae: 441.6679 - val_loss: 360130.5625 - val_mae: 439.1074\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 362395.1875 - mae: 441.2716 - val_loss: 359295.4375 - val_mae: 439.5420\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 361276.7812 - mae: 440.1609 - val_loss: 359010.2812 - val_mae: 438.4628\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 360879.0000 - mae: 440.1475 - val_loss: 358178.3125 - val_mae: 439.1804\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 359921.0000 - mae: 439.1312 - val_loss: 357616.7812 - val_mae: 437.5688\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 359480.9375 - mae: 438.5144 - val_loss: 356829.6562 - val_mae: 437.3147\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 358835.7188 - mae: 438.5602 - val_loss: 356229.4375 - val_mae: 435.7207\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 358218.1875 - mae: 437.2173 - val_loss: 355364.4062 - val_mae: 436.8522\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 357258.8125 - mae: 437.1396 - val_loss: 355398.6875 - val_mae: 434.5516\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 356969.7812 - mae: 436.4597 - val_loss: 353855.8750 - val_mae: 434.1766\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 356234.4062 - mae: 435.6151 - val_loss: 353375.5938 - val_mae: 433.7235\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 355457.1250 - mae: 435.5161 - val_loss: 352943.4688 - val_mae: 433.5355\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 354861.6250 - mae: 434.5307 - val_loss: 351979.6562 - val_mae: 433.1044\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 354102.7500 - mae: 434.1258 - val_loss: 352438.6250 - val_mae: 435.2899\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 353515.1250 - mae: 433.6527 - val_loss: 351105.1875 - val_mae: 431.5969\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 353134.9688 - mae: 433.4182 - val_loss: 350622.0625 - val_mae: 431.2649\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 352713.1562 - mae: 432.6481 - val_loss: 349846.1562 - val_mae: 432.0945\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 351784.8750 - mae: 432.7416 - val_loss: 349695.5938 - val_mae: 431.5047\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 351177.0000 - mae: 432.4392 - val_loss: 350940.5312 - val_mae: 429.3987\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 351099.5938 - mae: 431.8380 - val_loss: 349071.7500 - val_mae: 431.9312\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 350783.2812 - mae: 431.9268 - val_loss: 348157.3438 - val_mae: 429.9025\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 350126.2500 - mae: 431.1990 - val_loss: 347497.5938 - val_mae: 429.7421\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 349713.7812 - mae: 430.7796 - val_loss: 347655.7500 - val_mae: 429.4754\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 349296.1875 - mae: 430.8320 - val_loss: 346808.3125 - val_mae: 428.9556\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 349098.2500 - mae: 430.6962 - val_loss: 346533.1250 - val_mae: 430.3366\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348401.5938 - mae: 430.0456 - val_loss: 346046.7812 - val_mae: 428.8100\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 348201.4375 - mae: 430.1387 - val_loss: 346289.4688 - val_mae: 427.0248\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 347485.5938 - mae: 429.6763 - val_loss: 345655.0000 - val_mae: 428.4260\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 347509.1875 - mae: 429.5705 - val_loss: 344882.3750 - val_mae: 427.9849\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 346932.7812 - mae: 429.0668 - val_loss: 344343.5000 - val_mae: 426.9042\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 346522.2500 - mae: 428.2590 - val_loss: 344130.5000 - val_mae: 427.9617\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 345975.3438 - mae: 428.7379 - val_loss: 344119.9062 - val_mae: 426.2646\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 345855.6875 - mae: 427.8669 - val_loss: 343497.5938 - val_mae: 427.1586\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 345169.1562 - mae: 427.8673 - val_loss: 342999.1250 - val_mae: 426.3059\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 344781.3125 - mae: 427.2799 - val_loss: 342572.7188 - val_mae: 426.9778\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 344516.3125 - mae: 427.7620 - val_loss: 342336.5000 - val_mae: 427.1122\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 344595.0312 - mae: 427.1185 - val_loss: 341573.3125 - val_mae: 426.0182\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 343685.7500 - mae: 426.6541 - val_loss: 341525.4688 - val_mae: 425.9601\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 343904.5312 - mae: 427.0499 - val_loss: 341115.5312 - val_mae: 425.3484\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 343500.2500 - mae: 426.4913 - val_loss: 340709.3125 - val_mae: 424.3708\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342826.8125 - mae: 425.9913 - val_loss: 340335.9062 - val_mae: 424.6154\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 342585.6250 - mae: 426.1153 - val_loss: 339930.5938 - val_mae: 424.1207\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342078.4062 - mae: 425.4282 - val_loss: 340280.6875 - val_mae: 424.9129\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 342269.2500 - mae: 425.4980 - val_loss: 339378.8750 - val_mae: 424.5841\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 341408.8125 - mae: 425.4187 - val_loss: 339226.2188 - val_mae: 423.9944\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 341192.7188 - mae: 425.0628 - val_loss: 338747.5938 - val_mae: 423.5413\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340959.3750 - mae: 424.9447 - val_loss: 338906.8438 - val_mae: 425.0816\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340962.6875 - mae: 425.0999 - val_loss: 338417.6875 - val_mae: 422.8831\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340240.2500 - mae: 423.9092 - val_loss: 338657.0938 - val_mae: 425.5991\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 340229.3125 - mae: 424.6465 - val_loss: 337869.6250 - val_mae: 423.1129\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339694.6562 - mae: 423.8103 - val_loss: 337936.6875 - val_mae: 424.6183\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 340087.4062 - mae: 424.5529 - val_loss: 337245.3750 - val_mae: 421.7928\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339423.5938 - mae: 423.7025 - val_loss: 337129.5938 - val_mae: 422.7274\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 339261.0000 - mae: 423.9966 - val_loss: 336921.1562 - val_mae: 423.2512\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 339090.6875 - mae: 423.9875 - val_loss: 337010.8750 - val_mae: 421.0540\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 338751.8125 - mae: 422.8648 - val_loss: 336551.1875 - val_mae: 422.8116\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 338488.1562 - mae: 423.3171 - val_loss: 336495.4062 - val_mae: 421.6093\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 338273.2500 - mae: 422.9984 - val_loss: 335965.8750 - val_mae: 421.7952\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 338154.2812 - mae: 423.0348 - val_loss: 335972.0312 - val_mae: 420.6497\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 338019.5000 - mae: 423.1158 - val_loss: 335428.6875 - val_mae: 421.7641\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337316.2500 - mae: 422.2324 - val_loss: 335459.4375 - val_mae: 422.9623\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337394.2812 - mae: 422.5601 - val_loss: 335879.5312 - val_mae: 423.8707\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337561.5938 - mae: 423.0222 - val_loss: 334816.3750 - val_mae: 421.9826\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336976.5312 - mae: 422.4483 - val_loss: 335095.5000 - val_mae: 420.3970\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 337195.8750 - mae: 422.2880 - val_loss: 334665.5625 - val_mae: 421.3145\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 336757.5625 - mae: 422.2216 - val_loss: 334541.8125 - val_mae: 421.4192\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 336576.6250 - mae: 421.9932 - val_loss: 334015.8438 - val_mae: 420.8083\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 336203.4375 - mae: 421.8959 - val_loss: 334077.8750 - val_mae: 420.9857\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 336172.8750 - mae: 421.9993 - val_loss: 333672.1875 - val_mae: 421.1067\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335881.8125 - mae: 421.9281 - val_loss: 333453.7188 - val_mae: 420.7834\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335828.7812 - mae: 421.6075 - val_loss: 333371.6250 - val_mae: 420.8055\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 335507.4062 - mae: 421.5971 - val_loss: 333160.3125 - val_mae: 420.6182\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 335299.3750 - mae: 421.5643 - val_loss: 332797.9375 - val_mae: 421.1218\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 334841.8125 - mae: 421.1519 - val_loss: 332656.1562 - val_mae: 420.0188\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 334673.5000 - mae: 421.5811 - val_loss: 332522.4062 - val_mae: 419.9644\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 334763.3750 - mae: 421.0372 - val_loss: 332227.7188 - val_mae: 420.9144\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 334444.0625 - mae: 421.2330 - val_loss: 331974.4688 - val_mae: 420.9684\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 333950.7500 - mae: 421.0018 - val_loss: 331667.7812 - val_mae: 420.8850\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 333791.4375 - mae: 420.7349 - val_loss: 331777.7188 - val_mae: 421.4118\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 333289.0625 - mae: 421.2723 - val_loss: 331245.8125 - val_mae: 418.1092\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 332843.8125 - mae: 420.1854 - val_loss: 330498.2500 - val_mae: 419.0598\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 332589.7188 - mae: 420.5837 - val_loss: 330124.4375 - val_mae: 419.4734\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 332152.9688 - mae: 420.3925 - val_loss: 329951.0938 - val_mae: 419.0774\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 332059.6250 - mae: 420.2297 - val_loss: 329386.0625 - val_mae: 419.0995\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 331473.3438 - mae: 419.8661 - val_loss: 329444.2188 - val_mae: 417.5270\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 331420.5312 - mae: 419.9427 - val_loss: 329211.3750 - val_mae: 417.3723\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 331037.3125 - mae: 419.4391 - val_loss: 328688.2500 - val_mae: 418.9538\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 330570.1562 - mae: 419.1929 - val_loss: 328901.0312 - val_mae: 417.5993\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 330651.8750 - mae: 419.5659 - val_loss: 328668.3125 - val_mae: 417.5368\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 329710.3438 - mae: 418.8651 - val_loss: 330360.5312 - val_mae: 415.7640\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 329718.5312 - mae: 418.2619 - val_loss: 327841.4062 - val_mae: 419.0195\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 329648.1562 - mae: 418.7528 - val_loss: 327628.8750 - val_mae: 418.6062\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 329520.0625 - mae: 418.3286 - val_loss: 327351.5938 - val_mae: 418.8444\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 329296.3438 - mae: 418.5524 - val_loss: 326992.6250 - val_mae: 417.0237\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328872.7812 - mae: 418.1663 - val_loss: 326945.1875 - val_mae: 415.7716\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 328830.7812 - mae: 418.2376 - val_loss: 326290.5312 - val_mae: 416.2476\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 328579.4688 - mae: 417.7297 - val_loss: 326443.6875 - val_mae: 418.2644\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 328400.9062 - mae: 417.9380 - val_loss: 325943.6250 - val_mae: 415.8961\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 327806.5625 - mae: 417.3257 - val_loss: 326479.9688 - val_mae: 414.3561\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 327849.9688 - mae: 417.1248 - val_loss: 325788.0000 - val_mae: 417.3315\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327686.4375 - mae: 417.0154 - val_loss: 325318.9375 - val_mae: 416.2849\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327311.8438 - mae: 416.8416 - val_loss: 325098.8750 - val_mae: 416.2985\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 327374.0000 - mae: 417.0008 - val_loss: 324826.3438 - val_mae: 414.7828\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326870.8438 - mae: 416.4114 - val_loss: 325085.8438 - val_mae: 416.0417\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 327099.9688 - mae: 416.5818 - val_loss: 324403.6250 - val_mae: 415.3323\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 326736.3125 - mae: 416.5714 - val_loss: 324354.2188 - val_mae: 415.2622\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 326411.4062 - mae: 416.1302 - val_loss: 324996.1562 - val_mae: 413.9844\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 326154.9375 - mae: 416.6938 - val_loss: 324298.1875 - val_mae: 413.7312\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325841.9062 - mae: 415.7899 - val_loss: 324314.0312 - val_mae: 416.1589\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 326020.0625 - mae: 416.3826 - val_loss: 324202.3125 - val_mae: 413.2866\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325811.1250 - mae: 416.0146 - val_loss: 323396.5000 - val_mae: 414.8206\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 325443.5312 - mae: 415.6119 - val_loss: 323783.8438 - val_mae: 416.3077\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325438.8438 - mae: 415.7094 - val_loss: 323376.2812 - val_mae: 414.5232\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 325266.4062 - mae: 415.3512 - val_loss: 322930.5000 - val_mae: 413.5554\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324795.3125 - mae: 414.9951 - val_loss: 322768.9062 - val_mae: 412.8444\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324453.3125 - mae: 415.0715 - val_loss: 323719.7188 - val_mae: 416.3473\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324861.6875 - mae: 415.1966 - val_loss: 322528.9062 - val_mae: 412.8018\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324400.4688 - mae: 414.4913 - val_loss: 322114.3438 - val_mae: 412.6872\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324393.0938 - mae: 414.5121 - val_loss: 322459.2500 - val_mae: 414.2953\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 324274.1250 - mae: 414.4740 - val_loss: 321655.2188 - val_mae: 412.9965\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 323998.8438 - mae: 414.3154 - val_loss: 322199.1562 - val_mae: 414.4302\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 323700.1562 - mae: 414.5711 - val_loss: 321380.9062 - val_mae: 412.3301\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 323831.5625 - mae: 414.2596 - val_loss: 321426.5000 - val_mae: 414.0113\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 323455.8125 - mae: 414.0812 - val_loss: 321100.0938 - val_mae: 412.2978\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 323212.3438 - mae: 413.3442 - val_loss: 320952.1250 - val_mae: 413.6112\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 322884.4062 - mae: 413.7884 - val_loss: 320802.1562 - val_mae: 412.0618\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 322668.2188 - mae: 413.2786 - val_loss: 320848.5000 - val_mae: 413.4961\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 322937.1250 - mae: 413.8294 - val_loss: 320774.4062 - val_mae: 412.1653\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 322756.4062 - mae: 413.3948 - val_loss: 320707.8750 - val_mae: 412.5905\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 322398.9375 - mae: 413.1472 - val_loss: 320290.9688 - val_mae: 411.7168\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 322163.5625 - mae: 413.1032 - val_loss: 319980.6250 - val_mae: 410.7246\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 322016.4375 - mae: 412.7107 - val_loss: 319904.6875 - val_mae: 412.3145\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 321460.2500 - mae: 412.4502 - val_loss: 319953.0938 - val_mae: 412.6696\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 321672.8438 - mae: 412.8581 - val_loss: 319523.9688 - val_mae: 409.8911\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 321591.9062 - mae: 411.8425 - val_loss: 319444.1875 - val_mae: 411.7565\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 321410.1875 - mae: 411.7776 - val_loss: 319297.2188 - val_mae: 411.8791\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 321357.1250 - mae: 412.4506 - val_loss: 319107.5938 - val_mae: 410.5962\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 321058.3750 - mae: 411.9286 - val_loss: 318934.5312 - val_mae: 411.2986\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 320876.8125 - mae: 411.3121 - val_loss: 319102.5625 - val_mae: 412.5272\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 320597.3438 - mae: 411.5883 - val_loss: 318367.6875 - val_mae: 409.4740\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 320552.8125 - mae: 411.0501 - val_loss: 318851.8125 - val_mae: 412.6873\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 320569.8750 - mae: 412.0845 - val_loss: 319003.6250 - val_mae: 408.3962\n",
      "Epoch 216/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 320338.5625 - mae: 411.2571 - val_loss: 318676.5000 - val_mae: 409.2041\n",
      "Epoch 217/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 320808.8438 - mae: 410.8282 - val_loss: 318096.7812 - val_mae: 410.4799\n",
      "Epoch 218/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 320053.0625 - mae: 411.0886 - val_loss: 318067.5938 - val_mae: 409.1639\n",
      "Epoch 219/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 319984.4062 - mae: 410.9396 - val_loss: 317940.8125 - val_mae: 410.7190\n",
      "Epoch 220/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 320050.1562 - mae: 410.7167 - val_loss: 317784.2812 - val_mae: 410.7429\n",
      "Epoch 221/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 319787.7500 - mae: 410.8944 - val_loss: 317746.2812 - val_mae: 408.5283\n",
      "Epoch 222/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 319766.5312 - mae: 411.0309 - val_loss: 317682.5312 - val_mae: 408.0436\n",
      "Epoch 223/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 319519.5000 - mae: 410.6756 - val_loss: 317352.8125 - val_mae: 409.4276\n",
      "Epoch 224/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 319489.7188 - mae: 410.5481 - val_loss: 317356.3438 - val_mae: 409.9641\n",
      "Epoch 225/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 319240.0312 - mae: 410.5021 - val_loss: 317301.1250 - val_mae: 408.4981\n",
      "Epoch 226/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 319196.4062 - mae: 410.5416 - val_loss: 317329.0312 - val_mae: 407.9332\n",
      "Epoch 227/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318997.8125 - mae: 409.8389 - val_loss: 317054.0312 - val_mae: 409.7343\n",
      "Epoch 228/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318998.4375 - mae: 410.0522 - val_loss: 316890.0312 - val_mae: 408.3128\n",
      "Epoch 229/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 319026.5312 - mae: 410.2757 - val_loss: 316764.6875 - val_mae: 407.9971\n",
      "Epoch 230/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318904.1875 - mae: 409.9751 - val_loss: 316533.4062 - val_mae: 408.8113\n",
      "Epoch 231/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318636.3438 - mae: 409.7932 - val_loss: 316754.5312 - val_mae: 410.3340\n",
      "Epoch 232/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318935.4375 - mae: 410.1899 - val_loss: 316522.5000 - val_mae: 407.6263\n",
      "Epoch 233/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318679.4375 - mae: 409.6613 - val_loss: 316135.6875 - val_mae: 408.6944\n",
      "Epoch 234/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318188.7500 - mae: 409.4276 - val_loss: 316323.0312 - val_mae: 407.8230\n",
      "Epoch 235/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318433.8125 - mae: 409.6491 - val_loss: 316228.0312 - val_mae: 408.1155\n",
      "Epoch 236/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318509.3125 - mae: 409.4185 - val_loss: 316219.2500 - val_mae: 409.0202\n",
      "Epoch 237/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318203.5938 - mae: 409.6203 - val_loss: 316861.0000 - val_mae: 406.8616\n",
      "Epoch 238/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 318189.1250 - mae: 409.4021 - val_loss: 316491.4688 - val_mae: 406.2657\n",
      "Epoch 239/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318015.4062 - mae: 409.3499 - val_loss: 316302.2500 - val_mae: 406.8307\n",
      "Epoch 240/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 317794.6562 - mae: 408.9518 - val_loss: 315931.8125 - val_mae: 407.8451\n",
      "Epoch 241/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318217.8438 - mae: 409.4352 - val_loss: 316382.0000 - val_mae: 410.6245\n",
      "Epoch 242/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 317843.9062 - mae: 408.8960 - val_loss: 316057.8438 - val_mae: 409.8484\n",
      "Epoch 243/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 318211.1250 - mae: 409.8608 - val_loss: 315511.2500 - val_mae: 407.3083\n",
      "Epoch 244/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 317692.0000 - mae: 408.7538 - val_loss: 315176.3750 - val_mae: 407.3597\n",
      "Epoch 245/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 317610.1250 - mae: 408.6331 - val_loss: 315604.2812 - val_mae: 408.1695\n",
      "Epoch 246/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 317531.0000 - mae: 409.0682 - val_loss: 315118.1562 - val_mae: 407.0379\n",
      "Epoch 247/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 316986.8750 - mae: 408.7248 - val_loss: 315720.7500 - val_mae: 408.7680\n",
      "Epoch 248/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 317416.5312 - mae: 408.4608 - val_loss: 314999.1562 - val_mae: 408.4346\n"
     ]
    }
   ],
   "source": [
    "# MBGD - mse + adam\n",
    "\n",
    "result34_adam_dict = {\n",
    "    'units': [],\n",
    "    'batch_size': [],\n",
    "    'learning_rate': [],\n",
    "    'minimum_mae_error': []\n",
    "}\n",
    "\n",
    "for units in para_dict['hidden_units']:\n",
    "    for b_size in para_dict['batch_size']:\n",
    "        for rate in para_dict['learning_rate'][0]:\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor = 'val_mae',\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "            optimizer = Adam(learning_rate = rate)\n",
    "\n",
    "            model = create_model(columns = x_columns, units = units, loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "            best_model = model.fit(\n",
    "                x_train, y_train,\n",
    "                validation_data = (x_test, y_test),\n",
    "                batch_size = b_size,\n",
    "                epochs = 250,\n",
    "                callbacks = [early_stopping]\n",
    "            )\n",
    "\n",
    "            min_mae = early_stopping.best\n",
    "\n",
    "            result34_adam_dict['units'].append(units)\n",
    "            result34_adam_dict['batch_size'].append(b_size)\n",
    "            result34_adam_dict['learning_rate'].append(rate)\n",
    "            result34_adam_dict['minimum_mae_error'].append(min_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>minimum_mae_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>408.229248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>414.667053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>412.822906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>418.612244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>428.128174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>420.930450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>414.882843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>426.731384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>409.880554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>406.201569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>412.138977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>415.600342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>405.049316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>398.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>404.449554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>412.989960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>410.980225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>406.265686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  batch_size  learning_rate  minimum_mae_error\n",
       "0       7          16          0.008         408.229248\n",
       "1       7          16          0.010         414.667053\n",
       "2       7          32          0.008         412.822906\n",
       "3       7          32          0.010         418.612244\n",
       "4       7          64          0.008         428.128174\n",
       "5       7          64          0.010         420.930450\n",
       "6       8          16          0.008         414.882843\n",
       "7       8          16          0.010         426.731384\n",
       "8       8          32          0.008         409.880554\n",
       "9       8          32          0.010         406.201569\n",
       "10      8          64          0.008         412.138977\n",
       "11      8          64          0.010         415.600342\n",
       "12      9          16          0.008         405.049316\n",
       "13      9          16          0.010         398.260956\n",
       "14      9          32          0.008         404.449554\n",
       "15      9          32          0.010         412.989960\n",
       "16      9          64          0.008         410.980225\n",
       "17      9          64          0.010         406.265686"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result34_adam_df = pd.DataFrame(result34_adam_dict)\n",
    "\n",
    "result34_adam_df.to_csv('result34_adam.csv')\n",
    "\n",
    "result34_adam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>01 TO 03</th>\n",
       "      <th>22 TO 24</th>\n",
       "      <th>25 TO 27</th>\n",
       "      <th>28 TO 30</th>\n",
       "      <th>34 TO 36</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "      <th>resale_price_per_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.377567</td>\n",
       "      <td>93.166667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6410.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.371036</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5186.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.430421</td>\n",
       "      <td>71.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5335.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.352865</td>\n",
       "      <td>94.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6691.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.371233</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5476.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>1.341138</td>\n",
       "      <td>48.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4908.045977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>1.329478</td>\n",
       "      <td>57.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5176.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>1.389799</td>\n",
       "      <td>91.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6246.107527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>1.338132</td>\n",
       "      <td>76.416667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5709.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>1.390053</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6145.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13811 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat  remaining_lease   DBSS  Model A  New Generation  Type S1  \\\n",
       "0      1.377567        93.166667  False    False           False    False   \n",
       "1      1.371036        60.833333  False    False            True    False   \n",
       "2      1.430421        71.083333  False    False           False    False   \n",
       "3      1.352865        94.833333  False     True           False    False   \n",
       "4      1.371233        61.000000  False    False           False    False   \n",
       "...         ...              ...    ...      ...             ...      ...   \n",
       "13806  1.341138        48.833333  False    False           False    False   \n",
       "13807  1.329478        57.083333  False    False            True    False   \n",
       "13808  1.389799        91.833333  False     True           False    False   \n",
       "13809  1.338132        76.416667  False    False           False    False   \n",
       "13810  1.390053        88.916667  False    False           False    False   \n",
       "\n",
       "       01 TO 03  22 TO 24  25 TO 27  28 TO 30  34 TO 36  BUKIT MERAH  \\\n",
       "0         False     False     False     False     False        False   \n",
       "1          True     False     False     False     False        False   \n",
       "2         False     False     False     False     False        False   \n",
       "3         False     False     False     False     False        False   \n",
       "4         False     False     False     False     False        False   \n",
       "...         ...       ...       ...       ...       ...          ...   \n",
       "13806      True     False     False     False     False        False   \n",
       "13807     False     False     False     False     False        False   \n",
       "13808     False     False     False     False     False        False   \n",
       "13809     False     False     False     False     False        False   \n",
       "13810     False     False     False     False     False        False   \n",
       "\n",
       "       CENTRAL AREA  QUEENSTOWN  WOODLANDS  resale_price_per_sqm  \n",
       "0             False       False      False           6410.714286  \n",
       "1             False       False      False           5186.813187  \n",
       "2             False       False       True           5335.365854  \n",
       "3             False       False      False           6691.176471  \n",
       "4             False       False      False           5476.190476  \n",
       "...             ...         ...        ...                   ...  \n",
       "13806         False       False      False           4908.045977  \n",
       "13807         False       False      False           5176.470588  \n",
       "13808         False       False      False           6246.107527  \n",
       "13809         False       False      False           5709.090909  \n",
       "13810         False       False      False           6145.833333  \n",
       "\n",
       "[13811 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model 6\n",
    "'''\n",
    "\n",
    "train = pd.read_csv('full_hdb_perSqm_train_f16.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "test = pd.read_csv('full_hdb_perSqm_test_f16.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13811 entries, 0 to 13810\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   lat              13811 non-null  float64\n",
      " 1   remaining_lease  13811 non-null  float64\n",
      " 2   DBSS             13811 non-null  bool   \n",
      " 3   Model A          13811 non-null  bool   \n",
      " 4   New Generation   13811 non-null  bool   \n",
      " 5   Type S1          13811 non-null  bool   \n",
      " 6   01 TO 03         13811 non-null  bool   \n",
      " 7   22 TO 24         13811 non-null  bool   \n",
      " 8   25 TO 27         13811 non-null  bool   \n",
      " 9   28 TO 30         13811 non-null  bool   \n",
      " 10  34 TO 36         13811 non-null  bool   \n",
      " 11  BUKIT MERAH      13811 non-null  bool   \n",
      " 12  CENTRAL AREA     13811 non-null  bool   \n",
      " 13  QUEENSTOWN       13811 non-null  bool   \n",
      " 14  WOODLANDS        13811 non-null  bool   \n",
      "dtypes: bool(13), float64(2)\n",
      "memory usage: 391.3 KB\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "y_train = train['resale_price_per_sqm']\n",
    "x_train = train.drop(['resale_price_per_sqm'], axis = 1)\n",
    "\n",
    "# test set\n",
    "y_test = test['resale_price_per_sqm']\n",
    "x_test = test.drop(['resale_price_per_sqm'], axis = 1).astype(float)\n",
    "\n",
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>DBSS</th>\n",
       "      <th>Model A</th>\n",
       "      <th>New Generation</th>\n",
       "      <th>Type S1</th>\n",
       "      <th>01 TO 03</th>\n",
       "      <th>22 TO 24</th>\n",
       "      <th>25 TO 27</th>\n",
       "      <th>28 TO 30</th>\n",
       "      <th>34 TO 36</th>\n",
       "      <th>BUKIT MERAH</th>\n",
       "      <th>CENTRAL AREA</th>\n",
       "      <th>QUEENSTOWN</th>\n",
       "      <th>WOODLANDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156048</td>\n",
       "      <td>1.261190</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007990</td>\n",
       "      <td>-0.878525</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>2.772393</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>2.218645</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.354411</td>\n",
       "      <td>-0.200213</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>3.268705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.404001</td>\n",
       "      <td>1.371485</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.225188</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012449</td>\n",
       "      <td>-0.867495</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>-0.669887</td>\n",
       "      <td>-1.672645</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>2.218645</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>-0.934243</td>\n",
       "      <td>-1.126687</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>2.772393</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>0.433403</td>\n",
       "      <td>1.172955</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>1.225188</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>-0.738033</td>\n",
       "      <td>0.152730</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>0.439144</td>\n",
       "      <td>0.979939</td>\n",
       "      <td>-0.113286</td>\n",
       "      <td>-0.816201</td>\n",
       "      <td>-0.360699</td>\n",
       "      <td>-0.039943</td>\n",
       "      <td>-0.450726</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.100095</td>\n",
       "      <td>-0.076808</td>\n",
       "      <td>-0.057808</td>\n",
       "      <td>-0.198981</td>\n",
       "      <td>-0.082337</td>\n",
       "      <td>-0.159825</td>\n",
       "      <td>-0.305932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13811 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat  remaining_lease      DBSS   Model A  New Generation  \\\n",
       "0      0.156048         1.261190 -0.113286 -0.816201       -0.360699   \n",
       "1      0.007990        -0.878525 -0.113286 -0.816201        2.772393   \n",
       "2      1.354411        -0.200213 -0.113286 -0.816201       -0.360699   \n",
       "3     -0.404001         1.371485 -0.113286  1.225188       -0.360699   \n",
       "4      0.012449        -0.867495 -0.113286 -0.816201       -0.360699   \n",
       "...         ...              ...       ...       ...             ...   \n",
       "13806 -0.669887        -1.672645 -0.113286 -0.816201       -0.360699   \n",
       "13807 -0.934243        -1.126687 -0.113286 -0.816201        2.772393   \n",
       "13808  0.433403         1.172955 -0.113286  1.225188       -0.360699   \n",
       "13809 -0.738033         0.152730 -0.113286 -0.816201       -0.360699   \n",
       "13810  0.439144         0.979939 -0.113286 -0.816201       -0.360699   \n",
       "\n",
       "        Type S1  01 TO 03  22 TO 24  25 TO 27  28 TO 30  34 TO 36  \\\n",
       "0     -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "1     -0.039943  2.218645 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "2     -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "3     -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "4     -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "13806 -0.039943  2.218645 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "13807 -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "13808 -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "13809 -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "13810 -0.039943 -0.450726 -0.115237 -0.100095 -0.076808 -0.057808   \n",
       "\n",
       "       BUKIT MERAH  CENTRAL AREA  QUEENSTOWN  WOODLANDS  \n",
       "0        -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "1        -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "2        -0.198981     -0.082337   -0.159825   3.268705  \n",
       "3        -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "4        -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "...            ...           ...         ...        ...  \n",
       "13806    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "13807    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "13808    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "13809    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "13810    -0.198981     -0.082337   -0.159825  -0.305932  \n",
       "\n",
       "[13811 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_columns = list(train.columns)\n",
    "x_columns.remove('resale_price_per_sqm')\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns = x_columns)\n",
    "\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "x_test = pd.DataFrame(x_test, columns = x_columns)\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4258.7407 - mae: 4258.7407 - val_loss: 623.5948 - val_mae: 623.5948\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 614.2745 - mae: 614.2745 - val_loss: 632.7156 - val_mae: 632.7156\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610.3431 - mae: 610.3431 - val_loss: 611.3502 - val_mae: 611.3502\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 604.3668 - mae: 604.3668 - val_loss: 607.3942 - val_mae: 607.3942\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595.8400 - mae: 595.8400 - val_loss: 587.9836 - val_mae: 587.9836\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 581.7444 - mae: 581.7444 - val_loss: 568.5511 - val_mae: 568.5511\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 567.0915 - mae: 567.0915 - val_loss: 566.2225 - val_mae: 566.2225\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 562.6420 - mae: 562.6420 - val_loss: 560.5603 - val_mae: 560.5603\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560.4926 - mae: 560.4926 - val_loss: 561.6511 - val_mae: 561.6511\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558.6776 - mae: 558.6776 - val_loss: 555.4656 - val_mae: 555.4656\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557.8155 - mae: 557.8155 - val_loss: 554.8011 - val_mae: 554.8011\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 559.0577 - mae: 559.0577 - val_loss: 557.9356 - val_mae: 557.9356\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557.5156 - mae: 557.5156 - val_loss: 571.2706 - val_mae: 571.2706\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557.5164 - mae: 557.5164 - val_loss: 586.8207 - val_mae: 586.8207\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557.5632 - mae: 557.5632 - val_loss: 564.7343 - val_mae: 564.7343\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.7410 - mae: 555.7410 - val_loss: 578.6649 - val_mae: 578.6649\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556.1702 - mae: 556.1702 - val_loss: 562.2880 - val_mae: 562.2880\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554.5281 - mae: 554.5281 - val_loss: 554.1741 - val_mae: 554.1741\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.1100 - mae: 553.1100 - val_loss: 548.8837 - val_mae: 548.8837\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 553.0323 - mae: 553.0323 - val_loss: 555.7572 - val_mae: 555.7572\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 550.4134 - mae: 550.4134 - val_loss: 546.4071 - val_mae: 546.4071\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.0956 - mae: 551.0956 - val_loss: 554.7112 - val_mae: 554.7112\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.2020 - mae: 549.2020 - val_loss: 553.7444 - val_mae: 553.7444\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.8367 - mae: 547.8367 - val_loss: 541.1191 - val_mae: 541.1191\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546.3019 - mae: 546.3019 - val_loss: 539.9834 - val_mae: 539.9834\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.4886 - mae: 545.4886 - val_loss: 543.0972 - val_mae: 543.0972\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544.1519 - mae: 544.1519 - val_loss: 536.8217 - val_mae: 536.8217\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 543.3909 - mae: 543.3909 - val_loss: 538.9917 - val_mae: 538.9917\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 542.5414 - mae: 542.5414 - val_loss: 534.6881 - val_mae: 534.6881\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.4423 - mae: 541.4423 - val_loss: 537.3539 - val_mae: 537.3539\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.4589 - mae: 540.4589 - val_loss: 537.6345 - val_mae: 537.6345\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.2040 - mae: 540.2040 - val_loss: 540.6771 - val_mae: 540.6771\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.3024 - mae: 540.3024 - val_loss: 541.0331 - val_mae: 541.0331\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.7985 - mae: 537.7985 - val_loss: 550.9412 - val_mae: 550.9412\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.4243 - mae: 537.4243 - val_loss: 539.6143 - val_mae: 539.6143\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.1243 - mae: 537.1243 - val_loss: 536.2121 - val_mae: 536.2121\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.5823 - mae: 536.5823 - val_loss: 547.4996 - val_mae: 547.4996\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.3558 - mae: 536.3558 - val_loss: 529.7016 - val_mae: 529.7016\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.2794 - mae: 534.2794 - val_loss: 534.1967 - val_mae: 534.1967\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.3609 - mae: 534.3609 - val_loss: 536.3861 - val_mae: 536.3861\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.2534 - mae: 534.2534 - val_loss: 543.6894 - val_mae: 543.6894\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.2023 - mae: 533.2023 - val_loss: 546.0745 - val_mae: 546.0745\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.2028 - mae: 532.2028 - val_loss: 536.4965 - val_mae: 536.4965\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.5140 - mae: 532.5140 - val_loss: 537.6545 - val_mae: 537.6545\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.3410 - mae: 532.3410 - val_loss: 535.6837 - val_mae: 535.6837\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 532.8672 - mae: 532.8672 - val_loss: 535.2587 - val_mae: 535.2587\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.6525 - mae: 531.6525 - val_loss: 527.6043 - val_mae: 527.6043\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.1442 - mae: 531.1442 - val_loss: 543.6693 - val_mae: 543.6693\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.9399 - mae: 530.9399 - val_loss: 529.0410 - val_mae: 529.0410\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.2825 - mae: 530.2825 - val_loss: 545.0100 - val_mae: 545.0100\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.2291 - mae: 531.2291 - val_loss: 535.9344 - val_mae: 535.9344\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.8380 - mae: 530.8380 - val_loss: 534.5760 - val_mae: 534.5760\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.6706 - mae: 530.6706 - val_loss: 527.4696 - val_mae: 527.4696\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.6548 - mae: 530.6548 - val_loss: 540.6437 - val_mae: 540.6437\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.6355 - mae: 530.6355 - val_loss: 536.2475 - val_mae: 536.2475\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.3206 - mae: 531.3206 - val_loss: 542.8515 - val_mae: 542.8515\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 530.6658 - mae: 530.6658 - val_loss: 531.7040 - val_mae: 531.7040\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.7270 - mae: 530.7270 - val_loss: 527.8596 - val_mae: 527.8596\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.5745 - mae: 530.5745 - val_loss: 534.2715 - val_mae: 534.2715\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.1534 - mae: 529.1534 - val_loss: 533.4604 - val_mae: 533.4604\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.9849 - mae: 528.9849 - val_loss: 536.4390 - val_mae: 536.4390\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.0153 - mae: 531.0153 - val_loss: 525.0858 - val_mae: 525.0858\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.8240 - mae: 529.8240 - val_loss: 531.6331 - val_mae: 531.6331\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 530.3719 - mae: 530.3719 - val_loss: 538.4481 - val_mae: 538.4481\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.4153 - mae: 529.4153 - val_loss: 526.8934 - val_mae: 526.8934\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.9681 - mae: 528.9681 - val_loss: 540.5773 - val_mae: 540.5773\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.6267 - mae: 529.6267 - val_loss: 539.3934 - val_mae: 539.3934\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.7348 - mae: 530.7348 - val_loss: 529.7706 - val_mae: 529.7706\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.7986 - mae: 529.7986 - val_loss: 534.6315 - val_mae: 534.6315\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.9849 - mae: 529.9849 - val_loss: 528.4921 - val_mae: 528.4921\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.0009 - mae: 529.0009 - val_loss: 549.6020 - val_mae: 549.6020\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.4472 - mae: 530.4472 - val_loss: 526.5512 - val_mae: 526.5512\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3612.8662 - mae: 3612.8662 - val_loss: 622.1835 - val_mae: 622.1835\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 613.4112 - mae: 613.4112 - val_loss: 619.8937 - val_mae: 619.8937\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599.7585 - mae: 599.7585 - val_loss: 602.2457 - val_mae: 602.2457\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584.3377 - mae: 584.3377 - val_loss: 566.9043 - val_mae: 566.9043\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 569.0930 - mae: 569.0930 - val_loss: 572.4718 - val_mae: 572.4718\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560.0725 - mae: 560.0725 - val_loss: 558.9526 - val_mae: 558.9526\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554.9825 - mae: 554.9825 - val_loss: 563.0632 - val_mae: 563.0632\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.3555 - mae: 552.3555 - val_loss: 553.7038 - val_mae: 553.7038\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.8864 - mae: 547.8864 - val_loss: 557.2944 - val_mae: 557.2944\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546.3600 - mae: 546.3600 - val_loss: 548.9848 - val_mae: 548.9848\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 542.8593 - mae: 542.8593 - val_loss: 543.3302 - val_mae: 543.3302\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.3821 - mae: 541.3821 - val_loss: 534.2115 - val_mae: 534.2115\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.5642 - mae: 541.5642 - val_loss: 539.5504 - val_mae: 539.5504\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.5969 - mae: 538.5969 - val_loss: 544.0074 - val_mae: 544.0074\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.9398 - mae: 540.9398 - val_loss: 551.4865 - val_mae: 551.4865\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.8744 - mae: 538.8744 - val_loss: 539.3454 - val_mae: 539.3454\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.7181 - mae: 537.7181 - val_loss: 532.6315 - val_mae: 532.6315\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.9374 - mae: 536.9374 - val_loss: 537.1655 - val_mae: 537.1655\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.0574 - mae: 538.0574 - val_loss: 534.0549 - val_mae: 534.0549\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.6671 - mae: 535.6671 - val_loss: 530.4968 - val_mae: 530.4968\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.8674 - mae: 534.8674 - val_loss: 535.9412 - val_mae: 535.9412\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.3720 - mae: 533.3720 - val_loss: 530.2457 - val_mae: 530.2457\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.6148 - mae: 534.6148 - val_loss: 557.1031 - val_mae: 557.1031\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.2941 - mae: 535.2941 - val_loss: 530.9149 - val_mae: 530.9149\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.6084 - mae: 533.6084 - val_loss: 541.9763 - val_mae: 541.9763\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.8173 - mae: 532.8173 - val_loss: 536.0006 - val_mae: 536.0006\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.8518 - mae: 532.8518 - val_loss: 549.2293 - val_mae: 549.2293\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.6626 - mae: 532.6626 - val_loss: 530.5920 - val_mae: 530.5920\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.1987 - mae: 532.1987 - val_loss: 543.0217 - val_mae: 543.0217\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.9295 - mae: 531.9295 - val_loss: 526.2702 - val_mae: 526.2702\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.9424 - mae: 530.9424 - val_loss: 530.9011 - val_mae: 530.9011\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.4160 - mae: 531.4160 - val_loss: 530.8161 - val_mae: 530.8161\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.7665 - mae: 530.7665 - val_loss: 526.4886 - val_mae: 526.4886\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.1488 - mae: 531.1488 - val_loss: 524.4419 - val_mae: 524.4419\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.0563 - mae: 530.0563 - val_loss: 535.3969 - val_mae: 535.3969\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.2455 - mae: 530.2455 - val_loss: 526.6317 - val_mae: 526.6317\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.6312 - mae: 529.6312 - val_loss: 525.3234 - val_mae: 525.3234\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.3293 - mae: 530.3293 - val_loss: 527.9901 - val_mae: 527.9901\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.3886 - mae: 530.3886 - val_loss: 523.9113 - val_mae: 523.9113\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.7783 - mae: 529.7783 - val_loss: 527.8278 - val_mae: 527.8278\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.4474 - mae: 530.4474 - val_loss: 527.3569 - val_mae: 527.3569\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.6992 - mae: 529.6992 - val_loss: 523.8079 - val_mae: 523.8079\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.6880 - mae: 529.6880 - val_loss: 533.8849 - val_mae: 533.8849\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.6822 - mae: 528.6822 - val_loss: 554.1205 - val_mae: 554.1205\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 529.7059 - mae: 529.7059 - val_loss: 535.0013 - val_mae: 535.0013\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.9383 - mae: 528.9383 - val_loss: 543.8778 - val_mae: 543.8778\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.3641 - mae: 529.3641 - val_loss: 538.4133 - val_mae: 538.4133\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.6060 - mae: 528.6060 - val_loss: 535.6964 - val_mae: 535.6964\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.7877 - mae: 528.7877 - val_loss: 529.6472 - val_mae: 529.6472\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.4221 - mae: 529.4221 - val_loss: 535.2640 - val_mae: 535.2640\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.3535 - mae: 529.3535 - val_loss: 545.4154 - val_mae: 545.4154\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.4052 - mae: 528.4052 - val_loss: 538.6815 - val_mae: 538.6815\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6042.7520 - mae: 6042.7520 - val_loss: 5985.4360 - val_mae: 5985.4360\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3679.9917 - mae: 3679.9917 - val_loss: 841.0292 - val_mae: 841.0292\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 624.5292 - mae: 624.5292 - val_loss: 604.7672 - val_mae: 604.7672\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603.5209 - mae: 603.5209 - val_loss: 600.2879 - val_mae: 600.2879\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600.2995 - mae: 600.2995 - val_loss: 596.8416 - val_mae: 596.8416\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594.5209 - mae: 594.5209 - val_loss: 590.1993 - val_mae: 590.1993\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586.0672 - mae: 586.0672 - val_loss: 583.9801 - val_mae: 583.9801\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580.2521 - mae: 580.2521 - val_loss: 579.1635 - val_mae: 579.1635\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575.0696 - mae: 575.0696 - val_loss: 575.3273 - val_mae: 575.3273\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568.1327 - mae: 568.1327 - val_loss: 559.4829 - val_mae: 559.4829\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560.0547 - mae: 560.0547 - val_loss: 556.7632 - val_mae: 556.7632\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.2292 - mae: 554.2292 - val_loss: 552.0491 - val_mae: 552.0491\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.5074 - mae: 551.5074 - val_loss: 548.9044 - val_mae: 548.9044\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 549.0422 - mae: 549.0422 - val_loss: 546.3574 - val_mae: 546.3574\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.5535 - mae: 547.5535 - val_loss: 545.1713 - val_mae: 545.1713\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 546.8275 - mae: 546.8275 - val_loss: 549.1044 - val_mae: 549.1044\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 546.6400 - mae: 546.6400 - val_loss: 544.2151 - val_mae: 544.2151\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 546.2838 - mae: 546.2838 - val_loss: 540.8584 - val_mae: 540.8584\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 545.3857 - mae: 545.3857 - val_loss: 545.1866 - val_mae: 545.1866\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.6280 - mae: 546.6280 - val_loss: 545.4742 - val_mae: 545.4742\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.2477 - mae: 546.2477 - val_loss: 545.3813 - val_mae: 545.3813\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.6691 - mae: 545.6691 - val_loss: 542.9418 - val_mae: 542.9418\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.8737 - mae: 545.8737 - val_loss: 542.4830 - val_mae: 542.4830\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.5914 - mae: 545.5914 - val_loss: 547.2371 - val_mae: 547.2371\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.1069 - mae: 546.1069 - val_loss: 552.4138 - val_mae: 552.4138\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.9366 - mae: 545.9366 - val_loss: 543.9866 - val_mae: 543.9866\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.0794 - mae: 545.0794 - val_loss: 541.5469 - val_mae: 541.5469\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 544.3528 - mae: 544.3528 - val_loss: 545.4323 - val_mae: 545.4323\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 5917.0845 - mae: 5917.0845 - val_loss: 4932.9878 - val_mae: 4932.9878\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1253.6595 - mae: 1253.6595 - val_loss: 611.9733 - val_mae: 611.9733\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608.0903 - mae: 608.0903 - val_loss: 607.0023 - val_mae: 607.0023\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 606.4412 - mae: 606.4412 - val_loss: 602.1769 - val_mae: 602.1769\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 602.3619 - mae: 602.3619 - val_loss: 596.8945 - val_mae: 596.8945\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 598.7850 - mae: 598.7850 - val_loss: 592.9420 - val_mae: 592.9420\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589.9274 - mae: 589.9274 - val_loss: 587.2896 - val_mae: 587.2896\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581.8184 - mae: 581.8184 - val_loss: 571.4659 - val_mae: 571.4659\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571.8336 - mae: 571.8336 - val_loss: 568.6429 - val_mae: 568.6429\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566.1160 - mae: 566.1160 - val_loss: 561.3070 - val_mae: 561.3070\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560.8534 - mae: 560.8534 - val_loss: 556.3768 - val_mae: 556.3768\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 558.2809 - mae: 558.2809 - val_loss: 557.4283 - val_mae: 557.4283\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 558.2192 - mae: 558.2192 - val_loss: 553.4966 - val_mae: 553.4966\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557.1962 - mae: 557.1962 - val_loss: 557.4202 - val_mae: 557.4202\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556.4810 - mae: 556.4810 - val_loss: 552.4716 - val_mae: 552.4716\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555.9158 - mae: 555.9158 - val_loss: 553.9389 - val_mae: 553.9389\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.5054 - mae: 554.5054 - val_loss: 551.5935 - val_mae: 551.5935\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.2203 - mae: 554.2203 - val_loss: 560.1462 - val_mae: 560.1462\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.3638 - mae: 554.3638 - val_loss: 549.2827 - val_mae: 549.2827\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.4683 - mae: 553.4683 - val_loss: 552.9933 - val_mae: 552.9933\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553.4056 - mae: 553.4056 - val_loss: 555.9994 - val_mae: 555.9994\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.4135 - mae: 551.4135 - val_loss: 551.3942 - val_mae: 551.3942\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.1074 - mae: 551.1074 - val_loss: 556.5660 - val_mae: 556.5660\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.2043 - mae: 551.2043 - val_loss: 550.9896 - val_mae: 550.9896\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.3140 - mae: 551.3140 - val_loss: 546.0602 - val_mae: 546.0602\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.5970 - mae: 549.5970 - val_loss: 546.8721 - val_mae: 546.8721\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.1216 - mae: 549.1216 - val_loss: 552.0079 - val_mae: 552.0079\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 548.9464 - mae: 548.9464 - val_loss: 548.1880 - val_mae: 548.1880\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.8597 - mae: 546.8597 - val_loss: 546.6638 - val_mae: 546.6638\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.9713 - mae: 546.9713 - val_loss: 541.6826 - val_mae: 541.6826\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.1584 - mae: 546.1584 - val_loss: 551.7526 - val_mae: 551.7526\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.2755 - mae: 545.2755 - val_loss: 545.0902 - val_mae: 545.0902\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.5160 - mae: 544.5160 - val_loss: 541.9062 - val_mae: 541.9062\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.2068 - mae: 543.2068 - val_loss: 545.3285 - val_mae: 545.3285\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 542.8192 - mae: 542.8192 - val_loss: 542.1432 - val_mae: 542.1432\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 543.1519 - mae: 543.1519 - val_loss: 543.8428 - val_mae: 543.8428\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 541.4791 - mae: 541.4791 - val_loss: 539.4375 - val_mae: 539.4375\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 541.1183 - mae: 541.1183 - val_loss: 541.1118 - val_mae: 541.1118\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 540.5735 - mae: 540.5735 - val_loss: 540.9161 - val_mae: 540.9161\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 540.5003 - mae: 540.5003 - val_loss: 545.4326 - val_mae: 545.4326\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.5977 - mae: 539.5977 - val_loss: 540.9734 - val_mae: 540.9734\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 538.6277 - mae: 538.6277 - val_loss: 539.9417 - val_mae: 539.9417\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.7402 - mae: 538.7402 - val_loss: 538.8945 - val_mae: 538.8945\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.1583 - mae: 539.1583 - val_loss: 538.5617 - val_mae: 538.5617\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.0735 - mae: 539.0735 - val_loss: 537.1296 - val_mae: 537.1296\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.5143 - mae: 537.5143 - val_loss: 536.8199 - val_mae: 536.8199\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.8675 - mae: 537.8675 - val_loss: 538.8140 - val_mae: 538.8140\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.1624 - mae: 538.1624 - val_loss: 536.8769 - val_mae: 536.8769\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.2110 - mae: 537.2110 - val_loss: 536.6027 - val_mae: 536.6027\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.9010 - mae: 537.9010 - val_loss: 541.8625 - val_mae: 541.8625\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.5113 - mae: 536.5113 - val_loss: 537.3980 - val_mae: 537.3980\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.3119 - mae: 537.3119 - val_loss: 535.8083 - val_mae: 535.8083\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.0434 - mae: 537.0434 - val_loss: 532.3514 - val_mae: 532.3514\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.2881 - mae: 536.2881 - val_loss: 533.0753 - val_mae: 533.0753\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.9999 - mae: 535.9999 - val_loss: 535.7548 - val_mae: 535.7548\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.3984 - mae: 536.3984 - val_loss: 532.1973 - val_mae: 532.1973\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.6815 - mae: 535.6815 - val_loss: 532.9134 - val_mae: 532.9134\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.5510 - mae: 535.5510 - val_loss: 530.1289 - val_mae: 530.1289\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.0438 - mae: 536.0438 - val_loss: 532.9545 - val_mae: 532.9545\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.4293 - mae: 535.4293 - val_loss: 536.4570 - val_mae: 536.4570\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.9169 - mae: 535.9169 - val_loss: 531.4543 - val_mae: 531.4543\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.0654 - mae: 535.0654 - val_loss: 532.3976 - val_mae: 532.3976\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534.4252 - mae: 534.4252 - val_loss: 529.9907 - val_mae: 529.9907\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.1707 - mae: 533.1707 - val_loss: 531.1952 - val_mae: 531.1952\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.0056 - mae: 533.0056 - val_loss: 533.6557 - val_mae: 533.6557\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.3905 - mae: 533.3905 - val_loss: 530.5831 - val_mae: 530.5831\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.2032 - mae: 532.2032 - val_loss: 535.6071 - val_mae: 535.6071\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.4614 - mae: 531.4614 - val_loss: 529.4659 - val_mae: 529.4659\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.9117 - mae: 531.9117 - val_loss: 534.3022 - val_mae: 534.3022\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.9073 - mae: 531.9073 - val_loss: 529.4791 - val_mae: 529.4791\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 530.8525 - mae: 530.8525 - val_loss: 531.5345 - val_mae: 531.5345\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.0528 - mae: 532.0528 - val_loss: 528.9969 - val_mae: 528.9969\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.7609 - mae: 531.7609 - val_loss: 529.2498 - val_mae: 529.2498\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.7119 - mae: 529.7119 - val_loss: 528.9413 - val_mae: 528.9413\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.5595 - mae: 530.5595 - val_loss: 531.3911 - val_mae: 531.3911\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.0415 - mae: 531.0415 - val_loss: 530.0835 - val_mae: 530.0835\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 532.1699 - mae: 532.1699 - val_loss: 528.6414 - val_mae: 528.6414\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.8547 - mae: 529.8547 - val_loss: 529.8415 - val_mae: 529.8415\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.3832 - mae: 531.3832 - val_loss: 527.5323 - val_mae: 527.5323\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.3490 - mae: 531.3490 - val_loss: 526.1573 - val_mae: 526.1573\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.3031 - mae: 530.3031 - val_loss: 526.6888 - val_mae: 526.6888\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.7316 - mae: 529.7316 - val_loss: 535.5227 - val_mae: 535.5227\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.9529 - mae: 529.9529 - val_loss: 529.0879 - val_mae: 529.0879\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.1099 - mae: 530.1099 - val_loss: 529.6940 - val_mae: 529.6940\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.3433 - mae: 530.3433 - val_loss: 528.4554 - val_mae: 528.4554\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.0423 - mae: 529.0423 - val_loss: 529.3302 - val_mae: 529.3302\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.0456 - mae: 530.0456 - val_loss: 528.9828 - val_mae: 528.9828\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.4456 - mae: 530.4456 - val_loss: 534.0074 - val_mae: 534.0074\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.2144 - mae: 530.2144 - val_loss: 529.7913 - val_mae: 529.7913\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.1859 - mae: 529.1859 - val_loss: 527.3832 - val_mae: 527.3832\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6052.0532 - mae: 6052.0532 - val_loss: 6046.5391 - val_mae: 6046.5391\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6010.1455 - mae: 6010.1455 - val_loss: 5913.8228 - val_mae: 5913.8228\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 5034.9702 - mae: 5034.9702 - val_loss: 2585.3157 - val_mae: 2585.3157\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 996.6071 - mae: 996.6071 - val_loss: 630.6447 - val_mae: 630.6447\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619.7968 - mae: 619.7968 - val_loss: 611.3992 - val_mae: 611.3992\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608.9219 - mae: 608.9219 - val_loss: 606.6882 - val_mae: 606.6882\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606.7582 - mae: 606.7582 - val_loss: 603.5322 - val_mae: 603.5322\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 603.7986 - mae: 603.7986 - val_loss: 604.9455 - val_mae: 604.9455\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 602.7993 - mae: 602.7993 - val_loss: 601.3447 - val_mae: 601.3447\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601.8224 - mae: 601.8224 - val_loss: 600.3351 - val_mae: 600.3351\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600.8533 - mae: 600.8533 - val_loss: 601.5524 - val_mae: 601.5524\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 600.9719 - mae: 600.9719 - val_loss: 600.6000 - val_mae: 600.6000\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600.7353 - mae: 600.7353 - val_loss: 597.8458 - val_mae: 597.8458\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 600.6324 - mae: 600.6324 - val_loss: 599.5823 - val_mae: 599.5823\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599.8589 - mae: 599.8589 - val_loss: 597.5687 - val_mae: 597.5687\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599.1530 - mae: 599.1530 - val_loss: 596.8602 - val_mae: 596.8602\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599.7889 - mae: 599.7889 - val_loss: 597.9743 - val_mae: 597.9743\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599.2247 - mae: 599.2247 - val_loss: 598.1773 - val_mae: 598.1773\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 599.5079 - mae: 599.5079 - val_loss: 597.6245 - val_mae: 597.6245\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598.5879 - mae: 598.5879 - val_loss: 597.8651 - val_mae: 597.8651\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 598.9384 - mae: 598.9384 - val_loss: 596.2778 - val_mae: 596.2778\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597.9041 - mae: 597.9041 - val_loss: 596.7440 - val_mae: 596.7440\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 597.9410 - mae: 597.9410 - val_loss: 596.6655 - val_mae: 596.6655\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 597.6070 - mae: 597.6070 - val_loss: 598.0743 - val_mae: 598.0743\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 597.8227 - mae: 597.8227 - val_loss: 595.8914 - val_mae: 595.8914\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 597.2584 - mae: 597.2584 - val_loss: 595.2558 - val_mae: 595.2558\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597.0644 - mae: 597.0644 - val_loss: 595.8710 - val_mae: 595.8710\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 596.2888 - mae: 596.2888 - val_loss: 594.3167 - val_mae: 594.3167\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596.1913 - mae: 596.1913 - val_loss: 595.2203 - val_mae: 595.2203\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 596.0854 - mae: 596.0854 - val_loss: 594.2573 - val_mae: 594.2573\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594.7243 - mae: 594.7243 - val_loss: 592.9348 - val_mae: 592.9348\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595.2236 - mae: 595.2236 - val_loss: 590.9057 - val_mae: 590.9057\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593.3871 - mae: 593.3871 - val_loss: 592.2267 - val_mae: 592.2267\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 592.2788 - mae: 592.2788 - val_loss: 592.5062 - val_mae: 592.5062\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591.7894 - mae: 591.7894 - val_loss: 591.6222 - val_mae: 591.6222\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 591.0046 - mae: 591.0046 - val_loss: 589.1057 - val_mae: 589.1057\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 589.8866 - mae: 589.8866 - val_loss: 586.7068 - val_mae: 586.7068\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 587.7098 - mae: 587.7098 - val_loss: 586.3353 - val_mae: 586.3353\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 585.6503 - mae: 585.6503 - val_loss: 584.1559 - val_mae: 584.1559\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 583.7418 - mae: 583.7418 - val_loss: 581.6124 - val_mae: 581.6124\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 581.4340 - mae: 581.4340 - val_loss: 578.3692 - val_mae: 578.3692\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 579.0013 - mae: 579.0013 - val_loss: 574.7326 - val_mae: 574.7326\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 575.7713 - mae: 575.7713 - val_loss: 575.0103 - val_mae: 575.0103\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 572.4413 - mae: 572.4413 - val_loss: 569.3147 - val_mae: 569.3147\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 569.7097 - mae: 569.7097 - val_loss: 565.8130 - val_mae: 565.8130\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 565.1744 - mae: 565.1744 - val_loss: 562.2010 - val_mae: 562.2010\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 562.5607 - mae: 562.5607 - val_loss: 560.7291 - val_mae: 560.7291\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 559.9626 - mae: 559.9626 - val_loss: 556.2552 - val_mae: 556.2552\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 556.7574 - mae: 556.7574 - val_loss: 554.5721 - val_mae: 554.5721\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554.6908 - mae: 554.6908 - val_loss: 550.5985 - val_mae: 550.5985\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.4500 - mae: 552.4500 - val_loss: 550.9835 - val_mae: 550.9835\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.1477 - mae: 550.1477 - val_loss: 547.3707 - val_mae: 547.3707\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 549.3562 - mae: 549.3562 - val_loss: 547.5582 - val_mae: 547.5582\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.8732 - mae: 547.8732 - val_loss: 546.6705 - val_mae: 546.6705\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.5740 - mae: 546.5740 - val_loss: 544.9763 - val_mae: 544.9763\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.8012 - mae: 545.8012 - val_loss: 544.3287 - val_mae: 544.3287\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.6237 - mae: 545.6237 - val_loss: 542.3978 - val_mae: 542.3978\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.2448 - mae: 544.2448 - val_loss: 546.7166 - val_mae: 546.7166\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.8738 - mae: 544.8738 - val_loss: 544.0049 - val_mae: 544.0049\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.4440 - mae: 544.4440 - val_loss: 542.4742 - val_mae: 542.4742\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.1848 - mae: 544.1848 - val_loss: 541.2391 - val_mae: 541.2391\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.7498 - mae: 542.7498 - val_loss: 541.8400 - val_mae: 541.8400\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.8055 - mae: 542.8055 - val_loss: 541.7513 - val_mae: 541.7513\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.9116 - mae: 542.9116 - val_loss: 540.7281 - val_mae: 540.7281\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.5703 - mae: 542.5703 - val_loss: 540.9327 - val_mae: 540.9327\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.3196 - mae: 542.3196 - val_loss: 542.2136 - val_mae: 542.2136\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.2030 - mae: 542.2030 - val_loss: 539.4008 - val_mae: 539.4008\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.7858 - mae: 541.7858 - val_loss: 542.1635 - val_mae: 542.1635\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.1435 - mae: 542.1435 - val_loss: 540.2418 - val_mae: 540.2418\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.4398 - mae: 541.4398 - val_loss: 542.5914 - val_mae: 542.5914\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.1257 - mae: 541.1257 - val_loss: 541.2188 - val_mae: 541.2188\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.6692 - mae: 541.6692 - val_loss: 541.7523 - val_mae: 541.7523\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.6456 - mae: 540.6456 - val_loss: 539.9030 - val_mae: 539.9030\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.0011 - mae: 541.0011 - val_loss: 541.1873 - val_mae: 541.1873\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.3412 - mae: 541.3412 - val_loss: 538.1336 - val_mae: 538.1336\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.4409 - mae: 540.4409 - val_loss: 539.0361 - val_mae: 539.0361\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.9465 - mae: 539.9465 - val_loss: 537.9529 - val_mae: 537.9529\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.7957 - mae: 539.7957 - val_loss: 538.1179 - val_mae: 538.1179\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 539.3535 - mae: 539.3535 - val_loss: 536.6458 - val_mae: 536.6458\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.1730 - mae: 539.1730 - val_loss: 536.6832 - val_mae: 536.6832\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.2524 - mae: 538.2524 - val_loss: 538.4488 - val_mae: 538.4488\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.6555 - mae: 538.6555 - val_loss: 536.1195 - val_mae: 536.1195\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.1850 - mae: 538.1850 - val_loss: 537.3625 - val_mae: 537.3625\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.8741 - mae: 537.8741 - val_loss: 536.9509 - val_mae: 536.9509\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.3404 - mae: 537.3404 - val_loss: 535.7016 - val_mae: 535.7016\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.2032 - mae: 537.2032 - val_loss: 536.9319 - val_mae: 536.9319\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.7740 - mae: 536.7740 - val_loss: 534.4463 - val_mae: 534.4463\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.6214 - mae: 536.6214 - val_loss: 535.1818 - val_mae: 535.1818\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 535.9263 - mae: 535.9263 - val_loss: 535.8971 - val_mae: 535.8971\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.6771 - mae: 536.6771 - val_loss: 535.7386 - val_mae: 535.7386\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.7188 - mae: 536.7188 - val_loss: 535.4381 - val_mae: 535.4381\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.9249 - mae: 535.9249 - val_loss: 534.9166 - val_mae: 534.9166\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.8860 - mae: 535.8860 - val_loss: 535.7035 - val_mae: 535.7035\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.1268 - mae: 536.1268 - val_loss: 536.2198 - val_mae: 536.2198\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.1348 - mae: 536.1348 - val_loss: 533.4632 - val_mae: 533.4632\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.3226 - mae: 535.3226 - val_loss: 533.1105 - val_mae: 533.1105\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.1220 - mae: 535.1220 - val_loss: 534.3492 - val_mae: 534.3492\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.5083 - mae: 534.5083 - val_loss: 533.0106 - val_mae: 533.0106\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.4656 - mae: 534.4656 - val_loss: 532.6336 - val_mae: 532.6336\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.6923 - mae: 533.6923 - val_loss: 534.1781 - val_mae: 534.1781\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.2080 - mae: 534.2080 - val_loss: 533.5899 - val_mae: 533.5899\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.8009 - mae: 533.8009 - val_loss: 531.1235 - val_mae: 531.1235\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.9996 - mae: 532.9996 - val_loss: 532.4836 - val_mae: 532.4836\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.7722 - mae: 532.7722 - val_loss: 530.9849 - val_mae: 530.9849\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.8672 - mae: 532.8672 - val_loss: 530.5808 - val_mae: 530.5808\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.0375 - mae: 533.0375 - val_loss: 531.2154 - val_mae: 531.2154\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.7214 - mae: 532.7214 - val_loss: 531.8456 - val_mae: 531.8456\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.4427 - mae: 532.4427 - val_loss: 532.1592 - val_mae: 532.1592\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.1401 - mae: 532.1401 - val_loss: 530.8328 - val_mae: 530.8328\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.3215 - mae: 532.3215 - val_loss: 530.0959 - val_mae: 530.0959\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.2827 - mae: 532.2827 - val_loss: 529.9772 - val_mae: 529.9772\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.2844 - mae: 532.2844 - val_loss: 530.3463 - val_mae: 530.3463\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.5688 - mae: 532.5688 - val_loss: 530.3379 - val_mae: 530.3379\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.1015 - mae: 532.1015 - val_loss: 531.0620 - val_mae: 531.0620\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.9745 - mae: 531.9745 - val_loss: 529.9875 - val_mae: 529.9875\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.2312 - mae: 532.2312 - val_loss: 531.9038 - val_mae: 531.9038\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.1704 - mae: 532.1704 - val_loss: 530.3367 - val_mae: 530.3367\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.9993 - mae: 531.9993 - val_loss: 529.9868 - val_mae: 529.9868\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.2762 - mae: 531.2762 - val_loss: 530.6389 - val_mae: 530.6389\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.7623 - mae: 531.7623 - val_loss: 530.3907 - val_mae: 530.3907\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.9240 - mae: 530.9240 - val_loss: 531.5506 - val_mae: 531.5506\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6047.4023 - mae: 6047.4023 - val_loss: 6027.8672 - val_mae: 6027.8672\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5706.2056 - mae: 5706.2056 - val_loss: 4587.5176 - val_mae: 4587.5176\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1454.3326 - mae: 1454.3326 - val_loss: 630.2024 - val_mae: 630.2024\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 622.3526 - mae: 622.3526 - val_loss: 613.4860 - val_mae: 613.4860\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611.7192 - mae: 611.7192 - val_loss: 608.8648 - val_mae: 608.8648\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608.7465 - mae: 608.7465 - val_loss: 604.9274 - val_mae: 604.9274\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 606.4876 - mae: 606.4876 - val_loss: 606.6483 - val_mae: 606.6483\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605.3800 - mae: 605.3800 - val_loss: 603.5515 - val_mae: 603.5515\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604.3590 - mae: 604.3590 - val_loss: 602.8716 - val_mae: 602.8716\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603.7374 - mae: 603.7374 - val_loss: 601.5634 - val_mae: 601.5634\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601.2003 - mae: 601.2003 - val_loss: 600.0485 - val_mae: 600.0485\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601.1314 - mae: 601.1314 - val_loss: 595.9879 - val_mae: 595.9879\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598.3489 - mae: 598.3489 - val_loss: 597.0804 - val_mae: 597.0804\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594.0673 - mae: 594.0673 - val_loss: 592.8629 - val_mae: 592.8629\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589.6043 - mae: 589.6043 - val_loss: 586.6064 - val_mae: 586.6064\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584.4657 - mae: 584.4657 - val_loss: 581.3283 - val_mae: 581.3283\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 579.9331 - mae: 579.9331 - val_loss: 577.9527 - val_mae: 577.9527\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 574.8062 - mae: 574.8062 - val_loss: 573.6949 - val_mae: 573.6949\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 569.4300 - mae: 569.4300 - val_loss: 565.0496 - val_mae: 565.0496\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564.1073 - mae: 564.1073 - val_loss: 559.2776 - val_mae: 559.2776\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559.6255 - mae: 559.6255 - val_loss: 554.8276 - val_mae: 554.8276\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 556.0309 - mae: 556.0309 - val_loss: 552.5964 - val_mae: 552.5964\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553.9276 - mae: 553.9276 - val_loss: 551.1155 - val_mae: 551.1155\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.7466 - mae: 550.7466 - val_loss: 548.7979 - val_mae: 548.7979\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.6552 - mae: 549.6552 - val_loss: 547.6782 - val_mae: 547.6782\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.9869 - mae: 547.9869 - val_loss: 545.7119 - val_mae: 545.7119\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.8365 - mae: 546.8365 - val_loss: 543.5184 - val_mae: 543.5184\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.2537 - mae: 544.2537 - val_loss: 544.3913 - val_mae: 544.3913\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.7276 - mae: 543.7276 - val_loss: 541.4280 - val_mae: 541.4280\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.8741 - mae: 542.8741 - val_loss: 540.5618 - val_mae: 540.5618\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.4753 - mae: 541.4753 - val_loss: 542.2764 - val_mae: 542.2764\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.1660 - mae: 541.1660 - val_loss: 542.5420 - val_mae: 542.5420\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.5497 - mae: 540.5497 - val_loss: 539.1603 - val_mae: 539.1603\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.4290 - mae: 540.4290 - val_loss: 537.7300 - val_mae: 537.7300\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.9932 - mae: 538.9932 - val_loss: 536.8686 - val_mae: 536.8686\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.5937 - mae: 537.5937 - val_loss: 536.5455 - val_mae: 536.5455\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.2222 - mae: 537.2222 - val_loss: 533.7667 - val_mae: 533.7667\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.4208 - mae: 536.4208 - val_loss: 535.1937 - val_mae: 535.1937\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.2310 - mae: 536.2310 - val_loss: 533.1147 - val_mae: 533.1147\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.6953 - mae: 535.6953 - val_loss: 534.8864 - val_mae: 534.8864\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.4297 - mae: 535.4297 - val_loss: 535.0886 - val_mae: 535.0886\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.4644 - mae: 534.4644 - val_loss: 533.7492 - val_mae: 533.7492\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.9953 - mae: 534.9953 - val_loss: 534.3380 - val_mae: 534.3380\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.0283 - mae: 534.0283 - val_loss: 532.5557 - val_mae: 532.5557\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.6831 - mae: 534.6831 - val_loss: 532.2043 - val_mae: 532.2043\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.9371 - mae: 533.9371 - val_loss: 534.6478 - val_mae: 534.6478\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.9430 - mae: 533.9430 - val_loss: 532.7070 - val_mae: 532.7070\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.6819 - mae: 533.6819 - val_loss: 531.2572 - val_mae: 531.2572\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.2969 - mae: 533.2969 - val_loss: 534.7175 - val_mae: 534.7175\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.4308 - mae: 533.4308 - val_loss: 531.3404 - val_mae: 531.3404\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.9125 - mae: 532.9125 - val_loss: 532.4807 - val_mae: 532.4807\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.1034 - mae: 533.1034 - val_loss: 530.4307 - val_mae: 530.4307\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.0820 - mae: 532.0820 - val_loss: 531.3115 - val_mae: 531.3115\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.9646 - mae: 531.9646 - val_loss: 533.0477 - val_mae: 533.0477\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.5799 - mae: 532.5799 - val_loss: 528.2924 - val_mae: 528.2924\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.6978 - mae: 531.6978 - val_loss: 529.7172 - val_mae: 529.7172\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.0081 - mae: 532.0081 - val_loss: 531.4042 - val_mae: 531.4042\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.1492 - mae: 531.1492 - val_loss: 534.6719 - val_mae: 534.6719\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.9880 - mae: 531.9880 - val_loss: 528.5737 - val_mae: 528.5737\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.8868 - mae: 530.8868 - val_loss: 528.7365 - val_mae: 528.7365\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.4120 - mae: 531.4120 - val_loss: 528.7855 - val_mae: 528.7855\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.4900 - mae: 530.4900 - val_loss: 530.3635 - val_mae: 530.3635\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.0988 - mae: 531.0988 - val_loss: 530.1890 - val_mae: 530.1890\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.0160 - mae: 531.0160 - val_loss: 529.4705 - val_mae: 529.4705\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.2616 - mae: 530.2616 - val_loss: 528.8981 - val_mae: 528.8981\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 4086.8523 - mae: 4086.8523 - val_loss: 630.2447 - val_mae: 630.2447\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 611.6282 - mae: 611.6282 - val_loss: 605.1315 - val_mae: 605.1315\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 604.4357 - mae: 604.4357 - val_loss: 618.8666 - val_mae: 618.8666\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 601.0274 - mae: 601.0274 - val_loss: 603.8608 - val_mae: 603.8608\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593.4620 - mae: 593.4620 - val_loss: 586.0511 - val_mae: 586.0511\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 583.0702 - mae: 583.0702 - val_loss: 581.5380 - val_mae: 581.5380\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 571.7339 - mae: 571.7339 - val_loss: 572.8474 - val_mae: 572.8474\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 561.3867 - mae: 561.3867 - val_loss: 559.3533 - val_mae: 559.3533\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558.4351 - mae: 558.4351 - val_loss: 562.5681 - val_mae: 562.5681\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556.0507 - mae: 556.0507 - val_loss: 570.5403 - val_mae: 570.5403\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556.6086 - mae: 556.6086 - val_loss: 569.6634 - val_mae: 569.6634\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.9432 - mae: 555.9432 - val_loss: 563.1102 - val_mae: 563.1102\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556.0381 - mae: 556.0381 - val_loss: 562.7301 - val_mae: 562.7301\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.8670 - mae: 555.8670 - val_loss: 563.7911 - val_mae: 563.7911\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556.0875 - mae: 556.0875 - val_loss: 554.6804 - val_mae: 554.6804\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.4368 - mae: 555.4368 - val_loss: 559.1702 - val_mae: 559.1702\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554.8237 - mae: 554.8237 - val_loss: 555.4991 - val_mae: 555.4991\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.6484 - mae: 553.6484 - val_loss: 566.8080 - val_mae: 566.8080\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.0134 - mae: 553.0134 - val_loss: 574.0241 - val_mae: 574.0241\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.9076 - mae: 551.9076 - val_loss: 566.4166 - val_mae: 566.4166\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.9406 - mae: 553.9406 - val_loss: 550.8463 - val_mae: 550.8463\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.3520 - mae: 552.3520 - val_loss: 559.8943 - val_mae: 559.8943\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.8777 - mae: 552.8777 - val_loss: 548.5364 - val_mae: 548.5364\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.1107 - mae: 552.1107 - val_loss: 554.2201 - val_mae: 554.2201\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.9862 - mae: 550.9862 - val_loss: 560.7946 - val_mae: 560.7946\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.5300 - mae: 551.5300 - val_loss: 548.5120 - val_mae: 548.5120\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.1760 - mae: 552.1760 - val_loss: 550.5330 - val_mae: 550.5330\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.9315 - mae: 550.9315 - val_loss: 555.9210 - val_mae: 555.9210\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.4747 - mae: 550.4747 - val_loss: 549.7943 - val_mae: 549.7943\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.1776 - mae: 551.1776 - val_loss: 546.4213 - val_mae: 546.4213\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 550.3992 - mae: 550.3992 - val_loss: 554.8698 - val_mae: 554.8698\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.5564 - mae: 548.5564 - val_loss: 548.1118 - val_mae: 548.1118\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.8824 - mae: 547.8824 - val_loss: 546.6580 - val_mae: 546.6580\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.7718 - mae: 547.7718 - val_loss: 550.5822 - val_mae: 550.5822\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546.9924 - mae: 546.9924 - val_loss: 553.5377 - val_mae: 553.5377\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.0300 - mae: 547.0300 - val_loss: 544.5786 - val_mae: 544.5786\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 547.1188 - mae: 547.1188 - val_loss: 548.1172 - val_mae: 548.1172\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546.8726 - mae: 546.8726 - val_loss: 547.6807 - val_mae: 547.6807\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.6835 - mae: 545.6835 - val_loss: 542.0278 - val_mae: 542.0278\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546.1202 - mae: 546.1202 - val_loss: 551.0792 - val_mae: 551.0792\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 545.2030 - mae: 545.2030 - val_loss: 553.9841 - val_mae: 553.9841\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.4039 - mae: 545.4039 - val_loss: 550.8477 - val_mae: 550.8477\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.6274 - mae: 545.6274 - val_loss: 548.4424 - val_mae: 548.4424\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.4222 - mae: 545.4222 - val_loss: 545.8896 - val_mae: 545.8896\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 546.1727 - mae: 546.1727 - val_loss: 552.0591 - val_mae: 552.0591\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.6143 - mae: 545.6143 - val_loss: 548.6097 - val_mae: 548.6097\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.4921 - mae: 545.4921 - val_loss: 545.0300 - val_mae: 545.0300\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.1126 - mae: 545.1126 - val_loss: 549.4867 - val_mae: 549.4867\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.6786 - mae: 545.6786 - val_loss: 544.9631 - val_mae: 544.9631\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3818.0825 - mae: 3818.0825 - val_loss: 636.8723 - val_mae: 636.8723\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 618.3318 - mae: 618.3318 - val_loss: 635.4620 - val_mae: 635.4620\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 611.2856 - mae: 611.2856 - val_loss: 622.0595 - val_mae: 622.0595\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 600.6984 - mae: 600.6984 - val_loss: 620.7240 - val_mae: 620.7240\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584.6774 - mae: 584.6774 - val_loss: 585.2953 - val_mae: 585.2953\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 571.3220 - mae: 571.3220 - val_loss: 571.9185 - val_mae: 571.9185\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 566.6198 - mae: 566.6198 - val_loss: 562.9910 - val_mae: 562.9910\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560.6379 - mae: 560.6379 - val_loss: 585.9830 - val_mae: 585.9830\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 559.2512 - mae: 559.2512 - val_loss: 576.6323 - val_mae: 576.6323\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560.1052 - mae: 560.1052 - val_loss: 560.1545 - val_mae: 560.1545\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558.8234 - mae: 558.8234 - val_loss: 565.2803 - val_mae: 565.2803\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557.4913 - mae: 557.4913 - val_loss: 570.2952 - val_mae: 570.2952\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557.7015 - mae: 557.7015 - val_loss: 561.6707 - val_mae: 561.6707\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 557.2605 - mae: 557.2605 - val_loss: 548.4088 - val_mae: 548.4088\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.4252 - mae: 555.4252 - val_loss: 563.2352 - val_mae: 563.2352\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556.1124 - mae: 556.1124 - val_loss: 554.4801 - val_mae: 554.4801\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.6186 - mae: 555.6186 - val_loss: 552.5478 - val_mae: 552.5478\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553.9434 - mae: 553.9434 - val_loss: 565.0541 - val_mae: 565.0541\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.2878 - mae: 551.2878 - val_loss: 555.0295 - val_mae: 555.0295\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.1206 - mae: 551.1206 - val_loss: 560.4598 - val_mae: 560.4598\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.8969 - mae: 550.8969 - val_loss: 555.8456 - val_mae: 555.8456\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.5666 - mae: 547.5666 - val_loss: 546.4111 - val_mae: 546.4111\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.5941 - mae: 547.5941 - val_loss: 546.8834 - val_mae: 546.8834\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.5690 - mae: 545.5690 - val_loss: 546.5215 - val_mae: 546.5215\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.5384 - mae: 545.5384 - val_loss: 539.2939 - val_mae: 539.2939\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.4196 - mae: 541.4196 - val_loss: 549.8918 - val_mae: 549.8918\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.9735 - mae: 541.9735 - val_loss: 548.7224 - val_mae: 548.7224\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 543.2106 - mae: 543.2106 - val_loss: 546.5282 - val_mae: 546.5282\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.6951 - mae: 539.6951 - val_loss: 545.5491 - val_mae: 545.5491\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.1655 - mae: 540.1655 - val_loss: 536.3314 - val_mae: 536.3314\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.2817 - mae: 540.2817 - val_loss: 539.6059 - val_mae: 539.6059\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 539.2653 - mae: 539.2653 - val_loss: 535.6828 - val_mae: 535.6828\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.9165 - mae: 538.9165 - val_loss: 533.1643 - val_mae: 533.1643\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.1599 - mae: 537.1599 - val_loss: 545.5281 - val_mae: 545.5281\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.3038 - mae: 537.3038 - val_loss: 534.6715 - val_mae: 534.6715\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.1099 - mae: 537.1099 - val_loss: 533.1862 - val_mae: 533.1862\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.2549 - mae: 536.2549 - val_loss: 542.0995 - val_mae: 542.0995\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.9598 - mae: 537.9598 - val_loss: 541.9360 - val_mae: 541.9360\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.8323 - mae: 535.8323 - val_loss: 534.6084 - val_mae: 534.6084\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.6871 - mae: 535.6871 - val_loss: 537.8320 - val_mae: 537.8320\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.0125 - mae: 535.0125 - val_loss: 531.8671 - val_mae: 531.8671\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.6541 - mae: 536.6541 - val_loss: 534.8162 - val_mae: 534.8162\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.1853 - mae: 535.1853 - val_loss: 538.9219 - val_mae: 538.9219\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.8718 - mae: 534.8718 - val_loss: 530.8425 - val_mae: 530.8425\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.0749 - mae: 535.0749 - val_loss: 542.9875 - val_mae: 542.9875\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.7257 - mae: 533.7257 - val_loss: 526.6675 - val_mae: 526.6675\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.6973 - mae: 531.6973 - val_loss: 523.8145 - val_mae: 523.8145\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.2028 - mae: 531.2028 - val_loss: 571.8200 - val_mae: 571.8200\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.4804 - mae: 532.4804 - val_loss: 533.3608 - val_mae: 533.3608\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.7486 - mae: 530.7486 - val_loss: 534.4936 - val_mae: 534.4936\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.2798 - mae: 528.2798 - val_loss: 539.0852 - val_mae: 539.0852\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.6910 - mae: 529.6910 - val_loss: 525.8414 - val_mae: 525.8414\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.7592 - mae: 528.7592 - val_loss: 523.8669 - val_mae: 523.8669\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.1408 - mae: 527.1408 - val_loss: 526.7821 - val_mae: 526.7821\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.0696 - mae: 527.0696 - val_loss: 538.0291 - val_mae: 538.0291\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.5637 - mae: 526.5637 - val_loss: 529.9371 - val_mae: 529.9371\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 525.8115 - mae: 525.8115 - val_loss: 531.5497 - val_mae: 531.5497\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6001.0542 - mae: 6001.0542 - val_loss: 5717.4004 - val_mae: 5717.4004\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2185.1531 - mae: 2185.1531 - val_loss: 626.9144 - val_mae: 626.9144\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617.3944 - mae: 617.3944 - val_loss: 613.7311 - val_mae: 613.7311\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612.5843 - mae: 612.5843 - val_loss: 606.4407 - val_mae: 606.4407\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608.6351 - mae: 608.6351 - val_loss: 606.7269 - val_mae: 606.7269\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606.5042 - mae: 606.5042 - val_loss: 602.3599 - val_mae: 602.3599\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601.8171 - mae: 601.8171 - val_loss: 599.6615 - val_mae: 599.6615\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597.8891 - mae: 597.8891 - val_loss: 593.0101 - val_mae: 593.0101\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594.6454 - mae: 594.6454 - val_loss: 593.2111 - val_mae: 593.2111\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591.3206 - mae: 591.3206 - val_loss: 589.8271 - val_mae: 589.8271\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589.6180 - mae: 589.6180 - val_loss: 582.8952 - val_mae: 582.8952\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587.4457 - mae: 587.4457 - val_loss: 581.1058 - val_mae: 581.1058\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583.0997 - mae: 583.0997 - val_loss: 584.9835 - val_mae: 584.9835\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581.3553 - mae: 581.3553 - val_loss: 581.2628 - val_mae: 581.2628\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576.0206 - mae: 576.0206 - val_loss: 574.1385 - val_mae: 574.1385\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567.0240 - mae: 567.0240 - val_loss: 560.7665 - val_mae: 560.7665\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559.9054 - mae: 559.9054 - val_loss: 555.1454 - val_mae: 555.1454\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555.6941 - mae: 555.6941 - val_loss: 551.3500 - val_mae: 551.3500\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.2515 - mae: 553.2515 - val_loss: 550.5836 - val_mae: 550.5836\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.7341 - mae: 552.7341 - val_loss: 550.5557 - val_mae: 550.5557\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.5314 - mae: 550.5314 - val_loss: 553.0344 - val_mae: 553.0344\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.7869 - mae: 547.7869 - val_loss: 546.1436 - val_mae: 546.1436\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.4835 - mae: 548.4835 - val_loss: 550.4119 - val_mae: 550.4119\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.5047 - mae: 546.5047 - val_loss: 544.8607 - val_mae: 544.8607\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.4283 - mae: 546.4283 - val_loss: 542.3857 - val_mae: 542.3857\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.5142 - mae: 543.5142 - val_loss: 542.4519 - val_mae: 542.4519\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.4443 - mae: 544.4443 - val_loss: 541.2355 - val_mae: 541.2355\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.0098 - mae: 543.0098 - val_loss: 540.8596 - val_mae: 540.8596\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.1020 - mae: 543.1020 - val_loss: 541.5179 - val_mae: 541.5179\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.3647 - mae: 541.3647 - val_loss: 538.7274 - val_mae: 538.7274\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.3038 - mae: 541.3038 - val_loss: 541.4499 - val_mae: 541.4499\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.8862 - mae: 540.8862 - val_loss: 539.0504 - val_mae: 539.0504\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.6928 - mae: 539.6928 - val_loss: 537.6447 - val_mae: 537.6447\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.8795 - mae: 539.8795 - val_loss: 538.3915 - val_mae: 538.3915\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.2021 - mae: 539.2021 - val_loss: 537.3204 - val_mae: 537.3204\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.6544 - mae: 538.6544 - val_loss: 540.4614 - val_mae: 540.4614\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.4454 - mae: 539.4454 - val_loss: 536.5615 - val_mae: 536.5615\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.3760 - mae: 537.3760 - val_loss: 535.9398 - val_mae: 535.9398\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.5122 - mae: 537.5122 - val_loss: 536.2413 - val_mae: 536.2413\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.1910 - mae: 538.1910 - val_loss: 540.3845 - val_mae: 540.3845\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.1235 - mae: 538.1235 - val_loss: 534.7645 - val_mae: 534.7645\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.1823 - mae: 537.1823 - val_loss: 532.9640 - val_mae: 532.9640\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.8895 - mae: 536.8895 - val_loss: 536.8761 - val_mae: 536.8761\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.7935 - mae: 536.7935 - val_loss: 534.6675 - val_mae: 534.6675\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.4352 - mae: 536.4352 - val_loss: 535.8942 - val_mae: 535.8942\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.3105 - mae: 536.3105 - val_loss: 534.1177 - val_mae: 534.1177\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.2245 - mae: 536.2245 - val_loss: 535.2070 - val_mae: 535.2070\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.7537 - mae: 535.7537 - val_loss: 535.8788 - val_mae: 535.8788\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.1985 - mae: 536.1985 - val_loss: 534.2855 - val_mae: 534.2855\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.4992 - mae: 535.4992 - val_loss: 534.1769 - val_mae: 534.1769\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.7626 - mae: 535.7626 - val_loss: 534.8022 - val_mae: 534.8022\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.7601 - mae: 535.7601 - val_loss: 535.7595 - val_mae: 535.7595\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6043.0327 - mae: 6043.0327 - val_loss: 5971.1694 - val_mae: 5971.1694\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2776.7866 - mae: 2776.7866 - val_loss: 623.0925 - val_mae: 623.0925\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617.7668 - mae: 617.7668 - val_loss: 615.3343 - val_mae: 615.3343\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614.7482 - mae: 614.7482 - val_loss: 611.4609 - val_mae: 611.4609\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611.0621 - mae: 611.0621 - val_loss: 610.4761 - val_mae: 610.4761\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606.0234 - mae: 606.0234 - val_loss: 598.3732 - val_mae: 598.3732\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596.3656 - mae: 596.3656 - val_loss: 591.6649 - val_mae: 591.6649\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587.0544 - mae: 587.0544 - val_loss: 585.6873 - val_mae: 585.6873\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 577.7698 - mae: 577.7698 - val_loss: 574.8784 - val_mae: 574.8784\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572.1359 - mae: 572.1359 - val_loss: 564.2926 - val_mae: 564.2926\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567.1592 - mae: 567.1592 - val_loss: 566.3181 - val_mae: 566.3181\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561.6870 - mae: 561.6870 - val_loss: 558.5454 - val_mae: 558.5454\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557.8361 - mae: 557.8361 - val_loss: 560.7844 - val_mae: 560.7844\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.5090 - mae: 552.5090 - val_loss: 552.6969 - val_mae: 552.6969\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.1113 - mae: 549.1113 - val_loss: 546.9057 - val_mae: 546.9057\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.8765 - mae: 548.8765 - val_loss: 548.7183 - val_mae: 548.7183\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.0086 - mae: 547.0086 - val_loss: 549.8254 - val_mae: 549.8254\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.8348 - mae: 545.8348 - val_loss: 544.8846 - val_mae: 544.8846\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.1553 - mae: 546.1553 - val_loss: 541.8577 - val_mae: 541.8577\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.2175 - mae: 545.2175 - val_loss: 542.6650 - val_mae: 542.6650\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.7310 - mae: 544.7310 - val_loss: 543.0342 - val_mae: 543.0342\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.7993 - mae: 545.7993 - val_loss: 546.4219 - val_mae: 546.4219\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.3744 - mae: 544.3744 - val_loss: 540.3267 - val_mae: 540.3267\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.9598 - mae: 543.9598 - val_loss: 550.7906 - val_mae: 550.7906\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.9583 - mae: 544.9583 - val_loss: 543.0765 - val_mae: 543.0765\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.7355 - mae: 543.7355 - val_loss: 544.3212 - val_mae: 544.3212\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.8848 - mae: 543.8848 - val_loss: 542.6069 - val_mae: 542.6069\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.7689 - mae: 544.7689 - val_loss: 541.1500 - val_mae: 541.1500\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.3588 - mae: 543.3588 - val_loss: 543.9478 - val_mae: 543.9478\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.9113 - mae: 543.9113 - val_loss: 549.6733 - val_mae: 549.6733\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.6878 - mae: 543.6878 - val_loss: 545.4334 - val_mae: 545.4334\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 543.8821 - mae: 543.8821 - val_loss: 544.2471 - val_mae: 544.2471\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542.9458 - mae: 542.9458 - val_loss: 542.7702 - val_mae: 542.7702\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6053.4155 - mae: 6053.4155 - val_loss: 6050.5317 - val_mae: 6050.5317\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 6030.3721 - mae: 6030.3721 - val_loss: 5975.5713 - val_mae: 5975.5713\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5455.5547 - mae: 5455.5547 - val_loss: 3981.9011 - val_mae: 3981.9011\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1402.7729 - mae: 1402.7729 - val_loss: 756.2207 - val_mae: 756.2207\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 650.2693 - mae: 650.2693 - val_loss: 619.4210 - val_mae: 619.4210\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616.0396 - mae: 616.0396 - val_loss: 610.7045 - val_mae: 610.7045\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609.9564 - mae: 609.9564 - val_loss: 604.4818 - val_mae: 604.4818\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603.6341 - mae: 603.6341 - val_loss: 600.0792 - val_mae: 600.0792\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595.1776 - mae: 595.1776 - val_loss: 587.5517 - val_mae: 587.5517\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584.0895 - mae: 584.0895 - val_loss: 577.1317 - val_mae: 577.1317\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 574.2155 - mae: 574.2155 - val_loss: 569.4250 - val_mae: 569.4250\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 567.0244 - mae: 567.0244 - val_loss: 561.9614 - val_mae: 561.9614\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 562.6921 - mae: 562.6921 - val_loss: 560.1204 - val_mae: 560.1204\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560.9878 - mae: 560.9878 - val_loss: 557.1777 - val_mae: 557.1777\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557.9071 - mae: 557.9071 - val_loss: 554.9283 - val_mae: 554.9283\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554.0891 - mae: 554.0891 - val_loss: 551.1185 - val_mae: 551.1185\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.1063 - mae: 551.1063 - val_loss: 547.4674 - val_mae: 547.4674\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.6744 - mae: 547.6744 - val_loss: 544.6785 - val_mae: 544.6785\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.7793 - mae: 545.7793 - val_loss: 544.9319 - val_mae: 544.9319\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.0324 - mae: 545.0324 - val_loss: 542.9649 - val_mae: 542.9649\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.2166 - mae: 543.2166 - val_loss: 546.3342 - val_mae: 546.3342\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.9489 - mae: 541.9489 - val_loss: 542.7801 - val_mae: 542.7801\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.9542 - mae: 541.9542 - val_loss: 539.7418 - val_mae: 539.7418\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.4030 - mae: 541.4030 - val_loss: 539.6444 - val_mae: 539.6444\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.6958 - mae: 540.6958 - val_loss: 537.9288 - val_mae: 537.9288\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.4367 - mae: 540.4367 - val_loss: 538.5640 - val_mae: 538.5640\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.2495 - mae: 540.2495 - val_loss: 538.9988 - val_mae: 538.9988\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.7150 - mae: 539.7150 - val_loss: 538.3417 - val_mae: 538.3417\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.2381 - mae: 539.2381 - val_loss: 539.2415 - val_mae: 539.2415\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.0243 - mae: 539.0243 - val_loss: 537.8400 - val_mae: 537.8400\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.9931 - mae: 538.9931 - val_loss: 538.4238 - val_mae: 538.4238\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.0948 - mae: 539.0948 - val_loss: 537.8909 - val_mae: 537.8909\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.7344 - mae: 538.7344 - val_loss: 537.0163 - val_mae: 537.0163\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.8149 - mae: 538.8149 - val_loss: 537.6318 - val_mae: 537.6318\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.5563 - mae: 538.5563 - val_loss: 537.0337 - val_mae: 537.0337\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.1387 - mae: 538.1387 - val_loss: 538.5428 - val_mae: 538.5428\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.3384 - mae: 538.3384 - val_loss: 536.9976 - val_mae: 536.9976\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.9469 - mae: 537.9469 - val_loss: 536.2316 - val_mae: 536.2316\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.7881 - mae: 537.7881 - val_loss: 536.7335 - val_mae: 536.7335\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.4858 - mae: 537.4858 - val_loss: 536.5884 - val_mae: 536.5884\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.5841 - mae: 537.5841 - val_loss: 535.5311 - val_mae: 535.5311\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.1987 - mae: 537.1987 - val_loss: 535.6891 - val_mae: 535.6891\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.4050 - mae: 537.4050 - val_loss: 535.3965 - val_mae: 535.3965\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.8970 - mae: 536.8970 - val_loss: 537.2554 - val_mae: 537.2554\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.5964 - mae: 536.5964 - val_loss: 535.9487 - val_mae: 535.9487\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.1888 - mae: 537.1888 - val_loss: 536.2386 - val_mae: 536.2386\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.1778 - mae: 537.1778 - val_loss: 533.7798 - val_mae: 533.7798\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.7094 - mae: 536.7094 - val_loss: 534.6943 - val_mae: 534.6943\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.4733 - mae: 536.4733 - val_loss: 535.4110 - val_mae: 535.4110\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.1848 - mae: 537.1848 - val_loss: 533.9258 - val_mae: 533.9258\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.2535 - mae: 536.2535 - val_loss: 538.2393 - val_mae: 538.2393\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.1370 - mae: 536.1370 - val_loss: 535.8323 - val_mae: 535.8323\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.6431 - mae: 535.6431 - val_loss: 535.1556 - val_mae: 535.1556\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.9948 - mae: 535.9948 - val_loss: 534.0081 - val_mae: 534.0081\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.4954 - mae: 535.4954 - val_loss: 535.3264 - val_mae: 535.3264\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.5670 - mae: 535.5670 - val_loss: 534.1279 - val_mae: 534.1279\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.5800 - mae: 535.5800 - val_loss: 533.2556 - val_mae: 533.2556\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.4119 - mae: 535.4119 - val_loss: 534.7927 - val_mae: 534.7927\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.7789 - mae: 534.7789 - val_loss: 533.5800 - val_mae: 533.5800\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.3848 - mae: 535.3848 - val_loss: 533.7086 - val_mae: 533.7086\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.0271 - mae: 535.0271 - val_loss: 535.8779 - val_mae: 535.8779\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.1600 - mae: 535.1600 - val_loss: 534.4813 - val_mae: 534.4813\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.3464 - mae: 534.3464 - val_loss: 533.9197 - val_mae: 533.9197\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.8071 - mae: 534.8071 - val_loss: 532.5408 - val_mae: 532.5408\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.2969 - mae: 534.2969 - val_loss: 533.4766 - val_mae: 533.4766\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.5120 - mae: 534.5120 - val_loss: 532.9179 - val_mae: 532.9179\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.3801 - mae: 534.3801 - val_loss: 531.9284 - val_mae: 531.9284\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.1842 - mae: 534.1842 - val_loss: 531.6691 - val_mae: 531.6691\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.0162 - mae: 534.0162 - val_loss: 533.1602 - val_mae: 533.1602\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.5609 - mae: 534.5609 - val_loss: 532.8422 - val_mae: 532.8422\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.8540 - mae: 533.8540 - val_loss: 532.7413 - val_mae: 532.7413\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.6610 - mae: 533.6610 - val_loss: 532.2128 - val_mae: 532.2128\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.3800 - mae: 533.3800 - val_loss: 531.3331 - val_mae: 531.3331\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.6295 - mae: 533.6295 - val_loss: 531.7638 - val_mae: 531.7638\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.6907 - mae: 532.6907 - val_loss: 533.9635 - val_mae: 533.9635\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.5139 - mae: 533.5139 - val_loss: 533.1389 - val_mae: 533.1389\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.5829 - mae: 533.5829 - val_loss: 532.6504 - val_mae: 532.6504\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.0331 - mae: 533.0331 - val_loss: 531.1227 - val_mae: 531.1227\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.9807 - mae: 532.9807 - val_loss: 531.3779 - val_mae: 531.3779\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.4476 - mae: 532.4476 - val_loss: 532.4799 - val_mae: 532.4799\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.9799 - mae: 532.9799 - val_loss: 532.0763 - val_mae: 532.0763\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.7766 - mae: 532.7766 - val_loss: 530.8246 - val_mae: 530.8246\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.6928 - mae: 532.6928 - val_loss: 533.4099 - val_mae: 533.4099\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.9995 - mae: 531.9995 - val_loss: 531.5359 - val_mae: 531.5359\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.2783 - mae: 532.2783 - val_loss: 531.7502 - val_mae: 531.7502\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.7873 - mae: 531.7873 - val_loss: 531.5886 - val_mae: 531.5886\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.8577 - mae: 531.8577 - val_loss: 529.4055 - val_mae: 529.4055\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.7001 - mae: 531.7001 - val_loss: 530.6007 - val_mae: 530.6007\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.9111 - mae: 530.9111 - val_loss: 531.9418 - val_mae: 531.9418\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.5884 - mae: 531.5884 - val_loss: 530.8845 - val_mae: 530.8845\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.6611 - mae: 531.6611 - val_loss: 529.9825 - val_mae: 529.9825\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.2964 - mae: 531.2964 - val_loss: 529.9132 - val_mae: 529.9132\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.3975 - mae: 531.3975 - val_loss: 530.0131 - val_mae: 530.0131\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.8357 - mae: 530.8357 - val_loss: 529.4581 - val_mae: 529.4581\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 531.3386 - mae: 531.3386 - val_loss: 530.2175 - val_mae: 530.2175\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.8731 - mae: 530.8731 - val_loss: 529.0860 - val_mae: 529.0860\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.5856 - mae: 530.5856 - val_loss: 530.2466 - val_mae: 530.2466\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.5523 - mae: 530.5523 - val_loss: 530.9276 - val_mae: 530.9276\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.8661 - mae: 529.8661 - val_loss: 530.7681 - val_mae: 530.7681\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.1409 - mae: 530.1409 - val_loss: 528.5805 - val_mae: 528.5805\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.0687 - mae: 530.0687 - val_loss: 528.4170 - val_mae: 528.4170\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.7972 - mae: 529.7972 - val_loss: 529.0512 - val_mae: 529.0512\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.9439 - mae: 529.9439 - val_loss: 528.2401 - val_mae: 528.2401\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.9478 - mae: 529.9478 - val_loss: 528.1523 - val_mae: 528.1523\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.8079 - mae: 529.8079 - val_loss: 527.9953 - val_mae: 527.9953\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.4247 - mae: 529.4247 - val_loss: 529.8826 - val_mae: 529.8826\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.3732 - mae: 529.3732 - val_loss: 528.6452 - val_mae: 528.6452\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.6620 - mae: 529.6620 - val_loss: 528.5757 - val_mae: 528.5757\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.7514 - mae: 529.7514 - val_loss: 527.6340 - val_mae: 527.6340\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.9782 - mae: 528.9782 - val_loss: 528.4380 - val_mae: 528.4380\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.1377 - mae: 529.1377 - val_loss: 527.3983 - val_mae: 527.3983\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.7856 - mae: 528.7856 - val_loss: 527.7404 - val_mae: 527.7404\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.0711 - mae: 529.0711 - val_loss: 528.1027 - val_mae: 528.1027\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.9316 - mae: 528.9316 - val_loss: 526.8095 - val_mae: 526.8095\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.4386 - mae: 528.4386 - val_loss: 526.9257 - val_mae: 526.9257\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.8344 - mae: 528.8344 - val_loss: 526.5336 - val_mae: 526.5336\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.4333 - mae: 528.4333 - val_loss: 527.6710 - val_mae: 527.6710\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.3023 - mae: 528.3023 - val_loss: 527.9105 - val_mae: 527.9105\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.9662 - mae: 528.9662 - val_loss: 529.7924 - val_mae: 529.7924\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.3453 - mae: 528.3453 - val_loss: 528.5552 - val_mae: 528.5552\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.3985 - mae: 528.3985 - val_loss: 527.3456 - val_mae: 527.3456\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.2732 - mae: 528.2732 - val_loss: 526.0997 - val_mae: 526.0997\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.5039 - mae: 528.5039 - val_loss: 527.6285 - val_mae: 527.6285\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.5129 - mae: 528.5129 - val_loss: 527.6226 - val_mae: 527.6226\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.2239 - mae: 528.2239 - val_loss: 526.5046 - val_mae: 526.5046\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.6371 - mae: 527.6371 - val_loss: 526.5106 - val_mae: 526.5106\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.5723 - mae: 527.5723 - val_loss: 525.5689 - val_mae: 525.5689\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.5435 - mae: 527.5435 - val_loss: 525.6680 - val_mae: 525.6680\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.3265 - mae: 527.3265 - val_loss: 528.1441 - val_mae: 528.1441\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.0380 - mae: 528.0380 - val_loss: 525.9855 - val_mae: 525.9855\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 526.6553 - mae: 526.6553 - val_loss: 525.1605 - val_mae: 525.1605\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.5175 - mae: 527.5175 - val_loss: 525.6379 - val_mae: 525.6379\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.1029 - mae: 528.1029 - val_loss: 524.6298 - val_mae: 524.6298\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.5930 - mae: 527.5930 - val_loss: 525.5733 - val_mae: 525.5733\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.7041 - mae: 527.7041 - val_loss: 527.7731 - val_mae: 527.7731\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.1208 - mae: 527.1208 - val_loss: 524.7772 - val_mae: 524.7772\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.4506 - mae: 527.4506 - val_loss: 524.7071 - val_mae: 524.7071\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 526.9830 - mae: 526.9830 - val_loss: 525.1630 - val_mae: 525.1630\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.1269 - mae: 527.1269 - val_loss: 526.5996 - val_mae: 526.5996\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 526.9856 - mae: 526.9856 - val_loss: 526.0960 - val_mae: 526.0960\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 526.4575 - mae: 526.4575 - val_loss: 526.9782 - val_mae: 526.9782\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 526.6441 - mae: 526.6441 - val_loss: 524.9452 - val_mae: 524.9452\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 526.8329 - mae: 526.8329 - val_loss: 526.1957 - val_mae: 526.1957\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 6048.1465 - mae: 6048.1465 - val_loss: 6031.8765 - val_mae: 6031.8765\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5766.5508 - mae: 5766.5508 - val_loss: 4827.2310 - val_mae: 4827.2310\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1625.7194 - mae: 1625.7194 - val_loss: 612.4927 - val_mae: 612.4927\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609.9266 - mae: 609.9266 - val_loss: 610.2534 - val_mae: 610.2534\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609.2331 - mae: 609.2331 - val_loss: 607.2269 - val_mae: 607.2269\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607.9175 - mae: 607.9175 - val_loss: 605.8881 - val_mae: 605.8881\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607.3273 - mae: 607.3273 - val_loss: 607.0798 - val_mae: 607.0798\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605.1707 - mae: 605.1707 - val_loss: 606.3539 - val_mae: 606.3539\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 605.4487 - mae: 605.4487 - val_loss: 605.0283 - val_mae: 605.0283\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604.6129 - mae: 604.6129 - val_loss: 601.2877 - val_mae: 601.2877\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602.3801 - mae: 602.3801 - val_loss: 597.7505 - val_mae: 597.7505\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600.6608 - mae: 600.6608 - val_loss: 598.3574 - val_mae: 598.3574\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596.7693 - mae: 596.7693 - val_loss: 593.4536 - val_mae: 593.4536\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591.4079 - mae: 591.4079 - val_loss: 589.0176 - val_mae: 589.0176\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 585.0430 - mae: 585.0430 - val_loss: 581.7428 - val_mae: 581.7428\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580.4141 - mae: 580.4141 - val_loss: 577.6718 - val_mae: 577.6718\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 576.5870 - mae: 576.5870 - val_loss: 570.6569 - val_mae: 570.6569\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571.5823 - mae: 571.5823 - val_loss: 568.2312 - val_mae: 568.2312\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 566.7664 - mae: 566.7664 - val_loss: 563.5895 - val_mae: 563.5895\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564.3303 - mae: 564.3303 - val_loss: 560.2250 - val_mae: 560.2250\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560.6942 - mae: 560.6942 - val_loss: 558.4037 - val_mae: 558.4037\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559.9200 - mae: 559.9200 - val_loss: 559.3192 - val_mae: 559.3192\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558.2661 - mae: 558.2661 - val_loss: 553.7834 - val_mae: 553.7834\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 556.7971 - mae: 556.7971 - val_loss: 553.2045 - val_mae: 553.2045\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554.3460 - mae: 554.3460 - val_loss: 552.9390 - val_mae: 552.9390\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553.6135 - mae: 553.6135 - val_loss: 554.0724 - val_mae: 554.0724\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.8682 - mae: 552.8682 - val_loss: 549.4752 - val_mae: 549.4752\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.6707 - mae: 551.6707 - val_loss: 551.6520 - val_mae: 551.6520\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.2214 - mae: 552.2214 - val_loss: 553.8923 - val_mae: 553.8923\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.0339 - mae: 552.0339 - val_loss: 548.5084 - val_mae: 548.5084\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.7458 - mae: 551.7458 - val_loss: 550.3691 - val_mae: 550.3691\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 552.2792 - mae: 552.2792 - val_loss: 549.4126 - val_mae: 549.4126\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.6169 - mae: 551.6169 - val_loss: 547.8463 - val_mae: 547.8463\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.7213 - mae: 550.7213 - val_loss: 549.3316 - val_mae: 549.3316\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.2114 - mae: 551.2114 - val_loss: 551.6696 - val_mae: 551.6696\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 551.1254 - mae: 551.1254 - val_loss: 548.9157 - val_mae: 548.9157\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.5526 - mae: 550.5526 - val_loss: 551.1264 - val_mae: 551.1264\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.3476 - mae: 550.3476 - val_loss: 549.4815 - val_mae: 549.4815\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 550.7313 - mae: 550.7313 - val_loss: 549.6584 - val_mae: 549.6584\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.7817 - mae: 550.7817 - val_loss: 547.7742 - val_mae: 547.7742\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.8884 - mae: 550.8884 - val_loss: 549.9240 - val_mae: 549.9240\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.0324 - mae: 550.0324 - val_loss: 548.4507 - val_mae: 548.4507\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.0784 - mae: 550.0784 - val_loss: 549.0079 - val_mae: 549.0079\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.5978 - mae: 550.5978 - val_loss: 550.2698 - val_mae: 550.2698\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.4349 - mae: 549.4349 - val_loss: 548.7653 - val_mae: 548.7653\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.8383 - mae: 549.8383 - val_loss: 549.3909 - val_mae: 549.3909\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.7214 - mae: 549.7214 - val_loss: 547.9493 - val_mae: 547.9493\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.0508 - mae: 550.0508 - val_loss: 547.7560 - val_mae: 547.7560\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.7278 - mae: 549.7278 - val_loss: 546.5798 - val_mae: 546.5798\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.9482 - mae: 549.9482 - val_loss: 548.3843 - val_mae: 548.3843\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.8472 - mae: 549.8472 - val_loss: 547.1553 - val_mae: 547.1553\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.3167 - mae: 549.3167 - val_loss: 547.7007 - val_mae: 547.7007\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 549.6491 - mae: 549.6491 - val_loss: 548.3445 - val_mae: 548.3445\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.9253 - mae: 548.9253 - val_loss: 546.6624 - val_mae: 546.6624\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.7490 - mae: 548.7490 - val_loss: 546.4160 - val_mae: 546.4160\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.3998 - mae: 548.3998 - val_loss: 546.1396 - val_mae: 546.1396\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.5279 - mae: 547.5279 - val_loss: 547.0042 - val_mae: 547.0042\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.4140 - mae: 548.4140 - val_loss: 546.1613 - val_mae: 546.1613\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.9763 - mae: 547.9763 - val_loss: 545.5140 - val_mae: 545.5140\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.5396 - mae: 547.5396 - val_loss: 545.7703 - val_mae: 545.7703\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.0062 - mae: 547.0062 - val_loss: 548.3895 - val_mae: 548.3895\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 547.4913 - mae: 547.4913 - val_loss: 543.7760 - val_mae: 543.7760\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.6486 - mae: 546.6486 - val_loss: 544.9257 - val_mae: 544.9257\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.7276 - mae: 546.7276 - val_loss: 546.7020 - val_mae: 546.7020\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.9965 - mae: 545.9965 - val_loss: 544.7829 - val_mae: 544.7829\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 546.2288 - mae: 546.2288 - val_loss: 543.3513 - val_mae: 543.3513\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.3000 - mae: 545.3000 - val_loss: 544.4208 - val_mae: 544.4208\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.9034 - mae: 544.9034 - val_loss: 545.3400 - val_mae: 545.3400\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.1734 - mae: 545.1734 - val_loss: 543.5395 - val_mae: 543.5395\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.3177 - mae: 544.3177 - val_loss: 543.9829 - val_mae: 543.9829\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.3030 - mae: 543.3030 - val_loss: 541.6675 - val_mae: 541.6675\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 544.1477 - mae: 544.1477 - val_loss: 544.8275 - val_mae: 544.8275\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 543.2209 - mae: 543.2209 - val_loss: 540.5040 - val_mae: 540.5040\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.7476 - mae: 542.7476 - val_loss: 543.2617 - val_mae: 543.2617\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 542.4461 - mae: 542.4461 - val_loss: 541.3417 - val_mae: 541.3417\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.5980 - mae: 541.5980 - val_loss: 542.2770 - val_mae: 542.2770\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.8694 - mae: 541.8694 - val_loss: 539.7791 - val_mae: 539.7791\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.2307 - mae: 541.2307 - val_loss: 539.1683 - val_mae: 539.1683\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.6816 - mae: 541.6816 - val_loss: 538.9360 - val_mae: 538.9360\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.1469 - mae: 541.1469 - val_loss: 542.7747 - val_mae: 542.7747\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.5758 - mae: 540.5758 - val_loss: 539.9067 - val_mae: 539.9067\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.7667 - mae: 540.7667 - val_loss: 540.5060 - val_mae: 540.5060\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.0965 - mae: 540.0965 - val_loss: 537.8538 - val_mae: 537.8538\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.8153 - mae: 539.8153 - val_loss: 538.3831 - val_mae: 538.3831\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 540.0324 - mae: 540.0324 - val_loss: 537.1036 - val_mae: 537.1036\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.8534 - mae: 539.8534 - val_loss: 537.2166 - val_mae: 537.2166\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.2847 - mae: 539.2847 - val_loss: 539.7852 - val_mae: 539.7852\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.9426 - mae: 538.9426 - val_loss: 538.3221 - val_mae: 538.3221\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.5114 - mae: 538.5114 - val_loss: 541.2602 - val_mae: 541.2602\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.9807 - mae: 539.9807 - val_loss: 535.9766 - val_mae: 535.9766\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.3757 - mae: 539.3757 - val_loss: 537.1934 - val_mae: 537.1934\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.5620 - mae: 538.5620 - val_loss: 539.3110 - val_mae: 539.3110\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.0845 - mae: 539.0845 - val_loss: 536.6064 - val_mae: 536.6064\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.0181 - mae: 539.0181 - val_loss: 537.2337 - val_mae: 537.2337\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.3458 - mae: 538.3458 - val_loss: 539.1617 - val_mae: 539.1617\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.6041 - mae: 538.6041 - val_loss: 536.5956 - val_mae: 536.5956\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.7299 - mae: 537.7299 - val_loss: 538.6382 - val_mae: 538.6382\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.1254 - mae: 538.1254 - val_loss: 536.1475 - val_mae: 536.1475\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 537.8968 - mae: 537.8968 - val_loss: 537.0102 - val_mae: 537.0102\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 538.3978 - mae: 538.3978 - val_loss: 540.4687 - val_mae: 540.4687\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 5653.8979 - mae: 5653.8979 - val_loss: 1214.6730 - val_mae: 1214.6730\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 636.7894 - mae: 636.7894 - val_loss: 616.9286 - val_mae: 616.9286\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602.9426 - mae: 602.9426 - val_loss: 608.3047 - val_mae: 608.3047\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 600.0757 - mae: 600.0757 - val_loss: 601.1965 - val_mae: 601.1965\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 597.7537 - mae: 597.7537 - val_loss: 596.6564 - val_mae: 596.6564\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593.8946 - mae: 593.8946 - val_loss: 585.9277 - val_mae: 585.9277\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590.0421 - mae: 590.0421 - val_loss: 583.1212 - val_mae: 583.1212\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584.5138 - mae: 584.5138 - val_loss: 576.5695 - val_mae: 576.5695\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576.6650 - mae: 576.6650 - val_loss: 571.1367 - val_mae: 571.1367\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570.6929 - mae: 570.6929 - val_loss: 570.3161 - val_mae: 570.3161\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 564.3845 - mae: 564.3845 - val_loss: 568.9711 - val_mae: 568.9711\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560.0909 - mae: 560.0909 - val_loss: 547.4703 - val_mae: 547.4703\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555.4863 - mae: 555.4863 - val_loss: 564.5019 - val_mae: 564.5019\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.0988 - mae: 552.0988 - val_loss: 553.9782 - val_mae: 553.9782\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 552.8162 - mae: 552.8162 - val_loss: 556.3281 - val_mae: 556.3281\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.7071 - mae: 551.7071 - val_loss: 545.2109 - val_mae: 545.2109\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.0690 - mae: 550.0690 - val_loss: 546.4677 - val_mae: 546.4677\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.2400 - mae: 549.2400 - val_loss: 553.4562 - val_mae: 553.4562\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.6033 - mae: 548.6033 - val_loss: 547.4500 - val_mae: 547.4500\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.8696 - mae: 548.8696 - val_loss: 546.5991 - val_mae: 546.5991\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.4022 - mae: 548.4022 - val_loss: 555.1981 - val_mae: 555.1981\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.8843 - mae: 548.8843 - val_loss: 571.0141 - val_mae: 571.0141\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.9969 - mae: 548.9969 - val_loss: 553.5794 - val_mae: 553.5794\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.1878 - mae: 549.1878 - val_loss: 552.4566 - val_mae: 552.4566\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.2798 - mae: 548.2798 - val_loss: 550.3749 - val_mae: 550.3749\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 547.6454 - mae: 547.6454 - val_loss: 554.8672 - val_mae: 554.8672\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3799.1594 - mae: 3799.1594 - val_loss: 609.5201 - val_mae: 609.5201\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 612.6231 - mae: 612.6231 - val_loss: 628.4958 - val_mae: 628.4958\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 603.7762 - mae: 603.7762 - val_loss: 607.8193 - val_mae: 607.8193\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592.2953 - mae: 592.2953 - val_loss: 589.7191 - val_mae: 589.7191\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576.7743 - mae: 576.7743 - val_loss: 563.2784 - val_mae: 563.2784\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565.6835 - mae: 565.6835 - val_loss: 559.2253 - val_mae: 559.2253\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556.9555 - mae: 556.9555 - val_loss: 553.2094 - val_mae: 553.2094\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.7281 - mae: 551.7281 - val_loss: 559.5475 - val_mae: 559.5475\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 551.8311 - mae: 551.8311 - val_loss: 556.6907 - val_mae: 556.6907\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 550.8093 - mae: 550.8093 - val_loss: 555.0248 - val_mae: 555.0248\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 549.1390 - mae: 549.1390 - val_loss: 554.7490 - val_mae: 554.7490\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 548.4946 - mae: 548.4946 - val_loss: 545.8263 - val_mae: 545.8263\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.8090 - mae: 545.8090 - val_loss: 547.0889 - val_mae: 547.0889\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544.7200 - mae: 544.7200 - val_loss: 550.2530 - val_mae: 550.2530\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 545.5330 - mae: 545.5330 - val_loss: 547.1435 - val_mae: 547.1435\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 544.3988 - mae: 544.3988 - val_loss: 538.7328 - val_mae: 538.7328\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 542.9451 - mae: 542.9451 - val_loss: 542.2179 - val_mae: 542.2179\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.0280 - mae: 541.0280 - val_loss: 548.4792 - val_mae: 548.4792\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 540.6669 - mae: 540.6669 - val_loss: 534.4371 - val_mae: 534.4371\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 541.3578 - mae: 541.3578 - val_loss: 546.8529 - val_mae: 546.8529\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.9291 - mae: 538.9291 - val_loss: 548.7779 - val_mae: 548.7779\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.2327 - mae: 538.2327 - val_loss: 544.8862 - val_mae: 544.8862\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 538.1447 - mae: 538.1447 - val_loss: 536.7223 - val_mae: 536.7223\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 537.1498 - mae: 537.1498 - val_loss: 567.8211 - val_mae: 567.8211\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 536.5731 - mae: 536.5731 - val_loss: 535.3184 - val_mae: 535.3184\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.1890 - mae: 535.1890 - val_loss: 537.2487 - val_mae: 537.2487\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 535.0154 - mae: 535.0154 - val_loss: 531.2905 - val_mae: 531.2905\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 533.6667 - mae: 533.6667 - val_loss: 538.1686 - val_mae: 538.1686\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.6954 - mae: 534.6954 - val_loss: 549.6326 - val_mae: 549.6326\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 534.4198 - mae: 534.4198 - val_loss: 533.0862 - val_mae: 533.0862\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.5923 - mae: 532.5923 - val_loss: 532.7241 - val_mae: 532.7241\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.0345 - mae: 532.0345 - val_loss: 541.2854 - val_mae: 541.2854\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.8185 - mae: 531.8185 - val_loss: 528.6925 - val_mae: 528.6925\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 532.1401 - mae: 532.1401 - val_loss: 552.1462 - val_mae: 552.1462\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.3437 - mae: 531.3437 - val_loss: 532.4391 - val_mae: 532.4391\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.3896 - mae: 531.3896 - val_loss: 535.2643 - val_mae: 535.2643\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 531.6713 - mae: 531.6713 - val_loss: 543.1631 - val_mae: 543.1631\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.3983 - mae: 530.3983 - val_loss: 527.0541 - val_mae: 527.0541\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.9607 - mae: 529.9607 - val_loss: 537.0789 - val_mae: 537.0789\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.1187 - mae: 530.1187 - val_loss: 533.6684 - val_mae: 533.6684\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.7105 - mae: 529.7105 - val_loss: 539.2470 - val_mae: 539.2470\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 530.2526 - mae: 530.2526 - val_loss: 532.4791 - val_mae: 532.4791\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.6218 - mae: 529.6218 - val_loss: 526.7292 - val_mae: 526.7292\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.4408 - mae: 527.4408 - val_loss: 546.8682 - val_mae: 546.8682\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.2593 - mae: 529.2593 - val_loss: 532.7921 - val_mae: 532.7921\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 529.0598 - mae: 529.0598 - val_loss: 531.1908 - val_mae: 531.1908\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.7961 - mae: 527.7961 - val_loss: 526.9460 - val_mae: 526.9460\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.0880 - mae: 528.0880 - val_loss: 528.4880 - val_mae: 528.4880\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.0478 - mae: 528.0478 - val_loss: 525.3038 - val_mae: 525.3038\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.1320 - mae: 528.1320 - val_loss: 535.1617 - val_mae: 535.1617\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.3858 - mae: 528.3858 - val_loss: 525.0070 - val_mae: 525.0070\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.5129 - mae: 526.5129 - val_loss: 529.3304 - val_mae: 529.3304\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 528.5568 - mae: 528.5568 - val_loss: 524.4667 - val_mae: 524.4667\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.7521 - mae: 526.7521 - val_loss: 535.5801 - val_mae: 535.5801\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.4584 - mae: 527.4584 - val_loss: 537.5356 - val_mae: 537.5356\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.7728 - mae: 527.7728 - val_loss: 523.2265 - val_mae: 523.2265\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.6323 - mae: 526.6323 - val_loss: 544.8825 - val_mae: 544.8825\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.8717 - mae: 526.8717 - val_loss: 525.1458 - val_mae: 525.1458\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.4181 - mae: 527.4181 - val_loss: 539.6155 - val_mae: 539.6155\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.9929 - mae: 527.9929 - val_loss: 528.2534 - val_mae: 528.2534\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 527.7694 - mae: 527.7694 - val_loss: 526.6888 - val_mae: 526.6888\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.9307 - mae: 526.9307 - val_loss: 528.5046 - val_mae: 528.5046\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.3725 - mae: 526.3725 - val_loss: 528.5193 - val_mae: 528.5193\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.2330 - mae: 526.2330 - val_loss: 537.1862 - val_mae: 537.1862\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 526.7802 - mae: 526.7802 - val_loss: 523.8486 - val_mae: 523.8486\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 525.4984 - mae: 525.4984 - val_loss: 524.9781 - val_mae: 524.9781\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 6018.1743 - mae: 6018.1743 - val_loss: 5828.3999 - val_mae: 5828.3999\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2521.0334 - mae: 2521.0334 - val_loss: 610.6120 - val_mae: 610.6120\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608.6284 - mae: 608.6284 - val_loss: 607.8976 - val_mae: 607.8976\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604.9078 - mae: 604.9078 - val_loss: 602.3670 - val_mae: 602.3670\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602.3401 - mae: 602.3401 - val_loss: 601.2708 - val_mae: 601.2708\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597.1284 - mae: 597.1284 - val_loss: 595.4153 - val_mae: 595.4153\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592.8224 - mae: 592.8224 - val_loss: 586.8076 - val_mae: 586.8076\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586.8107 - mae: 586.8107 - val_loss: 578.7520 - val_mae: 578.7520\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578.6185 - mae: 578.6185 - val_loss: 572.8537 - val_mae: 572.8537\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571.7680 - mae: 571.7680 - val_loss: 570.5061 - val_mae: 570.5061\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566.9774 - mae: 566.9774 - val_loss: 559.4163 - val_mae: 559.4163\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562.8004 - mae: 562.8004 - val_loss: 556.5873 - val_mae: 556.5873\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559.8409 - mae: 559.8409 - val_loss: 556.1207 - val_mae: 556.1207\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557.8104 - mae: 557.8104 - val_loss: 554.2452 - val_mae: 554.2452\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555.3265 - mae: 555.3265 - val_loss: 554.9942 - val_mae: 554.9942\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555.9650 - mae: 555.9650 - val_loss: 553.5943 - val_mae: 553.5943\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553.6104 - mae: 553.6104 - val_loss: 554.2825 - val_mae: 554.2825\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.9238 - mae: 552.9238 - val_loss: 554.9019 - val_mae: 554.9019\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.2101 - mae: 552.2101 - val_loss: 556.5160 - val_mae: 556.5160\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.8857 - mae: 552.8857 - val_loss: 548.8553 - val_mae: 548.8553\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.7953 - mae: 551.7953 - val_loss: 550.9604 - val_mae: 550.9604\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.0208 - mae: 552.0208 - val_loss: 555.0792 - val_mae: 555.0792\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552.4308 - mae: 552.4308 - val_loss: 550.9460 - val_mae: 550.9460\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.2676 - mae: 551.2676 - val_loss: 550.3995 - val_mae: 550.3995\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.9398 - mae: 550.9398 - val_loss: 553.0076 - val_mae: 553.0076\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.3415 - mae: 551.3415 - val_loss: 551.5499 - val_mae: 551.5499\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.4684 - mae: 551.4684 - val_loss: 547.1836 - val_mae: 547.1836\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551.3244 - mae: 551.3244 - val_loss: 546.5446 - val_mae: 546.5446\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.3065 - mae: 550.3065 - val_loss: 548.5774 - val_mae: 548.5774\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548.0394 - mae: 548.0394 - val_loss: 546.1028 - val_mae: 546.1028\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.5916 - mae: 547.5916 - val_loss: 544.8598 - val_mae: 544.8598\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.9888 - mae: 547.9888 - val_loss: 546.3721 - val_mae: 546.3721\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.4680 - mae: 546.4680 - val_loss: 547.1452 - val_mae: 547.1452\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.8538 - mae: 545.8538 - val_loss: 550.5408 - val_mae: 550.5408\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.8898 - mae: 545.8898 - val_loss: 543.2318 - val_mae: 543.2318\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.8641 - mae: 545.8641 - val_loss: 542.3165 - val_mae: 542.3165\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.4165 - mae: 544.4165 - val_loss: 542.6630 - val_mae: 542.6630\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542.4915 - mae: 542.4915 - val_loss: 543.7161 - val_mae: 543.7161\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 542.8304 - mae: 542.8304 - val_loss: 539.1987 - val_mae: 539.1987\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.1288 - mae: 541.1288 - val_loss: 541.7542 - val_mae: 541.7542\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 540.8718 - mae: 540.8718 - val_loss: 539.6614 - val_mae: 539.6614\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.3707 - mae: 539.3707 - val_loss: 539.7854 - val_mae: 539.7854\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.1357 - mae: 539.1357 - val_loss: 538.9830 - val_mae: 538.9830\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.3995 - mae: 538.3995 - val_loss: 542.2749 - val_mae: 542.2749\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 538.7152 - mae: 538.7152 - val_loss: 534.8573 - val_mae: 534.8573\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.4050 - mae: 537.4050 - val_loss: 534.2322 - val_mae: 534.2322\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.0648 - mae: 537.0648 - val_loss: 536.1639 - val_mae: 536.1639\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.1486 - mae: 537.1486 - val_loss: 535.2548 - val_mae: 535.2548\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.9471 - mae: 536.9471 - val_loss: 536.1107 - val_mae: 536.1107\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.6096 - mae: 536.6096 - val_loss: 534.6190 - val_mae: 534.6190\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.2124 - mae: 535.2124 - val_loss: 535.1650 - val_mae: 535.1650\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.5749 - mae: 535.5749 - val_loss: 535.3229 - val_mae: 535.3229\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534.9243 - mae: 534.9243 - val_loss: 531.7489 - val_mae: 531.7489\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 535.1469 - mae: 535.1469 - val_loss: 532.5178 - val_mae: 532.5178\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.6030 - mae: 533.6030 - val_loss: 533.9251 - val_mae: 533.9251\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 534.2082 - mae: 534.2082 - val_loss: 530.6808 - val_mae: 530.6808\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.0317 - mae: 533.0317 - val_loss: 531.3073 - val_mae: 531.3073\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.0382 - mae: 533.0382 - val_loss: 531.4512 - val_mae: 531.4512\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 532.5093 - mae: 532.5093 - val_loss: 534.7971 - val_mae: 534.7971\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.9525 - mae: 531.9525 - val_loss: 531.3221 - val_mae: 531.3221\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.7112 - mae: 531.7112 - val_loss: 531.1243 - val_mae: 531.1243\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 531.1185 - mae: 531.1185 - val_loss: 530.4929 - val_mae: 530.4929\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.9854 - mae: 530.9854 - val_loss: 531.3400 - val_mae: 531.3400\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.4515 - mae: 530.4515 - val_loss: 526.0394 - val_mae: 526.0394\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.7258 - mae: 529.7258 - val_loss: 525.6639 - val_mae: 525.6639\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.7620 - mae: 529.7620 - val_loss: 526.0428 - val_mae: 526.0428\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.6620 - mae: 528.6620 - val_loss: 528.0384 - val_mae: 528.0384\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.4856 - mae: 528.4856 - val_loss: 529.1239 - val_mae: 529.1239\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.7720 - mae: 527.7720 - val_loss: 525.9883 - val_mae: 525.9883\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.3571 - mae: 527.3571 - val_loss: 529.6188 - val_mae: 529.6188\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.9172 - mae: 526.9172 - val_loss: 525.0657 - val_mae: 525.0657\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 527.1359 - mae: 527.1359 - val_loss: 525.6556 - val_mae: 525.6556\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.4228 - mae: 526.4228 - val_loss: 528.0777 - val_mae: 528.0777\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.4838 - mae: 526.4838 - val_loss: 528.7210 - val_mae: 528.7210\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 526.8165 - mae: 526.8165 - val_loss: 529.6287 - val_mae: 529.6287\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.8530 - mae: 525.8530 - val_loss: 524.7722 - val_mae: 524.7722\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.9083 - mae: 525.9083 - val_loss: 524.4214 - val_mae: 524.4214\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.5018 - mae: 525.5018 - val_loss: 523.8364 - val_mae: 523.8364\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 525.1803 - mae: 525.1803 - val_loss: 523.2164 - val_mae: 523.2164\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.6450 - mae: 524.6450 - val_loss: 522.8138 - val_mae: 522.8138\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.6226 - mae: 524.6226 - val_loss: 522.8582 - val_mae: 522.8582\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.6083 - mae: 524.6083 - val_loss: 521.6309 - val_mae: 521.6309\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.0781 - mae: 524.0781 - val_loss: 523.5563 - val_mae: 523.5563\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.4859 - mae: 524.4859 - val_loss: 522.2408 - val_mae: 522.2408\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 523.7778 - mae: 523.7778 - val_loss: 524.6433 - val_mae: 524.6433\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 523.6774 - mae: 523.6774 - val_loss: 521.6031 - val_mae: 521.6031\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 524.1125 - mae: 524.1125 - val_loss: 526.3912 - val_mae: 526.3912\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 523.2908 - mae: 523.2908 - val_loss: 521.8316 - val_mae: 521.8316\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.5025 - mae: 522.5025 - val_loss: 528.5651 - val_mae: 528.5651\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.0642 - mae: 522.0642 - val_loss: 519.2502 - val_mae: 519.2502\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.6414 - mae: 522.6414 - val_loss: 529.2269 - val_mae: 529.2269\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.5925 - mae: 522.5925 - val_loss: 525.1485 - val_mae: 525.1485\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.4526 - mae: 522.4526 - val_loss: 522.4673 - val_mae: 522.4673\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.0477 - mae: 522.0477 - val_loss: 521.5184 - val_mae: 521.5184\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.8862 - mae: 522.8862 - val_loss: 518.8991 - val_mae: 518.8991\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 521.9140 - mae: 521.9140 - val_loss: 520.7384 - val_mae: 520.7384\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.5145 - mae: 522.5145 - val_loss: 524.7180 - val_mae: 524.7180\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.1665 - mae: 522.1665 - val_loss: 518.9822 - val_mae: 518.9822\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 522.1993 - mae: 522.1993 - val_loss: 520.4473 - val_mae: 520.4473\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 520.8817 - mae: 520.8817 - val_loss: 520.7075 - val_mae: 520.7075\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 521.6341 - mae: 521.6341 - val_loss: 520.1061 - val_mae: 520.1061\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 520.8481 - mae: 520.8481 - val_loss: 520.4754 - val_mae: 520.4754\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 521.1226 - mae: 521.1226 - val_loss: 521.1614 - val_mae: 521.1614\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 521.3555 - mae: 521.3555 - val_loss: 521.2949 - val_mae: 521.2949\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 521.1441 - mae: 521.1441 - val_loss: 520.4802 - val_mae: 520.4802\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 5917.2461 - mae: 5917.2461 - val_loss: 4930.0918 - val_mae: 4930.0918\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1157.4467 - mae: 1157.4467 - val_loss: 619.7496 - val_mae: 619.7496\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 607.5786 - mae: 607.5786 - val_loss: 610.2603 - val_mae: 610.2603\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606.7831 - mae: 606.7831 - val_loss: 603.9174 - val_mae: 603.9174\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603.6464 - mae: 603.6464 - val_loss: 598.0277 - val_mae: 598.0277\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 600.1470 - mae: 600.1470 - val_loss: 601.1755 - val_mae: 601.1755\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 596.9822 - mae: 596.9822 - val_loss: 591.9266 - val_mae: 591.9266\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 589.1777 - mae: 589.1777 - val_loss: 584.0601 - val_mae: 584.0601\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580.8828 - mae: 580.8828 - val_loss: 577.5205 - val_mae: 577.5205\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572.0356 - mae: 572.0356 - val_loss: 572.7501 - val_mae: 572.7501\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563.9175 - mae: 563.9175 - val_loss: 568.6210 - val_mae: 568.6210\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558.2973 - mae: 558.2973 - val_loss: 559.8618 - val_mae: 559.8618\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554.0634 - mae: 554.0634 - val_loss: 550.0106 - val_mae: 550.0106\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550.8666 - mae: 550.8666 - val_loss: 547.7076 - val_mae: 547.7076\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549.0139 - mae: 549.0139 - val_loss: 551.7426 - val_mae: 551.7426\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547.6451 - mae: 547.6451 - val_loss: 545.9731 - val_mae: 545.9731\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546.8333 - mae: 546.8333 - val_loss: 542.9938 - val_mae: 542.9938\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545.1968 - mae: 545.1968 - val_loss: 541.1239 - val_mae: 541.1239\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544.0865 - mae: 544.0865 - val_loss: 546.1757 - val_mae: 546.1757\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.9029 - mae: 541.9029 - val_loss: 539.7772 - val_mae: 539.7772\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 541.5101 - mae: 541.5101 - val_loss: 537.9788 - val_mae: 537.9788\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.5082 - mae: 539.5082 - val_loss: 540.3644 - val_mae: 540.3644\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 541.1605 - mae: 541.1605 - val_loss: 537.3644 - val_mae: 537.3644\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 539.8050 - mae: 539.8050 - val_loss: 535.6124 - val_mae: 535.6124\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 537.6777 - mae: 537.6777 - val_loss: 535.5058 - val_mae: 535.5058\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.4315 - mae: 536.4315 - val_loss: 536.8507 - val_mae: 536.8507\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 536.1542 - mae: 536.1542 - val_loss: 534.8497 - val_mae: 534.8497\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 536.9443 - mae: 536.9443 - val_loss: 537.5715 - val_mae: 537.5715\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 534.8058 - mae: 534.8058 - val_loss: 535.3441 - val_mae: 535.3441\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 534.4818 - mae: 534.4818 - val_loss: 535.2892 - val_mae: 535.2892\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 533.2875 - mae: 533.2875 - val_loss: 537.9194 - val_mae: 537.9194\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 533.2354 - mae: 533.2354 - val_loss: 532.9748 - val_mae: 532.9748\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 533.0375 - mae: 533.0375 - val_loss: 531.3007 - val_mae: 531.3007\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 533.3076 - mae: 533.3076 - val_loss: 536.1439 - val_mae: 536.1439\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 533.3799 - mae: 533.3799 - val_loss: 528.0423 - val_mae: 528.0423\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 532.4031 - mae: 532.4031 - val_loss: 530.9146 - val_mae: 530.9146\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 532.0228 - mae: 532.0228 - val_loss: 525.9070 - val_mae: 525.9070\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.4335 - mae: 530.4335 - val_loss: 527.2592 - val_mae: 527.2592\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.9079 - mae: 530.9079 - val_loss: 531.2768 - val_mae: 531.2768\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.0911 - mae: 529.0911 - val_loss: 527.3026 - val_mae: 527.3026\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 528.8326 - mae: 528.8326 - val_loss: 530.8514 - val_mae: 530.8514\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 530.6656 - mae: 530.6656 - val_loss: 527.5330 - val_mae: 527.5330\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 529.5322 - mae: 529.5322 - val_loss: 527.2747 - val_mae: 527.2747\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 529.7454 - mae: 529.7454 - val_loss: 528.7856 - val_mae: 528.7856\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 528.6006 - mae: 528.6006 - val_loss: 536.7080 - val_mae: 536.7080\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.4658 - mae: 528.4658 - val_loss: 527.3671 - val_mae: 527.3671\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 528.9939 - mae: 528.9939 - val_loss: 527.7321 - val_mae: 527.7321\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 6052.6509 - mae: 6052.6509 - val_loss: 6048.2646 - val_mae: 6048.2646\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6018.0806 - mae: 6018.0806 - val_loss: 5936.5317 - val_mae: 5936.5317\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 5170.1680 - mae: 5170.1680 - val_loss: 3010.0471 - val_mae: 3010.0471\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1091.4005 - mae: 1091.4005 - val_loss: 613.9747 - val_mae: 613.9747\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 605.3453 - mae: 605.3453 - val_loss: 600.7415 - val_mae: 600.7415\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 600.4962 - mae: 600.4962 - val_loss: 597.8369 - val_mae: 597.8369\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 598.0053 - mae: 598.0053 - val_loss: 596.4160 - val_mae: 596.4160\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595.5883 - mae: 595.5883 - val_loss: 592.8746 - val_mae: 592.8746\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592.2957 - mae: 592.2957 - val_loss: 591.1088 - val_mae: 591.1088\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 589.4741 - mae: 589.4741 - val_loss: 584.9733 - val_mae: 584.9733\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584.7020 - mae: 584.7020 - val_loss: 579.6691 - val_mae: 579.6691\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 581.1628 - mae: 581.1628 - val_loss: 578.1808 - val_mae: 578.1808\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 578.3791 - mae: 578.3791 - val_loss: 577.6145 - val_mae: 577.6145\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 576.1036 - mae: 576.1036 - val_loss: 574.5624 - val_mae: 574.5624\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 573.5398 - mae: 573.5398 - val_loss: 571.0071 - val_mae: 571.0071\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570.6015 - mae: 570.6015 - val_loss: 567.2181 - val_mae: 567.2181\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 567.5297 - mae: 567.5297 - val_loss: 563.4262 - val_mae: 563.4262\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563.9365 - mae: 563.9365 - val_loss: 561.0139 - val_mae: 561.0139\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 562.3237 - mae: 562.3237 - val_loss: 560.5749 - val_mae: 560.5749\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561.3481 - mae: 561.3481 - val_loss: 558.5598 - val_mae: 558.5598\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 560.3757 - mae: 560.3757 - val_loss: 557.4297 - val_mae: 557.4297\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559.4873 - mae: 559.4873 - val_loss: 557.9949 - val_mae: 557.9949\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 559.3253 - mae: 559.3253 - val_loss: 559.2269 - val_mae: 559.2269\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 559.0270 - mae: 559.0270 - val_loss: 557.7285 - val_mae: 557.7285\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 557.7142 - mae: 557.7142 - val_loss: 557.0316 - val_mae: 557.0316\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556.9920 - mae: 556.9920 - val_loss: 553.9674 - val_mae: 553.9674\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556.5486 - mae: 556.5486 - val_loss: 554.9484 - val_mae: 554.9484\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555.7138 - mae: 555.7138 - val_loss: 555.8129 - val_mae: 555.8129\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555.2553 - mae: 555.2553 - val_loss: 553.2853 - val_mae: 553.2853\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 553.0843 - mae: 553.0843 - val_loss: 552.1918 - val_mae: 552.1918\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 551.7277 - mae: 551.7277 - val_loss: 548.9863 - val_mae: 548.9863\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 548.8553 - mae: 548.8553 - val_loss: 546.2557 - val_mae: 546.2557\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 548.1567 - mae: 548.1567 - val_loss: 543.6379 - val_mae: 543.6379\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 545.7371 - mae: 545.7371 - val_loss: 544.0095 - val_mae: 544.0095\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 544.9789 - mae: 544.9789 - val_loss: 542.1914 - val_mae: 542.1914\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 543.5517 - mae: 543.5517 - val_loss: 541.8540 - val_mae: 541.8540\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 543.3600 - mae: 543.3600 - val_loss: 542.1241 - val_mae: 542.1241\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 542.5219 - mae: 542.5219 - val_loss: 540.9962 - val_mae: 540.9962\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 541.9374 - mae: 541.9374 - val_loss: 540.3778 - val_mae: 540.3778\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 541.3291 - mae: 541.3291 - val_loss: 539.9819 - val_mae: 539.9819\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 541.2056 - mae: 541.2056 - val_loss: 539.3214 - val_mae: 539.3214\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 540.8749 - mae: 540.8749 - val_loss: 538.7960 - val_mae: 538.7960\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 540.7198 - mae: 540.7198 - val_loss: 539.7094 - val_mae: 539.7094\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 540.5209 - mae: 540.5209 - val_loss: 538.8204 - val_mae: 538.8204\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 539.5275 - mae: 539.5275 - val_loss: 538.4074 - val_mae: 538.4074\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 539.7391 - mae: 539.7391 - val_loss: 539.4216 - val_mae: 539.4216\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 539.4246 - mae: 539.4246 - val_loss: 537.5225 - val_mae: 537.5225\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 539.3831 - mae: 539.3831 - val_loss: 536.5449 - val_mae: 536.5449\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 538.7556 - mae: 538.7556 - val_loss: 537.4029 - val_mae: 537.4029\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 538.6438 - mae: 538.6438 - val_loss: 536.3430 - val_mae: 536.3430\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 537.5089 - mae: 537.5089 - val_loss: 536.0736 - val_mae: 536.0736\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 537.1638 - mae: 537.1638 - val_loss: 535.2428 - val_mae: 535.2428\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 536.4498 - mae: 536.4498 - val_loss: 536.2698 - val_mae: 536.2698\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 537.5002 - mae: 537.5002 - val_loss: 533.1323 - val_mae: 533.1323\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 535.9080 - mae: 535.9080 - val_loss: 536.8635 - val_mae: 536.8635\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 536.1728 - mae: 536.1728 - val_loss: 533.9203 - val_mae: 533.9203\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 535.6497 - mae: 535.6497 - val_loss: 536.3091 - val_mae: 536.3091\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 536.0962 - mae: 536.0962 - val_loss: 534.0809 - val_mae: 534.0809\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 534.9868 - mae: 534.9868 - val_loss: 533.9005 - val_mae: 533.9005\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 535.4319 - mae: 535.4319 - val_loss: 534.9864 - val_mae: 534.9864\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 535.6047 - mae: 535.6047 - val_loss: 533.7696 - val_mae: 533.7696\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 534.5221 - mae: 534.5221 - val_loss: 534.3718 - val_mae: 534.3718\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 534.6081 - mae: 534.6081 - val_loss: 534.2148 - val_mae: 534.2148\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 534.9328 - mae: 534.9328 - val_loss: 533.9859 - val_mae: 533.9859\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6045.5156 - mae: 6045.5156 - val_loss: 6021.9917 - val_mae: 6021.9917\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 5669.7705 - mae: 5669.7705 - val_loss: 4423.5972 - val_mae: 4423.5972\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1321.9572 - mae: 1321.9572 - val_loss: 607.9929 - val_mae: 607.9929\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 608.3685 - mae: 608.3685 - val_loss: 604.4952 - val_mae: 604.4952\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 605.1359 - mae: 605.1359 - val_loss: 603.9349 - val_mae: 603.9349\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 603.4688 - mae: 603.4688 - val_loss: 601.0974 - val_mae: 601.0974\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 602.2096 - mae: 602.2096 - val_loss: 599.5820 - val_mae: 599.5820\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 601.3231 - mae: 601.3231 - val_loss: 599.6101 - val_mae: 599.6101\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599.8097 - mae: 599.8097 - val_loss: 596.2444 - val_mae: 596.2444\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 597.4767 - mae: 597.4767 - val_loss: 594.2759 - val_mae: 594.2759\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 595.2725 - mae: 595.2725 - val_loss: 590.5705 - val_mae: 590.5705\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591.5645 - mae: 591.5645 - val_loss: 588.3060 - val_mae: 588.3060\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 586.0134 - mae: 586.0134 - val_loss: 582.8040 - val_mae: 582.8040\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582.3303 - mae: 582.3303 - val_loss: 579.9397 - val_mae: 579.9397\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 576.4391 - mae: 576.4391 - val_loss: 573.0771 - val_mae: 573.0771\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 570.7986 - mae: 570.7986 - val_loss: 566.9218 - val_mae: 566.9218\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 566.3871 - mae: 566.3871 - val_loss: 562.3951 - val_mae: 562.3951\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 562.7956 - mae: 562.7956 - val_loss: 558.8359 - val_mae: 558.8359\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 560.2425 - mae: 560.2425 - val_loss: 558.2333 - val_mae: 558.2333\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 556.2546 - mae: 556.2546 - val_loss: 555.7812 - val_mae: 555.7812\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 553.6542 - mae: 553.6542 - val_loss: 551.0709 - val_mae: 551.0709\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 550.7521 - mae: 550.7521 - val_loss: 548.4532 - val_mae: 548.4532\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 548.3599 - mae: 548.3599 - val_loss: 548.5354 - val_mae: 548.5354\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 547.6501 - mae: 547.6501 - val_loss: 544.5498 - val_mae: 544.5498\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 545.7287 - mae: 545.7287 - val_loss: 544.7167 - val_mae: 544.7167\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 545.1157 - mae: 545.1157 - val_loss: 541.9227 - val_mae: 541.9227\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 543.6052 - mae: 543.6052 - val_loss: 540.5326 - val_mae: 540.5326\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 543.1848 - mae: 543.1848 - val_loss: 539.9113 - val_mae: 539.9113\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 542.5177 - mae: 542.5177 - val_loss: 541.0304 - val_mae: 541.0304\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 542.1132 - mae: 542.1132 - val_loss: 540.4156 - val_mae: 540.4156\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 541.7419 - mae: 541.7419 - val_loss: 539.1285 - val_mae: 539.1285\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 540.7377 - mae: 540.7377 - val_loss: 537.1163 - val_mae: 537.1163\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 539.5431 - mae: 539.5431 - val_loss: 537.1171 - val_mae: 537.1171\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 538.2280 - mae: 538.2280 - val_loss: 535.9727 - val_mae: 535.9727\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 537.6329 - mae: 537.6329 - val_loss: 534.3922 - val_mae: 534.3922\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 536.6159 - mae: 536.6159 - val_loss: 534.5135 - val_mae: 534.5135\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 535.5806 - mae: 535.5806 - val_loss: 534.7791 - val_mae: 534.7791\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 535.4268 - mae: 535.4268 - val_loss: 535.4211 - val_mae: 535.4211\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 535.0244 - mae: 535.0244 - val_loss: 535.6622 - val_mae: 535.6622\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 535.2418 - mae: 535.2418 - val_loss: 533.2294 - val_mae: 533.2294\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 535.4883 - mae: 535.4883 - val_loss: 533.1771 - val_mae: 533.1771\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 534.6337 - mae: 534.6337 - val_loss: 531.9754 - val_mae: 531.9754\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 533.7534 - mae: 533.7534 - val_loss: 533.7110 - val_mae: 533.7110\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 533.9374 - mae: 533.9374 - val_loss: 531.2248 - val_mae: 531.2248\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 533.1826 - mae: 533.1826 - val_loss: 531.8015 - val_mae: 531.8015\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 532.7805 - mae: 532.7805 - val_loss: 532.3505 - val_mae: 532.3505\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 533.1031 - mae: 533.1031 - val_loss: 531.8214 - val_mae: 531.8214\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 532.2324 - mae: 532.2324 - val_loss: 529.7599 - val_mae: 529.7599\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 532.2050 - mae: 532.2050 - val_loss: 529.8404 - val_mae: 529.8404\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 531.5648 - mae: 531.5648 - val_loss: 533.7214 - val_mae: 533.7214\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 531.5265 - mae: 531.5265 - val_loss: 531.2258 - val_mae: 531.2258\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 531.0964 - mae: 531.0964 - val_loss: 527.9053 - val_mae: 527.9053\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 531.4233 - mae: 531.4233 - val_loss: 529.4152 - val_mae: 529.4152\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 529.8047 - mae: 529.8047 - val_loss: 529.1792 - val_mae: 529.1792\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 529.8726 - mae: 529.8726 - val_loss: 531.0175 - val_mae: 531.0175\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.9738 - mae: 530.9738 - val_loss: 530.8469 - val_mae: 530.8469\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 530.2457 - mae: 530.2457 - val_loss: 528.6013 - val_mae: 528.6013\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 530.0167 - mae: 530.0167 - val_loss: 528.4144 - val_mae: 528.4144\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 529.7384 - mae: 529.7384 - val_loss: 529.5398 - val_mae: 529.5398\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 529.7259 - mae: 529.7259 - val_loss: 528.8059 - val_mae: 528.8059\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 529.6158 - mae: 529.6158 - val_loss: 526.3376 - val_mae: 526.3376\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 529.1172 - mae: 529.1172 - val_loss: 527.9318 - val_mae: 527.9318\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 529.3602 - mae: 529.3602 - val_loss: 529.3709 - val_mae: 529.3709\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 528.9142 - mae: 528.9142 - val_loss: 525.8594 - val_mae: 525.8594\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 528.4185 - mae: 528.4185 - val_loss: 528.5360 - val_mae: 528.5360\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.8627 - mae: 528.8627 - val_loss: 526.0276 - val_mae: 526.0276\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 528.5191 - mae: 528.5191 - val_loss: 525.7044 - val_mae: 525.7044\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.1876 - mae: 528.1876 - val_loss: 530.4506 - val_mae: 530.4506\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 528.0996 - mae: 528.0996 - val_loss: 526.2063 - val_mae: 526.2063\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.4359 - mae: 528.4359 - val_loss: 525.8039 - val_mae: 525.8039\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 527.5192 - mae: 527.5192 - val_loss: 527.1326 - val_mae: 527.1326\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 528.0169 - mae: 528.0169 - val_loss: 528.1125 - val_mae: 528.1125\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 527.5204 - mae: 527.5204 - val_loss: 529.4123 - val_mae: 529.4123\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.9633 - mae: 527.9633 - val_loss: 527.4896 - val_mae: 527.4896\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 527.7220 - mae: 527.7220 - val_loss: 526.3736 - val_mae: 526.3736\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.5145 - mae: 527.5145 - val_loss: 527.0786 - val_mae: 527.0786\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.2892 - mae: 527.2892 - val_loss: 524.9263 - val_mae: 524.9263\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 526.8008 - mae: 526.8008 - val_loss: 524.9601 - val_mae: 524.9601\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 527.5739 - mae: 527.5739 - val_loss: 525.7509 - val_mae: 525.7509\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 526.5620 - mae: 526.5620 - val_loss: 526.8512 - val_mae: 526.8512\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 527.2571 - mae: 527.2571 - val_loss: 525.5815 - val_mae: 525.5815\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 526.8080 - mae: 526.8080 - val_loss: 525.5166 - val_mae: 525.5166\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 526.7178 - mae: 526.7178 - val_loss: 523.6089 - val_mae: 523.6089\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 526.5132 - mae: 526.5132 - val_loss: 523.4863 - val_mae: 523.4863\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 525.0427 - mae: 525.0427 - val_loss: 524.1361 - val_mae: 524.1361\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 525.4727 - mae: 525.4727 - val_loss: 524.4244 - val_mae: 524.4244\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 526.0769 - mae: 526.0769 - val_loss: 523.0950 - val_mae: 523.0950\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 525.8705 - mae: 525.8705 - val_loss: 526.2473 - val_mae: 526.2473\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 525.8102 - mae: 525.8102 - val_loss: 526.7936 - val_mae: 526.7936\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 525.7943 - mae: 525.7943 - val_loss: 522.3141 - val_mae: 522.3141\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 525.1381 - mae: 525.1381 - val_loss: 524.2943 - val_mae: 524.2943\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 525.4490 - mae: 525.4490 - val_loss: 525.4686 - val_mae: 525.4686\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 525.2304 - mae: 525.2304 - val_loss: 523.7780 - val_mae: 523.7780\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 525.3845 - mae: 525.3845 - val_loss: 523.8098 - val_mae: 523.8098\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 524.6467 - mae: 524.6467 - val_loss: 523.5426 - val_mae: 523.5426\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 524.9462 - mae: 524.9462 - val_loss: 522.8807 - val_mae: 522.8807\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 524.4908 - mae: 524.4908 - val_loss: 523.5339 - val_mae: 523.5339\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 524.8514 - mae: 524.8514 - val_loss: 523.5532 - val_mae: 523.5532\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 524.7231 - mae: 524.7231 - val_loss: 523.4688 - val_mae: 523.4688\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 524.5811 - mae: 524.5811 - val_loss: 523.1248 - val_mae: 523.1248\n"
     ]
    }
   ],
   "source": [
    "# MBGD - mae + sgd\n",
    "\n",
    "result16_sgd_dict = {\n",
    "    'units': [],\n",
    "    'batch_size': [],\n",
    "    'learning_rate': [],\n",
    "    'minimum_mae_error': []\n",
    "}\n",
    "\n",
    "for units in para_dict['hidden_units']:\n",
    "    for b_size in para_dict['batch_size']:\n",
    "        for rate in para_dict['learning_rate'][0]:\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "            optimizer = SGD(learning_rate = rate)\n",
    "\n",
    "            model = create_model(columns = x_columns, units = units, optimizer = optimizer)\n",
    "\n",
    "            best_model = model.fit(\n",
    "                x_train, y_train,\n",
    "                validation_data = (x_test, y_test),\n",
    "                batch_size = b_size,\n",
    "                epochs = 250,\n",
    "                callbacks = [early_stopping]\n",
    "            )\n",
    "\n",
    "            min_mae = early_stopping.best\n",
    "\n",
    "            result16_sgd_dict['units'].append(units)\n",
    "            result16_sgd_dict['batch_size'].append(b_size)\n",
    "            result16_sgd_dict['learning_rate'].append(rate)\n",
    "            result16_sgd_dict['minimum_mae_error'].append(min_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>minimum_mae_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>525.085815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>523.807922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>540.858398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>526.157349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>529.977234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>528.292419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>542.027832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>523.814514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>532.963989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>540.326721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>524.629761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>535.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>545.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>523.226501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>518.899109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>525.907043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>533.132263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>522.314087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  batch_size  learning_rate  minimum_mae_error\n",
       "0       7          16          0.008         525.085815\n",
       "1       7          16          0.010         523.807922\n",
       "2       7          32          0.008         540.858398\n",
       "3       7          32          0.010         526.157349\n",
       "4       7          64          0.008         529.977234\n",
       "5       7          64          0.010         528.292419\n",
       "6       8          16          0.008         542.027832\n",
       "7       8          16          0.010         523.814514\n",
       "8       8          32          0.008         532.963989\n",
       "9       8          32          0.010         540.326721\n",
       "10      8          64          0.008         524.629761\n",
       "11      8          64          0.010         535.976562\n",
       "12      9          16          0.008         545.210938\n",
       "13      9          16          0.010         523.226501\n",
       "14      9          32          0.008         518.899109\n",
       "15      9          32          0.010         525.907043\n",
       "16      9          64          0.008         533.132263\n",
       "17      9          64          0.010         522.314087"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result16_sgd_df = pd.DataFrame(result16_sgd_dict)\n",
    "\n",
    "result16_sgd_df.to_csv('result16_sgd.csv')\n",
    "\n",
    "result16_sgd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 33516648.0000 - mae: 5618.7324 - val_loss: 24379746.0000 - val_mae: 4775.1348\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 14430943.0000 - mae: 3501.7444 - val_loss: 6618073.5000 - val_mae: 2206.7776\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 3618969.5000 - mae: 1375.7642 - val_loss: 2113294.2500 - val_mae: 897.4286\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1817602.2500 - mae: 795.2473 - val_loss: 1654224.2500 - val_mae: 740.9238\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1588606.1250 - mae: 722.1716 - val_loss: 1533608.3750 - val_mae: 707.0337\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1500883.0000 - mae: 703.2123 - val_loss: 1466499.8750 - val_mae: 698.8793\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1439151.7500 - mae: 694.9844 - val_loss: 1407720.3750 - val_mae: 690.3574\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1384079.6250 - mae: 685.9907 - val_loss: 1360470.2500 - val_mae: 680.4910\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1343159.1250 - mae: 677.7838 - val_loss: 1323788.2500 - val_mae: 673.4987\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1312032.5000 - mae: 670.9056 - val_loss: 1297511.2500 - val_mae: 667.0219\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1290678.3750 - mae: 665.7138 - val_loss: 1280246.0000 - val_mae: 663.8474\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1275815.6250 - mae: 662.0735 - val_loss: 1267965.8750 - val_mae: 661.3199\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1265398.0000 - mae: 659.1285 - val_loss: 1258838.6250 - val_mae: 657.8904\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1257772.2500 - mae: 657.0479 - val_loss: 1253069.5000 - val_mae: 652.7836\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1251980.6250 - mae: 654.4536 - val_loss: 1247306.8750 - val_mae: 653.0734\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1247263.0000 - mae: 652.7902 - val_loss: 1243839.0000 - val_mae: 654.1262\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1243397.6250 - mae: 651.4899 - val_loss: 1238881.1250 - val_mae: 650.2166\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1239124.2500 - mae: 649.3983 - val_loss: 1235252.1250 - val_mae: 648.5421\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1235320.3750 - mae: 648.3497 - val_loss: 1231377.7500 - val_mae: 644.6770\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1231435.2500 - mae: 646.3369 - val_loss: 1228456.6250 - val_mae: 641.3077\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1226875.5000 - mae: 643.7971 - val_loss: 1223062.1250 - val_mae: 643.4637\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1223363.5000 - mae: 642.9995 - val_loss: 1219790.1250 - val_mae: 640.0190\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1219871.8750 - mae: 640.9762 - val_loss: 1216630.8750 - val_mae: 640.1418\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1217001.6250 - mae: 639.9605 - val_loss: 1214332.5000 - val_mae: 641.0005\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1214279.3750 - mae: 638.4644 - val_loss: 1211703.1250 - val_mae: 639.5593\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1211704.2500 - mae: 637.5753 - val_loss: 1208451.0000 - val_mae: 634.9647\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1209039.3750 - mae: 636.2620 - val_loss: 1205302.2500 - val_mae: 634.0526\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1206217.6250 - mae: 634.7703 - val_loss: 1202633.5000 - val_mae: 632.8785\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1203565.8750 - mae: 634.0249 - val_loss: 1200048.5000 - val_mae: 632.1476\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1200648.5000 - mae: 632.7446 - val_loss: 1198999.8750 - val_mae: 636.4714\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1198750.3750 - mae: 632.7603 - val_loss: 1196234.0000 - val_mae: 634.2640\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 1195859.2500 - mae: 631.0300 - val_loss: 1191820.5000 - val_mae: 629.9012\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1191675.3750 - mae: 629.3141 - val_loss: 1189137.8750 - val_mae: 631.0320\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1187962.3750 - mae: 627.4107 - val_loss: 1184454.1250 - val_mae: 626.0228\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1184864.0000 - mae: 625.5875 - val_loss: 1182268.1250 - val_mae: 626.1182\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1182951.1250 - mae: 624.9117 - val_loss: 1180340.0000 - val_mae: 625.3120\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1181010.5000 - mae: 624.6279 - val_loss: 1179653.0000 - val_mae: 620.4379\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1179756.1250 - mae: 623.4569 - val_loss: 1177708.0000 - val_mae: 621.2038\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1177929.7500 - mae: 622.5659 - val_loss: 1176213.7500 - val_mae: 623.8660\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1176502.8750 - mae: 622.8733 - val_loss: 1173759.6250 - val_mae: 620.1736\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1175180.8750 - mae: 621.2725 - val_loss: 1173632.6250 - val_mae: 618.0866\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1173414.7500 - mae: 620.6422 - val_loss: 1170864.0000 - val_mae: 619.3945\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1171517.8750 - mae: 619.6653 - val_loss: 1168780.5000 - val_mae: 619.1318\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1170072.8750 - mae: 619.0319 - val_loss: 1167145.6250 - val_mae: 618.1961\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1167978.5000 - mae: 617.8636 - val_loss: 1166740.8750 - val_mae: 619.6892\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1166947.0000 - mae: 617.9033 - val_loss: 1165317.6250 - val_mae: 619.1042\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1165719.6250 - mae: 617.3268 - val_loss: 1164075.1250 - val_mae: 619.6826\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1164999.7500 - mae: 617.1201 - val_loss: 1161598.5000 - val_mae: 616.5337\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1162679.5000 - mae: 616.1651 - val_loss: 1161209.3750 - val_mae: 616.3791\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1161534.1250 - mae: 615.6464 - val_loss: 1159643.3750 - val_mae: 613.4820\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1160522.2500 - mae: 614.9695 - val_loss: 1157304.3750 - val_mae: 613.2368\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1158163.6250 - mae: 613.9428 - val_loss: 1155563.8750 - val_mae: 612.8355\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1156859.8750 - mae: 613.3731 - val_loss: 1153959.1250 - val_mae: 611.4916\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1155003.1250 - mae: 612.4784 - val_loss: 1152483.6250 - val_mae: 613.3276\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1152998.6250 - mae: 612.2426 - val_loss: 1152831.1250 - val_mae: 608.5350\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1152365.8750 - mae: 610.7587 - val_loss: 1149983.1250 - val_mae: 612.7983\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1150860.5000 - mae: 611.0280 - val_loss: 1148941.3750 - val_mae: 611.3651\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1149902.3750 - mae: 610.3334 - val_loss: 1148030.8750 - val_mae: 611.3071\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1149111.6250 - mae: 610.3751 - val_loss: 1147350.1250 - val_mae: 610.8779\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1148635.0000 - mae: 610.2313 - val_loss: 1146415.7500 - val_mae: 611.4749\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1147721.0000 - mae: 610.1731 - val_loss: 1145343.5000 - val_mae: 606.8480\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1146945.8750 - mae: 609.2156 - val_loss: 1144577.0000 - val_mae: 609.8184\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1146072.6250 - mae: 609.1260 - val_loss: 1144592.1250 - val_mae: 611.3458\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1145141.3750 - mae: 609.1676 - val_loss: 1142779.1250 - val_mae: 606.1242\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1144230.5000 - mae: 608.5233 - val_loss: 1141244.7500 - val_mae: 608.2693\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1142531.0000 - mae: 608.2001 - val_loss: 1138900.0000 - val_mae: 607.1568\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1140128.0000 - mae: 608.5231 - val_loss: 1137895.3750 - val_mae: 605.5187\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1138849.6250 - mae: 607.9094 - val_loss: 1135632.0000 - val_mae: 606.2380\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1137297.3750 - mae: 607.9587 - val_loss: 1134137.7500 - val_mae: 606.2159\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1135489.3750 - mae: 607.6486 - val_loss: 1132694.2500 - val_mae: 606.0844\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1133710.6250 - mae: 606.8893 - val_loss: 1133627.2500 - val_mae: 611.8335\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1132713.3750 - mae: 608.1276 - val_loss: 1130125.5000 - val_mae: 605.5767\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1131535.8750 - mae: 607.8067 - val_loss: 1128172.1250 - val_mae: 605.7527\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1129055.5000 - mae: 606.7815 - val_loss: 1127456.1250 - val_mae: 607.8885\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1127695.5000 - mae: 607.2544 - val_loss: 1125845.7500 - val_mae: 606.1107\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1126448.3750 - mae: 606.7928 - val_loss: 1123345.6250 - val_mae: 607.4217\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1124139.6250 - mae: 606.6993 - val_loss: 1118765.8750 - val_mae: 606.6902\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 31444074.0000 - mae: 5425.5010 - val_loss: 18580298.0000 - val_mae: 4161.8237\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 8537981.0000 - mae: 2554.5029 - val_loss: 2680965.5000 - val_mae: 1273.8851\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1625966.3750 - mae: 908.9667 - val_loss: 1209007.7500 - val_mae: 763.9230\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1106315.1250 - mae: 732.9396 - val_loss: 1016119.3125 - val_mae: 710.5678\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 960642.6875 - mae: 695.3856 - val_loss: 905354.8125 - val_mae: 682.7309\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 869386.6875 - mae: 673.4223 - val_loss: 831851.6250 - val_mae: 663.0156\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 807837.1875 - mae: 657.1932 - val_loss: 780128.5000 - val_mae: 650.0047\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 764994.4375 - mae: 643.8329 - val_loss: 744298.2500 - val_mae: 637.6015\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 732820.2500 - mae: 633.1841 - val_loss: 716838.2500 - val_mae: 625.7541\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 710623.6250 - mae: 622.5844 - val_loss: 698599.5625 - val_mae: 617.0306\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 695421.3750 - mae: 615.2108 - val_loss: 686936.7500 - val_mae: 613.9717\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 682513.0625 - mae: 608.8041 - val_loss: 674736.2500 - val_mae: 601.4214\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 671816.7500 - mae: 601.0663 - val_loss: 665718.0625 - val_mae: 595.5150\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 664400.1875 - mae: 596.2816 - val_loss: 658406.2500 - val_mae: 592.3357\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 658073.0625 - mae: 592.6180 - val_loss: 652204.4375 - val_mae: 589.7479\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 652731.8125 - mae: 589.7393 - val_loss: 647941.1875 - val_mae: 586.3876\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 648794.1250 - mae: 587.5367 - val_loss: 645559.0625 - val_mae: 586.4183\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 645558.0625 - mae: 585.8387 - val_loss: 641398.0000 - val_mae: 582.6295\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 642821.8125 - mae: 583.7599 - val_loss: 639924.5000 - val_mae: 581.7571\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 641070.0000 - mae: 582.8644 - val_loss: 637519.6875 - val_mae: 582.2156\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 639214.6250 - mae: 581.8602 - val_loss: 635553.1250 - val_mae: 582.3168\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 637056.6875 - mae: 580.9244 - val_loss: 633116.9375 - val_mae: 579.8318\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 634546.6250 - mae: 579.9646 - val_loss: 633616.0625 - val_mae: 581.0590\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 633837.8125 - mae: 578.9146 - val_loss: 630725.5625 - val_mae: 579.2335\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 632866.2500 - mae: 578.9919 - val_loss: 629603.1250 - val_mae: 575.0582\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 631250.0000 - mae: 577.4317 - val_loss: 628193.1875 - val_mae: 574.3266\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 629818.0000 - mae: 576.5587 - val_loss: 628612.6875 - val_mae: 573.3872\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 628416.4375 - mae: 576.1722 - val_loss: 625151.3125 - val_mae: 573.3167\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 625492.3125 - mae: 575.1108 - val_loss: 624090.9375 - val_mae: 573.0628\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 624515.3125 - mae: 573.9996 - val_loss: 621275.0625 - val_mae: 571.6003\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 622930.0000 - mae: 572.6505 - val_loss: 619262.5625 - val_mae: 571.0961\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 620414.0000 - mae: 571.2811 - val_loss: 616295.4375 - val_mae: 571.2032\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 618281.1250 - mae: 569.9846 - val_loss: 614566.2500 - val_mae: 570.0915\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 615205.3750 - mae: 568.7021 - val_loss: 610836.5625 - val_mae: 566.1301\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 613013.7500 - mae: 566.9616 - val_loss: 609783.3750 - val_mae: 568.4766\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 611330.6250 - mae: 566.1779 - val_loss: 608786.6875 - val_mae: 566.9648\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610523.4375 - mae: 565.4057 - val_loss: 606309.5625 - val_mae: 563.8326\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 609044.5625 - mae: 564.4570 - val_loss: 606012.7500 - val_mae: 564.2733\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 607759.9375 - mae: 564.0314 - val_loss: 604670.8750 - val_mae: 563.4659\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 606576.2500 - mae: 563.5769 - val_loss: 602919.1875 - val_mae: 561.9244\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 604402.6875 - mae: 561.9587 - val_loss: 602311.6250 - val_mae: 558.4182\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 603291.3125 - mae: 560.9146 - val_loss: 601613.5000 - val_mae: 564.4260\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602067.7500 - mae: 560.6302 - val_loss: 598780.1875 - val_mae: 558.8780\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 600905.4375 - mae: 559.9470 - val_loss: 597972.5000 - val_mae: 557.4402\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599672.1250 - mae: 558.4525 - val_loss: 596531.5000 - val_mae: 556.7429\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 598940.6250 - mae: 557.8699 - val_loss: 595516.9375 - val_mae: 558.1604\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 597467.5625 - mae: 557.3683 - val_loss: 595945.0625 - val_mae: 556.7675\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 597678.0625 - mae: 557.2630 - val_loss: 594113.6875 - val_mae: 554.1136\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 596363.2500 - mae: 556.6445 - val_loss: 594634.6875 - val_mae: 553.9309\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595488.8750 - mae: 556.5071 - val_loss: 593361.3750 - val_mae: 553.5240\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595236.2500 - mae: 555.5328 - val_loss: 592749.7500 - val_mae: 555.9955\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594092.5625 - mae: 555.3427 - val_loss: 591342.5000 - val_mae: 553.7888\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593909.2500 - mae: 555.2315 - val_loss: 590937.7500 - val_mae: 553.9199\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592663.4375 - mae: 554.2765 - val_loss: 590965.0000 - val_mae: 555.1548\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592839.0000 - mae: 554.1782 - val_loss: 589298.5625 - val_mae: 552.0958\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591762.8750 - mae: 553.5526 - val_loss: 589522.6250 - val_mae: 551.9737\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591887.3750 - mae: 553.8385 - val_loss: 588472.6250 - val_mae: 551.9240\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591069.5000 - mae: 553.0057 - val_loss: 587728.8125 - val_mae: 553.1891\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590250.1250 - mae: 552.8693 - val_loss: 588528.4375 - val_mae: 555.4622\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590314.5625 - mae: 552.7515 - val_loss: 587122.6250 - val_mae: 553.1945\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 589712.5625 - mae: 552.6200 - val_loss: 586838.8125 - val_mae: 549.3607\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588876.1875 - mae: 552.2592 - val_loss: 586226.5625 - val_mae: 549.9556\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588584.0625 - mae: 551.8198 - val_loss: 586012.2500 - val_mae: 553.2411\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 587772.3125 - mae: 552.1806 - val_loss: 586060.0625 - val_mae: 549.6450\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 587904.8750 - mae: 552.2531 - val_loss: 585935.6250 - val_mae: 547.7329\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 587144.4375 - mae: 551.3948 - val_loss: 584186.8750 - val_mae: 551.5666\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 586917.6250 - mae: 551.4557 - val_loss: 583569.9375 - val_mae: 549.7430\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 586380.5625 - mae: 551.2887 - val_loss: 583672.3125 - val_mae: 550.8344\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585661.0000 - mae: 550.7354 - val_loss: 584179.4375 - val_mae: 552.2339\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585465.4375 - mae: 550.6589 - val_loss: 584201.5000 - val_mae: 552.9031\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585961.5625 - mae: 551.0903 - val_loss: 582437.6250 - val_mae: 549.1120\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584957.6250 - mae: 550.6793 - val_loss: 582318.9375 - val_mae: 548.0250\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585299.8750 - mae: 550.2541 - val_loss: 582080.0625 - val_mae: 549.3596\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584609.1250 - mae: 550.0612 - val_loss: 581660.4375 - val_mae: 547.9103\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584014.8125 - mae: 549.9558 - val_loss: 582551.4375 - val_mae: 550.0862\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 37438192.0000 - mae: 5960.5928 - val_loss: 34986652.0000 - val_mae: 5755.4229\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 29839058.0000 - mae: 5282.7246 - val_loss: 23975398.0000 - val_mae: 4703.4180\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 18314486.0000 - mae: 4020.0403 - val_loss: 13124761.0000 - val_mae: 3309.0261\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 9376229.0000 - mae: 2634.6609 - val_loss: 6325967.5000 - val_mae: 2001.8649\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4543891.0000 - mae: 1548.8745 - val_loss: 3238995.7500 - val_mae: 1193.2572\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2619764.7500 - mae: 1020.3270 - val_loss: 2191254.7500 - val_mae: 907.1093\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1977238.5000 - mae: 859.3828 - val_loss: 1803200.0000 - val_mae: 825.2241\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1677637.3750 - mae: 804.2959 - val_loss: 1552561.2500 - val_mae: 783.2092\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1450351.6250 - mae: 765.9783 - val_loss: 1348895.5000 - val_mae: 748.6534\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1266814.3750 - mae: 732.5026 - val_loss: 1184469.7500 - val_mae: 719.7128\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1117593.2500 - mae: 704.0679 - val_loss: 1052325.7500 - val_mae: 692.1598\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1001294.7500 - mae: 679.8733 - val_loss: 951265.8750 - val_mae: 665.1155\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 914112.7500 - mae: 658.4426 - val_loss: 876089.1875 - val_mae: 649.4213\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 848853.0000 - mae: 642.7844 - val_loss: 821568.4375 - val_mae: 636.9067\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 804150.3750 - mae: 630.9931 - val_loss: 785550.3125 - val_mae: 625.9185\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 774334.1875 - mae: 622.5273 - val_loss: 759627.8125 - val_mae: 617.9250\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 751682.1250 - mae: 615.8679 - val_loss: 741749.0000 - val_mae: 610.6435\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 736756.6250 - mae: 611.4626 - val_loss: 729737.2500 - val_mae: 606.6241\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 726436.5625 - mae: 607.3694 - val_loss: 720516.6250 - val_mae: 605.4644\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 718492.8750 - mae: 604.7027 - val_loss: 713608.8750 - val_mae: 603.5532\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 712394.4375 - mae: 602.5049 - val_loss: 708161.7500 - val_mae: 602.7830\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 707218.3750 - mae: 601.1096 - val_loss: 703634.3125 - val_mae: 601.8702\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 702721.7500 - mae: 599.8246 - val_loss: 699060.5000 - val_mae: 598.9484\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 698868.2500 - mae: 598.4174 - val_loss: 695719.0000 - val_mae: 600.2410\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 695257.5000 - mae: 597.9497 - val_loss: 691274.8125 - val_mae: 594.8826\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 690804.0625 - mae: 596.1194 - val_loss: 686537.8125 - val_mae: 594.0302\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 685710.8125 - mae: 594.7215 - val_loss: 681344.5625 - val_mae: 594.9791\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 680667.5625 - mae: 593.4548 - val_loss: 676359.6250 - val_mae: 592.4847\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 674521.5000 - mae: 591.6069 - val_loss: 669466.3750 - val_mae: 590.6158\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 668644.2500 - mae: 589.8604 - val_loss: 664643.1250 - val_mae: 586.9248\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 664047.9375 - mae: 588.1381 - val_loss: 660459.5625 - val_mae: 589.0743\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 660000.0625 - mae: 587.7250 - val_loss: 656360.5625 - val_mae: 584.8948\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 656447.6250 - mae: 585.9240 - val_loss: 653263.8125 - val_mae: 586.5185\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 653686.3750 - mae: 585.8561 - val_loss: 650080.4375 - val_mae: 584.9571\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 650505.1875 - mae: 584.6707 - val_loss: 647506.2500 - val_mae: 584.8120\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 647921.3125 - mae: 584.8702 - val_loss: 644780.1875 - val_mae: 582.3868\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 645543.0625 - mae: 583.4238 - val_loss: 642385.4375 - val_mae: 583.8379\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 642985.6875 - mae: 583.2784 - val_loss: 640580.3125 - val_mae: 582.4898\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 641024.4375 - mae: 582.3832 - val_loss: 638364.4375 - val_mae: 582.6647\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 639129.3125 - mae: 582.4130 - val_loss: 636468.1875 - val_mae: 581.8636\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 637146.1250 - mae: 581.7864 - val_loss: 634606.1875 - val_mae: 580.9501\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 635751.9375 - mae: 581.3958 - val_loss: 633194.0000 - val_mae: 582.2041\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 634214.6250 - mae: 581.9257 - val_loss: 631676.6875 - val_mae: 579.8747\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 632845.1875 - mae: 580.9315 - val_loss: 630375.2500 - val_mae: 581.0646\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 631380.8125 - mae: 581.1970 - val_loss: 630165.8750 - val_mae: 578.3646\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 630789.5625 - mae: 580.4995 - val_loss: 628916.6250 - val_mae: 577.8456\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 629393.8750 - mae: 579.9948 - val_loss: 627811.5000 - val_mae: 578.8129\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 628770.1875 - mae: 580.1394 - val_loss: 626606.4375 - val_mae: 577.4070\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 627547.7500 - mae: 579.3353 - val_loss: 625589.5000 - val_mae: 577.4481\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 626635.8125 - mae: 579.0466 - val_loss: 625164.1875 - val_mae: 577.7050\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625960.5000 - mae: 578.4381 - val_loss: 624711.5625 - val_mae: 580.4216\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625487.6875 - mae: 579.0034 - val_loss: 623613.5000 - val_mae: 578.6207\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 624865.6875 - mae: 578.6091 - val_loss: 623448.9375 - val_mae: 576.1592\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 624428.9375 - mae: 578.1889 - val_loss: 622692.1250 - val_mae: 578.2308\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 624050.1250 - mae: 578.2937 - val_loss: 622464.6250 - val_mae: 576.0057\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 623369.7500 - mae: 578.0539 - val_loss: 622292.3750 - val_mae: 575.6887\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 623072.0000 - mae: 577.5401 - val_loss: 621975.8750 - val_mae: 579.4172\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 622641.2500 - mae: 577.9589 - val_loss: 621004.4375 - val_mae: 577.6084\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 622311.5000 - mae: 577.7926 - val_loss: 621012.1875 - val_mae: 575.0270\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 622095.2500 - mae: 577.7487 - val_loss: 620051.3750 - val_mae: 576.1356\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621248.0625 - mae: 577.0795 - val_loss: 619753.6250 - val_mae: 577.5706\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621347.7500 - mae: 577.2719 - val_loss: 618955.2500 - val_mae: 576.4314\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 620250.7500 - mae: 576.8851 - val_loss: 618748.5625 - val_mae: 577.2127\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 619897.3750 - mae: 577.0291 - val_loss: 618306.0625 - val_mae: 574.8829\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619821.2500 - mae: 576.3707 - val_loss: 617821.2500 - val_mae: 576.3857\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618947.3750 - mae: 576.0957 - val_loss: 617925.3750 - val_mae: 575.7607\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618687.7500 - mae: 576.2878 - val_loss: 617339.5625 - val_mae: 574.5478\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618386.7500 - mae: 576.1151 - val_loss: 616995.8125 - val_mae: 576.2950\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618158.7500 - mae: 576.1075 - val_loss: 616733.3125 - val_mae: 573.8691\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617660.2500 - mae: 575.5441 - val_loss: 615806.8125 - val_mae: 575.2073\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617318.6250 - mae: 575.4880 - val_loss: 615461.6875 - val_mae: 574.2700\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616810.6250 - mae: 575.3674 - val_loss: 615008.6250 - val_mae: 574.7075\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616638.6875 - mae: 575.3707 - val_loss: 614585.5000 - val_mae: 573.2987\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615868.4375 - mae: 574.3486 - val_loss: 614511.1250 - val_mae: 576.8978\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615502.0000 - mae: 574.6680 - val_loss: 614382.6250 - val_mae: 577.1839\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615041.2500 - mae: 574.6564 - val_loss: 613229.3125 - val_mae: 573.6227\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614605.1250 - mae: 574.4515 - val_loss: 612883.0000 - val_mae: 572.8738\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614331.0625 - mae: 574.0234 - val_loss: 612498.5000 - val_mae: 574.5051\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614098.2500 - mae: 573.7805 - val_loss: 612162.4375 - val_mae: 574.7742\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613186.1250 - mae: 573.8011 - val_loss: 611420.9375 - val_mae: 571.0513\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612653.6250 - mae: 572.7798 - val_loss: 610714.2500 - val_mae: 573.5645\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611551.1875 - mae: 572.9445 - val_loss: 610377.8750 - val_mae: 573.7574\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611020.3125 - mae: 572.3036 - val_loss: 608900.4375 - val_mae: 570.3615\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 609965.2500 - mae: 571.4260 - val_loss: 607916.6250 - val_mae: 570.1224\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609172.5000 - mae: 570.9664 - val_loss: 607091.4375 - val_mae: 570.7861\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608276.2500 - mae: 570.3205 - val_loss: 606396.5000 - val_mae: 569.3923\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607328.8125 - mae: 569.4100 - val_loss: 606364.4375 - val_mae: 572.6031\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605905.8750 - mae: 569.1592 - val_loss: 604733.0000 - val_mae: 567.0676\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605283.8125 - mae: 567.9111 - val_loss: 603064.0000 - val_mae: 567.5869\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604288.5000 - mae: 567.2488 - val_loss: 602030.0625 - val_mae: 567.0592\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603108.6875 - mae: 566.6826 - val_loss: 600998.9375 - val_mae: 564.8628\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602115.8750 - mae: 565.9655 - val_loss: 600047.1250 - val_mae: 564.2285\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601405.6875 - mae: 565.4116 - val_loss: 599319.9375 - val_mae: 563.9699\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600525.5625 - mae: 564.6367 - val_loss: 598419.8750 - val_mae: 563.4337\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599965.1875 - mae: 564.4648 - val_loss: 597962.8125 - val_mae: 562.7963\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599371.2500 - mae: 563.9180 - val_loss: 597499.3125 - val_mae: 562.2006\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598846.8125 - mae: 563.3491 - val_loss: 596918.7500 - val_mae: 564.0781\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 598199.9375 - mae: 562.9897 - val_loss: 596460.4375 - val_mae: 564.1486\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597755.1875 - mae: 563.5442 - val_loss: 596029.8125 - val_mae: 561.0507\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597447.7500 - mae: 562.8400 - val_loss: 595511.8750 - val_mae: 561.8283\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 596922.4375 - mae: 562.6263 - val_loss: 595244.1250 - val_mae: 561.7234\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596595.8750 - mae: 562.2621 - val_loss: 594907.6875 - val_mae: 560.5873\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595877.6875 - mae: 561.5789 - val_loss: 594214.1250 - val_mae: 563.1177\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594875.7500 - mae: 561.4384 - val_loss: 592549.1875 - val_mae: 560.1614\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 593316.5625 - mae: 560.1907 - val_loss: 590986.0625 - val_mae: 558.3069\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592072.2500 - mae: 558.9402 - val_loss: 589828.2500 - val_mae: 558.4031\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 591115.0625 - mae: 558.3513 - val_loss: 589273.9375 - val_mae: 556.4607\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590047.1250 - mae: 557.4297 - val_loss: 588399.3750 - val_mae: 558.2161\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588907.5625 - mae: 557.1081 - val_loss: 587941.3125 - val_mae: 554.4410\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588944.0000 - mae: 556.5922 - val_loss: 586901.5000 - val_mae: 554.7570\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588179.8125 - mae: 555.9468 - val_loss: 586296.5000 - val_mae: 555.1398\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587683.7500 - mae: 555.6945 - val_loss: 586286.3750 - val_mae: 555.2324\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587644.6250 - mae: 555.4041 - val_loss: 585673.8125 - val_mae: 556.6570\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587186.7500 - mae: 555.6699 - val_loss: 585087.9375 - val_mae: 554.4059\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 586654.5625 - mae: 555.4745 - val_loss: 585554.1250 - val_mae: 552.3997\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586437.3125 - mae: 554.4202 - val_loss: 585218.3750 - val_mae: 556.7204\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586369.2500 - mae: 555.3520 - val_loss: 584311.1250 - val_mae: 553.5759\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586062.0000 - mae: 554.8287 - val_loss: 584259.4375 - val_mae: 552.9295\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585823.5000 - mae: 554.4987 - val_loss: 584180.9375 - val_mae: 554.3444\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585624.1875 - mae: 554.6937 - val_loss: 584021.6250 - val_mae: 552.2306\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585496.4375 - mae: 554.0316 - val_loss: 583589.5625 - val_mae: 554.4565\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585324.0000 - mae: 554.4001 - val_loss: 583433.5625 - val_mae: 553.0297\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584803.6875 - mae: 554.4186 - val_loss: 583617.8750 - val_mae: 551.5108\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584791.1250 - mae: 553.6878 - val_loss: 582944.0625 - val_mae: 553.8381\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 584499.8125 - mae: 554.2664 - val_loss: 583741.7500 - val_mae: 551.5917\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584231.3125 - mae: 553.5784 - val_loss: 582526.2500 - val_mae: 553.3796\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584294.1875 - mae: 553.9992 - val_loss: 582492.8125 - val_mae: 551.8510\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 583959.0625 - mae: 553.5244 - val_loss: 582150.6875 - val_mae: 553.1350\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 583766.0625 - mae: 553.4195 - val_loss: 582062.0000 - val_mae: 553.0280\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 583020.6250 - mae: 553.5927 - val_loss: 582515.1875 - val_mae: 550.5306\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 583593.5625 - mae: 553.2033 - val_loss: 581954.0000 - val_mae: 551.0746\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583101.0625 - mae: 552.5131 - val_loss: 582700.5625 - val_mae: 556.2420\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582985.7500 - mae: 553.3033 - val_loss: 581549.3750 - val_mae: 551.3594\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583005.0000 - mae: 552.8771 - val_loss: 581137.0000 - val_mae: 553.0104\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582643.6250 - mae: 553.0161 - val_loss: 581114.5000 - val_mae: 551.7122\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582475.6250 - mae: 552.5518 - val_loss: 580876.5000 - val_mae: 553.2886\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582407.1250 - mae: 553.0354 - val_loss: 581657.0000 - val_mae: 549.4789\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582256.6250 - mae: 552.2028 - val_loss: 580552.4375 - val_mae: 552.2689\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582108.8125 - mae: 552.4490 - val_loss: 580255.3750 - val_mae: 550.9630\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581998.4375 - mae: 552.4292 - val_loss: 580281.1250 - val_mae: 550.2499\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581740.3750 - mae: 552.0607 - val_loss: 579959.9375 - val_mae: 552.3052\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581207.1250 - mae: 551.9815 - val_loss: 579690.9375 - val_mae: 550.3283\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581339.5625 - mae: 551.9468 - val_loss: 579474.3750 - val_mae: 550.4069\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580474.8750 - mae: 550.8029 - val_loss: 580988.9375 - val_mae: 556.2006\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580521.3750 - mae: 551.4228 - val_loss: 579672.0625 - val_mae: 553.1520\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580398.4375 - mae: 551.6788 - val_loss: 578706.0625 - val_mae: 550.9785\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580134.0625 - mae: 551.4243 - val_loss: 578752.1875 - val_mae: 551.6506\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 2ms/step - loss: 36628100.0000 - mae: 5894.2500 - val_loss: 32303444.0000 - val_mae: 5530.7808\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 25168474.0000 - mae: 4841.7905 - val_loss: 17748354.0000 - val_mae: 4041.4629\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 11661313.0000 - mae: 3159.4497 - val_loss: 6679049.5000 - val_mae: 2297.9458\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 4035611.7500 - mae: 1640.7661 - val_loss: 2290498.0000 - val_mae: 1135.9567\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1678602.5000 - mae: 920.4365 - val_loss: 1321362.1250 - val_mae: 797.5527\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1199126.0000 - mae: 761.8674 - val_loss: 1109439.0000 - val_mae: 737.4921\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1061158.3750 - mae: 725.5251 - val_loss: 1015701.4375 - val_mae: 712.6241\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 981384.5000 - mae: 702.2869 - val_loss: 946489.1250 - val_mae: 692.8829\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 921799.4375 - mae: 684.5363 - val_loss: 895926.2500 - val_mae: 676.6456\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 878563.0000 - mae: 670.2786 - val_loss: 857850.1875 - val_mae: 662.8155\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 846491.7500 - mae: 658.2751 - val_loss: 830700.7500 - val_mae: 653.3839\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 820915.8125 - mae: 648.9490 - val_loss: 806689.1875 - val_mae: 643.9518\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 799043.1875 - mae: 640.8103 - val_loss: 787646.2500 - val_mae: 634.6104\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 780625.1875 - mae: 632.8448 - val_loss: 769313.6875 - val_mae: 627.8189\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 763229.8125 - mae: 625.6016 - val_loss: 751976.9375 - val_mae: 622.3106\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 746142.3125 - mae: 618.3942 - val_loss: 736372.5000 - val_mae: 614.8407\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 732543.3750 - mae: 612.4653 - val_loss: 724935.1875 - val_mae: 610.0685\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 722768.1250 - mae: 608.0455 - val_loss: 716544.1875 - val_mae: 606.9386\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 714461.7500 - mae: 605.2405 - val_loss: 708707.3750 - val_mae: 600.0315\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 705682.4375 - mae: 601.4671 - val_loss: 700161.9375 - val_mae: 598.9942\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 698121.9375 - mae: 598.4966 - val_loss: 694166.6875 - val_mae: 601.1785\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 692232.2500 - mae: 597.4296 - val_loss: 687896.2500 - val_mae: 594.9755\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 687718.8750 - mae: 595.3263 - val_loss: 684506.4375 - val_mae: 597.7160\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 683322.1250 - mae: 594.6287 - val_loss: 678943.1875 - val_mae: 591.5180\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 678994.2500 - mae: 592.5244 - val_loss: 674930.6875 - val_mae: 591.6735\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 674688.1875 - mae: 591.0666 - val_loss: 671839.3750 - val_mae: 591.5864\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 671199.2500 - mae: 590.2252 - val_loss: 667201.5000 - val_mae: 587.3811\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 666804.0000 - mae: 587.9834 - val_loss: 663236.2500 - val_mae: 589.5202\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 662690.5000 - mae: 587.3774 - val_loss: 658451.8125 - val_mae: 586.2914\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 658855.1250 - mae: 585.6459 - val_loss: 655584.4375 - val_mae: 586.1293\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 655925.2500 - mae: 585.0832 - val_loss: 652066.6250 - val_mae: 582.5877\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 652870.8750 - mae: 583.1646 - val_loss: 650052.9375 - val_mae: 584.9773\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 650252.6250 - mae: 583.2282 - val_loss: 646627.5000 - val_mae: 580.5347\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 647444.1250 - mae: 581.8375 - val_loss: 644619.6250 - val_mae: 579.0035\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 645365.5625 - mae: 580.8472 - val_loss: 641732.1250 - val_mae: 579.7688\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 642541.1250 - mae: 580.0110 - val_loss: 639978.4375 - val_mae: 581.2359\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 640851.6875 - mae: 580.1186 - val_loss: 636985.2500 - val_mae: 578.2672\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 638141.5000 - mae: 579.0019 - val_loss: 634861.1875 - val_mae: 578.3691\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 635937.1875 - mae: 578.2279 - val_loss: 632354.3125 - val_mae: 576.2107\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 633268.9375 - mae: 576.6083 - val_loss: 631265.1875 - val_mae: 576.4401\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 631514.4375 - mae: 576.6533 - val_loss: 628284.6250 - val_mae: 574.9796\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 629738.9375 - mae: 576.1686 - val_loss: 626724.6875 - val_mae: 573.5572\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 628066.4375 - mae: 575.2074 - val_loss: 624686.2500 - val_mae: 573.9585\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625931.1875 - mae: 574.7161 - val_loss: 623131.9375 - val_mae: 573.8740\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 624696.3750 - mae: 574.2982 - val_loss: 621609.6250 - val_mae: 574.4090\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 622720.6875 - mae: 573.5674 - val_loss: 619995.2500 - val_mae: 574.3995\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 620888.4375 - mae: 573.0155 - val_loss: 617565.1875 - val_mae: 571.9531\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618844.8750 - mae: 572.1555 - val_loss: 615750.9375 - val_mae: 571.3384\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616706.3750 - mae: 571.6351 - val_loss: 614276.6250 - val_mae: 568.8413\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614564.5000 - mae: 569.8711 - val_loss: 611971.3750 - val_mae: 571.0166\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612956.0625 - mae: 570.6072 - val_loss: 609922.1875 - val_mae: 567.9532\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611341.7500 - mae: 569.3206 - val_loss: 608510.0000 - val_mae: 568.6348\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609453.0000 - mae: 568.9785 - val_loss: 606820.3750 - val_mae: 567.3609\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608142.5000 - mae: 568.1740 - val_loss: 605187.0625 - val_mae: 567.5964\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606591.8125 - mae: 567.8345 - val_loss: 603964.1250 - val_mae: 565.7110\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605120.0625 - mae: 566.9657 - val_loss: 602371.4375 - val_mae: 566.5311\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603683.5625 - mae: 566.7082 - val_loss: 601233.8125 - val_mae: 565.3648\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602537.1250 - mae: 566.3775 - val_loss: 599945.1250 - val_mae: 564.1635\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 601131.3125 - mae: 565.4661 - val_loss: 598543.6250 - val_mae: 565.2728\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600085.3125 - mae: 564.9694 - val_loss: 597224.9375 - val_mae: 563.6470\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598825.0000 - mae: 564.6838 - val_loss: 596421.8125 - val_mae: 562.3716\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597554.6250 - mae: 564.2714 - val_loss: 595592.2500 - val_mae: 561.9147\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596832.6250 - mae: 563.8439 - val_loss: 594711.6875 - val_mae: 561.2368\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595562.7500 - mae: 563.3483 - val_loss: 593437.1875 - val_mae: 562.5687\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594622.6875 - mae: 563.0213 - val_loss: 592647.5000 - val_mae: 564.0790\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593811.6875 - mae: 563.2856 - val_loss: 591510.5000 - val_mae: 560.7008\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 592683.8125 - mae: 562.4371 - val_loss: 591151.7500 - val_mae: 559.4949\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 591941.4375 - mae: 562.1832 - val_loss: 589213.9375 - val_mae: 560.2946\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590949.2500 - mae: 561.4828 - val_loss: 588508.8125 - val_mae: 559.7745\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589874.3125 - mae: 561.1727 - val_loss: 587699.1250 - val_mae: 561.7316\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 588871.8750 - mae: 561.0567 - val_loss: 586907.7500 - val_mae: 557.7872\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 587778.4375 - mae: 560.0759 - val_loss: 584680.7500 - val_mae: 558.4084\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 585877.7500 - mae: 559.6592 - val_loss: 583445.5625 - val_mae: 557.3403\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584543.6250 - mae: 558.6719 - val_loss: 582715.8125 - val_mae: 560.0362\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583342.1875 - mae: 558.4818 - val_loss: 581148.0000 - val_mae: 556.7018\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582454.0000 - mae: 558.3164 - val_loss: 579917.5625 - val_mae: 555.3536\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581322.4375 - mae: 556.7040 - val_loss: 579802.8125 - val_mae: 559.2870\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580857.4375 - mae: 557.3646 - val_loss: 578396.8750 - val_mae: 555.9948\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580046.4375 - mae: 556.7027 - val_loss: 577848.7500 - val_mae: 557.3990\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 579472.2500 - mae: 556.3683 - val_loss: 577805.8125 - val_mae: 558.5471\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 578670.0000 - mae: 556.0651 - val_loss: 576819.2500 - val_mae: 556.1921\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578125.3125 - mae: 555.4947 - val_loss: 576344.8750 - val_mae: 555.3148\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 577992.1875 - mae: 555.4811 - val_loss: 575625.6875 - val_mae: 555.4999\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576893.0000 - mae: 554.8943 - val_loss: 574752.3750 - val_mae: 555.6602\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576308.5625 - mae: 554.8383 - val_loss: 573928.5000 - val_mae: 553.5798\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575727.9375 - mae: 553.9376 - val_loss: 573435.3750 - val_mae: 553.8040\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574927.5625 - mae: 553.5930 - val_loss: 573271.1250 - val_mae: 555.8084\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574122.5625 - mae: 553.3867 - val_loss: 571639.8125 - val_mae: 551.0292\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573455.8750 - mae: 552.1747 - val_loss: 571167.3750 - val_mae: 553.6079\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572339.5625 - mae: 551.8735 - val_loss: 570080.3750 - val_mae: 552.4874\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571162.5000 - mae: 551.3538 - val_loss: 569019.6875 - val_mae: 549.7521\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570749.6875 - mae: 550.9626 - val_loss: 568267.9375 - val_mae: 549.5768\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569801.2500 - mae: 550.3294 - val_loss: 567880.0000 - val_mae: 548.9984\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568901.6875 - mae: 549.8569 - val_loss: 566995.6250 - val_mae: 550.1501\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568705.9375 - mae: 549.5731 - val_loss: 566415.9375 - val_mae: 547.5611\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567757.5000 - mae: 549.1396 - val_loss: 565875.0625 - val_mae: 547.7184\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567413.9375 - mae: 548.6061 - val_loss: 565930.8750 - val_mae: 545.8877\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566684.5625 - mae: 547.9395 - val_loss: 564762.6875 - val_mae: 548.2918\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566081.3125 - mae: 547.9589 - val_loss: 563818.5000 - val_mae: 545.7062\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565699.6250 - mae: 547.1831 - val_loss: 563360.7500 - val_mae: 547.4960\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565088.2500 - mae: 547.3361 - val_loss: 563152.5625 - val_mae: 543.9489\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564464.4375 - mae: 546.2675 - val_loss: 562248.9375 - val_mae: 545.7862\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564015.1250 - mae: 546.1677 - val_loss: 561612.0000 - val_mae: 545.4535\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562696.1250 - mae: 545.3802 - val_loss: 561456.8750 - val_mae: 546.9944\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561784.0625 - mae: 544.8804 - val_loss: 559478.8125 - val_mae: 544.8101\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560715.0625 - mae: 544.3332 - val_loss: 559728.7500 - val_mae: 545.8511\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560050.0625 - mae: 544.5729 - val_loss: 558104.8750 - val_mae: 543.3519\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559518.2500 - mae: 543.5720 - val_loss: 557407.1250 - val_mae: 544.0368\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559069.5625 - mae: 543.5627 - val_loss: 557210.8750 - val_mae: 543.6707\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558205.8125 - mae: 543.2155 - val_loss: 556231.1875 - val_mae: 541.2642\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557735.6875 - mae: 542.7682 - val_loss: 556082.4375 - val_mae: 541.2410\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557520.6875 - mae: 542.3383 - val_loss: 555559.5625 - val_mae: 541.1511\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 556870.3750 - mae: 541.9225 - val_loss: 556082.5000 - val_mae: 544.3466\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556800.5625 - mae: 542.1121 - val_loss: 555257.2500 - val_mae: 542.2294\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556783.6875 - mae: 542.1184 - val_loss: 554678.9375 - val_mae: 540.1749\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 556084.5000 - mae: 541.3860 - val_loss: 554602.7500 - val_mae: 540.4308\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555856.0000 - mae: 541.2341 - val_loss: 553674.7500 - val_mae: 539.8707\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555416.8750 - mae: 540.9175 - val_loss: 553590.0625 - val_mae: 539.7025\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555309.6250 - mae: 540.7969 - val_loss: 553063.9375 - val_mae: 540.2645\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555073.8750 - mae: 540.6540 - val_loss: 553069.0000 - val_mae: 538.8835\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554704.4375 - mae: 539.8246 - val_loss: 552591.5625 - val_mae: 540.3167\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554330.9375 - mae: 540.1295 - val_loss: 552255.1250 - val_mae: 539.0249\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554075.0000 - mae: 540.0413 - val_loss: 552323.0000 - val_mae: 538.3425\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553567.6250 - mae: 539.3511 - val_loss: 552382.2500 - val_mae: 540.8738\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553832.0625 - mae: 539.7225 - val_loss: 551603.4375 - val_mae: 538.7717\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553544.3750 - mae: 539.5903 - val_loss: 551728.6875 - val_mae: 536.8937\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553342.7500 - mae: 539.6198 - val_loss: 551325.0625 - val_mae: 537.4100\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553237.6875 - mae: 538.8883 - val_loss: 551196.6250 - val_mae: 537.0840\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553096.0625 - mae: 538.8757 - val_loss: 550887.4375 - val_mae: 539.1089\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552333.0625 - mae: 539.2819 - val_loss: 551102.3125 - val_mae: 536.3591\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552899.7500 - mae: 538.1831 - val_loss: 551450.8125 - val_mae: 541.4514\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552346.5000 - mae: 538.7765 - val_loss: 551359.0000 - val_mae: 537.0630\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552368.3750 - mae: 538.5618 - val_loss: 550510.5000 - val_mae: 538.6833\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551771.2500 - mae: 538.5449 - val_loss: 550498.0625 - val_mae: 535.7408\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551930.0000 - mae: 538.5829 - val_loss: 550553.6875 - val_mae: 535.4631\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551920.0625 - mae: 537.9545 - val_loss: 550021.0625 - val_mae: 537.3007\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552157.0625 - mae: 538.1899 - val_loss: 549630.3125 - val_mae: 536.7009\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551308.3750 - mae: 537.5842 - val_loss: 550301.0000 - val_mae: 539.7523\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551300.6250 - mae: 538.1239 - val_loss: 549582.2500 - val_mae: 536.6369\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551493.6250 - mae: 538.0433 - val_loss: 549230.6250 - val_mae: 537.2184\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551259.1250 - mae: 537.7504 - val_loss: 549286.3750 - val_mae: 537.7423\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550899.6250 - mae: 537.5038 - val_loss: 549425.3750 - val_mae: 537.5691\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550854.3750 - mae: 537.4443 - val_loss: 549100.9375 - val_mae: 537.0409\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550766.8750 - mae: 537.5254 - val_loss: 548943.4375 - val_mae: 535.5417\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550835.3125 - mae: 537.4329 - val_loss: 548918.5625 - val_mae: 534.7585\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550621.8750 - mae: 537.2027 - val_loss: 549342.1250 - val_mae: 535.6088\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550440.0000 - mae: 537.2378 - val_loss: 549413.6250 - val_mae: 534.0584\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550267.3125 - mae: 536.5595 - val_loss: 549371.5000 - val_mae: 539.7255\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550238.6250 - mae: 537.6480 - val_loss: 548306.3750 - val_mae: 535.2656\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550267.0625 - mae: 537.1677 - val_loss: 547823.7500 - val_mae: 535.9016\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550009.8750 - mae: 536.8742 - val_loss: 548595.3125 - val_mae: 537.8928\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550052.5625 - mae: 536.5557 - val_loss: 548531.6250 - val_mae: 539.4055\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 549368.6875 - mae: 536.6351 - val_loss: 548432.1875 - val_mae: 537.3069\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549758.8125 - mae: 536.9896 - val_loss: 548456.0000 - val_mae: 533.7563\n",
      "Epoch 155/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549275.7500 - mae: 536.2488 - val_loss: 548159.2500 - val_mae: 536.3841\n",
      "Epoch 156/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549613.3125 - mae: 536.6122 - val_loss: 547496.7500 - val_mae: 535.0428\n",
      "Epoch 157/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549288.0000 - mae: 536.0402 - val_loss: 547080.3750 - val_mae: 534.8146\n",
      "Epoch 158/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548511.7500 - mae: 535.7520 - val_loss: 547578.6250 - val_mae: 536.7335\n",
      "Epoch 159/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 549176.8750 - mae: 536.3699 - val_loss: 547104.5000 - val_mae: 533.7067\n",
      "Epoch 160/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548981.9375 - mae: 535.9575 - val_loss: 546988.8125 - val_mae: 535.6507\n",
      "Epoch 161/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548495.3750 - mae: 536.0914 - val_loss: 546627.5625 - val_mae: 535.8643\n",
      "Epoch 162/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548472.0625 - mae: 536.1041 - val_loss: 547841.3750 - val_mae: 532.5558\n",
      "Epoch 163/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548574.7500 - mae: 535.6083 - val_loss: 546420.8750 - val_mae: 534.8455\n",
      "Epoch 164/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548132.7500 - mae: 535.6152 - val_loss: 546417.7500 - val_mae: 535.0880\n",
      "Epoch 165/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 548225.9375 - mae: 535.8700 - val_loss: 547061.6875 - val_mae: 533.1426\n",
      "Epoch 166/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547892.6250 - mae: 535.3035 - val_loss: 546423.4375 - val_mae: 532.8987\n",
      "Epoch 167/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547980.1875 - mae: 535.6826 - val_loss: 546478.8750 - val_mae: 532.5042\n",
      "Epoch 168/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547932.8750 - mae: 535.3624 - val_loss: 545822.7500 - val_mae: 534.0184\n",
      "Epoch 169/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547599.2500 - mae: 535.3609 - val_loss: 546161.3750 - val_mae: 535.3431\n",
      "Epoch 170/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547523.1250 - mae: 534.6805 - val_loss: 545690.0000 - val_mae: 534.8906\n",
      "Epoch 171/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547249.6250 - mae: 535.4183 - val_loss: 546622.9375 - val_mae: 532.2950\n",
      "Epoch 172/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547511.0625 - mae: 534.9577 - val_loss: 545354.6875 - val_mae: 534.3989\n",
      "Epoch 173/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546970.5625 - mae: 534.6480 - val_loss: 546136.8125 - val_mae: 537.5362\n",
      "Epoch 174/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 547266.1875 - mae: 535.1338 - val_loss: 545449.8125 - val_mae: 536.1143\n",
      "Epoch 175/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546938.2500 - mae: 535.1246 - val_loss: 545867.7500 - val_mae: 531.5834\n",
      "Epoch 176/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546712.5625 - mae: 534.7577 - val_loss: 545435.6875 - val_mae: 532.2250\n",
      "Epoch 177/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546903.1250 - mae: 534.5499 - val_loss: 545071.9375 - val_mae: 535.4404\n",
      "Epoch 178/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546276.1875 - mae: 534.9443 - val_loss: 545378.8750 - val_mae: 533.5574\n",
      "Epoch 179/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546503.1875 - mae: 534.6345 - val_loss: 544855.0625 - val_mae: 533.8804\n",
      "Epoch 180/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546828.5000 - mae: 534.9210 - val_loss: 545355.1875 - val_mae: 532.4093\n",
      "Epoch 181/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546405.7500 - mae: 534.5323 - val_loss: 544843.7500 - val_mae: 532.5726\n",
      "Epoch 182/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546446.1250 - mae: 534.4310 - val_loss: 544991.1875 - val_mae: 531.5593\n",
      "Epoch 183/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546384.1875 - mae: 534.3383 - val_loss: 544364.5625 - val_mae: 533.0511\n",
      "Epoch 184/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 546198.5625 - mae: 534.4551 - val_loss: 544208.0000 - val_mae: 533.1299\n",
      "Epoch 185/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545787.1250 - mae: 534.1257 - val_loss: 544953.1875 - val_mae: 532.4825\n",
      "Epoch 186/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545858.8125 - mae: 534.7911 - val_loss: 544426.5000 - val_mae: 531.5918\n",
      "Epoch 187/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545802.2500 - mae: 534.0077 - val_loss: 544062.9375 - val_mae: 534.2119\n",
      "Epoch 188/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545473.5625 - mae: 534.3795 - val_loss: 544459.6250 - val_mae: 531.8505\n",
      "Epoch 189/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545620.3125 - mae: 533.5017 - val_loss: 544809.7500 - val_mae: 537.2426\n",
      "Epoch 190/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545769.3750 - mae: 534.3146 - val_loss: 544290.3750 - val_mae: 536.0995\n",
      "Epoch 191/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545650.0000 - mae: 534.5507 - val_loss: 543932.8750 - val_mae: 531.2361\n",
      "Epoch 192/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545404.5000 - mae: 533.6508 - val_loss: 544033.0625 - val_mae: 535.2325\n",
      "Epoch 193/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544950.4375 - mae: 533.9951 - val_loss: 543698.1250 - val_mae: 532.4186\n",
      "Epoch 194/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 545044.3125 - mae: 534.2106 - val_loss: 543903.3750 - val_mae: 530.6392\n",
      "Epoch 195/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545012.1250 - mae: 533.4288 - val_loss: 543904.5000 - val_mae: 534.9460\n",
      "Epoch 196/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545004.7500 - mae: 533.7640 - val_loss: 543028.1250 - val_mae: 533.0794\n",
      "Epoch 197/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 545079.8125 - mae: 533.7016 - val_loss: 542987.8750 - val_mae: 531.9430\n",
      "Epoch 198/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544948.0000 - mae: 533.8627 - val_loss: 543022.1250 - val_mae: 533.2966\n",
      "Epoch 199/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544633.0625 - mae: 533.8275 - val_loss: 543764.4375 - val_mae: 535.4884\n",
      "Epoch 200/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544571.7500 - mae: 533.4681 - val_loss: 544351.8125 - val_mae: 537.2632\n",
      "Epoch 201/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544776.6250 - mae: 533.8207 - val_loss: 542793.9375 - val_mae: 532.2068\n",
      "Epoch 202/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544215.3750 - mae: 533.1677 - val_loss: 543411.3125 - val_mae: 535.5009\n",
      "Epoch 203/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544763.3125 - mae: 533.8757 - val_loss: 542929.8750 - val_mae: 530.6907\n",
      "Epoch 204/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 544256.7500 - mae: 533.6191 - val_loss: 542984.7500 - val_mae: 530.7640\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38327396.0000 - mae: 6033.6230 - val_loss: 37717772.0000 - val_mae: 5984.2773\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 36221228.0000 - mae: 5860.2407 - val_loss: 34263812.0000 - val_mae: 5695.4062\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 31736472.0000 - mae: 5471.8574 - val_loss: 28965786.0000 - val_mae: 5219.1562\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 25994402.0000 - mae: 4926.5034 - val_loss: 22938628.0000 - val_mae: 4612.5498\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 19981090.0000 - mae: 4276.1006 - val_loss: 17072024.0000 - val_mae: 3925.3464\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 14474154.0000 - mae: 3570.4651 - val_loss: 12010684.0000 - val_mae: 3210.7466\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 9963275.0000 - mae: 2865.1970 - val_loss: 8084165.5000 - val_mae: 2525.4756\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6617725.5000 - mae: 2221.2422 - val_loss: 5319968.0000 - val_mae: 1936.4916\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 4385677.0000 - mae: 1712.4607 - val_loss: 3579782.5000 - val_mae: 1512.5775\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 3034745.0000 - mae: 1359.9652 - val_loss: 2575282.0000 - val_mae: 1227.0298\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2273579.0000 - mae: 1131.1710 - val_loss: 2022267.6250 - val_mae: 1051.4836\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1857739.2500 - mae: 996.5002 - val_loss: 1717544.5000 - val_mae: 950.1907\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 1623690.3750 - mae: 918.7438 - val_loss: 1538331.2500 - val_mae: 892.2465\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1475543.6250 - mae: 872.7520 - val_loss: 1415522.0000 - val_mae: 855.2422\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1368731.8750 - mae: 840.8493 - val_loss: 1321900.1250 - val_mae: 827.0312\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1282434.3750 - mae: 815.7142 - val_loss: 1241442.5000 - val_mae: 803.3275\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1209583.3750 - mae: 793.6070 - val_loss: 1174856.1250 - val_mae: 782.8567\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1146976.1250 - mae: 774.3077 - val_loss: 1117287.7500 - val_mae: 765.8641\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1094308.0000 - mae: 758.0751 - val_loss: 1069233.6250 - val_mae: 750.8138\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1049359.1250 - mae: 744.3736 - val_loss: 1027201.0000 - val_mae: 737.0886\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1009998.0625 - mae: 732.1660 - val_loss: 989998.1875 - val_mae: 725.6696\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 975341.4375 - mae: 720.6487 - val_loss: 958110.9375 - val_mae: 715.4804\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 944456.8750 - mae: 711.4147 - val_loss: 928264.3125 - val_mae: 706.3987\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 915653.3125 - mae: 701.9875 - val_loss: 900131.6875 - val_mae: 697.0035\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 887146.4375 - mae: 693.3161 - val_loss: 871515.4375 - val_mae: 687.2485\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 859584.5625 - mae: 683.2673 - val_loss: 845498.8125 - val_mae: 680.3074\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 835370.7500 - mae: 675.5203 - val_loss: 822539.6875 - val_mae: 671.0518\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 813153.5625 - mae: 667.7059 - val_loss: 801445.3125 - val_mae: 662.7296\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 792386.5000 - mae: 659.5402 - val_loss: 780718.8750 - val_mae: 654.2067\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 771723.8125 - mae: 650.2547 - val_loss: 759518.6250 - val_mae: 644.7594\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 748605.7500 - mae: 640.6211 - val_loss: 735087.2500 - val_mae: 633.6622\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 724964.8750 - mae: 629.4600 - val_loss: 713512.1875 - val_mae: 625.3317\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 706729.1250 - mae: 621.6306 - val_loss: 698715.8125 - val_mae: 615.6690\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 693976.6875 - mae: 614.3512 - val_loss: 687310.0000 - val_mae: 611.5081\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 684475.3750 - mae: 609.4804 - val_loss: 678919.8750 - val_mae: 608.3693\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 676752.9375 - mae: 606.5094 - val_loss: 672169.8750 - val_mae: 601.9407\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 670116.2500 - mae: 601.0782 - val_loss: 666962.3125 - val_mae: 602.2430\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 665394.2500 - mae: 599.6791 - val_loss: 661361.6250 - val_mae: 596.2123\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 5ms/step - loss: 660287.0625 - mae: 595.8791 - val_loss: 656802.7500 - val_mae: 594.6564\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 655757.5000 - mae: 593.6351 - val_loss: 652559.6875 - val_mae: 592.7995\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 652046.8750 - mae: 591.8509 - val_loss: 648781.4375 - val_mae: 590.3740\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 648520.8125 - mae: 590.0101 - val_loss: 645213.5000 - val_mae: 587.2061\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 644891.9375 - mae: 587.8676 - val_loss: 642025.1875 - val_mae: 585.9869\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 641672.7500 - mae: 586.1221 - val_loss: 638467.4375 - val_mae: 583.6304\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 638131.9375 - mae: 583.9423 - val_loss: 634809.6250 - val_mae: 582.9434\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 634716.8750 - mae: 583.0959 - val_loss: 631401.3750 - val_mae: 580.9230\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 631316.1875 - mae: 580.9253 - val_loss: 628517.5000 - val_mae: 581.0263\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 628651.3125 - mae: 580.3258 - val_loss: 626452.5000 - val_mae: 578.3003\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 626722.1875 - mae: 579.0244 - val_loss: 624726.8125 - val_mae: 577.8796\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 625507.0625 - mae: 578.4907 - val_loss: 623508.3125 - val_mae: 578.6691\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 624056.6250 - mae: 577.9125 - val_loss: 622014.5000 - val_mae: 577.0952\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 622969.7500 - mae: 578.1422 - val_loss: 621009.5000 - val_mae: 575.7018\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 621677.1875 - mae: 576.8073 - val_loss: 619701.9375 - val_mae: 576.8946\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 620677.3750 - mae: 577.4797 - val_loss: 618678.6250 - val_mae: 575.0931\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 619592.8125 - mae: 576.2454 - val_loss: 617999.3750 - val_mae: 574.0266\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 618684.8750 - mae: 575.8575 - val_loss: 616763.8125 - val_mae: 574.3740\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 617497.7500 - mae: 575.2221 - val_loss: 615972.5625 - val_mae: 575.6372\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 5ms/step - loss: 616719.7500 - mae: 575.4488 - val_loss: 615274.1250 - val_mae: 573.9293\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 5ms/step - loss: 615702.0625 - mae: 574.6155 - val_loss: 614181.8125 - val_mae: 575.2260\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 614881.8750 - mae: 574.6412 - val_loss: 613421.0625 - val_mae: 573.8544\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 614241.8750 - mae: 574.5863 - val_loss: 612731.5625 - val_mae: 571.9005\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613418.1875 - mae: 573.2457 - val_loss: 611307.9375 - val_mae: 573.0829\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 612134.8125 - mae: 573.1607 - val_loss: 610217.6250 - val_mae: 572.8403\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 610676.3125 - mae: 572.6577 - val_loss: 608986.3750 - val_mae: 572.7636\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 609485.8750 - mae: 572.1668 - val_loss: 607640.5625 - val_mae: 571.4665\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 608452.9375 - mae: 572.1165 - val_loss: 607229.7500 - val_mae: 568.9887\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607415.2500 - mae: 570.9442 - val_loss: 605861.1250 - val_mae: 571.6196\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 606910.4375 - mae: 571.1015 - val_loss: 605093.5000 - val_mae: 570.7967\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 605802.1250 - mae: 570.6546 - val_loss: 604602.8125 - val_mae: 571.6118\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 605502.3125 - mae: 570.7803 - val_loss: 603803.1250 - val_mae: 569.3154\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 604394.2500 - mae: 570.3808 - val_loss: 602623.5000 - val_mae: 569.3659\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 603538.3125 - mae: 570.1991 - val_loss: 602118.7500 - val_mae: 568.1424\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602806.0000 - mae: 569.7783 - val_loss: 601377.3750 - val_mae: 568.0367\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602269.8750 - mae: 569.4749 - val_loss: 600701.5625 - val_mae: 568.3544\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 601752.9375 - mae: 569.1984 - val_loss: 600071.6875 - val_mae: 568.2379\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 601107.0625 - mae: 569.2031 - val_loss: 599834.6875 - val_mae: 567.3050\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 600792.1875 - mae: 568.9036 - val_loss: 598860.2500 - val_mae: 567.7114\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599890.2500 - mae: 568.1526 - val_loss: 598148.3750 - val_mae: 567.4235\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 599129.6250 - mae: 568.7690 - val_loss: 598161.5000 - val_mae: 565.3387\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598477.8125 - mae: 567.5214 - val_loss: 596677.5000 - val_mae: 566.6398\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 597526.5625 - mae: 566.9489 - val_loss: 595877.1875 - val_mae: 567.1313\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596848.8750 - mae: 567.4684 - val_loss: 595269.4375 - val_mae: 567.0975\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596171.8125 - mae: 566.5104 - val_loss: 594774.4375 - val_mae: 568.1546\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595446.3750 - mae: 566.4045 - val_loss: 593913.3125 - val_mae: 566.5472\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594682.4375 - mae: 566.2017 - val_loss: 593247.5000 - val_mae: 566.7146\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593947.2500 - mae: 566.0443 - val_loss: 592407.7500 - val_mae: 564.6827\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 593452.8125 - mae: 565.5250 - val_loss: 592090.5625 - val_mae: 564.5776\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592771.0625 - mae: 565.2433 - val_loss: 591383.9375 - val_mae: 563.7272\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 592091.6250 - mae: 564.4499 - val_loss: 590643.3750 - val_mae: 564.8290\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591766.6875 - mae: 564.4119 - val_loss: 590446.6875 - val_mae: 565.9927\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591356.6875 - mae: 564.9006 - val_loss: 589489.1875 - val_mae: 562.6539\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 590280.6250 - mae: 563.5955 - val_loss: 588712.8125 - val_mae: 563.7606\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 589665.6875 - mae: 563.5726 - val_loss: 588156.3125 - val_mae: 562.4413\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 589147.9375 - mae: 563.1489 - val_loss: 587482.1250 - val_mae: 563.4061\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588068.8125 - mae: 563.2153 - val_loss: 588110.6250 - val_mae: 559.6000\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587867.6875 - mae: 562.1063 - val_loss: 586134.9375 - val_mae: 560.8503\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586784.1875 - mae: 561.9372 - val_loss: 585518.1250 - val_mae: 560.4340\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586091.6875 - mae: 561.8387 - val_loss: 585187.6875 - val_mae: 559.0531\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 585607.5000 - mae: 561.0945 - val_loss: 584133.7500 - val_mae: 559.8381\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 584957.6250 - mae: 560.3738 - val_loss: 583230.0000 - val_mae: 560.8410\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 584218.5000 - mae: 560.8381 - val_loss: 582627.5000 - val_mae: 560.3177\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583535.3750 - mae: 559.8288 - val_loss: 581862.1250 - val_mae: 559.4402\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582600.3125 - mae: 559.5845 - val_loss: 581762.9375 - val_mae: 558.3859\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582353.1875 - mae: 559.3753 - val_loss: 580715.0625 - val_mae: 558.5497\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581751.8750 - mae: 558.7036 - val_loss: 580390.7500 - val_mae: 560.0708\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580828.9375 - mae: 558.8851 - val_loss: 579880.7500 - val_mae: 555.7225\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580315.6875 - mae: 557.9166 - val_loss: 578849.6250 - val_mae: 556.9832\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 579593.5625 - mae: 557.4116 - val_loss: 578024.3750 - val_mae: 557.3552\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 578936.7500 - mae: 557.3134 - val_loss: 577572.1875 - val_mae: 556.9374\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578421.3125 - mae: 557.2348 - val_loss: 576808.8125 - val_mae: 556.6550\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 577646.5625 - mae: 556.8061 - val_loss: 576624.6875 - val_mae: 554.4968\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 577399.0625 - mae: 556.0638 - val_loss: 575636.9375 - val_mae: 555.0140\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 576541.1250 - mae: 555.5073 - val_loss: 574944.0000 - val_mae: 553.5870\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 575829.2500 - mae: 554.7416 - val_loss: 574172.7500 - val_mae: 555.2162\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 574829.0625 - mae: 554.7117 - val_loss: 573368.5000 - val_mae: 552.4081\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 573721.5625 - mae: 553.4157 - val_loss: 571700.0000 - val_mae: 553.4962\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 572468.3750 - mae: 552.5012 - val_loss: 570523.8750 - val_mae: 553.2789\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571160.1250 - mae: 551.8467 - val_loss: 569355.6250 - val_mae: 552.5273\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 570000.8125 - mae: 551.5026 - val_loss: 568343.1875 - val_mae: 550.5622\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 569169.5625 - mae: 550.5959 - val_loss: 567453.2500 - val_mae: 549.7115\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 568255.0000 - mae: 549.7533 - val_loss: 567110.0625 - val_mae: 551.6661\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 567492.2500 - mae: 550.0032 - val_loss: 565925.8125 - val_mae: 548.9697\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 566858.5000 - mae: 549.1882 - val_loss: 565386.0625 - val_mae: 547.6330\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 566304.0000 - mae: 548.4786 - val_loss: 564729.5000 - val_mae: 548.5239\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 565965.3125 - mae: 548.3770 - val_loss: 564374.1875 - val_mae: 548.3154\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 565049.2500 - mae: 547.8878 - val_loss: 563822.6250 - val_mae: 546.6660\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 564838.3750 - mae: 547.5838 - val_loss: 563417.6250 - val_mae: 546.1851\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564282.8750 - mae: 547.2169 - val_loss: 563047.3125 - val_mae: 547.2798\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 564027.8750 - mae: 547.1705 - val_loss: 562621.6250 - val_mae: 546.7730\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 563534.9375 - mae: 546.8757 - val_loss: 562438.1875 - val_mae: 546.2797\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563665.6875 - mae: 546.7451 - val_loss: 561982.8750 - val_mae: 546.0388\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563063.1875 - mae: 546.1621 - val_loss: 562009.3125 - val_mae: 547.8663\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 563018.6250 - mae: 546.6320 - val_loss: 561730.3750 - val_mae: 543.8898\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 562370.8750 - mae: 545.8822 - val_loss: 561170.6250 - val_mae: 546.3442\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 562116.1250 - mae: 545.5769 - val_loss: 561003.6250 - val_mae: 545.7762\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561966.0000 - mae: 545.7280 - val_loss: 560628.5000 - val_mae: 544.0421\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 561575.3125 - mae: 545.0322 - val_loss: 560365.2500 - val_mae: 545.5317\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 561646.0000 - mae: 545.7516 - val_loss: 560315.1875 - val_mae: 543.1761\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 561638.8125 - mae: 544.9150 - val_loss: 559828.9375 - val_mae: 543.4879\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560919.8750 - mae: 545.1370 - val_loss: 559710.6875 - val_mae: 544.8403\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560864.0000 - mae: 544.7815 - val_loss: 559576.2500 - val_mae: 543.0955\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560434.1250 - mae: 544.2856 - val_loss: 559221.0625 - val_mae: 544.1988\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560516.2500 - mae: 544.5899 - val_loss: 559059.0625 - val_mae: 543.5178\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 560178.6250 - mae: 544.2041 - val_loss: 558867.3125 - val_mae: 544.6628\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559889.2500 - mae: 544.2377 - val_loss: 558884.6250 - val_mae: 544.0612\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559731.0625 - mae: 543.9404 - val_loss: 558658.3750 - val_mae: 544.6937\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 559776.8750 - mae: 543.7684 - val_loss: 558834.8125 - val_mae: 546.0599\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559373.5000 - mae: 543.9326 - val_loss: 558331.8125 - val_mae: 543.8550\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559426.0625 - mae: 543.8449 - val_loss: 558118.5000 - val_mae: 544.7318\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559255.3125 - mae: 544.0446 - val_loss: 557986.6875 - val_mae: 541.5176\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558690.3125 - mae: 542.8738 - val_loss: 558072.3125 - val_mae: 544.7934\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558837.5000 - mae: 543.3893 - val_loss: 557496.1250 - val_mae: 543.4948\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558657.6250 - mae: 543.6957 - val_loss: 557403.6875 - val_mae: 541.6447\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558586.3750 - mae: 543.1570 - val_loss: 557200.7500 - val_mae: 543.4823\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558237.1875 - mae: 542.9886 - val_loss: 556845.0000 - val_mae: 542.4579\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558030.9375 - mae: 543.3167 - val_loss: 556646.5625 - val_mae: 541.8921\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557748.6250 - mae: 542.5467 - val_loss: 556573.6250 - val_mae: 541.4338\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557738.3750 - mae: 542.4694 - val_loss: 556279.8125 - val_mae: 542.2673\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557661.3750 - mae: 542.7377 - val_loss: 556267.8750 - val_mae: 541.8569\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557474.7500 - mae: 542.1107 - val_loss: 556422.6875 - val_mae: 544.2890\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 557179.4375 - mae: 542.4368 - val_loss: 556015.1250 - val_mae: 541.7863\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 557038.3125 - mae: 542.2847 - val_loss: 556079.6875 - val_mae: 543.1392\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 557191.5000 - mae: 542.2733 - val_loss: 555742.4375 - val_mae: 542.4185\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 556815.7500 - mae: 542.4513 - val_loss: 555647.9375 - val_mae: 541.9081\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556895.5625 - mae: 542.1730 - val_loss: 555439.2500 - val_mae: 541.7330\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556402.1875 - mae: 541.5672 - val_loss: 555239.6875 - val_mae: 541.6756\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556297.8750 - mae: 542.1273 - val_loss: 555001.3750 - val_mae: 540.3853\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555891.1875 - mae: 541.0003 - val_loss: 555028.0000 - val_mae: 541.9405\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 556019.0000 - mae: 541.9042 - val_loss: 554673.5000 - val_mae: 541.5821\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555781.3125 - mae: 541.5852 - val_loss: 554602.2500 - val_mae: 541.6147\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555684.6875 - mae: 541.7774 - val_loss: 554692.4375 - val_mae: 540.3794\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555573.3125 - mae: 541.1364 - val_loss: 554381.8125 - val_mae: 541.6089\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555492.7500 - mae: 541.3670 - val_loss: 554489.7500 - val_mae: 542.3622\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555406.3125 - mae: 541.8170 - val_loss: 554372.8750 - val_mae: 540.3440\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555429.6875 - mae: 541.0178 - val_loss: 554299.6875 - val_mae: 542.3677\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555094.8125 - mae: 541.6519 - val_loss: 554428.6250 - val_mae: 540.9741\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555436.6875 - mae: 540.9076 - val_loss: 554117.4375 - val_mae: 541.8470\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554983.4375 - mae: 541.2108 - val_loss: 554270.0625 - val_mae: 542.8495\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554890.0625 - mae: 541.4128 - val_loss: 553797.0625 - val_mae: 541.4590\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555077.6875 - mae: 541.2341 - val_loss: 553728.6250 - val_mae: 540.6699\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554860.6250 - mae: 540.8341 - val_loss: 553736.4375 - val_mae: 540.7211\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 555054.4375 - mae: 541.1125 - val_loss: 553556.8750 - val_mae: 541.2566\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554662.3125 - mae: 541.3206 - val_loss: 553574.2500 - val_mae: 539.1683\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 554730.3750 - mae: 541.1569 - val_loss: 553720.5000 - val_mae: 539.3228\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554498.3750 - mae: 540.6015 - val_loss: 553432.2500 - val_mae: 541.5327\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554470.6875 - mae: 541.1089 - val_loss: 553279.2500 - val_mae: 540.3666\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 554280.6875 - mae: 540.9904 - val_loss: 553334.5625 - val_mae: 539.5770\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 554502.5000 - mae: 540.6667 - val_loss: 553125.7500 - val_mae: 540.3470\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554160.6250 - mae: 540.8448 - val_loss: 553313.5625 - val_mae: 539.3699\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554367.0625 - mae: 540.4743 - val_loss: 552995.2500 - val_mae: 540.8637\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554194.6250 - mae: 541.0209 - val_loss: 553071.7500 - val_mae: 539.0189\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554353.8750 - mae: 540.4846 - val_loss: 553014.6250 - val_mae: 540.0568\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554189.8125 - mae: 540.6157 - val_loss: 553050.4375 - val_mae: 540.6216\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553841.5000 - mae: 540.2351 - val_loss: 552891.3750 - val_mae: 540.6185\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554015.9375 - mae: 540.3208 - val_loss: 552821.5000 - val_mae: 540.5195\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554258.2500 - mae: 541.0948 - val_loss: 552789.7500 - val_mae: 539.2700\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 554214.3750 - mae: 540.6122 - val_loss: 552646.6250 - val_mae: 539.8132\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553955.2500 - mae: 540.6124 - val_loss: 552802.6875 - val_mae: 540.0598\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553747.3125 - mae: 540.2269 - val_loss: 552537.4375 - val_mae: 540.0391\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 553439.9375 - mae: 540.9635 - val_loss: 553933.5625 - val_mae: 536.9696\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553800.8125 - mae: 540.2308 - val_loss: 552871.8125 - val_mae: 537.9114\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553301.6875 - mae: 539.6158 - val_loss: 553521.3125 - val_mae: 543.3671\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553760.2500 - mae: 540.8108 - val_loss: 552442.8125 - val_mae: 539.8965\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553559.4375 - mae: 540.1705 - val_loss: 552520.8750 - val_mae: 540.5463\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553613.0000 - mae: 540.5096 - val_loss: 552264.8750 - val_mae: 539.9282\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553337.1250 - mae: 539.8821 - val_loss: 552261.8125 - val_mae: 539.7584\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553606.2500 - mae: 540.6063 - val_loss: 552294.3750 - val_mae: 539.0923\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553497.0000 - mae: 539.9479 - val_loss: 552242.2500 - val_mae: 539.3359\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 553381.4375 - mae: 540.2126 - val_loss: 552078.3125 - val_mae: 540.0185\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 553294.3125 - mae: 539.9998 - val_loss: 552154.2500 - val_mae: 540.0971\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38173296.0000 - mae: 6023.0205 - val_loss: 37145624.0000 - val_mae: 5945.1694\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 34610496.0000 - mae: 5747.0723 - val_loss: 31519054.0000 - val_mae: 5496.7656\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 27853744.0000 - mae: 5168.5015 - val_loss: 24034400.0000 - val_mae: 4803.1533\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 20392004.0000 - mae: 4399.9980 - val_loss: 16881438.0000 - val_mae: 3977.3115\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 13927045.0000 - mae: 3554.2346 - val_loss: 11224740.0000 - val_mae: 3132.5518\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 9118881.0000 - mae: 2746.0581 - val_loss: 7243504.5000 - val_mae: 2380.8533\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 5844652.0000 - mae: 2082.1804 - val_loss: 4619028.0000 - val_mae: 1813.4344\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 3731311.7500 - mae: 1601.3521 - val_loss: 2962680.5000 - val_mae: 1405.0802\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2422425.2500 - mae: 1250.1041 - val_loss: 1960491.3750 - val_mae: 1109.9666\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1658183.0000 - mae: 1009.9261 - val_loss: 1410418.7500 - val_mae: 924.5383\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1258174.1250 - mae: 869.1157 - val_loss: 1135475.2500 - val_mae: 823.1169\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1063683.1250 - mae: 795.0702 - val_loss: 1003757.0625 - val_mae: 770.5879\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 968610.0625 - mae: 756.0845 - val_loss: 937092.4375 - val_mae: 743.1147\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 917238.4375 - mae: 734.3662 - val_loss: 896923.5625 - val_mae: 725.4684\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 883216.5625 - mae: 719.5842 - val_loss: 867750.6250 - val_mae: 712.3271\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 857052.8750 - mae: 706.9235 - val_loss: 844607.4375 - val_mae: 701.6642\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 835435.8125 - mae: 696.2588 - val_loss: 823962.2500 - val_mae: 690.7376\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 816345.6875 - mae: 685.8302 - val_loss: 806242.5625 - val_mae: 680.7676\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 799770.7500 - mae: 676.9109 - val_loss: 790358.5625 - val_mae: 671.9409\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 784580.5000 - mae: 668.2061 - val_loss: 776224.7500 - val_mae: 664.3506\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 771197.8125 - mae: 660.4011 - val_loss: 763400.5625 - val_mae: 657.1566\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 759340.0000 - mae: 653.9937 - val_loss: 752390.7500 - val_mae: 650.0891\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 748849.3750 - mae: 647.8918 - val_loss: 742521.6250 - val_mae: 645.4375\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 739595.0625 - mae: 642.7785 - val_loss: 733496.5000 - val_mae: 639.4603\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 730795.3750 - mae: 638.1103 - val_loss: 726049.1875 - val_mae: 633.3459\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 724095.1875 - mae: 632.8660 - val_loss: 718435.8125 - val_mae: 631.0936\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 716755.7500 - mae: 629.6599 - val_loss: 711890.8125 - val_mae: 627.0932\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 710512.8750 - mae: 626.2721 - val_loss: 705988.9375 - val_mae: 623.4525\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 705092.5625 - mae: 623.2537 - val_loss: 700781.0000 - val_mae: 620.1035\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 699891.8125 - mae: 620.1597 - val_loss: 696101.5625 - val_mae: 619.2803\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 695588.4375 - mae: 618.2359 - val_loss: 691752.2500 - val_mae: 615.7197\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 691530.0625 - mae: 615.2073 - val_loss: 687962.0625 - val_mae: 614.5044\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 687662.6250 - mae: 613.2803 - val_loss: 684374.3750 - val_mae: 611.6614\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 684261.3750 - mae: 611.3372 - val_loss: 681015.0000 - val_mae: 608.3902\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 680765.3125 - mae: 609.2010 - val_loss: 677809.7500 - val_mae: 609.0366\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 677784.6875 - mae: 607.8043 - val_loss: 674774.6250 - val_mae: 604.9520\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 675139.5625 - mae: 606.0075 - val_loss: 671969.3125 - val_mae: 603.6573\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 672263.5000 - mae: 603.7031 - val_loss: 669415.3125 - val_mae: 603.4552\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 669953.0625 - mae: 602.4771 - val_loss: 667723.0625 - val_mae: 602.4416\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 667704.5625 - mae: 601.8630 - val_loss: 664830.6875 - val_mae: 598.7307\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 665249.7500 - mae: 599.4819 - val_loss: 662924.2500 - val_mae: 598.7271\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 662750.0625 - mae: 597.5765 - val_loss: 661723.1875 - val_mae: 601.7789\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 661289.5625 - mae: 597.7822 - val_loss: 658079.6875 - val_mae: 596.3817\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 659182.7500 - mae: 596.5239 - val_loss: 656471.6250 - val_mae: 595.7389\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 657149.4375 - mae: 595.3399 - val_loss: 655561.3750 - val_mae: 597.3165\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 655918.6250 - mae: 595.1324 - val_loss: 653260.6250 - val_mae: 593.9521\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 654205.5000 - mae: 593.9205 - val_loss: 651950.3750 - val_mae: 593.8834\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 652961.3125 - mae: 593.6509 - val_loss: 650572.6250 - val_mae: 591.9630\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 651154.5000 - mae: 592.4377 - val_loss: 649232.3125 - val_mae: 593.4442\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 649740.1250 - mae: 592.0521 - val_loss: 647558.5625 - val_mae: 592.5892\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 647657.0625 - mae: 591.5428 - val_loss: 645431.7500 - val_mae: 589.6353\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 646120.3750 - mae: 589.7829 - val_loss: 643888.1875 - val_mae: 591.1475\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 644234.5625 - mae: 589.8622 - val_loss: 642191.9375 - val_mae: 587.2637\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 642689.8750 - mae: 588.7089 - val_loss: 640261.1875 - val_mae: 589.2651\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 641324.8125 - mae: 588.2519 - val_loss: 638770.5625 - val_mae: 588.5815\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 639324.5000 - mae: 588.3235 - val_loss: 637441.3750 - val_mae: 586.3198\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 638368.8125 - mae: 586.7306 - val_loss: 636212.3750 - val_mae: 588.0109\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637018.4375 - mae: 587.7032 - val_loss: 635111.3125 - val_mae: 584.5560\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 635973.6875 - mae: 586.3861 - val_loss: 633664.2500 - val_mae: 586.4268\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 634770.6875 - mae: 586.3441 - val_loss: 633106.1250 - val_mae: 583.9964\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 634209.1250 - mae: 585.9828 - val_loss: 631820.6875 - val_mae: 584.2680\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 633002.3125 - mae: 585.0522 - val_loss: 631366.2500 - val_mae: 582.8541\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 632173.2500 - mae: 585.2711 - val_loss: 629975.3750 - val_mae: 584.7985\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 631011.0000 - mae: 585.0333 - val_loss: 629381.6875 - val_mae: 582.6323\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 630030.6875 - mae: 584.1803 - val_loss: 628231.1250 - val_mae: 583.4699\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 628851.0000 - mae: 583.7932 - val_loss: 626362.4375 - val_mae: 583.0269\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 627523.8750 - mae: 583.6113 - val_loss: 625010.6250 - val_mae: 583.1540\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 625797.0000 - mae: 582.3786 - val_loss: 623504.6250 - val_mae: 582.6487\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 624625.5625 - mae: 582.1572 - val_loss: 622071.6875 - val_mae: 581.1658\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 623228.0000 - mae: 581.5306 - val_loss: 620961.5625 - val_mae: 579.5286\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 621732.8750 - mae: 580.3821 - val_loss: 620258.5000 - val_mae: 581.1860\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 621250.6875 - mae: 580.7012 - val_loss: 619160.1875 - val_mae: 580.3866\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 620445.0625 - mae: 580.7327 - val_loss: 618440.3750 - val_mae: 578.5267\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 619766.2500 - mae: 580.0245 - val_loss: 617863.5000 - val_mae: 580.3289\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619102.0000 - mae: 580.1155 - val_loss: 616864.0000 - val_mae: 579.0129\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 618213.8750 - mae: 579.5997 - val_loss: 616307.5625 - val_mae: 577.4389\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 617084.6875 - mae: 579.5933 - val_loss: 615961.5625 - val_mae: 576.5695\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 616445.6875 - mae: 578.8440 - val_loss: 614881.5625 - val_mae: 578.6614\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615752.7500 - mae: 578.4811 - val_loss: 614226.8750 - val_mae: 577.4846\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 615162.8125 - mae: 578.5942 - val_loss: 613343.6875 - val_mae: 578.6377\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614991.3750 - mae: 578.5630 - val_loss: 612807.0625 - val_mae: 576.9647\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 614028.1875 - mae: 577.7430 - val_loss: 611889.4375 - val_mae: 577.6202\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 613274.4375 - mae: 578.0876 - val_loss: 611300.3125 - val_mae: 576.2117\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 612486.3750 - mae: 577.0392 - val_loss: 611057.6250 - val_mae: 578.7281\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611693.5000 - mae: 577.3938 - val_loss: 610259.6250 - val_mae: 576.3969\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 611458.0000 - mae: 576.8357 - val_loss: 609377.5625 - val_mae: 577.0068\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 610563.4375 - mae: 577.3376 - val_loss: 608373.7500 - val_mae: 575.2317\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 609392.6875 - mae: 576.2138 - val_loss: 607188.5625 - val_mae: 575.2011\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 608042.0000 - mae: 575.5789 - val_loss: 606247.7500 - val_mae: 575.9793\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 607205.3125 - mae: 575.2706 - val_loss: 605398.5625 - val_mae: 575.0345\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 606118.0000 - mae: 574.7486 - val_loss: 604549.3750 - val_mae: 575.9816\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 605597.0625 - mae: 574.8365 - val_loss: 603395.3750 - val_mae: 574.2292\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 604780.4375 - mae: 574.4626 - val_loss: 603046.6250 - val_mae: 573.2021\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603992.8125 - mae: 574.1511 - val_loss: 602492.6875 - val_mae: 572.2759\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 603778.6250 - mae: 573.9607 - val_loss: 601580.1875 - val_mae: 573.9468\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602686.0625 - mae: 573.3346 - val_loss: 601215.3750 - val_mae: 573.9858\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 602368.7500 - mae: 573.6541 - val_loss: 600977.1250 - val_mae: 571.3306\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601945.5000 - mae: 573.2000 - val_loss: 600168.0000 - val_mae: 572.3392\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601581.7500 - mae: 573.4026 - val_loss: 599873.0000 - val_mae: 572.2280\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601181.0000 - mae: 572.8102 - val_loss: 599717.8750 - val_mae: 570.9326\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 601089.6875 - mae: 572.7801 - val_loss: 599406.3750 - val_mae: 573.2944\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600326.6250 - mae: 572.5291 - val_loss: 598984.6250 - val_mae: 573.4724\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 600333.3750 - mae: 572.6965 - val_loss: 598556.0000 - val_mae: 571.2610\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599652.9375 - mae: 571.7498 - val_loss: 598497.8750 - val_mae: 573.4850\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599729.3750 - mae: 572.2886 - val_loss: 598417.8750 - val_mae: 573.6929\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 599797.7500 - mae: 572.8954 - val_loss: 597742.1875 - val_mae: 570.8469\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599210.6875 - mae: 571.8245 - val_loss: 597642.0625 - val_mae: 570.3666\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 598848.6250 - mae: 571.7438 - val_loss: 597276.4375 - val_mae: 571.0411\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 598175.7500 - mae: 572.0180 - val_loss: 598051.7500 - val_mae: 569.1689\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 597995.9375 - mae: 570.8596 - val_loss: 597345.5000 - val_mae: 573.7968\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 598011.4375 - mae: 572.0408 - val_loss: 596290.8750 - val_mae: 569.6676\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597597.8750 - mae: 571.0905 - val_loss: 596280.9375 - val_mae: 570.5565\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597688.5625 - mae: 571.0613 - val_loss: 595784.8750 - val_mae: 571.7106\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597319.8125 - mae: 571.4253 - val_loss: 595894.0000 - val_mae: 568.6844\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 596841.1875 - mae: 571.0945 - val_loss: 595330.5000 - val_mae: 569.4762\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596952.5000 - mae: 570.7643 - val_loss: 595027.8750 - val_mae: 569.6049\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596100.1875 - mae: 570.1954 - val_loss: 595074.7500 - val_mae: 570.5558\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596503.0625 - mae: 571.0700 - val_loss: 594868.4375 - val_mae: 569.7781\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595721.3125 - mae: 569.7303 - val_loss: 596383.3750 - val_mae: 574.7239\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596055.9375 - mae: 570.8025 - val_loss: 594045.3125 - val_mae: 570.2679\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595329.8125 - mae: 570.7764 - val_loss: 594021.3125 - val_mae: 569.3555\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595785.0625 - mae: 570.3477 - val_loss: 593684.5000 - val_mae: 569.1446\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 595087.1875 - mae: 569.6688 - val_loss: 593503.4375 - val_mae: 570.2710\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 594920.3125 - mae: 569.8188 - val_loss: 593123.5000 - val_mae: 569.2012\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 32911950.0000 - mae: 5559.2046 - val_loss: 22644474.0000 - val_mae: 4578.7266\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 12424107.0000 - mae: 3156.5889 - val_loss: 4979731.0000 - val_mae: 1790.7133\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 2622992.5000 - mae: 1135.0283 - val_loss: 1482478.2500 - val_mae: 819.4373\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1194667.6250 - mae: 746.3999 - val_loss: 1002549.8125 - val_mae: 701.2955\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 913893.9375 - mae: 678.5790 - val_loss: 844340.0625 - val_mae: 659.0053\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 808388.4375 - mae: 648.7417 - val_loss: 778001.5625 - val_mae: 639.6083\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 761824.8750 - mae: 633.3676 - val_loss: 745900.9375 - val_mae: 630.0734\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 735916.6875 - mae: 625.0670 - val_loss: 722945.8750 - val_mae: 619.8130\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 716800.8125 - mae: 617.4205 - val_loss: 706310.7500 - val_mae: 614.3376\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 702494.1875 - mae: 611.7338 - val_loss: 695266.5000 - val_mae: 606.1028\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 691859.4375 - mae: 607.0503 - val_loss: 684645.1875 - val_mae: 604.0238\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 683325.5000 - mae: 603.7402 - val_loss: 677193.9375 - val_mae: 602.3998\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 676358.8750 - mae: 600.2755 - val_loss: 671015.9375 - val_mae: 597.8103\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 671239.6250 - mae: 597.7885 - val_loss: 666914.4375 - val_mae: 597.4672\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 666750.2500 - mae: 596.0040 - val_loss: 663169.3750 - val_mae: 593.7322\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 663541.0000 - mae: 594.1899 - val_loss: 659713.5000 - val_mae: 590.4313\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 659972.1875 - mae: 592.1901 - val_loss: 656256.2500 - val_mae: 589.9199\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 656674.5625 - mae: 590.6610 - val_loss: 652306.0625 - val_mae: 588.6083\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 651252.8125 - mae: 587.5027 - val_loss: 645981.1875 - val_mae: 582.9438\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 644888.5000 - mae: 583.5792 - val_loss: 640051.8750 - val_mae: 582.2859\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 639786.5625 - mae: 581.2479 - val_loss: 635098.9375 - val_mae: 577.3118\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 634527.3750 - mae: 578.0733 - val_loss: 630909.5000 - val_mae: 579.3446\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 630381.5000 - mae: 575.8151 - val_loss: 625889.3750 - val_mae: 573.9267\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 626262.5000 - mae: 573.1828 - val_loss: 624941.6875 - val_mae: 575.7446\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 624251.5000 - mae: 572.5983 - val_loss: 620953.8750 - val_mae: 571.3112\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 622660.0625 - mae: 571.3328 - val_loss: 619092.3750 - val_mae: 569.9153\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 620802.9375 - mae: 570.3441 - val_loss: 617627.7500 - val_mae: 569.7753\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 619009.4375 - mae: 569.7366 - val_loss: 617274.8750 - val_mae: 569.1944\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 618131.1875 - mae: 569.4062 - val_loss: 615549.0625 - val_mae: 570.1275\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 616704.6250 - mae: 568.0425 - val_loss: 613548.5625 - val_mae: 568.2990\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 614935.5625 - mae: 567.6424 - val_loss: 611953.5625 - val_mae: 566.7814\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 613310.3750 - mae: 566.4580 - val_loss: 611200.7500 - val_mae: 567.6064\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 612011.3125 - mae: 566.3734 - val_loss: 608753.6250 - val_mae: 564.3713\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 610709.0625 - mae: 565.3354 - val_loss: 607582.0625 - val_mae: 563.1635\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 608995.7500 - mae: 564.0770 - val_loss: 606359.0000 - val_mae: 561.7074\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 607474.3750 - mae: 563.3726 - val_loss: 605984.0000 - val_mae: 565.9644\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 606276.3750 - mae: 563.3344 - val_loss: 604068.3750 - val_mae: 562.4402\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 605034.8750 - mae: 562.4008 - val_loss: 602818.6250 - val_mae: 560.4148\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 603728.5000 - mae: 561.6445 - val_loss: 601403.1875 - val_mae: 562.7410\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 602676.6250 - mae: 561.0245 - val_loss: 599964.2500 - val_mae: 559.5801\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602008.4375 - mae: 560.6327 - val_loss: 598776.5000 - val_mae: 559.7437\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 601051.4375 - mae: 560.5990 - val_loss: 598129.0625 - val_mae: 558.7207\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599790.0625 - mae: 559.5718 - val_loss: 598123.5625 - val_mae: 560.7344\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 600009.4375 - mae: 560.2408 - val_loss: 597210.0000 - val_mae: 558.1182\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 599210.0625 - mae: 559.3248 - val_loss: 597154.3750 - val_mae: 560.2206\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 598544.4375 - mae: 559.6707 - val_loss: 596381.7500 - val_mae: 557.2040\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 598218.3125 - mae: 559.4265 - val_loss: 595906.5000 - val_mae: 557.7873\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 597801.7500 - mae: 558.8148 - val_loss: 596372.0000 - val_mae: 561.1871\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 597380.5000 - mae: 559.1642 - val_loss: 595137.3750 - val_mae: 557.5283\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 596947.2500 - mae: 558.5495 - val_loss: 594351.5000 - val_mae: 559.3521\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 596276.5000 - mae: 558.2473 - val_loss: 594230.1250 - val_mae: 559.0995\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 595617.7500 - mae: 558.4626 - val_loss: 594043.1250 - val_mae: 557.4213\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595579.6875 - mae: 558.5955 - val_loss: 593384.0625 - val_mae: 555.2044\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595237.5625 - mae: 558.0570 - val_loss: 593047.1875 - val_mae: 555.0679\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595088.5000 - mae: 557.9105 - val_loss: 592446.8750 - val_mae: 555.2267\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594112.1875 - mae: 557.6597 - val_loss: 592269.8125 - val_mae: 557.5544\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594042.6875 - mae: 557.5908 - val_loss: 592032.6250 - val_mae: 556.9042\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 593428.2500 - mae: 556.5920 - val_loss: 592945.1875 - val_mae: 560.3822\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 593660.2500 - mae: 557.6484 - val_loss: 592193.8125 - val_mae: 558.4872\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 593388.6250 - mae: 557.2572 - val_loss: 591516.1875 - val_mae: 558.1177\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593510.3750 - mae: 557.3363 - val_loss: 591091.4375 - val_mae: 554.9623\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 593301.0000 - mae: 557.0035 - val_loss: 591112.3125 - val_mae: 558.3767\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592705.6250 - mae: 557.0549 - val_loss: 590782.8125 - val_mae: 557.2764\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592738.8750 - mae: 557.1916 - val_loss: 591619.8125 - val_mae: 559.6245\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592795.8750 - mae: 557.1713 - val_loss: 590727.0625 - val_mae: 557.6189\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592264.7500 - mae: 556.8199 - val_loss: 591543.1875 - val_mae: 558.2099\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592501.2500 - mae: 556.9234 - val_loss: 590156.5625 - val_mae: 556.2376\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591383.9375 - mae: 556.1341 - val_loss: 591464.7500 - val_mae: 559.5828\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 592282.6250 - mae: 557.2706 - val_loss: 590719.0625 - val_mae: 554.0049\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 591691.0000 - mae: 556.2006 - val_loss: 590158.0625 - val_mae: 554.9997\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591567.8125 - mae: 556.5164 - val_loss: 589889.3750 - val_mae: 557.3956\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591434.9375 - mae: 557.1307 - val_loss: 591260.1875 - val_mae: 552.3800\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 591571.6250 - mae: 555.9467 - val_loss: 589289.8125 - val_mae: 555.1095\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 591260.9375 - mae: 556.5247 - val_loss: 589799.4375 - val_mae: 556.4886\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 591656.7500 - mae: 556.5391 - val_loss: 589431.2500 - val_mae: 555.7380\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591067.5625 - mae: 556.0640 - val_loss: 589292.0000 - val_mae: 555.7220\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 591200.8750 - mae: 556.2495 - val_loss: 588983.5625 - val_mae: 556.5881\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 590890.3125 - mae: 556.1692 - val_loss: 589169.8125 - val_mae: 557.0936\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591007.3125 - mae: 556.4814 - val_loss: 589056.3750 - val_mae: 556.1129\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591124.7500 - mae: 556.3301 - val_loss: 588889.6250 - val_mae: 555.7790\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590750.0000 - mae: 556.4157 - val_loss: 589152.9375 - val_mae: 553.4855\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 590647.8750 - mae: 556.0782 - val_loss: 588574.6875 - val_mae: 554.4468\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 3s 2ms/step - loss: 30753868.0000 - mae: 5359.4268 - val_loss: 17270688.0000 - val_mae: 3990.7256\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 7968658.5000 - mae: 2412.0120 - val_loss: 2771666.0000 - val_mae: 1292.0918\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1724546.5000 - mae: 981.7460 - val_loss: 1200677.0000 - val_mae: 829.6269\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1024259.1875 - mae: 776.5045 - val_loss: 895192.9375 - val_mae: 729.7442\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 834144.8125 - mae: 697.0643 - val_loss: 781907.8750 - val_mae: 668.8619\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 753554.6250 - mae: 651.5593 - val_loss: 725017.8750 - val_mae: 636.2601\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 710662.3750 - mae: 626.4571 - val_loss: 692842.9375 - val_mae: 613.2448\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 684167.5625 - mae: 610.7058 - val_loss: 671780.3750 - val_mae: 605.2277\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 667597.0625 - mae: 600.9053 - val_loss: 657335.1250 - val_mae: 597.4521\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 655293.0000 - mae: 595.0580 - val_loss: 649252.2500 - val_mae: 587.4827\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 646297.3750 - mae: 589.7611 - val_loss: 641367.7500 - val_mae: 591.6362\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 639372.6875 - mae: 587.4468 - val_loss: 632723.7500 - val_mae: 583.7426\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 634011.3750 - mae: 584.6041 - val_loss: 628975.2500 - val_mae: 579.7967\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 629666.1875 - mae: 581.4122 - val_loss: 623859.6875 - val_mae: 580.4990\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 624962.0625 - mae: 579.2061 - val_loss: 619697.0000 - val_mae: 578.2642\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 620691.9375 - mae: 577.6265 - val_loss: 616035.1875 - val_mae: 576.0117\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 617063.0000 - mae: 575.3572 - val_loss: 612258.8125 - val_mae: 573.6323\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 612216.0000 - mae: 572.4096 - val_loss: 607025.1250 - val_mae: 572.9656\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 604904.0625 - mae: 569.0153 - val_loss: 601213.0625 - val_mae: 569.5386\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 599820.5000 - mae: 565.2305 - val_loss: 594642.5625 - val_mae: 565.2310\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595466.1875 - mae: 562.2480 - val_loss: 592331.5625 - val_mae: 564.3680\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591907.6250 - mae: 560.2899 - val_loss: 589112.5000 - val_mae: 561.1550\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 589745.2500 - mae: 558.9105 - val_loss: 586839.1875 - val_mae: 559.9507\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 587622.0000 - mae: 557.9899 - val_loss: 585874.8125 - val_mae: 553.1293\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 586466.3750 - mae: 556.0920 - val_loss: 584001.7500 - val_mae: 558.4197\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585704.8125 - mae: 555.9333 - val_loss: 583273.3125 - val_mae: 553.1857\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584332.4375 - mae: 555.1815 - val_loss: 581899.6875 - val_mae: 557.0765\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 583934.8750 - mae: 554.8347 - val_loss: 581324.4375 - val_mae: 552.1810\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 583246.5625 - mae: 555.0357 - val_loss: 579816.9375 - val_mae: 552.8087\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 582557.6875 - mae: 554.6063 - val_loss: 580178.8125 - val_mae: 552.1740\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 581826.8125 - mae: 553.0503 - val_loss: 580812.5625 - val_mae: 557.2552\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 581534.5625 - mae: 553.7757 - val_loss: 578845.6250 - val_mae: 555.7275\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 580879.0000 - mae: 553.2189 - val_loss: 578614.0000 - val_mae: 554.6491\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 580419.1250 - mae: 552.6711 - val_loss: 578751.1875 - val_mae: 549.6623\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 580279.3125 - mae: 552.8996 - val_loss: 577131.1250 - val_mae: 549.7854\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579703.1875 - mae: 552.6165 - val_loss: 576684.0000 - val_mae: 551.0009\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579469.1250 - mae: 552.3171 - val_loss: 577439.2500 - val_mae: 553.3700\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 579140.7500 - mae: 552.3099 - val_loss: 575937.4375 - val_mae: 552.8083\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 578109.2500 - mae: 552.0581 - val_loss: 576653.5625 - val_mae: 548.4527\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 577950.0000 - mae: 551.6234 - val_loss: 575947.3125 - val_mae: 550.9215\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 577250.4375 - mae: 551.7494 - val_loss: 575465.8125 - val_mae: 554.1756\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576655.6250 - mae: 551.4905 - val_loss: 573591.8125 - val_mae: 550.5079\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575136.4375 - mae: 550.8293 - val_loss: 574539.1875 - val_mae: 548.7238\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 575273.0000 - mae: 550.6652 - val_loss: 571602.1250 - val_mae: 549.4232\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 573960.1875 - mae: 549.7576 - val_loss: 571418.8125 - val_mae: 550.4482\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 572973.2500 - mae: 549.6478 - val_loss: 572755.9375 - val_mae: 544.8627\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 572752.9375 - mae: 548.8279 - val_loss: 569346.9375 - val_mae: 549.3623\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 571020.6250 - mae: 548.4848 - val_loss: 568790.7500 - val_mae: 545.2043\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 571039.2500 - mae: 548.0825 - val_loss: 567999.7500 - val_mae: 548.0721\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 570684.5000 - mae: 547.3056 - val_loss: 567590.0000 - val_mae: 547.7200\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 569709.0625 - mae: 547.5848 - val_loss: 567421.1250 - val_mae: 548.0607\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 569762.6250 - mae: 547.4240 - val_loss: 566472.6875 - val_mae: 544.1911\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 568820.3750 - mae: 546.4979 - val_loss: 567437.8125 - val_mae: 550.8854\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 568634.0625 - mae: 547.3373 - val_loss: 565231.1250 - val_mae: 544.7290\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 567994.1875 - mae: 546.1473 - val_loss: 565943.4375 - val_mae: 545.8094\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 567286.8125 - mae: 546.0117 - val_loss: 565206.5000 - val_mae: 547.9403\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 566196.6875 - mae: 545.8292 - val_loss: 565983.8125 - val_mae: 542.1730\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 566360.9375 - mae: 545.1371 - val_loss: 564060.0000 - val_mae: 547.3027\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565479.6250 - mae: 545.0508 - val_loss: 563866.6875 - val_mae: 547.6762\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565251.6250 - mae: 545.3375 - val_loss: 563063.8125 - val_mae: 542.3902\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 564590.3750 - mae: 544.2467 - val_loss: 562230.8125 - val_mae: 545.9044\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 564452.5000 - mae: 544.7272 - val_loss: 561274.1250 - val_mae: 544.1833\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563491.2500 - mae: 544.2129 - val_loss: 561151.7500 - val_mae: 542.7128\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563743.6250 - mae: 544.3757 - val_loss: 561595.0000 - val_mae: 545.9152\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 563495.0000 - mae: 544.2139 - val_loss: 560143.0625 - val_mae: 543.6343\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 562639.8750 - mae: 543.6623 - val_loss: 560090.5000 - val_mae: 542.6061\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 562457.6250 - mae: 543.5889 - val_loss: 561830.3125 - val_mae: 548.3655\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 37118728.0000 - mae: 5937.5137 - val_loss: 33879368.0000 - val_mae: 5676.2231\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 27994100.0000 - mae: 5152.2183 - val_loss: 21623006.0000 - val_mae: 4532.6387\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 15736468.0000 - mae: 3813.1006 - val_loss: 10461957.0000 - val_mae: 3072.3838\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 6855710.0000 - mae: 2384.0215 - val_loss: 4037888.7500 - val_mae: 1756.1179\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2562079.0000 - mae: 1319.5935 - val_loss: 1555583.6250 - val_mae: 983.8033\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1165389.0000 - mae: 828.2153 - val_loss: 931510.3125 - val_mae: 728.9264\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 859636.3750 - mae: 697.0981 - val_loss: 813906.0625 - val_mae: 675.5037\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 797108.3125 - mae: 667.4354 - val_loss: 781735.3750 - val_mae: 661.0212\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 773951.8125 - mae: 656.0124 - val_loss: 764085.0000 - val_mae: 652.9957\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 758167.1250 - mae: 649.3977 - val_loss: 749566.9375 - val_mae: 643.2103\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 744435.6250 - mae: 641.4512 - val_loss: 735831.6250 - val_mae: 637.9274\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 731189.1875 - mae: 635.0778 - val_loss: 723498.8750 - val_mae: 631.1614\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 719523.6250 - mae: 628.0913 - val_loss: 712359.8750 - val_mae: 625.8076\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 708975.0625 - mae: 622.5620 - val_loss: 702777.0625 - val_mae: 620.6697\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 699983.9375 - mae: 617.9822 - val_loss: 695102.4375 - val_mae: 615.3442\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 693402.7500 - mae: 614.2189 - val_loss: 689617.5625 - val_mae: 612.7161\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 688721.1250 - mae: 611.8371 - val_loss: 684774.1875 - val_mae: 608.6431\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 684144.2500 - mae: 609.1443 - val_loss: 680964.5000 - val_mae: 605.7369\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 680878.5000 - mae: 606.5904 - val_loss: 677862.0625 - val_mae: 607.4138\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 678116.1875 - mae: 605.4341 - val_loss: 675143.1250 - val_mae: 605.9002\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 674978.3125 - mae: 603.4995 - val_loss: 672197.3750 - val_mae: 604.7491\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 672445.2500 - mae: 601.9626 - val_loss: 670253.9375 - val_mae: 604.2755\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 670495.0625 - mae: 601.0284 - val_loss: 667631.8125 - val_mae: 601.7682\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 668166.1250 - mae: 599.9972 - val_loss: 664909.9375 - val_mae: 598.6796\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 665359.6250 - mae: 599.0269 - val_loss: 665142.0000 - val_mae: 594.0437\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 664202.5625 - mae: 596.7580 - val_loss: 660934.1250 - val_mae: 595.6268\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 661999.0625 - mae: 596.4814 - val_loss: 658950.2500 - val_mae: 594.6359\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 659865.4375 - mae: 594.7640 - val_loss: 657333.9375 - val_mae: 594.7650\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 657635.3750 - mae: 594.0255 - val_loss: 655070.5625 - val_mae: 592.9717\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 655805.6875 - mae: 593.2232 - val_loss: 653515.1250 - val_mae: 591.0959\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 654476.0625 - mae: 591.8380 - val_loss: 651234.8750 - val_mae: 590.2773\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 652075.8750 - mae: 591.2635 - val_loss: 649588.8750 - val_mae: 588.3649\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 650586.7500 - mae: 590.1486 - val_loss: 647598.6250 - val_mae: 588.1071\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 648444.0625 - mae: 589.0756 - val_loss: 645975.5000 - val_mae: 587.1573\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 647164.0000 - mae: 588.5676 - val_loss: 644098.4375 - val_mae: 586.4242\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 645018.3750 - mae: 587.4570 - val_loss: 642217.8750 - val_mae: 586.1838\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 642295.3125 - mae: 586.6443 - val_loss: 637805.1875 - val_mae: 583.3203\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 637724.5000 - mae: 583.5122 - val_loss: 633477.2500 - val_mae: 582.9002\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 633039.6875 - mae: 581.2236 - val_loss: 630352.8750 - val_mae: 582.1661\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 630003.6250 - mae: 580.1691 - val_loss: 626504.6250 - val_mae: 577.5059\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 626882.8750 - mae: 577.5269 - val_loss: 623608.4375 - val_mae: 575.4418\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 623934.3750 - mae: 576.7295 - val_loss: 622498.8750 - val_mae: 572.0854\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621793.2500 - mae: 574.7328 - val_loss: 618732.1250 - val_mae: 573.7228\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619592.9375 - mae: 573.6975 - val_loss: 616573.4375 - val_mae: 572.1315\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617516.4375 - mae: 572.4924 - val_loss: 615323.9375 - val_mae: 573.4131\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615835.2500 - mae: 572.0427 - val_loss: 613171.6250 - val_mae: 568.7357\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613525.0625 - mae: 570.5142 - val_loss: 611740.5625 - val_mae: 568.5170\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612194.8750 - mae: 569.5311 - val_loss: 609599.0625 - val_mae: 566.8948\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609884.5625 - mae: 568.2760 - val_loss: 606804.8750 - val_mae: 566.2741\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607401.8125 - mae: 566.7382 - val_loss: 605344.5625 - val_mae: 568.8574\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605477.4375 - mae: 566.4160 - val_loss: 602532.5625 - val_mae: 565.1505\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603268.5625 - mae: 565.3802 - val_loss: 601407.2500 - val_mae: 561.1838\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601825.3125 - mae: 563.4106 - val_loss: 598691.1250 - val_mae: 561.5890\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599461.5625 - mae: 562.4811 - val_loss: 596784.8125 - val_mae: 560.7034\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597644.3750 - mae: 561.5028 - val_loss: 595458.4375 - val_mae: 558.0494\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595739.6875 - mae: 559.9951 - val_loss: 593209.8125 - val_mae: 559.6019\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593618.5625 - mae: 559.2435 - val_loss: 592957.8125 - val_mae: 555.3640\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592318.8750 - mae: 558.0580 - val_loss: 589731.6250 - val_mae: 557.2366\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 590684.1250 - mae: 556.8283 - val_loss: 588352.8750 - val_mae: 558.2032\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589376.1250 - mae: 556.4480 - val_loss: 586918.6875 - val_mae: 555.9946\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 587951.3750 - mae: 555.6859 - val_loss: 586529.0000 - val_mae: 555.6138\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586889.9375 - mae: 555.2708 - val_loss: 584999.8750 - val_mae: 553.1237\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 586099.3750 - mae: 554.8082 - val_loss: 583773.3750 - val_mae: 553.2385\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 584935.0625 - mae: 554.4874 - val_loss: 583034.2500 - val_mae: 552.0503\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 583910.7500 - mae: 553.4920 - val_loss: 581653.3750 - val_mae: 552.3949\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582794.5625 - mae: 552.9750 - val_loss: 580469.2500 - val_mae: 553.2059\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 581413.2500 - mae: 552.2598 - val_loss: 579295.7500 - val_mae: 550.1652\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 580528.9375 - mae: 551.2615 - val_loss: 578075.8125 - val_mae: 550.6800\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578838.4375 - mae: 550.1368 - val_loss: 579166.0625 - val_mae: 555.0792\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578377.6250 - mae: 550.6840 - val_loss: 576150.6875 - val_mae: 551.1896\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 577420.3125 - mae: 549.5994 - val_loss: 575807.4375 - val_mae: 551.5991\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576917.5000 - mae: 549.6027 - val_loss: 574416.1250 - val_mae: 547.7083\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575867.3750 - mae: 548.8642 - val_loss: 574605.8750 - val_mae: 550.7656\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 575265.8750 - mae: 548.4847 - val_loss: 573578.6250 - val_mae: 546.7640\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574840.2500 - mae: 548.1375 - val_loss: 572743.1875 - val_mae: 546.3849\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574164.0625 - mae: 548.0563 - val_loss: 572101.1250 - val_mae: 546.3779\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573511.3125 - mae: 547.3546 - val_loss: 571624.3750 - val_mae: 546.8867\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573540.6250 - mae: 547.6115 - val_loss: 571130.3750 - val_mae: 545.2391\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573148.3125 - mae: 547.0469 - val_loss: 570643.7500 - val_mae: 544.8804\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571915.0000 - mae: 546.6006 - val_loss: 571809.6875 - val_mae: 542.8481\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571929.1250 - mae: 546.1047 - val_loss: 569891.8750 - val_mae: 543.9716\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570986.6875 - mae: 545.7600 - val_loss: 569836.3750 - val_mae: 545.8541\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570734.7500 - mae: 546.0641 - val_loss: 569209.8125 - val_mae: 543.5875\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570536.3125 - mae: 545.4219 - val_loss: 569012.6875 - val_mae: 542.9472\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569915.8125 - mae: 545.2133 - val_loss: 568468.8125 - val_mae: 546.7838\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569782.0625 - mae: 544.9985 - val_loss: 568303.6875 - val_mae: 546.7278\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569454.5000 - mae: 545.5962 - val_loss: 567475.3750 - val_mae: 542.4998\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569116.1250 - mae: 544.3435 - val_loss: 567017.0000 - val_mae: 543.9495\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568845.6875 - mae: 544.7204 - val_loss: 566993.8125 - val_mae: 542.4527\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568228.5625 - mae: 543.6696 - val_loss: 566654.1875 - val_mae: 544.9482\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568210.3125 - mae: 544.4442 - val_loss: 566108.8750 - val_mae: 543.4630\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567680.0625 - mae: 543.7253 - val_loss: 566418.7500 - val_mae: 545.4351\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567236.5000 - mae: 543.7399 - val_loss: 567723.2500 - val_mae: 539.9399\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567433.0625 - mae: 543.4937 - val_loss: 565550.3750 - val_mae: 541.2999\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567126.5625 - mae: 543.3921 - val_loss: 564998.1250 - val_mae: 541.7595\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566744.3750 - mae: 543.0016 - val_loss: 564623.8125 - val_mae: 542.8857\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566163.7500 - mae: 542.9498 - val_loss: 564873.6875 - val_mae: 544.6747\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565911.8750 - mae: 542.9944 - val_loss: 564243.7500 - val_mae: 543.7580\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565742.5000 - mae: 543.3196 - val_loss: 564254.6875 - val_mae: 540.2889\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565646.5000 - mae: 542.6073 - val_loss: 563632.0625 - val_mae: 541.2401\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565315.8125 - mae: 542.6559 - val_loss: 563334.0625 - val_mae: 540.5289\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564600.3125 - mae: 542.7767 - val_loss: 564024.9375 - val_mae: 538.9553\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564831.0625 - mae: 542.1574 - val_loss: 563286.3750 - val_mae: 539.9694\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564708.0000 - mae: 542.2247 - val_loss: 562736.5000 - val_mae: 542.7161\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564214.6875 - mae: 542.5825 - val_loss: 562884.9375 - val_mae: 539.7673\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563920.4375 - mae: 542.1886 - val_loss: 562483.7500 - val_mae: 539.4795\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563632.4375 - mae: 541.3821 - val_loss: 561898.3750 - val_mae: 542.6761\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563453.9375 - mae: 542.4746 - val_loss: 561384.5625 - val_mae: 540.3640\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562968.5625 - mae: 541.6368 - val_loss: 561138.6875 - val_mae: 541.0353\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562853.9375 - mae: 541.8184 - val_loss: 561038.1875 - val_mae: 541.0931\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562361.2500 - mae: 541.3820 - val_loss: 560512.5000 - val_mae: 540.2241\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562184.8125 - mae: 541.2744 - val_loss: 560102.8125 - val_mae: 540.2251\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 36410300.0000 - mae: 5873.6577 - val_loss: 31496492.0000 - val_mae: 5459.1221\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 23655692.0000 - mae: 4680.0459 - val_loss: 15840387.0000 - val_mae: 3795.2642\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 9989411.0000 - mae: 2872.7161 - val_loss: 5425994.5000 - val_mae: 1999.3702\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 3197421.7500 - mae: 1421.4725 - val_loss: 1759827.6250 - val_mae: 1003.7946\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1277973.5000 - mae: 831.6381 - val_loss: 993158.3750 - val_mae: 725.3148\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 893729.8125 - mae: 691.4462 - val_loss: 823373.7500 - val_mae: 669.4648\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 790400.3125 - mae: 659.5970 - val_loss: 762276.2500 - val_mae: 649.3092\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 747180.8750 - mae: 643.5809 - val_loss: 731993.5625 - val_mae: 638.4433\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 724873.0000 - mae: 633.7446 - val_loss: 715453.9375 - val_mae: 627.6782\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 711796.0625 - mae: 626.0032 - val_loss: 704591.1875 - val_mae: 623.5884\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 702932.6875 - mae: 620.8593 - val_loss: 696939.3750 - val_mae: 620.5217\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 695474.7500 - mae: 617.7336 - val_loss: 690455.0000 - val_mae: 613.7626\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 689281.2500 - mae: 613.3750 - val_loss: 684815.9375 - val_mae: 612.3312\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 684048.6250 - mae: 610.8507 - val_loss: 680246.0000 - val_mae: 606.2527\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 678686.6250 - mae: 607.1677 - val_loss: 674041.1875 - val_mae: 604.5226\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 672759.0000 - mae: 603.8958 - val_loss: 669156.7500 - val_mae: 603.5798\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 668169.3125 - mae: 601.0970 - val_loss: 664138.9375 - val_mae: 601.0424\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 663753.1250 - mae: 599.0600 - val_loss: 659797.3750 - val_mae: 595.7627\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 659837.7500 - mae: 595.7336 - val_loss: 658366.6875 - val_mae: 600.5143\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 656717.8750 - mae: 595.6826 - val_loss: 654360.1875 - val_mae: 590.9062\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 654220.2500 - mae: 592.9578 - val_loss: 649743.3750 - val_mae: 590.9659\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 650738.0000 - mae: 591.6168 - val_loss: 647553.1250 - val_mae: 591.1603\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 648093.5625 - mae: 590.3530 - val_loss: 645060.9375 - val_mae: 587.9116\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 645487.7500 - mae: 588.5574 - val_loss: 642631.8125 - val_mae: 588.6390\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 643807.0625 - mae: 587.9772 - val_loss: 640289.3750 - val_mae: 586.5626\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 641915.3125 - mae: 587.1707 - val_loss: 638411.6875 - val_mae: 584.2911\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 639523.9375 - mae: 585.3069 - val_loss: 636698.0000 - val_mae: 585.3093\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 638228.6250 - mae: 585.1221 - val_loss: 635082.6250 - val_mae: 581.7474\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 636057.9375 - mae: 583.7683 - val_loss: 632739.1875 - val_mae: 582.1573\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 634311.1875 - mae: 582.4074 - val_loss: 633152.6250 - val_mae: 586.3887\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 633027.6875 - mae: 582.3094 - val_loss: 629823.1250 - val_mae: 580.9901\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 631508.0000 - mae: 581.2297 - val_loss: 629100.5000 - val_mae: 581.8755\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 629939.6250 - mae: 580.1942 - val_loss: 627469.6875 - val_mae: 580.6876\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 627896.6875 - mae: 578.8808 - val_loss: 624815.3750 - val_mae: 576.7219\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625992.8750 - mae: 577.4949 - val_loss: 623181.0000 - val_mae: 576.3796\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625121.6875 - mae: 577.1860 - val_loss: 622591.8750 - val_mae: 575.9809\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 623848.8750 - mae: 576.3865 - val_loss: 622085.8125 - val_mae: 577.4659\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 623693.1250 - mae: 576.0172 - val_loss: 621285.8125 - val_mae: 577.8663\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 622408.6875 - mae: 575.7657 - val_loss: 620201.8125 - val_mae: 576.3083\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621877.6250 - mae: 575.5659 - val_loss: 619195.8125 - val_mae: 573.3782\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 620937.8750 - mae: 575.0571 - val_loss: 618574.8750 - val_mae: 573.4871\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 620793.8750 - mae: 574.7164 - val_loss: 617996.6250 - val_mae: 573.3255\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619755.3750 - mae: 574.2764 - val_loss: 617761.4375 - val_mae: 574.0081\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619452.8750 - mae: 574.0918 - val_loss: 617360.1250 - val_mae: 570.8002\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618720.0000 - mae: 573.7095 - val_loss: 616276.3125 - val_mae: 571.9670\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 618243.6875 - mae: 573.0659 - val_loss: 616293.8125 - val_mae: 573.9170\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617485.9375 - mae: 573.1600 - val_loss: 615427.4375 - val_mae: 570.3417\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617083.7500 - mae: 572.3658 - val_loss: 614308.4375 - val_mae: 571.7021\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616091.5625 - mae: 572.0486 - val_loss: 614142.2500 - val_mae: 572.7257\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615742.1250 - mae: 571.6544 - val_loss: 614873.6875 - val_mae: 575.3113\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 615400.0000 - mae: 572.1918 - val_loss: 613454.5000 - val_mae: 572.2160\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614507.1250 - mae: 571.1973 - val_loss: 612752.6875 - val_mae: 572.0289\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614030.3125 - mae: 570.8162 - val_loss: 613685.6250 - val_mae: 575.0118\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613512.6250 - mae: 570.9304 - val_loss: 610579.5000 - val_mae: 569.7750\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612085.2500 - mae: 569.4629 - val_loss: 609887.7500 - val_mae: 570.1633\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611447.7500 - mae: 569.3533 - val_loss: 608628.5000 - val_mae: 567.8835\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 610090.1875 - mae: 568.8764 - val_loss: 607882.0625 - val_mae: 565.2166\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608995.5000 - mae: 567.7051 - val_loss: 606655.3750 - val_mae: 567.2886\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608422.2500 - mae: 567.4530 - val_loss: 606652.5625 - val_mae: 569.2988\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607833.5000 - mae: 567.3906 - val_loss: 606130.5000 - val_mae: 564.0482\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606970.8125 - mae: 566.5341 - val_loss: 604241.7500 - val_mae: 565.2111\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 606213.1250 - mae: 566.7521 - val_loss: 603406.8750 - val_mae: 564.8159\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605168.8750 - mae: 565.3101 - val_loss: 602917.8125 - val_mae: 566.8528\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604234.9375 - mae: 565.3782 - val_loss: 601730.4375 - val_mae: 564.0467\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603201.7500 - mae: 565.0364 - val_loss: 601151.5625 - val_mae: 564.6429\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603096.2500 - mae: 563.8689 - val_loss: 600638.0000 - val_mae: 564.0153\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602503.5000 - mae: 564.1478 - val_loss: 600429.8750 - val_mae: 560.6824\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601554.1250 - mae: 563.4698 - val_loss: 600014.9375 - val_mae: 560.4813\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601336.0625 - mae: 562.9808 - val_loss: 599219.4375 - val_mae: 561.6698\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601140.3750 - mae: 562.9189 - val_loss: 598912.3750 - val_mae: 560.3085\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600498.7500 - mae: 562.4030 - val_loss: 599799.6250 - val_mae: 565.3387\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600395.1875 - mae: 562.9728 - val_loss: 598768.3125 - val_mae: 558.8303\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 600051.3750 - mae: 562.3320 - val_loss: 597849.5000 - val_mae: 559.6532\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599919.3750 - mae: 561.9957 - val_loss: 597760.9375 - val_mae: 562.9392\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599542.6875 - mae: 562.0582 - val_loss: 596965.3750 - val_mae: 559.9650\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598806.4375 - mae: 561.6141 - val_loss: 597196.3125 - val_mae: 559.2276\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598740.1875 - mae: 561.1431 - val_loss: 596216.8125 - val_mae: 560.0580\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598300.5625 - mae: 561.3268 - val_loss: 596779.5000 - val_mae: 558.1542\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 598029.0625 - mae: 560.6528 - val_loss: 595992.3125 - val_mae: 558.8954\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597835.8125 - mae: 560.6663 - val_loss: 595986.6250 - val_mae: 561.2393\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597802.1875 - mae: 561.3869 - val_loss: 596649.3750 - val_mae: 558.3730\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597523.3750 - mae: 560.8279 - val_loss: 595605.0625 - val_mae: 557.5121\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597432.3125 - mae: 560.1313 - val_loss: 595037.3125 - val_mae: 559.3137\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597126.5625 - mae: 560.3068 - val_loss: 596157.0000 - val_mae: 563.5891\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596776.4375 - mae: 560.2786 - val_loss: 595508.0000 - val_mae: 563.1105\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596705.8125 - mae: 560.3376 - val_loss: 594711.4375 - val_mae: 560.6249\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596545.5625 - mae: 560.4406 - val_loss: 594333.8125 - val_mae: 559.0454\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596190.5000 - mae: 559.6814 - val_loss: 594140.1250 - val_mae: 561.0291\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595945.5625 - mae: 560.0461 - val_loss: 593943.8125 - val_mae: 557.2788\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595605.8750 - mae: 559.5892 - val_loss: 594136.4375 - val_mae: 556.3514\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595292.3750 - mae: 559.7327 - val_loss: 594021.1250 - val_mae: 556.3339\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 595014.0000 - mae: 559.2688 - val_loss: 593005.6875 - val_mae: 557.6499\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594860.3125 - mae: 559.1856 - val_loss: 592839.2500 - val_mae: 557.9564\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594974.1250 - mae: 559.6056 - val_loss: 592737.5625 - val_mae: 559.4767\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594761.0625 - mae: 558.7046 - val_loss: 592415.3750 - val_mae: 558.6731\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594462.1250 - mae: 559.2429 - val_loss: 592521.2500 - val_mae: 560.2704\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 594378.9375 - mae: 559.4854 - val_loss: 592177.2500 - val_mae: 557.8970\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594200.5625 - mae: 558.9708 - val_loss: 592021.3750 - val_mae: 558.5684\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 593971.6250 - mae: 558.8233 - val_loss: 591913.0000 - val_mae: 558.2379\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593789.0000 - mae: 559.0823 - val_loss: 593311.0625 - val_mae: 556.1027\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594000.0625 - mae: 558.8643 - val_loss: 592804.3750 - val_mae: 561.2467\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593791.4375 - mae: 558.7750 - val_loss: 591802.4375 - val_mae: 559.8860\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593332.5000 - mae: 558.8441 - val_loss: 592164.8125 - val_mae: 560.5324\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593653.8750 - mae: 559.1454 - val_loss: 591480.8750 - val_mae: 556.9840\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593261.4375 - mae: 558.3844 - val_loss: 592440.6875 - val_mae: 562.2867\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 593370.6875 - mae: 559.2006 - val_loss: 591127.8125 - val_mae: 557.0117\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 593067.2500 - mae: 558.2239 - val_loss: 591903.9375 - val_mae: 560.6195\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593232.1250 - mae: 558.6625 - val_loss: 590782.3125 - val_mae: 557.3577\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592541.9375 - mae: 558.5897 - val_loss: 593448.4375 - val_mae: 554.7383\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593201.6875 - mae: 557.8328 - val_loss: 591056.8750 - val_mae: 559.3097\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 593017.4375 - mae: 559.0020 - val_loss: 591926.8750 - val_mae: 554.9526\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592890.8125 - mae: 558.0638 - val_loss: 590678.9375 - val_mae: 557.2841\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592708.3125 - mae: 558.8664 - val_loss: 590457.1250 - val_mae: 557.4180\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 592476.5625 - mae: 558.1808 - val_loss: 590544.1875 - val_mae: 557.5382\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592590.3750 - mae: 558.4202 - val_loss: 590892.5625 - val_mae: 556.1815\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592614.6250 - mae: 558.3026 - val_loss: 590507.3750 - val_mae: 557.7921\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592430.4375 - mae: 558.1136 - val_loss: 590238.0625 - val_mae: 557.6502\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592347.4375 - mae: 558.7741 - val_loss: 590982.3750 - val_mae: 555.5237\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592312.4375 - mae: 558.3239 - val_loss: 590953.3125 - val_mae: 555.1023\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38319312.0000 - mae: 6033.4609 - val_loss: 37670592.0000 - val_mae: 5982.0063\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 35860936.0000 - mae: 5837.6113 - val_loss: 33543722.0000 - val_mae: 5649.0010\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 30599624.0000 - mae: 5393.4873 - val_loss: 27413966.0000 - val_mae: 5106.5566\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 24095342.0000 - mae: 4776.0518 - val_loss: 20743382.0000 - val_mae: 4425.0967\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 17606404.0000 - mae: 4051.8867 - val_loss: 14586649.0000 - val_mae: 3667.0796\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 11995882.0000 - mae: 3285.1008 - val_loss: 9597157.0000 - val_mae: 2904.8103\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 7702631.5000 - mae: 2550.0835 - val_loss: 6004008.0000 - val_mae: 2204.1301\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 4762453.5000 - mae: 1900.3843 - val_loss: 3689294.0000 - val_mae: 1618.8799\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2955621.5000 - mae: 1405.3596 - val_loss: 2343957.5000 - val_mae: 1223.9969\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1953468.6250 - mae: 1103.1257 - val_loss: 1634014.1250 - val_mae: 998.9755\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1436738.7500 - mae: 930.1072 - val_loss: 1274554.1250 - val_mae: 870.5593\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1175612.6250 - mae: 831.8747 - val_loss: 1092255.3750 - val_mae: 797.7432\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1039376.1875 - mae: 775.2855 - val_loss: 992350.7500 - val_mae: 755.8282\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 960002.0625 - mae: 742.0005 - val_loss: 928791.9375 - val_mae: 728.5538\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 906111.9375 - mae: 718.9645 - val_loss: 882658.0625 - val_mae: 707.9280\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 864166.8125 - mae: 699.2805 - val_loss: 844994.6875 - val_mae: 692.6531\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 830528.0000 - mae: 685.8053 - val_loss: 814251.9375 - val_mae: 677.7068\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 802394.3750 - mae: 672.2994 - val_loss: 789010.0625 - val_mae: 665.6655\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 779630.8750 - mae: 661.1443 - val_loss: 768517.8750 - val_mae: 656.6525\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 761208.1875 - mae: 653.1010 - val_loss: 751296.0000 - val_mae: 647.4261\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 745297.0000 - mae: 644.6068 - val_loss: 737129.0000 - val_mae: 641.0851\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 732229.0000 - mae: 638.2458 - val_loss: 725073.0625 - val_mae: 635.0108\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 721433.5625 - mae: 632.8120 - val_loss: 715265.7500 - val_mae: 629.8842\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 712601.6250 - mae: 628.1267 - val_loss: 707329.5625 - val_mae: 625.6125\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 705313.6250 - mae: 623.9623 - val_loss: 700884.1875 - val_mae: 622.7723\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 699612.0000 - mae: 621.0004 - val_loss: 695556.2500 - val_mae: 619.6418\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 694498.9375 - mae: 618.6559 - val_loss: 691387.9375 - val_mae: 615.5571\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 690761.8125 - mae: 615.9894 - val_loss: 687420.3750 - val_mae: 614.7408\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 687174.8125 - mae: 614.4874 - val_loss: 684056.1250 - val_mae: 613.1918\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 684006.6250 - mae: 612.6789 - val_loss: 681136.1875 - val_mae: 610.9836\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 680883.2500 - mae: 610.7205 - val_loss: 678127.5000 - val_mae: 610.3065\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 678075.6875 - mae: 609.6063 - val_loss: 675440.7500 - val_mae: 608.3906\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 675489.7500 - mae: 608.5510 - val_loss: 672757.1875 - val_mae: 605.9744\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 672794.3750 - mae: 606.6020 - val_loss: 669924.1875 - val_mae: 605.1806\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 669969.8750 - mae: 605.2242 - val_loss: 667239.7500 - val_mae: 605.0518\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 667459.4375 - mae: 604.2362 - val_loss: 664501.8750 - val_mae: 603.1717\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 664687.3125 - mae: 602.6691 - val_loss: 661882.8750 - val_mae: 600.6508\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 661833.1250 - mae: 601.2370 - val_loss: 659743.5000 - val_mae: 598.7943\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 659807.5000 - mae: 599.9641 - val_loss: 657234.9375 - val_mae: 597.2063\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 657209.0625 - mae: 597.9240 - val_loss: 655171.6875 - val_mae: 599.5074\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 655064.9375 - mae: 597.0813 - val_loss: 652635.4375 - val_mae: 597.2143\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 653075.2500 - mae: 595.8599 - val_loss: 650288.0000 - val_mae: 594.2918\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 650617.7500 - mae: 595.1130 - val_loss: 648205.8750 - val_mae: 592.6523\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 648706.0625 - mae: 593.1046 - val_loss: 646214.8125 - val_mae: 593.2104\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 646817.5000 - mae: 592.4310 - val_loss: 644341.2500 - val_mae: 592.7961\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 644794.3750 - mae: 591.9531 - val_loss: 642570.4375 - val_mae: 589.1816\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 643366.5000 - mae: 590.5085 - val_loss: 640865.8750 - val_mae: 590.1725\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 642038.3125 - mae: 589.8423 - val_loss: 639278.5000 - val_mae: 588.5837\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 639969.2500 - mae: 588.9437 - val_loss: 637881.6875 - val_mae: 587.2822\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 638813.1875 - mae: 587.8963 - val_loss: 636757.3125 - val_mae: 587.8904\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 637508.1875 - mae: 587.3184 - val_loss: 635258.5000 - val_mae: 586.3521\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 635873.0625 - mae: 586.0685 - val_loss: 633970.3750 - val_mae: 586.6840\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 634613.0625 - mae: 585.7228 - val_loss: 632715.0000 - val_mae: 585.9062\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 633183.9375 - mae: 585.1568 - val_loss: 631210.6250 - val_mae: 583.0052\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 631867.5625 - mae: 583.8431 - val_loss: 629688.7500 - val_mae: 582.5051\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 630354.6875 - mae: 583.0836 - val_loss: 628668.1875 - val_mae: 580.7495\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 629412.0625 - mae: 582.0647 - val_loss: 627162.5000 - val_mae: 582.2584\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 627629.6875 - mae: 582.0539 - val_loss: 626028.3125 - val_mae: 580.7365\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 627011.8125 - mae: 581.2319 - val_loss: 624911.5000 - val_mae: 581.1274\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 625748.8125 - mae: 580.7104 - val_loss: 624008.8125 - val_mae: 580.8060\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 624802.5000 - mae: 580.1155 - val_loss: 622815.5625 - val_mae: 578.2917\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 623639.9375 - mae: 579.4893 - val_loss: 621792.1875 - val_mae: 579.3336\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 622650.5625 - mae: 579.0917 - val_loss: 621055.8750 - val_mae: 578.0199\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 621807.4375 - mae: 578.8123 - val_loss: 620257.1250 - val_mae: 576.8184\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 621051.5625 - mae: 578.1213 - val_loss: 619307.3750 - val_mae: 576.4991\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 620318.4375 - mae: 577.7657 - val_loss: 618546.6875 - val_mae: 577.5847\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 619576.6250 - mae: 577.9437 - val_loss: 617779.0000 - val_mae: 576.2974\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 618907.4375 - mae: 576.8948 - val_loss: 617233.9375 - val_mae: 577.5648\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 618265.0625 - mae: 576.6446 - val_loss: 616714.1875 - val_mae: 577.5687\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 617577.8750 - mae: 576.5806 - val_loss: 616063.6875 - val_mae: 576.6750\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 617279.5000 - mae: 576.6209 - val_loss: 615861.6875 - val_mae: 573.7198\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 616590.5625 - mae: 575.9401 - val_loss: 614992.5000 - val_mae: 575.6934\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 616119.3750 - mae: 575.8110 - val_loss: 614419.6250 - val_mae: 574.4398\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 615377.7500 - mae: 574.9351 - val_loss: 614310.3125 - val_mae: 576.2430\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 615236.1250 - mae: 575.3732 - val_loss: 613868.0000 - val_mae: 576.4343\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 614607.6875 - mae: 575.2554 - val_loss: 612947.8125 - val_mae: 574.2393\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 614461.5625 - mae: 574.7395 - val_loss: 612482.2500 - val_mae: 574.5234\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 613597.5625 - mae: 575.0900 - val_loss: 612396.2500 - val_mae: 572.3322\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 613174.1250 - mae: 574.0958 - val_loss: 611909.3125 - val_mae: 572.5620\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 612757.0000 - mae: 573.5499 - val_loss: 611191.4375 - val_mae: 574.7462\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 612447.1875 - mae: 574.3876 - val_loss: 610611.8750 - val_mae: 573.3947\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 611764.0625 - mae: 573.5956 - val_loss: 610333.8125 - val_mae: 571.8082\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 611391.5625 - mae: 573.4188 - val_loss: 609724.7500 - val_mae: 573.1204\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 610534.0000 - mae: 573.3897 - val_loss: 608688.3125 - val_mae: 571.1933\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 609778.5625 - mae: 572.3421 - val_loss: 607359.3125 - val_mae: 569.8792\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 607890.8750 - mae: 570.9648 - val_loss: 605596.8750 - val_mae: 570.1912\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 606381.1250 - mae: 570.8623 - val_loss: 604524.6875 - val_mae: 568.3447\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 604948.2500 - mae: 569.1135 - val_loss: 603171.6875 - val_mae: 568.0594\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 604047.8125 - mae: 568.6657 - val_loss: 602186.5000 - val_mae: 568.4416\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 603069.6250 - mae: 568.5740 - val_loss: 601615.6875 - val_mae: 568.9571\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602272.6250 - mae: 568.4093 - val_loss: 600709.5625 - val_mae: 565.9965\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602059.6875 - mae: 567.8068 - val_loss: 599724.1875 - val_mae: 567.3136\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 600876.3750 - mae: 567.4766 - val_loss: 599235.0625 - val_mae: 565.3325\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 600244.7500 - mae: 566.5392 - val_loss: 598355.7500 - val_mae: 566.6519\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599464.8125 - mae: 566.7826 - val_loss: 597848.7500 - val_mae: 565.9319\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599355.7500 - mae: 566.3724 - val_loss: 597230.8750 - val_mae: 565.6140\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598580.6875 - mae: 566.1011 - val_loss: 597160.5000 - val_mae: 564.2627\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598016.8750 - mae: 565.9136 - val_loss: 596924.6250 - val_mae: 563.4208\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 597570.4375 - mae: 565.1582 - val_loss: 596259.0000 - val_mae: 567.7462\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596688.0000 - mae: 565.3666 - val_loss: 594889.6250 - val_mae: 564.6521\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596134.3750 - mae: 565.1747 - val_loss: 594290.2500 - val_mae: 563.7828\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595567.0000 - mae: 564.3743 - val_loss: 594058.9375 - val_mae: 565.2969\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595036.4375 - mae: 564.5665 - val_loss: 593288.9375 - val_mae: 563.6920\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 594569.3750 - mae: 564.3004 - val_loss: 592915.5625 - val_mae: 563.5137\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 594203.3125 - mae: 563.7733 - val_loss: 592613.9375 - val_mae: 564.1834\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 593529.9375 - mae: 563.9622 - val_loss: 592311.5000 - val_mae: 561.7647\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 593432.3125 - mae: 563.1616 - val_loss: 591743.2500 - val_mae: 563.6453\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592804.3750 - mae: 563.4651 - val_loss: 591687.0625 - val_mae: 560.9702\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592491.1250 - mae: 562.7443 - val_loss: 591250.6875 - val_mae: 563.3669\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592176.0000 - mae: 562.8376 - val_loss: 590761.5000 - val_mae: 562.8676\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592470.5000 - mae: 563.2379 - val_loss: 590481.1875 - val_mae: 561.2458\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 5ms/step - loss: 591585.5625 - mae: 562.9733 - val_loss: 590737.0625 - val_mae: 560.3909\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 591362.4375 - mae: 562.3283 - val_loss: 589856.1250 - val_mae: 562.6862\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591291.2500 - mae: 562.5840 - val_loss: 589628.5000 - val_mae: 561.8152\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591084.2500 - mae: 562.5144 - val_loss: 589548.6875 - val_mae: 563.2974\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 590713.4375 - mae: 562.4130 - val_loss: 589101.3125 - val_mae: 561.0995\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 590339.2500 - mae: 561.9651 - val_loss: 588921.3125 - val_mae: 562.1588\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 590082.6250 - mae: 561.9115 - val_loss: 588744.4375 - val_mae: 561.8548\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589876.9375 - mae: 561.5375 - val_loss: 588471.0000 - val_mae: 561.0840\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 589797.0625 - mae: 561.6876 - val_loss: 588208.5000 - val_mae: 561.1552\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589412.6250 - mae: 561.7250 - val_loss: 588261.1250 - val_mae: 559.3044\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 589316.8750 - mae: 561.1260 - val_loss: 587812.6875 - val_mae: 560.1771\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 589179.1875 - mae: 561.4760 - val_loss: 587721.5625 - val_mae: 561.4097\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588869.0000 - mae: 561.1180 - val_loss: 587932.9375 - val_mae: 562.9385\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 588575.3125 - mae: 560.9989 - val_loss: 587571.5000 - val_mae: 561.9073\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588496.4375 - mae: 561.5963 - val_loss: 587228.1250 - val_mae: 559.5842\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588509.9375 - mae: 561.1367 - val_loss: 587506.0000 - val_mae: 558.3891\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 588405.5000 - mae: 560.9247 - val_loss: 586860.6875 - val_mae: 559.0384\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587990.1875 - mae: 560.8214 - val_loss: 586665.1250 - val_mae: 558.7527\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587694.3125 - mae: 560.7010 - val_loss: 586185.7500 - val_mae: 559.4351\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587546.9375 - mae: 560.4681 - val_loss: 585924.2500 - val_mae: 559.5319\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587384.5625 - mae: 560.5541 - val_loss: 586407.5625 - val_mae: 557.5405\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 587139.4375 - mae: 559.7600 - val_loss: 585591.6875 - val_mae: 560.4933\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586645.6250 - mae: 560.4742 - val_loss: 585449.0625 - val_mae: 557.9356\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586561.5000 - mae: 559.5468 - val_loss: 584990.3125 - val_mae: 559.1502\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 586051.6250 - mae: 559.5978 - val_loss: 584717.1875 - val_mae: 559.1201\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 586193.3750 - mae: 559.2259 - val_loss: 584370.9375 - val_mae: 559.2898\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 585219.0000 - mae: 559.8989 - val_loss: 584405.2500 - val_mae: 556.9979\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 585714.5000 - mae: 558.8648 - val_loss: 584130.4375 - val_mae: 557.5234\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 585008.5000 - mae: 559.0478 - val_loss: 583966.2500 - val_mae: 556.5580\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 584732.5000 - mae: 558.1679 - val_loss: 583628.0625 - val_mae: 559.7583\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584483.8125 - mae: 559.0067 - val_loss: 583176.8125 - val_mae: 558.4301\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 584172.0625 - mae: 558.3153 - val_loss: 583365.1250 - val_mae: 555.7219\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583858.3750 - mae: 557.9188 - val_loss: 582471.2500 - val_mae: 557.0277\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583634.0000 - mae: 557.6252 - val_loss: 582063.1250 - val_mae: 557.7495\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 583303.0625 - mae: 557.6554 - val_loss: 581714.8750 - val_mae: 556.5085\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582874.9375 - mae: 557.3425 - val_loss: 581429.0625 - val_mae: 556.2979\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582779.1875 - mae: 557.3174 - val_loss: 581175.8125 - val_mae: 555.6263\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582258.5000 - mae: 556.5237 - val_loss: 580907.5625 - val_mae: 555.8728\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582074.0000 - mae: 556.7201 - val_loss: 580585.1875 - val_mae: 555.2090\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581444.5000 - mae: 555.9612 - val_loss: 580474.2500 - val_mae: 557.3510\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581175.5625 - mae: 556.0186 - val_loss: 579951.6875 - val_mae: 556.3069\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581002.0625 - mae: 555.6583 - val_loss: 579573.9375 - val_mae: 554.8102\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580824.8125 - mae: 555.6954 - val_loss: 579119.0000 - val_mae: 554.6182\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580439.0625 - mae: 555.0481 - val_loss: 578744.5000 - val_mae: 554.1458\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 580407.1250 - mae: 554.9086 - val_loss: 578630.3125 - val_mae: 554.9357\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 579759.3125 - mae: 554.6359 - val_loss: 578236.3750 - val_mae: 554.1083\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 579605.6875 - mae: 554.3845 - val_loss: 578143.8750 - val_mae: 555.2659\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 579137.1875 - mae: 554.6086 - val_loss: 577928.8750 - val_mae: 552.1349\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 578443.0625 - mae: 553.0708 - val_loss: 577717.4375 - val_mae: 555.4467\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 578451.3750 - mae: 553.8441 - val_loss: 576809.9375 - val_mae: 553.3134\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 577942.0625 - mae: 553.0425 - val_loss: 576518.0000 - val_mae: 553.6391\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 577394.0000 - mae: 553.2049 - val_loss: 576448.6875 - val_mae: 550.1426\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 577286.1250 - mae: 552.0705 - val_loss: 575765.6250 - val_mae: 552.4150\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 576810.7500 - mae: 552.7145 - val_loss: 575454.4375 - val_mae: 550.9781\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 576696.1875 - mae: 551.9186 - val_loss: 575241.5000 - val_mae: 551.4202\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 576468.1875 - mae: 552.3018 - val_loss: 575113.6875 - val_mae: 551.7804\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 576116.5000 - mae: 551.4706 - val_loss: 575049.5625 - val_mae: 552.6141\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 575845.1250 - mae: 551.9274 - val_loss: 574652.6875 - val_mae: 550.5555\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 575740.6250 - mae: 551.4517 - val_loss: 574722.7500 - val_mae: 549.5959\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 575553.5625 - mae: 551.2027 - val_loss: 574672.3750 - val_mae: 549.1913\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 575366.8125 - mae: 550.7554 - val_loss: 573866.5625 - val_mae: 551.3192\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 575085.4375 - mae: 551.2316 - val_loss: 573577.2500 - val_mae: 550.8122\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 574952.0625 - mae: 550.7772 - val_loss: 573350.7500 - val_mae: 549.4976\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 574617.5000 - mae: 550.1847 - val_loss: 573462.3750 - val_mae: 552.1038\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 574615.7500 - mae: 550.7980 - val_loss: 572905.5625 - val_mae: 549.4452\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 574512.5000 - mae: 550.6777 - val_loss: 572908.9375 - val_mae: 548.6130\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 574158.3125 - mae: 549.7238 - val_loss: 572718.3125 - val_mae: 551.0646\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 574053.2500 - mae: 550.4990 - val_loss: 572388.6875 - val_mae: 549.6889\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 573772.5625 - mae: 550.2331 - val_loss: 572268.3125 - val_mae: 549.5355\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 573560.8125 - mae: 550.2377 - val_loss: 572100.1250 - val_mae: 548.4786\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 573324.3125 - mae: 549.9109 - val_loss: 572024.3125 - val_mae: 549.9553\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 573229.3750 - mae: 549.3985 - val_loss: 572180.7500 - val_mae: 551.2484\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 572949.9375 - mae: 550.1878 - val_loss: 571626.3125 - val_mae: 548.7045\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 572822.7500 - mae: 549.2881 - val_loss: 571801.3750 - val_mae: 550.8627\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 572867.5625 - mae: 549.5535 - val_loss: 571638.8750 - val_mae: 550.8618\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 572721.9375 - mae: 549.6445 - val_loss: 571472.2500 - val_mae: 550.3643\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 572561.6250 - mae: 549.8079 - val_loss: 571209.6250 - val_mae: 548.7886\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 572368.3125 - mae: 549.2325 - val_loss: 571171.2500 - val_mae: 549.9889\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 572259.6250 - mae: 549.4304 - val_loss: 571273.3750 - val_mae: 550.3574\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 572323.5625 - mae: 549.9169 - val_loss: 571408.0625 - val_mae: 546.9001\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 572186.6250 - mae: 549.1468 - val_loss: 571093.5625 - val_mae: 549.6318\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 572099.6875 - mae: 549.6949 - val_loss: 570753.1875 - val_mae: 547.9186\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 572027.3125 - mae: 549.3527 - val_loss: 570803.6250 - val_mae: 547.3788\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 571849.8125 - mae: 548.9611 - val_loss: 570443.3750 - val_mae: 548.3574\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 571902.1250 - mae: 549.3420 - val_loss: 570349.8750 - val_mae: 548.2307\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 571757.0000 - mae: 549.0221 - val_loss: 570569.1875 - val_mae: 550.2050\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 571730.0000 - mae: 549.0247 - val_loss: 570208.5625 - val_mae: 549.1651\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 571752.1250 - mae: 549.5736 - val_loss: 570291.8750 - val_mae: 547.9150\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571372.0000 - mae: 548.6027 - val_loss: 570291.5625 - val_mae: 549.9158\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 571393.9375 - mae: 549.2434 - val_loss: 570050.4375 - val_mae: 548.8442\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38184240.0000 - mae: 6021.3574 - val_loss: 37153548.0000 - val_mae: 5939.2515\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 34413252.0000 - mae: 5718.6909 - val_loss: 31025844.0000 - val_mae: 5436.1890\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 26991416.0000 - mae: 5065.6597 - val_loss: 22777610.0000 - val_mae: 4654.1768\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 18728400.0000 - mae: 4196.5615 - val_loss: 14838069.0000 - val_mae: 3717.2339\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 11603878.0000 - mae: 3238.5032 - val_loss: 8686493.0000 - val_mae: 2761.9873\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 6527410.5000 - mae: 2329.9124 - val_loss: 4689771.5000 - val_mae: 1921.0283\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 3475640.5000 - mae: 1584.3784 - val_loss: 2506421.0000 - val_mae: 1291.6289\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1942551.5000 - mae: 1099.0039 - val_loss: 1511828.1250 - val_mae: 946.2383\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1281499.5000 - mae: 858.8157 - val_loss: 1106004.7500 - val_mae: 791.2841\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1012706.0000 - mae: 753.4748 - val_loss: 937544.8750 - val_mae: 722.9764\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 892581.0625 - mae: 703.3265 - val_loss: 852926.3750 - val_mae: 686.9626\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 828296.8750 - mae: 675.6300 - val_loss: 803861.3750 - val_mae: 664.9813\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 788478.3125 - mae: 657.3950 - val_loss: 771789.6250 - val_mae: 649.3303\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 761262.3125 - mae: 644.3794 - val_loss: 749069.0625 - val_mae: 638.6899\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 742131.4375 - mae: 635.1777 - val_loss: 732586.7500 - val_mae: 630.6929\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 727712.0625 - mae: 627.6821 - val_loss: 720542.1875 - val_mae: 624.3063\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 717269.3125 - mae: 622.6651 - val_loss: 711435.3750 - val_mae: 620.0120\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 709463.8125 - mae: 618.7234 - val_loss: 704449.2500 - val_mae: 616.6082\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 703349.5000 - mae: 615.8079 - val_loss: 698977.7500 - val_mae: 613.9853\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 698355.3125 - mae: 613.5671 - val_loss: 694542.1250 - val_mae: 612.1991\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 694234.3125 - mae: 611.6069 - val_loss: 690893.3125 - val_mae: 610.2559\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 690622.5625 - mae: 609.6846 - val_loss: 687340.5625 - val_mae: 609.1807\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 687541.7500 - mae: 608.8600 - val_loss: 684575.9375 - val_mae: 608.7051\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 684948.0625 - mae: 608.2219 - val_loss: 681872.1250 - val_mae: 605.7866\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 682210.5625 - mae: 606.2574 - val_loss: 679426.8750 - val_mae: 605.5617\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 679535.5000 - mae: 605.4234 - val_loss: 676979.5625 - val_mae: 604.2838\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 677455.8750 - mae: 604.6880 - val_loss: 674581.8750 - val_mae: 603.2123\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 675049.6250 - mae: 603.6049 - val_loss: 672008.6875 - val_mae: 601.8334\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 672621.1250 - mae: 602.2623 - val_loss: 669724.1875 - val_mae: 600.8098\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 670139.3125 - mae: 600.7162 - val_loss: 668207.0000 - val_mae: 602.9365\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 668376.1875 - mae: 601.1482 - val_loss: 665309.3125 - val_mae: 598.8277\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 665992.5000 - mae: 599.2010 - val_loss: 664467.7500 - val_mae: 596.4357\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 664225.8125 - mae: 597.8143 - val_loss: 662089.5625 - val_mae: 597.9036\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 662408.1250 - mae: 597.3272 - val_loss: 660391.5625 - val_mae: 598.5248\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 660930.8750 - mae: 597.3551 - val_loss: 658042.0625 - val_mae: 595.0349\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 658928.6250 - mae: 595.5181 - val_loss: 656054.0000 - val_mae: 594.3160\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 656738.1875 - mae: 594.6057 - val_loss: 654339.9375 - val_mae: 595.4445\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 654569.9375 - mae: 593.7252 - val_loss: 652559.3750 - val_mae: 592.5540\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 653001.6250 - mae: 592.5448 - val_loss: 650150.9375 - val_mae: 590.7163\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 650955.2500 - mae: 591.3441 - val_loss: 648185.5000 - val_mae: 591.0373\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 648740.3125 - mae: 590.8704 - val_loss: 646215.9375 - val_mae: 588.6017\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 646616.0000 - mae: 588.8112 - val_loss: 644244.3750 - val_mae: 589.8753\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 644853.0625 - mae: 588.4523 - val_loss: 642003.5000 - val_mae: 587.3614\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 643001.0000 - mae: 587.0266 - val_loss: 640395.7500 - val_mae: 585.4492\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 641301.2500 - mae: 586.1666 - val_loss: 638620.5625 - val_mae: 584.3384\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 639727.5000 - mae: 585.5889 - val_loss: 636961.6875 - val_mae: 583.4863\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 637714.0625 - mae: 583.7609 - val_loss: 636055.6875 - val_mae: 585.0878\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 636580.8125 - mae: 583.7585 - val_loss: 634121.1875 - val_mae: 581.5467\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 635356.3125 - mae: 582.5680 - val_loss: 632441.8750 - val_mae: 582.2419\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 633451.2500 - mae: 582.0793 - val_loss: 631235.2500 - val_mae: 580.2133\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 632120.5000 - mae: 580.8725 - val_loss: 629861.5000 - val_mae: 579.4863\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 630734.6875 - mae: 579.9479 - val_loss: 628781.7500 - val_mae: 581.2232\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 629390.9375 - mae: 579.6038 - val_loss: 627103.5000 - val_mae: 579.1492\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 627969.7500 - mae: 579.9069 - val_loss: 626439.5625 - val_mae: 576.3904\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 626835.1875 - mae: 577.9747 - val_loss: 624871.1250 - val_mae: 577.6741\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 625806.6250 - mae: 577.9188 - val_loss: 623747.2500 - val_mae: 575.6733\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 624505.7500 - mae: 576.9941 - val_loss: 622396.5000 - val_mae: 576.1914\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 623474.3125 - mae: 576.5204 - val_loss: 621338.3125 - val_mae: 574.7549\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 623286.7500 - mae: 576.1536 - val_loss: 620223.0625 - val_mae: 575.1261\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 621646.5625 - mae: 574.8055 - val_loss: 619353.1250 - val_mae: 574.8105\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 620675.6875 - mae: 574.6392 - val_loss: 618393.7500 - val_mae: 575.1579\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 619692.9375 - mae: 574.8827 - val_loss: 617465.9375 - val_mae: 572.1064\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 619035.6250 - mae: 573.6208 - val_loss: 616346.6250 - val_mae: 572.5540\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 617628.5625 - mae: 573.7786 - val_loss: 615568.1875 - val_mae: 571.6722\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 616898.1250 - mae: 573.0345 - val_loss: 615266.7500 - val_mae: 569.9652\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 615950.8125 - mae: 572.2341 - val_loss: 613964.6250 - val_mae: 571.0302\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 615239.8750 - mae: 571.9601 - val_loss: 613362.8125 - val_mae: 570.8054\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 614892.5000 - mae: 571.6672 - val_loss: 612496.5000 - val_mae: 571.1558\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 613771.5625 - mae: 571.1639 - val_loss: 611897.5625 - val_mae: 571.3649\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 613090.8125 - mae: 570.7712 - val_loss: 611332.2500 - val_mae: 570.0989\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 612849.6250 - mae: 570.7819 - val_loss: 610565.1875 - val_mae: 570.5353\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 612013.0000 - mae: 570.0056 - val_loss: 610396.3750 - val_mae: 571.6445\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 611621.8750 - mae: 570.5428 - val_loss: 609540.1250 - val_mae: 566.9971\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 610691.1875 - mae: 569.4534 - val_loss: 608473.3125 - val_mae: 568.6017\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 610033.5000 - mae: 569.3939 - val_loss: 608093.0625 - val_mae: 567.2914\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 609555.0000 - mae: 569.0319 - val_loss: 607958.0000 - val_mae: 567.4994\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 609144.3750 - mae: 568.3438 - val_loss: 607148.6250 - val_mae: 567.7883\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 608697.6875 - mae: 569.0432 - val_loss: 608205.0000 - val_mae: 565.1616\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 608510.2500 - mae: 568.0591 - val_loss: 606642.5000 - val_mae: 568.8216\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 607815.1250 - mae: 568.3841 - val_loss: 606325.5625 - val_mae: 568.8530\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 607501.5625 - mae: 567.8897 - val_loss: 605883.0000 - val_mae: 568.6522\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 606966.3125 - mae: 567.8748 - val_loss: 606075.0625 - val_mae: 565.0583\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 607095.9375 - mae: 567.7930 - val_loss: 605477.2500 - val_mae: 565.6360\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 606569.2500 - mae: 567.4191 - val_loss: 604860.3125 - val_mae: 567.6987\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 606591.5000 - mae: 567.0136 - val_loss: 604868.2500 - val_mae: 568.8027\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 606150.5000 - mae: 567.6047 - val_loss: 604237.8750 - val_mae: 565.7276\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 605699.5625 - mae: 566.7578 - val_loss: 603556.2500 - val_mae: 567.5048\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 604523.0000 - mae: 566.5060 - val_loss: 603354.7500 - val_mae: 566.2234\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 604322.1250 - mae: 565.7688 - val_loss: 602336.1250 - val_mae: 565.3912\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 603995.8750 - mae: 565.9128 - val_loss: 601760.2500 - val_mae: 564.7933\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 603531.7500 - mae: 565.6224 - val_loss: 601681.8750 - val_mae: 563.3104\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 603054.8750 - mae: 565.3050 - val_loss: 600735.0625 - val_mae: 564.8833\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602561.8125 - mae: 564.5330 - val_loss: 600613.5625 - val_mae: 563.5327\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602093.7500 - mae: 564.5693 - val_loss: 599805.3125 - val_mae: 563.6592\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 601608.8125 - mae: 564.5276 - val_loss: 599629.3125 - val_mae: 564.2723\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 601176.5625 - mae: 563.7864 - val_loss: 599319.7500 - val_mae: 564.3974\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 600769.6875 - mae: 563.7781 - val_loss: 599056.0000 - val_mae: 564.5897\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 600217.1250 - mae: 563.6935 - val_loss: 598529.5000 - val_mae: 561.6307\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 599776.8125 - mae: 562.9537 - val_loss: 598256.1250 - val_mae: 562.3713\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599528.9375 - mae: 562.8317 - val_loss: 597568.1250 - val_mae: 562.1270\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599138.9375 - mae: 562.8530 - val_loss: 597495.1875 - val_mae: 562.0376\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598775.1875 - mae: 562.4882 - val_loss: 597301.1250 - val_mae: 559.6799\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598541.5000 - mae: 561.9387 - val_loss: 596476.6875 - val_mae: 562.1257\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598162.6875 - mae: 561.9540 - val_loss: 596082.1875 - val_mae: 560.1652\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 597243.0625 - mae: 560.7731 - val_loss: 597386.6875 - val_mae: 565.1767\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 597526.1250 - mae: 561.8690 - val_loss: 595486.7500 - val_mae: 559.3468\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596785.0000 - mae: 560.6125 - val_loss: 595083.7500 - val_mae: 559.7318\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596563.8125 - mae: 560.5569 - val_loss: 595024.0000 - val_mae: 559.1287\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596359.8125 - mae: 560.7623 - val_loss: 594569.3750 - val_mae: 559.3630\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595856.0625 - mae: 559.8032 - val_loss: 594976.0000 - val_mae: 562.5547\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595926.9375 - mae: 560.4811 - val_loss: 593866.3750 - val_mae: 559.1039\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595508.3750 - mae: 559.9121 - val_loss: 593503.0000 - val_mae: 559.4468\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595102.8750 - mae: 559.7662 - val_loss: 593607.6875 - val_mae: 558.3599\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 594840.0000 - mae: 559.3406 - val_loss: 593325.1250 - val_mae: 559.2051\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 594672.3125 - mae: 559.4669 - val_loss: 592809.3125 - val_mae: 558.5864\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 594817.0625 - mae: 559.2756 - val_loss: 592882.1875 - val_mae: 559.7695\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 594402.3125 - mae: 559.1425 - val_loss: 592640.0000 - val_mae: 557.6124\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 593888.8125 - mae: 558.8641 - val_loss: 592828.2500 - val_mae: 556.8577\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 594025.0000 - mae: 558.7452 - val_loss: 592175.0000 - val_mae: 559.2994\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 593523.2500 - mae: 558.5025 - val_loss: 592395.6250 - val_mae: 560.1771\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 593282.1250 - mae: 558.5237 - val_loss: 591624.5625 - val_mae: 558.6488\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 593637.1250 - mae: 559.2531 - val_loss: 591625.6250 - val_mae: 556.8505\n",
      "Epoch 123/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592934.5000 - mae: 557.9656 - val_loss: 591504.8125 - val_mae: 556.4744\n",
      "Epoch 124/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592461.1250 - mae: 557.8248 - val_loss: 591165.9375 - val_mae: 557.8615\n",
      "Epoch 125/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592370.7500 - mae: 558.1255 - val_loss: 590802.5625 - val_mae: 556.5002\n",
      "Epoch 126/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592639.3750 - mae: 558.0909 - val_loss: 590917.3750 - val_mae: 557.7889\n",
      "Epoch 127/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 592042.9375 - mae: 558.1332 - val_loss: 590972.6250 - val_mae: 555.9352\n",
      "Epoch 128/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591753.5625 - mae: 557.2607 - val_loss: 590754.3750 - val_mae: 559.2323\n",
      "Epoch 129/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 591812.6250 - mae: 557.6940 - val_loss: 590356.3750 - val_mae: 558.1384\n",
      "Epoch 130/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591626.0625 - mae: 557.9943 - val_loss: 589988.6250 - val_mae: 557.3723\n",
      "Epoch 131/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 591817.1250 - mae: 557.3761 - val_loss: 589943.1250 - val_mae: 558.0303\n",
      "Epoch 132/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591443.1250 - mae: 557.6357 - val_loss: 589918.3125 - val_mae: 555.6281\n",
      "Epoch 133/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591318.1250 - mae: 557.5088 - val_loss: 589527.5625 - val_mae: 556.1037\n",
      "Epoch 134/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591342.4375 - mae: 557.1230 - val_loss: 589295.8750 - val_mae: 556.1448\n",
      "Epoch 135/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 590765.0625 - mae: 556.7334 - val_loss: 589380.1250 - val_mae: 557.2139\n",
      "Epoch 136/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591319.8750 - mae: 557.4672 - val_loss: 589354.3125 - val_mae: 558.2931\n",
      "Epoch 137/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 590744.1875 - mae: 557.1818 - val_loss: 588885.7500 - val_mae: 556.2703\n",
      "Epoch 138/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 590575.6250 - mae: 556.8180 - val_loss: 588706.0000 - val_mae: 556.4965\n",
      "Epoch 139/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 590322.5625 - mae: 557.2358 - val_loss: 588803.9375 - val_mae: 555.1163\n",
      "Epoch 140/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 590185.3750 - mae: 556.2092 - val_loss: 588996.1250 - val_mae: 558.3184\n",
      "Epoch 141/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 590125.8125 - mae: 556.8239 - val_loss: 588637.1875 - val_mae: 557.6081\n",
      "Epoch 142/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 589946.1875 - mae: 556.3936 - val_loss: 588501.4375 - val_mae: 557.0905\n",
      "Epoch 143/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 590061.8750 - mae: 556.8801 - val_loss: 588366.8125 - val_mae: 554.6010\n",
      "Epoch 144/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 589838.6250 - mae: 556.2933 - val_loss: 588031.5625 - val_mae: 556.7785\n",
      "Epoch 145/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 589737.1875 - mae: 556.2720 - val_loss: 588493.5000 - val_mae: 558.3865\n",
      "Epoch 146/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 589620.5625 - mae: 556.7941 - val_loss: 587743.3750 - val_mae: 556.3149\n",
      "Epoch 147/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 589463.8750 - mae: 556.6458 - val_loss: 587815.4375 - val_mae: 555.3866\n",
      "Epoch 148/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 589147.9375 - mae: 555.6964 - val_loss: 587941.7500 - val_mae: 557.5374\n",
      "Epoch 149/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 588989.3750 - mae: 556.6813 - val_loss: 587895.8125 - val_mae: 554.4335\n",
      "Epoch 150/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 588848.1250 - mae: 556.1088 - val_loss: 587217.4375 - val_mae: 555.3738\n",
      "Epoch 151/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 588730.2500 - mae: 555.8373 - val_loss: 587327.1250 - val_mae: 555.5635\n",
      "Epoch 152/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 588724.3750 - mae: 555.7153 - val_loss: 586973.2500 - val_mae: 555.3682\n",
      "Epoch 153/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 588639.0625 - mae: 556.0182 - val_loss: 587057.9375 - val_mae: 555.6427\n",
      "Epoch 154/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 588110.6250 - mae: 556.0825 - val_loss: 587097.6250 - val_mae: 553.6219\n",
      "Epoch 155/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 587882.5000 - mae: 555.2106 - val_loss: 587213.6250 - val_mae: 557.1591\n",
      "Epoch 156/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 588271.4375 - mae: 556.2079 - val_loss: 586616.5000 - val_mae: 554.6722\n",
      "Epoch 157/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 588116.4375 - mae: 555.8182 - val_loss: 587022.4375 - val_mae: 553.2441\n",
      "Epoch 158/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 587936.3125 - mae: 555.2930 - val_loss: 586201.7500 - val_mae: 554.6989\n",
      "Epoch 159/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 587632.5625 - mae: 555.3800 - val_loss: 585929.4375 - val_mae: 555.0298\n",
      "Epoch 160/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 587695.5000 - mae: 555.4210 - val_loss: 585870.0625 - val_mae: 554.1355\n",
      "Epoch 161/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 587520.2500 - mae: 554.9394 - val_loss: 586085.9375 - val_mae: 556.3399\n",
      "Epoch 162/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 587356.5625 - mae: 555.1547 - val_loss: 585619.8125 - val_mae: 554.0551\n",
      "Epoch 163/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 587103.6875 - mae: 554.8795 - val_loss: 585353.0625 - val_mae: 555.1212\n",
      "Epoch 164/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 587087.1250 - mae: 554.8409 - val_loss: 585258.8750 - val_mae: 554.6224\n",
      "Epoch 165/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 586836.0625 - mae: 555.2078 - val_loss: 584843.6250 - val_mae: 553.3025\n",
      "Epoch 166/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 586654.0625 - mae: 554.6946 - val_loss: 584566.9375 - val_mae: 553.3370\n",
      "Epoch 167/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 586336.8750 - mae: 554.9405 - val_loss: 584868.6875 - val_mae: 552.0142\n",
      "Epoch 168/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 585881.3750 - mae: 553.6808 - val_loss: 584338.6875 - val_mae: 554.9529\n",
      "Epoch 169/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 585239.5625 - mae: 553.8018 - val_loss: 584269.1250 - val_mae: 555.2632\n",
      "Epoch 170/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 585238.8125 - mae: 554.0445 - val_loss: 583816.3125 - val_mae: 553.1611\n",
      "Epoch 171/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 585234.6875 - mae: 553.7193 - val_loss: 583459.1250 - val_mae: 554.0964\n",
      "Epoch 172/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 584864.0000 - mae: 553.8853 - val_loss: 583053.8750 - val_mae: 552.6472\n",
      "Epoch 173/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 584945.5000 - mae: 553.5859 - val_loss: 583206.1250 - val_mae: 551.3965\n",
      "Epoch 174/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 584855.8750 - mae: 553.4719 - val_loss: 582709.0000 - val_mae: 552.8068\n",
      "Epoch 175/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 584449.6250 - mae: 553.1025 - val_loss: 582546.1875 - val_mae: 552.2327\n",
      "Epoch 176/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 584224.5000 - mae: 553.0635 - val_loss: 582886.8750 - val_mae: 551.2498\n",
      "Epoch 177/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583656.4375 - mae: 553.3172 - val_loss: 582861.5000 - val_mae: 551.0035\n",
      "Epoch 178/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583899.1875 - mae: 552.6570 - val_loss: 582272.4375 - val_mae: 553.5372\n",
      "Epoch 179/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 583754.8750 - mae: 552.5464 - val_loss: 582188.8750 - val_mae: 553.3510\n",
      "Epoch 180/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583333.2500 - mae: 552.8007 - val_loss: 582273.0000 - val_mae: 553.6744\n",
      "Epoch 181/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583838.6250 - mae: 552.9944 - val_loss: 581770.8125 - val_mae: 552.4791\n",
      "Epoch 182/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583355.5625 - mae: 552.8551 - val_loss: 581599.5625 - val_mae: 551.6046\n",
      "Epoch 183/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583327.8125 - mae: 552.7188 - val_loss: 581515.3125 - val_mae: 551.7352\n",
      "Epoch 184/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582654.6250 - mae: 552.2079 - val_loss: 582323.6875 - val_mae: 554.5580\n",
      "Epoch 185/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583565.6250 - mae: 552.8001 - val_loss: 581421.8125 - val_mae: 550.6933\n",
      "Epoch 186/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 583088.7500 - mae: 552.4486 - val_loss: 581088.5000 - val_mae: 551.7950\n",
      "Epoch 187/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 582918.8125 - mae: 552.3524 - val_loss: 581345.9375 - val_mae: 553.1675\n",
      "Epoch 188/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582442.5625 - mae: 552.0862 - val_loss: 581091.5000 - val_mae: 552.4132\n",
      "Epoch 189/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582449.6875 - mae: 552.3383 - val_loss: 581096.4375 - val_mae: 552.4642\n",
      "Epoch 190/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582544.3125 - mae: 552.1087 - val_loss: 580958.0000 - val_mae: 550.5095\n",
      "Epoch 191/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 582099.8750 - mae: 552.3759 - val_loss: 581248.0625 - val_mae: 549.7740\n",
      "Epoch 192/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582856.5625 - mae: 552.3720 - val_loss: 580760.0000 - val_mae: 550.3439\n",
      "Epoch 193/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 582275.5625 - mae: 551.6194 - val_loss: 580402.6875 - val_mae: 551.2291\n",
      "Epoch 194/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 581825.2500 - mae: 551.6161 - val_loss: 580268.5625 - val_mae: 550.0941\n",
      "Epoch 195/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 581664.3125 - mae: 551.4538 - val_loss: 579969.3125 - val_mae: 551.4971\n",
      "Epoch 196/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 581251.0000 - mae: 551.2653 - val_loss: 579333.1875 - val_mae: 550.7015\n",
      "Epoch 197/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 581059.0000 - mae: 550.7853 - val_loss: 578744.9375 - val_mae: 551.6585\n",
      "Epoch 198/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 579966.8125 - mae: 550.5104 - val_loss: 577850.7500 - val_mae: 550.6738\n",
      "Epoch 199/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 578879.5000 - mae: 550.1771 - val_loss: 576951.6875 - val_mae: 550.5982\n",
      "Epoch 200/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 578049.6250 - mae: 549.9987 - val_loss: 576309.4375 - val_mae: 548.6938\n",
      "Epoch 201/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 577261.1250 - mae: 549.3828 - val_loss: 575303.0625 - val_mae: 549.1416\n",
      "Epoch 202/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 576462.5000 - mae: 549.0854 - val_loss: 574319.0000 - val_mae: 548.5618\n",
      "Epoch 203/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 575357.1250 - mae: 548.3619 - val_loss: 573594.1250 - val_mae: 544.9142\n",
      "Epoch 204/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 573636.4375 - mae: 547.1494 - val_loss: 571627.0000 - val_mae: 546.9272\n",
      "Epoch 205/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 572266.6250 - mae: 546.7770 - val_loss: 570004.0000 - val_mae: 547.0170\n",
      "Epoch 206/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 570992.0625 - mae: 546.9016 - val_loss: 567951.8750 - val_mae: 544.2312\n",
      "Epoch 207/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 568609.1250 - mae: 544.7142 - val_loss: 567453.5000 - val_mae: 545.9535\n",
      "Epoch 208/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 567701.5000 - mae: 544.5982 - val_loss: 565931.9375 - val_mae: 545.0095\n",
      "Epoch 209/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 566401.0625 - mae: 544.0871 - val_loss: 564045.7500 - val_mae: 542.3217\n",
      "Epoch 210/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 565223.3125 - mae: 543.1010 - val_loss: 563940.0000 - val_mae: 545.7467\n",
      "Epoch 211/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 564377.4375 - mae: 543.0638 - val_loss: 562257.0000 - val_mae: 540.8132\n",
      "Epoch 212/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 563437.9375 - mae: 542.6080 - val_loss: 561332.2500 - val_mae: 541.2681\n",
      "Epoch 213/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 562923.7500 - mae: 542.2325 - val_loss: 560546.8750 - val_mae: 540.6905\n",
      "Epoch 214/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 561917.6875 - mae: 541.5311 - val_loss: 560065.3750 - val_mae: 541.9020\n",
      "Epoch 215/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 561290.6875 - mae: 541.7954 - val_loss: 560046.6250 - val_mae: 540.0374\n",
      "Epoch 216/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 560883.1875 - mae: 541.1280 - val_loss: 559309.6250 - val_mae: 539.7729\n",
      "Epoch 217/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 560303.2500 - mae: 541.3689 - val_loss: 559064.2500 - val_mae: 538.5205\n",
      "Epoch 218/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 560099.6250 - mae: 541.0851 - val_loss: 559415.8125 - val_mae: 537.6940\n",
      "Epoch 219/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 559427.7500 - mae: 540.5692 - val_loss: 557954.6250 - val_mae: 539.0789\n",
      "Epoch 220/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 559318.8750 - mae: 540.8983 - val_loss: 557615.7500 - val_mae: 538.3716\n",
      "Epoch 221/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 558085.8125 - mae: 539.7731 - val_loss: 556632.9375 - val_mae: 540.5181\n",
      "Epoch 222/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 558061.3750 - mae: 540.1969 - val_loss: 556192.8750 - val_mae: 539.0422\n",
      "Epoch 223/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 557525.5625 - mae: 539.8216 - val_loss: 556063.5625 - val_mae: 539.4026\n",
      "Epoch 224/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 557207.9375 - mae: 540.0897 - val_loss: 555949.3125 - val_mae: 537.9785\n",
      "Epoch 225/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 557110.9375 - mae: 539.7702 - val_loss: 555335.9375 - val_mae: 537.5933\n",
      "Epoch 226/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556874.8750 - mae: 539.0302 - val_loss: 555258.6875 - val_mae: 540.7992\n",
      "Epoch 227/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556727.1250 - mae: 539.5519 - val_loss: 555072.7500 - val_mae: 540.4344\n",
      "Epoch 228/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556122.3750 - mae: 539.2032 - val_loss: 554437.7500 - val_mae: 538.2889\n",
      "Epoch 229/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 556104.1875 - mae: 539.1880 - val_loss: 554343.6875 - val_mae: 539.0977\n",
      "Epoch 230/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 556187.3750 - mae: 539.1064 - val_loss: 554414.0625 - val_mae: 537.3201\n",
      "Epoch 231/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555617.4375 - mae: 538.9875 - val_loss: 554148.9375 - val_mae: 538.9371\n",
      "Epoch 232/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554744.3750 - mae: 538.2060 - val_loss: 556915.0625 - val_mae: 544.7927\n",
      "Epoch 233/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555780.8125 - mae: 539.1241 - val_loss: 554073.9375 - val_mae: 539.8616\n",
      "Epoch 234/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555434.5625 - mae: 538.7139 - val_loss: 553967.1875 - val_mae: 540.1838\n",
      "Epoch 235/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555211.9375 - mae: 539.1808 - val_loss: 553683.5625 - val_mae: 536.8244\n",
      "Epoch 236/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555280.6875 - mae: 538.6870 - val_loss: 553575.0000 - val_mae: 536.5922\n",
      "Epoch 237/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 554950.0000 - mae: 538.5472 - val_loss: 553593.1250 - val_mae: 538.5198\n",
      "Epoch 238/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555103.0625 - mae: 538.4935 - val_loss: 553339.6250 - val_mae: 537.8112\n",
      "Epoch 239/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 555509.0000 - mae: 538.4385 - val_loss: 553254.2500 - val_mae: 537.9327\n",
      "Epoch 240/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 554926.2500 - mae: 538.4532 - val_loss: 553128.3750 - val_mae: 538.5996\n",
      "Epoch 241/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554211.9375 - mae: 538.2838 - val_loss: 554892.2500 - val_mae: 541.3048\n",
      "Epoch 242/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555137.8750 - mae: 538.4543 - val_loss: 553409.6250 - val_mae: 538.2714\n",
      "Epoch 243/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554599.8750 - mae: 538.6900 - val_loss: 553193.5625 - val_mae: 537.0726\n",
      "Epoch 244/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554671.0625 - mae: 538.5930 - val_loss: 552856.5000 - val_mae: 537.0062\n",
      "Epoch 245/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 554203.0000 - mae: 537.8646 - val_loss: 552929.0000 - val_mae: 537.1831\n",
      "Epoch 246/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 554356.7500 - mae: 538.5148 - val_loss: 552719.5000 - val_mae: 537.1206\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 32981868.0000 - mae: 5574.3516 - val_loss: 21978036.0000 - val_mae: 4555.7251\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 11274302.0000 - mae: 3081.8560 - val_loss: 3933257.5000 - val_mae: 1704.3737\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 2019511.0000 - mae: 1083.9910 - val_loss: 1214400.2500 - val_mae: 810.7888\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 1058450.6250 - mae: 759.1776 - val_loss: 947950.1250 - val_mae: 721.2337\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 890533.8125 - mae: 699.4260 - val_loss: 840707.1875 - val_mae: 678.4836\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 811676.5000 - mae: 668.5643 - val_loss: 782816.5000 - val_mae: 657.0756\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 762375.3125 - mae: 650.2983 - val_loss: 739936.3750 - val_mae: 641.1525\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 727755.2500 - mae: 636.9159 - val_loss: 711808.6250 - val_mae: 632.5567\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 703768.8125 - mae: 626.1306 - val_loss: 690093.7500 - val_mae: 617.8246\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 684076.1250 - mae: 615.2478 - val_loss: 674741.2500 - val_mae: 608.8261\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 671327.5625 - mae: 607.7260 - val_loss: 664813.5625 - val_mae: 601.8863\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 663376.0625 - mae: 602.3525 - val_loss: 657426.6875 - val_mae: 601.5023\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 655985.6250 - mae: 598.1998 - val_loss: 650982.7500 - val_mae: 594.4917\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 649598.7500 - mae: 594.0475 - val_loss: 643548.3125 - val_mae: 592.4239\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 643647.3750 - mae: 590.2924 - val_loss: 638800.9375 - val_mae: 591.3633\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 638698.5625 - mae: 588.2021 - val_loss: 633686.6250 - val_mae: 585.4300\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 634306.5000 - mae: 585.3795 - val_loss: 630457.8125 - val_mae: 581.6954\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 630908.8125 - mae: 583.1845 - val_loss: 627092.7500 - val_mae: 581.3394\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 627202.6875 - mae: 580.8856 - val_loss: 624454.0000 - val_mae: 581.8423\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 624380.6250 - mae: 579.1708 - val_loss: 621116.0000 - val_mae: 576.2865\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 621565.2500 - mae: 577.8673 - val_loss: 617732.7500 - val_mae: 574.5281\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 618000.4375 - mae: 575.9366 - val_loss: 612872.8750 - val_mae: 573.5503\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 613726.1875 - mae: 573.6652 - val_loss: 608794.1250 - val_mae: 569.3025\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 608626.2500 - mae: 570.6263 - val_loss: 603951.6875 - val_mae: 568.1517\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 604880.2500 - mae: 569.1433 - val_loss: 600964.9375 - val_mae: 567.5778\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 602561.0625 - mae: 568.5294 - val_loss: 599547.6875 - val_mae: 567.9776\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 601140.5625 - mae: 567.5567 - val_loss: 598446.7500 - val_mae: 563.6920\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 599650.3750 - mae: 566.1312 - val_loss: 596761.6250 - val_mae: 567.5048\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 598459.7500 - mae: 565.8008 - val_loss: 594514.5625 - val_mae: 564.3655\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 596297.0625 - mae: 565.0009 - val_loss: 593172.5625 - val_mae: 562.3481\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 594751.2500 - mae: 563.8105 - val_loss: 591704.9375 - val_mae: 562.6815\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 593999.6875 - mae: 563.4402 - val_loss: 590643.5625 - val_mae: 563.8209\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 592533.0625 - mae: 562.8200 - val_loss: 589554.9375 - val_mae: 560.5910\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 591683.8750 - mae: 561.5800 - val_loss: 588010.0625 - val_mae: 560.8550\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 589942.9375 - mae: 560.9898 - val_loss: 588263.3750 - val_mae: 562.3286\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 589537.8750 - mae: 560.5848 - val_loss: 587321.6875 - val_mae: 557.4996\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588734.8125 - mae: 559.9387 - val_loss: 585055.8750 - val_mae: 558.5226\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 586932.0000 - mae: 558.9719 - val_loss: 585336.8750 - val_mae: 562.1471\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 585798.0625 - mae: 558.6445 - val_loss: 583818.2500 - val_mae: 557.2392\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 584881.5000 - mae: 557.3810 - val_loss: 581405.8125 - val_mae: 556.8769\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 582883.7500 - mae: 556.4909 - val_loss: 580749.8750 - val_mae: 557.5826\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 581666.0000 - mae: 555.2195 - val_loss: 579541.2500 - val_mae: 556.6436\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 580747.6875 - mae: 554.5344 - val_loss: 577996.0000 - val_mae: 555.1154\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 578898.1250 - mae: 552.9254 - val_loss: 576737.9375 - val_mae: 554.0191\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 577758.4375 - mae: 552.7288 - val_loss: 576126.0625 - val_mae: 549.5707\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 576712.8125 - mae: 551.5347 - val_loss: 573608.3125 - val_mae: 550.0121\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 575137.6875 - mae: 550.4310 - val_loss: 574667.4375 - val_mae: 553.9807\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 573987.6250 - mae: 550.2579 - val_loss: 571627.3750 - val_mae: 550.5588\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 572996.8750 - mae: 549.4304 - val_loss: 569613.5625 - val_mae: 547.6666\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 570938.2500 - mae: 548.4263 - val_loss: 568310.7500 - val_mae: 547.5424\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 569368.0625 - mae: 547.5084 - val_loss: 566829.5000 - val_mae: 549.8707\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 567680.0000 - mae: 547.4449 - val_loss: 564457.8750 - val_mae: 544.1202\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565938.7500 - mae: 545.4808 - val_loss: 563309.5625 - val_mae: 546.4159\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 565197.6875 - mae: 545.2923 - val_loss: 561416.5000 - val_mae: 543.9082\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 563395.5000 - mae: 544.2877 - val_loss: 561878.0000 - val_mae: 547.0625\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 562270.2500 - mae: 544.1116 - val_loss: 561460.0000 - val_mae: 539.7531\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 562303.6250 - mae: 543.6610 - val_loss: 558535.7500 - val_mae: 541.3527\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 560865.2500 - mae: 543.2319 - val_loss: 557677.8750 - val_mae: 541.0375\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560185.5625 - mae: 542.3970 - val_loss: 557213.0625 - val_mae: 542.8625\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558842.1875 - mae: 542.0646 - val_loss: 557467.2500 - val_mae: 543.5008\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 558639.5000 - mae: 542.3492 - val_loss: 555685.8125 - val_mae: 540.3702\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 557971.4375 - mae: 541.5135 - val_loss: 556237.2500 - val_mae: 537.6187\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557309.1875 - mae: 541.6487 - val_loss: 557854.0625 - val_mae: 535.8932\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 556832.4375 - mae: 540.1852 - val_loss: 554930.8125 - val_mae: 538.8198\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556277.8125 - mae: 540.4090 - val_loss: 553924.1875 - val_mae: 540.6987\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555833.4375 - mae: 539.9354 - val_loss: 553668.8750 - val_mae: 542.0786\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555252.9375 - mae: 540.5781 - val_loss: 553773.2500 - val_mae: 539.1711\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555134.2500 - mae: 539.6819 - val_loss: 553026.0000 - val_mae: 541.0378\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 555187.0625 - mae: 539.9024 - val_loss: 551727.8125 - val_mae: 538.9527\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554350.7500 - mae: 539.3108 - val_loss: 551764.3125 - val_mae: 538.8054\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 554163.5625 - mae: 539.4111 - val_loss: 551617.3125 - val_mae: 538.6807\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553194.4375 - mae: 539.0814 - val_loss: 551498.3750 - val_mae: 537.1481\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553508.5625 - mae: 539.3434 - val_loss: 552191.0625 - val_mae: 541.3096\n",
      "Epoch 1/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 29699474.0000 - mae: 5236.0537 - val_loss: 15302280.0000 - val_mae: 3692.6294\n",
      "Epoch 2/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 6356393.0000 - mae: 2048.0320 - val_loss: 1760361.5000 - val_mae: 957.0005\n",
      "Epoch 3/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 1128228.1250 - mae: 749.9589 - val_loss: 871700.6875 - val_mae: 673.6427\n",
      "Epoch 4/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 800478.3125 - mae: 651.3977 - val_loss: 744290.9375 - val_mae: 631.7933\n",
      "Epoch 5/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 717354.3125 - mae: 622.0023 - val_loss: 693785.2500 - val_mae: 615.2964\n",
      "Epoch 6/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 683215.8125 - mae: 607.8069 - val_loss: 671048.6250 - val_mae: 597.1525\n",
      "Epoch 7/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 665787.3750 - mae: 597.3705 - val_loss: 656128.6250 - val_mae: 594.2484\n",
      "Epoch 8/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 652994.0000 - mae: 590.5167 - val_loss: 645174.5000 - val_mae: 587.8604\n",
      "Epoch 9/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 643073.1250 - mae: 586.2391 - val_loss: 638628.1875 - val_mae: 585.7861\n",
      "Epoch 10/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 637072.0000 - mae: 583.3627 - val_loss: 631243.3750 - val_mae: 579.8317\n",
      "Epoch 11/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 631059.2500 - mae: 580.6610 - val_loss: 627370.3750 - val_mae: 580.7076\n",
      "Epoch 12/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 627967.4375 - mae: 579.3817 - val_loss: 626523.6875 - val_mae: 583.7793\n",
      "Epoch 13/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 625220.0000 - mae: 578.4065 - val_loss: 621279.2500 - val_mae: 577.2808\n",
      "Epoch 14/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 622780.1875 - mae: 576.9121 - val_loss: 619540.3750 - val_mae: 574.2578\n",
      "Epoch 15/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 620588.8750 - mae: 576.5458 - val_loss: 617291.3750 - val_mae: 575.8105\n",
      "Epoch 16/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 618935.6875 - mae: 575.9509 - val_loss: 616518.3125 - val_mae: 572.0696\n",
      "Epoch 17/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 616953.6875 - mae: 574.6503 - val_loss: 613869.0625 - val_mae: 575.8923\n",
      "Epoch 18/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 614969.3750 - mae: 574.6066 - val_loss: 612806.9375 - val_mae: 570.2310\n",
      "Epoch 19/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 613793.8750 - mae: 573.8762 - val_loss: 610216.7500 - val_mae: 572.4139\n",
      "Epoch 20/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 611706.6250 - mae: 572.5362 - val_loss: 608639.6875 - val_mae: 573.4640\n",
      "Epoch 21/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 610140.8125 - mae: 572.1299 - val_loss: 608023.6875 - val_mae: 567.5141\n",
      "Epoch 22/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 607593.6875 - mae: 570.6669 - val_loss: 606557.5625 - val_mae: 568.2805\n",
      "Epoch 23/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 606779.4375 - mae: 570.2250 - val_loss: 603047.8125 - val_mae: 567.6202\n",
      "Epoch 24/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 605023.7500 - mae: 569.4393 - val_loss: 602041.5625 - val_mae: 568.3492\n",
      "Epoch 25/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 603733.0625 - mae: 569.5823 - val_loss: 600595.1875 - val_mae: 565.8135\n",
      "Epoch 26/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 602210.8125 - mae: 567.7358 - val_loss: 599318.6250 - val_mae: 569.0452\n",
      "Epoch 27/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 600912.8750 - mae: 567.9853 - val_loss: 597920.8125 - val_mae: 565.0735\n",
      "Epoch 28/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 599748.3125 - mae: 567.2117 - val_loss: 595918.8125 - val_mae: 565.0825\n",
      "Epoch 29/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 597952.0000 - mae: 566.4547 - val_loss: 595097.7500 - val_mae: 566.0716\n",
      "Epoch 30/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 595981.5000 - mae: 565.6104 - val_loss: 592809.4375 - val_mae: 564.0883\n",
      "Epoch 31/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 594010.0000 - mae: 564.2750 - val_loss: 591955.9375 - val_mae: 567.2533\n",
      "Epoch 32/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 592856.1875 - mae: 563.8914 - val_loss: 588935.9375 - val_mae: 561.9374\n",
      "Epoch 33/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 591342.1250 - mae: 563.0076 - val_loss: 587166.4375 - val_mae: 560.2195\n",
      "Epoch 34/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 589961.8125 - mae: 562.0029 - val_loss: 587083.3125 - val_mae: 561.5880\n",
      "Epoch 35/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 588786.8125 - mae: 561.1060 - val_loss: 587656.7500 - val_mae: 557.7397\n",
      "Epoch 36/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 588257.8125 - mae: 561.1055 - val_loss: 585092.3125 - val_mae: 557.8694\n",
      "Epoch 37/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 587183.5000 - mae: 560.0993 - val_loss: 586067.8750 - val_mae: 556.7857\n",
      "Epoch 38/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 586867.6875 - mae: 559.8387 - val_loss: 584539.1250 - val_mae: 560.7556\n",
      "Epoch 39/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 586235.7500 - mae: 560.0817 - val_loss: 584477.1250 - val_mae: 555.8499\n",
      "Epoch 40/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 585898.3750 - mae: 559.1940 - val_loss: 583410.1250 - val_mae: 557.6157\n",
      "Epoch 41/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 585386.0625 - mae: 559.1480 - val_loss: 583693.5000 - val_mae: 556.0350\n",
      "Epoch 42/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 584997.2500 - mae: 558.7190 - val_loss: 583021.3750 - val_mae: 556.9107\n",
      "Epoch 43/250\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 584551.9375 - mae: 558.3213 - val_loss: 582278.2500 - val_mae: 557.0991\n",
      "Epoch 44/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 583853.8750 - mae: 558.3973 - val_loss: 581159.3125 - val_mae: 555.0180\n",
      "Epoch 45/250\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 583713.2500 - mae: 557.3674 - val_loss: 580998.4375 - val_mae: 554.2541\n",
      "Epoch 46/250\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 583013.8750 - mae: 556.5652 - val_loss: 580395.8125 - val_mae: 558.2407\n",
      "Epoch 47/250\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 582255.0000 - mae: 556.8336 - val_loss: 579305.4375 - val_mae: 555.3778\n",
      "Epoch 48/250\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 581142.1875 - mae: 555.9559 - val_loss: 578914.8750 - val_mae: 556.4008\n",
      "Epoch 49/250\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 580610.0625 - mae: 555.9216 - val_loss: 579139.8125 - val_mae: 551.2292\n",
      "Epoch 50/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 579952.8125 - mae: 554.4221 - val_loss: 577601.0000 - val_mae: 555.3423\n",
      "Epoch 51/250\n",
      "864/864 [==============================] - 3s 4ms/step - loss: 578919.8125 - mae: 554.0272 - val_loss: 576003.0625 - val_mae: 553.1630\n",
      "Epoch 52/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 577323.0625 - mae: 553.3698 - val_loss: 575268.8125 - val_mae: 551.0877\n",
      "Epoch 53/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 576085.4375 - mae: 552.3911 - val_loss: 572819.9375 - val_mae: 550.0701\n",
      "Epoch 54/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 574578.3125 - mae: 551.8604 - val_loss: 572789.3750 - val_mae: 546.8486\n",
      "Epoch 55/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 573512.5625 - mae: 550.6097 - val_loss: 569995.2500 - val_mae: 546.7693\n",
      "Epoch 56/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 571986.8125 - mae: 550.1966 - val_loss: 568215.6875 - val_mae: 548.0843\n",
      "Epoch 57/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 569548.6875 - mae: 548.5247 - val_loss: 566508.0625 - val_mae: 549.0378\n",
      "Epoch 58/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 568400.9375 - mae: 548.4918 - val_loss: 565192.1875 - val_mae: 546.0259\n",
      "Epoch 59/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 567390.2500 - mae: 547.0038 - val_loss: 564080.8750 - val_mae: 547.2822\n",
      "Epoch 60/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 566504.2500 - mae: 546.7930 - val_loss: 563195.8750 - val_mae: 543.0059\n",
      "Epoch 61/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 565642.7500 - mae: 546.0280 - val_loss: 562521.9375 - val_mae: 545.4788\n",
      "Epoch 62/250\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 564422.6250 - mae: 545.5784 - val_loss: 561959.2500 - val_mae: 546.3713\n",
      "Epoch 63/250\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 564116.2500 - mae: 545.4104 - val_loss: 561611.8125 - val_mae: 545.8721\n",
      "Epoch 64/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 563147.0625 - mae: 544.5845 - val_loss: 560085.2500 - val_mae: 542.8152\n",
      "Epoch 65/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 562626.0625 - mae: 544.4426 - val_loss: 559800.5625 - val_mae: 545.4683\n",
      "Epoch 66/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 561651.6250 - mae: 543.7130 - val_loss: 558923.8750 - val_mae: 542.6944\n",
      "Epoch 67/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560375.1875 - mae: 543.6075 - val_loss: 558628.0000 - val_mae: 544.2048\n",
      "Epoch 68/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 560023.0000 - mae: 542.7507 - val_loss: 557296.9375 - val_mae: 543.0784\n",
      "Epoch 69/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 559408.8125 - mae: 542.4687 - val_loss: 557341.4375 - val_mae: 542.8938\n",
      "Epoch 70/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558583.1250 - mae: 542.3381 - val_loss: 556402.6250 - val_mae: 540.1453\n",
      "Epoch 71/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 558006.8750 - mae: 541.4712 - val_loss: 556264.3125 - val_mae: 542.1359\n",
      "Epoch 72/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 557625.0000 - mae: 541.7441 - val_loss: 555285.6875 - val_mae: 537.5791\n",
      "Epoch 73/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556682.6250 - mae: 541.2257 - val_loss: 554144.1250 - val_mae: 538.2802\n",
      "Epoch 74/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 556837.5625 - mae: 540.8079 - val_loss: 553402.6875 - val_mae: 540.2821\n",
      "Epoch 75/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 555518.1250 - mae: 540.5891 - val_loss: 553739.8750 - val_mae: 539.0510\n",
      "Epoch 76/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555938.8750 - mae: 540.1419 - val_loss: 554376.6875 - val_mae: 539.5996\n",
      "Epoch 77/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555735.3750 - mae: 540.2874 - val_loss: 553824.5000 - val_mae: 542.1340\n",
      "Epoch 78/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554558.6875 - mae: 539.7604 - val_loss: 552864.1250 - val_mae: 537.6458\n",
      "Epoch 79/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555042.3125 - mae: 539.9365 - val_loss: 552803.5000 - val_mae: 537.9342\n",
      "Epoch 80/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555127.0625 - mae: 539.5547 - val_loss: 552384.0625 - val_mae: 536.9295\n",
      "Epoch 81/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554870.4375 - mae: 539.8898 - val_loss: 552985.3125 - val_mae: 535.4459\n",
      "Epoch 82/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554719.0625 - mae: 539.4370 - val_loss: 552370.5625 - val_mae: 539.2806\n",
      "Epoch 83/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 555133.6875 - mae: 539.8423 - val_loss: 553394.2500 - val_mae: 541.9185\n",
      "Epoch 84/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554601.0000 - mae: 539.6486 - val_loss: 552121.7500 - val_mae: 539.5603\n",
      "Epoch 85/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 553918.3750 - mae: 539.8981 - val_loss: 551551.1250 - val_mae: 536.4839\n",
      "Epoch 86/250\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 554531.5000 - mae: 539.4495 - val_loss: 551000.8125 - val_mae: 538.8856\n",
      "Epoch 87/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 553607.5625 - mae: 539.0656 - val_loss: 551735.4375 - val_mae: 540.4799\n",
      "Epoch 88/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 553072.6250 - mae: 539.0321 - val_loss: 551185.9375 - val_mae: 539.1200\n",
      "Epoch 89/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 553171.2500 - mae: 538.8597 - val_loss: 549700.3750 - val_mae: 538.1254\n",
      "Epoch 90/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 552672.7500 - mae: 538.5307 - val_loss: 549780.0625 - val_mae: 537.7458\n",
      "Epoch 91/250\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 551441.8750 - mae: 538.1204 - val_loss: 549555.8125 - val_mae: 537.0881\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 36821308.0000 - mae: 5911.9087 - val_loss: 32955222.0000 - val_mae: 5591.1011\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 26664416.0000 - mae: 4995.8936 - val_loss: 20042498.0000 - val_mae: 4304.6196\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 14294895.0000 - mae: 3529.8779 - val_loss: 9327853.0000 - val_mae: 2751.4062\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 6178700.5000 - mae: 2092.0896 - val_loss: 3798833.2500 - val_mae: 1546.5588\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2616098.7500 - mae: 1222.7930 - val_loss: 1811216.2500 - val_mae: 982.1427\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1489809.8750 - mae: 868.8168 - val_loss: 1278606.3750 - val_mae: 793.7050\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1187172.8750 - mae: 764.5582 - val_loss: 1112977.3750 - val_mae: 743.3358\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 1064339.5000 - mae: 730.6794 - val_loss: 1017055.7500 - val_mae: 717.6483\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 983194.0625 - mae: 707.8583 - val_loss: 948237.0000 - val_mae: 697.9167\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 922154.8125 - mae: 689.0029 - val_loss: 893290.6250 - val_mae: 680.2177\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 868417.1875 - mae: 672.3005 - val_loss: 842220.2500 - val_mae: 661.9552\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 822200.3750 - mae: 656.5728 - val_loss: 799909.5000 - val_mae: 649.6498\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 785706.1250 - mae: 644.6060 - val_loss: 768430.8750 - val_mae: 637.9355\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 757133.1875 - mae: 634.1057 - val_loss: 742826.7500 - val_mae: 629.8558\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 734005.0000 - mae: 624.9382 - val_loss: 723256.0625 - val_mae: 623.0009\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 717186.6875 - mae: 618.8694 - val_loss: 709614.5625 - val_mae: 614.2424\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 705498.0625 - mae: 614.1589 - val_loss: 698097.3125 - val_mae: 609.4819\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 695839.5000 - mae: 609.3890 - val_loss: 689236.4375 - val_mae: 607.1418\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 687811.7500 - mae: 606.1526 - val_loss: 682341.5000 - val_mae: 605.2842\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 681118.0000 - mae: 603.5938 - val_loss: 676195.8750 - val_mae: 601.4150\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 675334.5625 - mae: 600.5953 - val_loss: 671291.5625 - val_mae: 600.0616\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 671076.3125 - mae: 598.5956 - val_loss: 667020.5000 - val_mae: 595.7928\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 667268.2500 - mae: 596.4478 - val_loss: 663618.8125 - val_mae: 595.1293\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 663789.6250 - mae: 594.6507 - val_loss: 659934.3125 - val_mae: 593.1520\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 660662.4375 - mae: 593.1709 - val_loss: 657124.3125 - val_mae: 590.1435\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 657719.1250 - mae: 591.5945 - val_loss: 654326.8750 - val_mae: 591.3010\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 654935.7500 - mae: 589.9428 - val_loss: 651582.2500 - val_mae: 589.3134\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 652256.4375 - mae: 589.0801 - val_loss: 649790.3750 - val_mae: 585.7623\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 650125.5000 - mae: 587.3691 - val_loss: 647286.0625 - val_mae: 588.0110\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 648280.6875 - mae: 586.7397 - val_loss: 644952.8750 - val_mae: 585.4254\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 645505.0000 - mae: 585.2716 - val_loss: 643139.1875 - val_mae: 585.4022\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 643750.9375 - mae: 584.5349 - val_loss: 641850.3125 - val_mae: 584.0392\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 642372.8125 - mae: 583.7728 - val_loss: 639474.0000 - val_mae: 582.9276\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 640342.1250 - mae: 582.8815 - val_loss: 638802.1875 - val_mae: 580.1281\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 639242.0000 - mae: 582.4276 - val_loss: 636322.2500 - val_mae: 579.6895\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 637281.2500 - mae: 580.8415 - val_loss: 633839.1250 - val_mae: 579.7898\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 634701.3125 - mae: 580.4827 - val_loss: 631543.5000 - val_mae: 579.0800\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 632414.5625 - mae: 579.4841 - val_loss: 630701.9375 - val_mae: 576.8566\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 631086.0625 - mae: 578.8788 - val_loss: 628235.1875 - val_mae: 577.0580\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 629629.4375 - mae: 578.1422 - val_loss: 626875.0000 - val_mae: 576.0491\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 628027.1250 - mae: 577.2970 - val_loss: 625605.0000 - val_mae: 575.4382\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 627152.5000 - mae: 576.9208 - val_loss: 624683.5000 - val_mae: 574.5610\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 625790.3125 - mae: 575.9245 - val_loss: 623565.3750 - val_mae: 574.2520\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 624312.3750 - mae: 575.1663 - val_loss: 623330.5625 - val_mae: 578.2631\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 622959.3750 - mae: 574.9284 - val_loss: 620665.9375 - val_mae: 575.2969\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 621687.2500 - mae: 573.7826 - val_loss: 618172.3125 - val_mae: 573.2609\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 619364.6875 - mae: 572.4097 - val_loss: 616453.0625 - val_mae: 572.2643\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617101.9375 - mae: 572.1585 - val_loss: 615834.0000 - val_mae: 568.6416\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 616447.6250 - mae: 570.9110 - val_loss: 613730.2500 - val_mae: 570.3820\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614992.5000 - mae: 570.2845 - val_loss: 612801.1250 - val_mae: 570.2185\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 614338.8125 - mae: 569.8474 - val_loss: 612103.1875 - val_mae: 571.2402\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613241.6875 - mae: 569.9297 - val_loss: 611454.0000 - val_mae: 566.9025\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 612426.1250 - mae: 568.8220 - val_loss: 610055.3125 - val_mae: 568.1024\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 611198.3750 - mae: 568.3516 - val_loss: 609946.9375 - val_mae: 570.3572\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 610328.4375 - mae: 568.0240 - val_loss: 608176.3125 - val_mae: 567.5519\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609642.6875 - mae: 568.0537 - val_loss: 608894.5000 - val_mae: 564.2757\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 609278.3125 - mae: 567.3158 - val_loss: 606708.1875 - val_mae: 565.4679\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 608192.0625 - mae: 566.6940 - val_loss: 606347.6875 - val_mae: 567.4606\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607523.1250 - mae: 565.9662 - val_loss: 606211.2500 - val_mae: 568.7758\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 606850.4375 - mae: 566.6709 - val_loss: 606007.9375 - val_mae: 562.5798\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 606461.0625 - mae: 565.3669 - val_loss: 603948.5625 - val_mae: 564.8646\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605505.5000 - mae: 565.1218 - val_loss: 603419.8125 - val_mae: 565.6857\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605014.1250 - mae: 565.3668 - val_loss: 602526.0000 - val_mae: 563.6270\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 604047.8125 - mae: 564.0900 - val_loss: 602355.8125 - val_mae: 565.6262\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 603416.6250 - mae: 564.2786 - val_loss: 601621.9375 - val_mae: 563.6698\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602829.1250 - mae: 563.6322 - val_loss: 600081.7500 - val_mae: 562.5961\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 601417.6875 - mae: 562.8190 - val_loss: 599233.1250 - val_mae: 563.9373\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 599472.2500 - mae: 561.8604 - val_loss: 598129.6875 - val_mae: 564.2198\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 597634.0000 - mae: 561.2445 - val_loss: 596458.8125 - val_mae: 558.0736\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 596523.6875 - mae: 559.7305 - val_loss: 593205.3750 - val_mae: 559.0172\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 594293.6250 - mae: 558.7883 - val_loss: 591240.3750 - val_mae: 556.5803\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 592157.5625 - mae: 557.5961 - val_loss: 589357.2500 - val_mae: 557.9752\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 589633.1250 - mae: 556.6131 - val_loss: 586381.9375 - val_mae: 554.7428\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 585898.5625 - mae: 554.5085 - val_loss: 582153.8750 - val_mae: 551.3983\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 582170.6250 - mae: 552.1023 - val_loss: 578697.0000 - val_mae: 550.2194\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 579100.8750 - mae: 550.5806 - val_loss: 576471.0625 - val_mae: 551.5660\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576402.5000 - mae: 549.2357 - val_loss: 573975.3750 - val_mae: 547.5920\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574481.0625 - mae: 548.1070 - val_loss: 572612.0625 - val_mae: 548.5382\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 573742.6875 - mae: 547.9491 - val_loss: 570832.3125 - val_mae: 546.0199\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572504.9375 - mae: 547.1552 - val_loss: 570190.0625 - val_mae: 547.2885\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571317.6875 - mae: 546.7484 - val_loss: 569901.9375 - val_mae: 547.8585\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570814.6250 - mae: 546.9609 - val_loss: 568844.6250 - val_mae: 544.9670\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570233.1250 - mae: 546.1196 - val_loss: 568402.1250 - val_mae: 545.7424\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569937.6250 - mae: 545.9680 - val_loss: 567874.5000 - val_mae: 546.5875\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 569574.3750 - mae: 545.8348 - val_loss: 567405.0000 - val_mae: 545.8970\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 568950.8750 - mae: 545.5112 - val_loss: 567201.1875 - val_mae: 546.2207\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 568437.3125 - mae: 545.5962 - val_loss: 566694.5000 - val_mae: 544.0480\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567923.8125 - mae: 545.0237 - val_loss: 566558.6875 - val_mae: 546.1218\n",
      "Epoch 89/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 567902.3750 - mae: 545.3937 - val_loss: 566025.5625 - val_mae: 544.7967\n",
      "Epoch 90/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 567527.0000 - mae: 544.8330 - val_loss: 565972.0625 - val_mae: 543.6653\n",
      "Epoch 91/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 567474.3750 - mae: 545.0609 - val_loss: 565915.3750 - val_mae: 542.1315\n",
      "Epoch 92/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 566803.4375 - mae: 544.5300 - val_loss: 565555.3125 - val_mae: 543.8666\n",
      "Epoch 93/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566982.6875 - mae: 544.9567 - val_loss: 564776.4375 - val_mae: 543.4560\n",
      "Epoch 94/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566702.5000 - mae: 544.1083 - val_loss: 564935.7500 - val_mae: 545.7129\n",
      "Epoch 95/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566390.1250 - mae: 544.6342 - val_loss: 564397.8125 - val_mae: 543.7845\n",
      "Epoch 96/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565857.9375 - mae: 544.2918 - val_loss: 564246.0000 - val_mae: 544.2065\n",
      "Epoch 97/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 565445.3750 - mae: 543.8582 - val_loss: 563812.6250 - val_mae: 544.8185\n",
      "Epoch 98/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565381.4375 - mae: 543.7405 - val_loss: 563547.5625 - val_mae: 542.7755\n",
      "Epoch 99/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565011.7500 - mae: 543.7214 - val_loss: 563112.9375 - val_mae: 542.7052\n",
      "Epoch 100/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 565007.3125 - mae: 543.6065 - val_loss: 562867.6875 - val_mae: 542.2179\n",
      "Epoch 101/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564278.3750 - mae: 543.5042 - val_loss: 563027.0000 - val_mae: 541.6829\n",
      "Epoch 102/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564074.2500 - mae: 542.9619 - val_loss: 562836.1250 - val_mae: 540.3231\n",
      "Epoch 103/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564163.6875 - mae: 543.1915 - val_loss: 561950.9375 - val_mae: 541.7446\n",
      "Epoch 104/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 563688.0000 - mae: 542.6317 - val_loss: 562559.1875 - val_mae: 544.5948\n",
      "Epoch 105/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563618.8125 - mae: 543.1130 - val_loss: 561940.6250 - val_mae: 542.2532\n",
      "Epoch 106/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 563331.0000 - mae: 542.9305 - val_loss: 561506.3125 - val_mae: 541.7744\n",
      "Epoch 107/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 563426.1875 - mae: 542.4374 - val_loss: 561234.2500 - val_mae: 540.9367\n",
      "Epoch 108/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 562742.7500 - mae: 542.7822 - val_loss: 561487.8750 - val_mae: 539.9570\n",
      "Epoch 109/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562715.8125 - mae: 542.3366 - val_loss: 561196.3125 - val_mae: 539.7139\n",
      "Epoch 110/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562443.9375 - mae: 541.9709 - val_loss: 561327.3750 - val_mae: 544.1532\n",
      "Epoch 111/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 562327.7500 - mae: 541.9734 - val_loss: 560431.8125 - val_mae: 542.2560\n",
      "Epoch 112/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 562155.5625 - mae: 542.3085 - val_loss: 560795.6250 - val_mae: 540.4675\n",
      "Epoch 113/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561954.0000 - mae: 541.5197 - val_loss: 560543.0625 - val_mae: 542.4897\n",
      "Epoch 114/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 562006.0000 - mae: 541.8598 - val_loss: 560037.1875 - val_mae: 542.1186\n",
      "Epoch 115/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 561522.3750 - mae: 541.6900 - val_loss: 559706.7500 - val_mae: 540.7957\n",
      "Epoch 116/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561297.5000 - mae: 541.5302 - val_loss: 559820.8750 - val_mae: 539.7600\n",
      "Epoch 117/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 561413.5625 - mae: 541.1725 - val_loss: 559335.8750 - val_mae: 541.2432\n",
      "Epoch 118/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560980.0000 - mae: 541.4384 - val_loss: 559658.6250 - val_mae: 538.3648\n",
      "Epoch 119/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560573.3750 - mae: 540.8829 - val_loss: 559461.6875 - val_mae: 538.5513\n",
      "Epoch 120/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560702.3750 - mae: 540.6942 - val_loss: 559252.9375 - val_mae: 542.4330\n",
      "Epoch 121/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560943.1875 - mae: 542.1349 - val_loss: 558670.4375 - val_mae: 539.2827\n",
      "Epoch 122/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 560578.5000 - mae: 540.7461 - val_loss: 558786.5000 - val_mae: 540.7416\n",
      "Epoch 123/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 560297.3750 - mae: 541.0967 - val_loss: 558676.0000 - val_mae: 538.6364\n",
      "Epoch 124/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 560034.9375 - mae: 540.5498 - val_loss: 558398.8750 - val_mae: 539.8051\n",
      "Epoch 125/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 560130.0000 - mae: 541.0785 - val_loss: 558004.1250 - val_mae: 539.8773\n",
      "Epoch 126/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559522.1875 - mae: 540.2236 - val_loss: 557738.0625 - val_mae: 539.0807\n",
      "Epoch 127/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 559321.0625 - mae: 540.1747 - val_loss: 557047.3125 - val_mae: 538.2580\n",
      "Epoch 128/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 558649.8750 - mae: 539.7294 - val_loss: 556750.8125 - val_mae: 540.8387\n",
      "Epoch 129/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 557910.9375 - mae: 539.9467 - val_loss: 555988.3125 - val_mae: 538.6609\n",
      "Epoch 130/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557490.5000 - mae: 539.2535 - val_loss: 556584.7500 - val_mae: 542.0959\n",
      "Epoch 131/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 557457.6250 - mae: 539.4292 - val_loss: 555318.1250 - val_mae: 539.6637\n",
      "Epoch 132/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556929.1250 - mae: 539.0883 - val_loss: 554762.1250 - val_mae: 537.3380\n",
      "Epoch 133/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 556125.6875 - mae: 538.6483 - val_loss: 554930.3125 - val_mae: 538.6603\n",
      "Epoch 134/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 556467.0625 - mae: 539.0809 - val_loss: 554737.6875 - val_mae: 536.4051\n",
      "Epoch 135/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 555971.3750 - mae: 538.4716 - val_loss: 554599.1875 - val_mae: 539.6292\n",
      "Epoch 136/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 555808.1875 - mae: 538.7205 - val_loss: 554191.5625 - val_mae: 536.3366\n",
      "Epoch 137/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 555573.6250 - mae: 538.5401 - val_loss: 553560.3125 - val_mae: 537.2588\n",
      "Epoch 138/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 555179.8750 - mae: 537.9020 - val_loss: 553726.8125 - val_mae: 539.1027\n",
      "Epoch 139/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 554810.1250 - mae: 538.0825 - val_loss: 553545.1250 - val_mae: 535.9965\n",
      "Epoch 140/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 554785.6875 - mae: 537.7757 - val_loss: 552776.6250 - val_mae: 536.2502\n",
      "Epoch 141/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 554474.8125 - mae: 537.8979 - val_loss: 553042.1250 - val_mae: 535.4434\n",
      "Epoch 142/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 554186.1250 - mae: 537.5397 - val_loss: 552324.9375 - val_mae: 536.0395\n",
      "Epoch 143/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553991.3125 - mae: 537.2284 - val_loss: 552115.6875 - val_mae: 537.3913\n",
      "Epoch 144/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553819.0625 - mae: 536.9793 - val_loss: 552843.6875 - val_mae: 540.3727\n",
      "Epoch 145/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553624.1875 - mae: 537.2380 - val_loss: 551962.5000 - val_mae: 537.8605\n",
      "Epoch 146/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553599.6250 - mae: 537.7317 - val_loss: 551578.2500 - val_mae: 535.0362\n",
      "Epoch 147/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553138.3750 - mae: 536.9846 - val_loss: 551282.0625 - val_mae: 535.9849\n",
      "Epoch 148/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553029.8750 - mae: 537.2765 - val_loss: 551673.4375 - val_mae: 538.5808\n",
      "Epoch 149/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 552726.5625 - mae: 536.7574 - val_loss: 551386.5000 - val_mae: 538.1117\n",
      "Epoch 150/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 552481.9375 - mae: 536.7247 - val_loss: 551037.4375 - val_mae: 535.0549\n",
      "Epoch 151/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 552483.5000 - mae: 536.7471 - val_loss: 550855.5000 - val_mae: 535.4574\n",
      "Epoch 152/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 552409.3125 - mae: 536.5938 - val_loss: 550538.7500 - val_mae: 536.3060\n",
      "Epoch 153/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 552089.3125 - mae: 536.3801 - val_loss: 550546.1875 - val_mae: 535.3143\n",
      "Epoch 154/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 552020.0625 - mae: 536.3330 - val_loss: 550387.5000 - val_mae: 536.8010\n",
      "Epoch 155/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551794.7500 - mae: 536.4174 - val_loss: 550260.1875 - val_mae: 536.1005\n",
      "Epoch 156/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551721.4375 - mae: 536.6297 - val_loss: 550726.0000 - val_mae: 533.7220\n",
      "Epoch 157/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551635.8125 - mae: 536.2947 - val_loss: 550053.5000 - val_mae: 536.0430\n",
      "Epoch 158/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551580.9375 - mae: 536.2788 - val_loss: 550099.0000 - val_mae: 535.8056\n",
      "Epoch 159/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 551413.3125 - mae: 536.2303 - val_loss: 550058.0000 - val_mae: 534.7168\n",
      "Epoch 160/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551440.8750 - mae: 535.8373 - val_loss: 550338.8125 - val_mae: 537.4484\n",
      "Epoch 161/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551412.1250 - mae: 536.1024 - val_loss: 549533.1250 - val_mae: 535.8854\n",
      "Epoch 162/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551130.1250 - mae: 536.2069 - val_loss: 549919.6875 - val_mae: 533.6946\n",
      "Epoch 163/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551130.6250 - mae: 535.7578 - val_loss: 549802.8750 - val_mae: 537.7472\n",
      "Epoch 164/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551027.7500 - mae: 536.2585 - val_loss: 549815.3125 - val_mae: 534.4625\n",
      "Epoch 165/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 551083.6875 - mae: 536.0745 - val_loss: 549337.3125 - val_mae: 534.7731\n",
      "Epoch 166/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 551180.6875 - mae: 536.0923 - val_loss: 549267.1250 - val_mae: 535.3394\n",
      "Epoch 167/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550960.3125 - mae: 536.2071 - val_loss: 549189.1250 - val_mae: 534.7162\n",
      "Epoch 168/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550921.4375 - mae: 535.9183 - val_loss: 549210.0000 - val_mae: 534.2213\n",
      "Epoch 169/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550856.3750 - mae: 535.8734 - val_loss: 549329.8750 - val_mae: 536.8112\n",
      "Epoch 170/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550419.5000 - mae: 536.3141 - val_loss: 551009.6250 - val_mae: 531.7499\n",
      "Epoch 171/250\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 550934.3750 - mae: 535.7761 - val_loss: 548868.0625 - val_mae: 533.9335\n",
      "Epoch 172/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550365.6250 - mae: 535.2477 - val_loss: 550225.9375 - val_mae: 539.7935\n",
      "Epoch 173/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550339.6250 - mae: 536.0809 - val_loss: 548947.8125 - val_mae: 533.9457\n",
      "Epoch 174/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550222.3750 - mae: 535.5713 - val_loss: 549172.4375 - val_mae: 536.3520\n",
      "Epoch 175/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 550170.3125 - mae: 536.1192 - val_loss: 548430.8125 - val_mae: 534.6733\n",
      "Epoch 176/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550454.0000 - mae: 535.9218 - val_loss: 548860.7500 - val_mae: 532.9062\n",
      "Epoch 177/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550169.6875 - mae: 535.2391 - val_loss: 548360.3125 - val_mae: 535.0158\n",
      "Epoch 178/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550174.8750 - mae: 535.6785 - val_loss: 548265.8750 - val_mae: 534.3122\n",
      "Epoch 179/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 550212.0625 - mae: 535.4767 - val_loss: 548266.0000 - val_mae: 534.3569\n",
      "Epoch 180/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 549918.1250 - mae: 535.1760 - val_loss: 548870.4375 - val_mae: 537.0117\n",
      "Epoch 1/250\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 35804876.0000 - mae: 5827.6196 - val_loss: 30173742.0000 - val_mae: 5350.8062\n",
      "Epoch 2/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 21876872.0000 - mae: 4502.2529 - val_loss: 13786398.0000 - val_mae: 3544.6899\n",
      "Epoch 3/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 8219281.5000 - mae: 2582.9585 - val_loss: 4136634.0000 - val_mae: 1722.8423\n",
      "Epoch 4/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 2427636.5000 - mae: 1225.6781 - val_loss: 1411834.5000 - val_mae: 887.4312\n",
      "Epoch 5/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 1122306.2500 - mae: 777.9387 - val_loss: 952690.0625 - val_mae: 713.8889\n",
      "Epoch 6/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 889532.7500 - mae: 692.6797 - val_loss: 839557.5625 - val_mae: 674.1216\n",
      "Epoch 7/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 809856.3125 - mae: 664.3599 - val_loss: 781149.7500 - val_mae: 654.1055\n",
      "Epoch 8/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 763771.6250 - mae: 646.6839 - val_loss: 744899.6250 - val_mae: 640.9632\n",
      "Epoch 9/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 733721.3750 - mae: 634.8699 - val_loss: 720069.5000 - val_mae: 628.1819\n",
      "Epoch 10/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 712736.9375 - mae: 625.4420 - val_loss: 702088.2500 - val_mae: 619.8671\n",
      "Epoch 11/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 698239.9375 - mae: 617.9719 - val_loss: 690218.1250 - val_mae: 614.2177\n",
      "Epoch 12/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 688077.0000 - mae: 612.7339 - val_loss: 682082.2500 - val_mae: 609.4009\n",
      "Epoch 13/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 680590.8125 - mae: 609.0990 - val_loss: 675402.6875 - val_mae: 606.9173\n",
      "Epoch 14/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 674466.8125 - mae: 605.8494 - val_loss: 669323.3750 - val_mae: 604.8257\n",
      "Epoch 15/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 669086.3750 - mae: 604.0925 - val_loss: 664534.7500 - val_mae: 599.9144\n",
      "Epoch 16/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 664758.9375 - mae: 601.0299 - val_loss: 660534.4375 - val_mae: 599.3293\n",
      "Epoch 17/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 660742.8125 - mae: 599.7271 - val_loss: 656910.5625 - val_mae: 599.4274\n",
      "Epoch 18/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 656878.2500 - mae: 597.6481 - val_loss: 652890.8125 - val_mae: 594.8098\n",
      "Epoch 19/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 652756.7500 - mae: 595.0440 - val_loss: 648182.3750 - val_mae: 592.8116\n",
      "Epoch 20/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 648220.2500 - mae: 592.6902 - val_loss: 643873.5000 - val_mae: 590.3298\n",
      "Epoch 21/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 644542.6875 - mae: 590.5373 - val_loss: 640781.2500 - val_mae: 590.8437\n",
      "Epoch 22/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 641162.4375 - mae: 588.8990 - val_loss: 636888.8750 - val_mae: 587.4495\n",
      "Epoch 23/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 637730.0625 - mae: 587.5687 - val_loss: 635107.9375 - val_mae: 585.3103\n",
      "Epoch 24/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 635358.3750 - mae: 585.6701 - val_loss: 631767.6875 - val_mae: 584.9512\n",
      "Epoch 25/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 633170.0000 - mae: 585.3013 - val_loss: 630226.8750 - val_mae: 583.8933\n",
      "Epoch 26/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 630579.1250 - mae: 583.8525 - val_loss: 627628.6875 - val_mae: 581.9376\n",
      "Epoch 27/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 628554.2500 - mae: 582.2859 - val_loss: 626818.5000 - val_mae: 585.1692\n",
      "Epoch 28/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 626068.8750 - mae: 581.4861 - val_loss: 622815.9375 - val_mae: 581.2791\n",
      "Epoch 29/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 621864.8750 - mae: 579.0843 - val_loss: 618068.6250 - val_mae: 575.2585\n",
      "Epoch 30/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 617709.1250 - mae: 576.3055 - val_loss: 613968.7500 - val_mae: 576.6985\n",
      "Epoch 31/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 613610.3750 - mae: 574.1742 - val_loss: 610500.7500 - val_mae: 573.2148\n",
      "Epoch 32/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 610727.8125 - mae: 572.7795 - val_loss: 607070.2500 - val_mae: 569.5754\n",
      "Epoch 33/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 607625.4375 - mae: 570.6840 - val_loss: 606481.1250 - val_mae: 566.6091\n",
      "Epoch 34/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 605303.7500 - mae: 569.4076 - val_loss: 601976.6875 - val_mae: 566.6506\n",
      "Epoch 35/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 602804.1875 - mae: 568.3677 - val_loss: 599977.0000 - val_mae: 565.6693\n",
      "Epoch 36/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 600793.4375 - mae: 567.3406 - val_loss: 598400.3750 - val_mae: 564.3600\n",
      "Epoch 37/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 598527.9375 - mae: 566.1292 - val_loss: 595888.6875 - val_mae: 564.4414\n",
      "Epoch 38/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 596469.7500 - mae: 564.9996 - val_loss: 593793.8750 - val_mae: 565.4734\n",
      "Epoch 39/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 594628.9375 - mae: 564.2560 - val_loss: 591877.8125 - val_mae: 560.5267\n",
      "Epoch 40/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 592280.5625 - mae: 562.8751 - val_loss: 588778.6250 - val_mae: 561.2874\n",
      "Epoch 41/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 589503.3750 - mae: 561.1246 - val_loss: 585745.9375 - val_mae: 558.7855\n",
      "Epoch 42/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 586615.6250 - mae: 559.6723 - val_loss: 583306.6250 - val_mae: 558.9396\n",
      "Epoch 43/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 584504.1875 - mae: 558.8651 - val_loss: 580996.3750 - val_mae: 555.9340\n",
      "Epoch 44/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 581655.8750 - mae: 557.5547 - val_loss: 579064.0000 - val_mae: 555.5474\n",
      "Epoch 45/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 580496.7500 - mae: 556.5442 - val_loss: 577873.6250 - val_mae: 555.6747\n",
      "Epoch 46/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 578902.5625 - mae: 556.1861 - val_loss: 575937.6250 - val_mae: 554.3804\n",
      "Epoch 47/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 577581.2500 - mae: 555.2217 - val_loss: 574359.4375 - val_mae: 554.9478\n",
      "Epoch 48/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 576350.1875 - mae: 554.6948 - val_loss: 573609.4375 - val_mae: 554.7764\n",
      "Epoch 49/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 574539.3750 - mae: 554.0446 - val_loss: 572111.8125 - val_mae: 551.1651\n",
      "Epoch 50/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 573062.7500 - mae: 552.9479 - val_loss: 572626.3125 - val_mae: 555.8141\n",
      "Epoch 51/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 572485.6250 - mae: 553.0449 - val_loss: 569963.8125 - val_mae: 551.7565\n",
      "Epoch 52/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 571517.8125 - mae: 552.5947 - val_loss: 569142.3125 - val_mae: 549.8681\n",
      "Epoch 53/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 570606.6875 - mae: 551.8325 - val_loss: 568436.0625 - val_mae: 548.1419\n",
      "Epoch 54/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 569149.3750 - mae: 550.5696 - val_loss: 569975.1875 - val_mae: 556.4462\n",
      "Epoch 55/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 568856.0000 - mae: 550.7958 - val_loss: 566225.7500 - val_mae: 550.7114\n",
      "Epoch 56/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 567275.3750 - mae: 549.9643 - val_loss: 564837.4375 - val_mae: 548.2379\n",
      "Epoch 57/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 566224.8125 - mae: 549.1302 - val_loss: 564229.3125 - val_mae: 549.6035\n",
      "Epoch 58/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 564936.6250 - mae: 548.6087 - val_loss: 563830.8750 - val_mae: 549.6979\n",
      "Epoch 59/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 564449.6875 - mae: 548.3142 - val_loss: 561849.4375 - val_mae: 547.1387\n",
      "Epoch 60/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 563382.6250 - mae: 547.6481 - val_loss: 562142.3750 - val_mae: 544.8082\n",
      "Epoch 61/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 562582.3750 - mae: 546.8207 - val_loss: 560522.5625 - val_mae: 546.9640\n",
      "Epoch 62/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 561801.8750 - mae: 546.5557 - val_loss: 559458.9375 - val_mae: 544.9644\n",
      "Epoch 63/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 561202.0000 - mae: 546.1019 - val_loss: 558836.8125 - val_mae: 546.0140\n",
      "Epoch 64/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 560874.3125 - mae: 545.9573 - val_loss: 558811.8750 - val_mae: 543.4069\n",
      "Epoch 65/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 560343.8125 - mae: 545.7853 - val_loss: 557924.0625 - val_mae: 543.9828\n",
      "Epoch 66/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 559721.0625 - mae: 545.1558 - val_loss: 556889.0000 - val_mae: 543.5927\n",
      "Epoch 67/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 558961.0000 - mae: 544.9416 - val_loss: 556948.9375 - val_mae: 543.4276\n",
      "Epoch 68/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 558341.6250 - mae: 543.9612 - val_loss: 556061.0000 - val_mae: 545.1345\n",
      "Epoch 69/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557673.4375 - mae: 544.3901 - val_loss: 556450.6875 - val_mae: 545.6101\n",
      "Epoch 70/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557491.2500 - mae: 544.5057 - val_loss: 556728.2500 - val_mae: 540.4480\n",
      "Epoch 71/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 557232.0000 - mae: 543.7826 - val_loss: 556286.4375 - val_mae: 540.5153\n",
      "Epoch 72/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556724.4375 - mae: 543.5009 - val_loss: 554608.5625 - val_mae: 542.5555\n",
      "Epoch 73/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556735.5625 - mae: 543.4550 - val_loss: 554068.8125 - val_mae: 543.8290\n",
      "Epoch 74/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 556036.5625 - mae: 543.2449 - val_loss: 554039.3750 - val_mae: 541.2181\n",
      "Epoch 75/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555745.1250 - mae: 542.9127 - val_loss: 553856.4375 - val_mae: 542.7361\n",
      "Epoch 76/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555386.3750 - mae: 542.9731 - val_loss: 553487.6875 - val_mae: 542.2995\n",
      "Epoch 77/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555717.7500 - mae: 543.0376 - val_loss: 553135.5625 - val_mae: 541.2607\n",
      "Epoch 78/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 555068.7500 - mae: 542.6173 - val_loss: 553335.7500 - val_mae: 539.8095\n",
      "Epoch 79/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554575.5000 - mae: 541.8654 - val_loss: 553197.5000 - val_mae: 543.2888\n",
      "Epoch 80/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 554263.9375 - mae: 542.1076 - val_loss: 554287.6875 - val_mae: 544.4905\n",
      "Epoch 81/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 554719.0000 - mae: 542.6507 - val_loss: 551965.5625 - val_mae: 541.5805\n",
      "Epoch 82/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 554295.5625 - mae: 542.2535 - val_loss: 551812.6875 - val_mae: 540.5753\n",
      "Epoch 83/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553768.1875 - mae: 542.0081 - val_loss: 552212.3750 - val_mae: 539.8516\n",
      "Epoch 84/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553641.2500 - mae: 541.8148 - val_loss: 551783.0625 - val_mae: 541.6155\n",
      "Epoch 85/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553412.5625 - mae: 541.7210 - val_loss: 551417.3125 - val_mae: 540.7143\n",
      "Epoch 86/250\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 553276.3750 - mae: 541.1692 - val_loss: 551478.3750 - val_mae: 539.9211\n",
      "Epoch 87/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 553210.1250 - mae: 541.3917 - val_loss: 551335.8750 - val_mae: 541.2659\n",
      "Epoch 88/250\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 552700.3750 - mae: 541.6307 - val_loss: 551080.3750 - val_mae: 540.3538\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 38179148.0000 - mae: 6022.5352 - val_loss: 37312172.0000 - val_mae: 5953.3989\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 35397548.0000 - mae: 5796.2974 - val_loss: 33027138.0000 - val_mae: 5596.8950\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 30078742.0000 - mae: 5330.6772 - val_loss: 26872860.0000 - val_mae: 5030.7217\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 23558884.0000 - mae: 4687.0352 - val_loss: 20209518.0000 - val_mae: 4321.9565\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 17109262.0000 - mae: 3938.2756 - val_loss: 14129498.0000 - val_mae: 3547.0588\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 11597482.0000 - mae: 3166.7893 - val_loss: 9258502.0000 - val_mae: 2790.5564\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 7423235.0000 - mae: 2442.8035 - val_loss: 5793990.5000 - val_mae: 2102.7109\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 4608909.5000 - mae: 1807.0688 - val_loss: 3596824.5000 - val_mae: 1535.2572\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2903171.2500 - mae: 1323.6992 - val_loss: 2318057.5000 - val_mae: 1142.9746\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1927679.1250 - mae: 1023.6919 - val_loss: 1599424.2500 - val_mae: 926.2604\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1382180.5000 - mae: 865.3545 - val_loss: 1202211.1250 - val_mae: 814.5923\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1088837.8750 - mae: 781.0257 - val_loss: 994843.7500 - val_mae: 751.5543\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 935395.6875 - mae: 730.6678 - val_loss: 885314.1250 - val_mae: 712.5710\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 853703.2500 - mae: 699.3687 - val_loss: 824594.9375 - val_mae: 687.4341\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 806348.3750 - mae: 678.8248 - val_loss: 787593.5625 - val_mae: 670.2253\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 775830.1250 - mae: 663.6351 - val_loss: 762956.5625 - val_mae: 658.1472\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 754510.9375 - mae: 653.1657 - val_loss: 744464.1875 - val_mae: 647.9754\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 738309.0625 - mae: 644.9861 - val_loss: 729870.7500 - val_mae: 640.2654\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 725067.6250 - mae: 637.9891 - val_loss: 718111.6875 - val_mae: 634.6169\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 714202.8750 - mae: 632.0936 - val_loss: 708386.2500 - val_mae: 630.3666\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 705370.5625 - mae: 628.2299 - val_loss: 700134.3750 - val_mae: 626.5703\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 697507.1250 - mae: 624.3132 - val_loss: 692457.3750 - val_mae: 621.3883\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 690405.2500 - mae: 620.2490 - val_loss: 685581.0000 - val_mae: 617.6969\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 683842.2500 - mae: 617.0266 - val_loss: 679342.0625 - val_mae: 615.0941\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 677717.7500 - mae: 613.8337 - val_loss: 673842.2500 - val_mae: 612.8217\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 672474.8125 - mae: 611.5892 - val_loss: 668487.3750 - val_mae: 610.5015\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 667053.5000 - mae: 609.1422 - val_loss: 663416.0000 - val_mae: 606.7158\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 662188.2500 - mae: 606.5782 - val_loss: 658619.9375 - val_mae: 603.3515\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 657272.3125 - mae: 603.7964 - val_loss: 654249.1875 - val_mae: 600.9171\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 653349.4375 - mae: 601.3044 - val_loss: 650005.5000 - val_mae: 600.7023\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 649427.2500 - mae: 599.7232 - val_loss: 646296.6875 - val_mae: 599.2959\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 645807.8125 - mae: 597.8491 - val_loss: 642528.3125 - val_mae: 596.4985\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 642451.0625 - mae: 596.2060 - val_loss: 639639.8125 - val_mae: 593.3309\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 639448.0000 - mae: 593.7385 - val_loss: 636587.0000 - val_mae: 593.9336\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 636685.5625 - mae: 592.6233 - val_loss: 633487.0625 - val_mae: 590.9910\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 633662.2500 - mae: 590.5664 - val_loss: 631017.0625 - val_mae: 589.9601\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 631284.3125 - mae: 589.3423 - val_loss: 628490.0000 - val_mae: 588.5925\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 628787.8750 - mae: 587.7907 - val_loss: 626276.5625 - val_mae: 586.7188\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 626464.3125 - mae: 586.1554 - val_loss: 624234.3125 - val_mae: 586.4309\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 624515.8750 - mae: 585.2191 - val_loss: 622213.8125 - val_mae: 584.8233\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 622338.6250 - mae: 584.2448 - val_loss: 620360.2500 - val_mae: 583.7456\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 621024.6875 - mae: 582.5029 - val_loss: 618356.1250 - val_mae: 581.1515\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 618891.8750 - mae: 581.4174 - val_loss: 616888.6875 - val_mae: 579.4945\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 617722.0625 - mae: 580.0593 - val_loss: 615472.3750 - val_mae: 580.3608\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 616382.4375 - mae: 579.8701 - val_loss: 614260.6250 - val_mae: 578.3293\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 615027.3125 - mae: 578.6999 - val_loss: 613668.6875 - val_mae: 579.5360\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 614095.6875 - mae: 578.6734 - val_loss: 612514.7500 - val_mae: 577.2312\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 613224.4375 - mae: 577.8466 - val_loss: 611748.1875 - val_mae: 577.2125\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 612438.0000 - mae: 577.6671 - val_loss: 610859.1875 - val_mae: 575.0801\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 611945.3125 - mae: 576.4039 - val_loss: 609804.6250 - val_mae: 575.7805\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 611044.8125 - mae: 576.2734 - val_loss: 609301.0625 - val_mae: 576.8796\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 610442.5625 - mae: 576.7205 - val_loss: 608522.9375 - val_mae: 575.6319\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 609662.7500 - mae: 576.0982 - val_loss: 608061.0625 - val_mae: 574.0795\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 609438.3750 - mae: 575.7292 - val_loss: 607348.0000 - val_mae: 575.0048\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 608505.5000 - mae: 575.0873 - val_loss: 606802.0625 - val_mae: 575.0703\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 607876.1875 - mae: 575.1762 - val_loss: 606199.1875 - val_mae: 572.7811\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 607381.3125 - mae: 574.2333 - val_loss: 605393.4375 - val_mae: 573.6955\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 606396.1250 - mae: 574.2985 - val_loss: 604452.4375 - val_mae: 573.5074\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 605601.7500 - mae: 573.7566 - val_loss: 603649.8750 - val_mae: 572.7889\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 604519.7500 - mae: 572.9550 - val_loss: 603436.4375 - val_mae: 572.0128\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 604221.9375 - mae: 572.4525 - val_loss: 603230.8750 - val_mae: 574.8300\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 603522.3750 - mae: 572.5719 - val_loss: 602585.5625 - val_mae: 574.1120\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602970.0000 - mae: 572.2172 - val_loss: 601718.3125 - val_mae: 572.1556\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602846.5625 - mae: 571.8671 - val_loss: 601034.3750 - val_mae: 570.7177\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 602446.4375 - mae: 571.8062 - val_loss: 600497.7500 - val_mae: 570.8398\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 601534.8125 - mae: 570.8985 - val_loss: 600717.1250 - val_mae: 572.7598\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 601411.5000 - mae: 571.4993 - val_loss: 599652.9375 - val_mae: 570.4973\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 601056.8750 - mae: 571.0119 - val_loss: 599537.0000 - val_mae: 569.0970\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 600727.7500 - mae: 570.2230 - val_loss: 598896.9375 - val_mae: 569.7967\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 600302.3750 - mae: 571.0283 - val_loss: 598822.0625 - val_mae: 568.6582\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599934.0000 - mae: 570.0115 - val_loss: 598360.1250 - val_mae: 570.3282\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599584.7500 - mae: 570.1996 - val_loss: 597941.0625 - val_mae: 569.4940\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599026.1250 - mae: 569.7230 - val_loss: 597716.1250 - val_mae: 569.0259\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598845.6875 - mae: 569.7282 - val_loss: 597587.0625 - val_mae: 567.9658\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598654.6875 - mae: 569.3922 - val_loss: 597062.9375 - val_mae: 568.5118\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598338.3125 - mae: 569.2916 - val_loss: 596720.0625 - val_mae: 567.9206\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598013.1875 - mae: 568.9657 - val_loss: 596731.1875 - val_mae: 569.3203\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 597366.7500 - mae: 569.0364 - val_loss: 597529.7500 - val_mae: 565.9103\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 597649.9375 - mae: 568.5159 - val_loss: 596009.3125 - val_mae: 567.3657\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 597316.0625 - mae: 568.3909 - val_loss: 595866.3750 - val_mae: 569.1779\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 596610.6875 - mae: 568.3842 - val_loss: 595684.3750 - val_mae: 569.0858\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 596801.6875 - mae: 568.8633 - val_loss: 595856.1250 - val_mae: 565.8239\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 596525.6250 - mae: 568.0865 - val_loss: 595087.2500 - val_mae: 567.3484\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 596508.1875 - mae: 568.0350 - val_loss: 594934.7500 - val_mae: 568.5861\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 596279.6875 - mae: 568.3588 - val_loss: 594868.3750 - val_mae: 566.0061\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 595660.2500 - mae: 567.1689 - val_loss: 595591.0625 - val_mae: 570.9780\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 596250.7500 - mae: 568.2697 - val_loss: 594304.5000 - val_mae: 568.1146\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 595464.4375 - mae: 568.2465 - val_loss: 594178.2500 - val_mae: 567.3668\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595334.5625 - mae: 567.8502 - val_loss: 593955.7500 - val_mae: 566.2702\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595250.5625 - mae: 567.3172 - val_loss: 593748.5000 - val_mae: 567.5712\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 595133.5000 - mae: 567.4539 - val_loss: 593867.5625 - val_mae: 568.5281\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595090.0625 - mae: 567.2447 - val_loss: 593987.9375 - val_mae: 569.3154\n",
      "Epoch 1/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 37940456.0000 - mae: 6003.2866 - val_loss: 36457644.0000 - val_mae: 5885.0493\n",
      "Epoch 2/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 33400372.0000 - mae: 5629.6304 - val_loss: 29708870.0000 - val_mae: 5310.1123\n",
      "Epoch 3/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 25390542.0000 - mae: 4894.6235 - val_loss: 20916040.0000 - val_mae: 4433.9976\n",
      "Epoch 4/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 16752402.0000 - mae: 3927.9670 - val_loss: 12820500.0000 - val_mae: 3403.4407\n",
      "Epoch 5/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 9726680.0000 - mae: 2889.9670 - val_loss: 7032964.5000 - val_mae: 2392.3455\n",
      "Epoch 6/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 5210761.5000 - mae: 1970.0973 - val_loss: 3728433.5000 - val_mae: 1597.7678\n",
      "Epoch 7/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2849251.0000 - mae: 1345.0399 - val_loss: 2167849.5000 - val_mae: 1138.0647\n",
      "Epoch 8/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1797949.2500 - mae: 1012.6135 - val_loss: 1518099.1250 - val_mae: 916.6172\n",
      "Epoch 9/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 1364349.8750 - mae: 863.4303 - val_loss: 1243696.3750 - val_mae: 822.9533\n",
      "Epoch 10/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1170494.6250 - mae: 799.1927 - val_loss: 1105240.3750 - val_mae: 778.4230\n",
      "Epoch 11/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1060148.6250 - mae: 763.2420 - val_loss: 1016097.6875 - val_mae: 748.7903\n",
      "Epoch 12/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 983142.4375 - mae: 737.6940 - val_loss: 949960.1250 - val_mae: 725.2611\n",
      "Epoch 13/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 922856.5625 - mae: 715.4700 - val_loss: 894068.7500 - val_mae: 704.3171\n",
      "Epoch 14/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 871457.1250 - mae: 695.2520 - val_loss: 847905.9375 - val_mae: 686.3422\n",
      "Epoch 15/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 830239.6875 - mae: 679.1000 - val_loss: 810832.4375 - val_mae: 670.7715\n",
      "Epoch 16/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 796305.8750 - mae: 664.6685 - val_loss: 780506.0625 - val_mae: 657.2382\n",
      "Epoch 17/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 769055.4375 - mae: 652.9520 - val_loss: 755418.9375 - val_mae: 646.0034\n",
      "Epoch 18/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 745800.3125 - mae: 642.0753 - val_loss: 734351.3750 - val_mae: 637.0250\n",
      "Epoch 19/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 725099.9375 - mae: 632.5480 - val_loss: 713857.2500 - val_mae: 626.6766\n",
      "Epoch 20/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 706388.3750 - mae: 623.1056 - val_loss: 696344.1250 - val_mae: 618.4200\n",
      "Epoch 21/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 690335.5000 - mae: 614.9962 - val_loss: 682149.6875 - val_mae: 611.8047\n",
      "Epoch 22/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 678031.5625 - mae: 609.0901 - val_loss: 671507.5000 - val_mae: 604.7773\n",
      "Epoch 23/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 668723.7500 - mae: 603.8260 - val_loss: 663383.9375 - val_mae: 601.4464\n",
      "Epoch 24/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 661452.8125 - mae: 599.7129 - val_loss: 656951.7500 - val_mae: 597.5312\n",
      "Epoch 25/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 655673.0625 - mae: 596.2736 - val_loss: 651669.5625 - val_mae: 595.3069\n",
      "Epoch 26/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 651055.3750 - mae: 594.1637 - val_loss: 647409.1875 - val_mae: 592.2436\n",
      "Epoch 27/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 646954.7500 - mae: 590.9152 - val_loss: 643591.4375 - val_mae: 589.6584\n",
      "Epoch 28/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 643241.6250 - mae: 589.2332 - val_loss: 640275.0625 - val_mae: 586.6544\n",
      "Epoch 29/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 640095.7500 - mae: 586.2786 - val_loss: 637036.6875 - val_mae: 587.3192\n",
      "Epoch 30/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 636490.3125 - mae: 585.5534 - val_loss: 632878.5000 - val_mae: 582.0403\n",
      "Epoch 31/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 632004.2500 - mae: 582.2498 - val_loss: 628844.6250 - val_mae: 582.4412\n",
      "Epoch 32/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 628033.3125 - mae: 580.7889 - val_loss: 625119.5000 - val_mae: 576.3077\n",
      "Epoch 33/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 624642.0625 - mae: 577.7896 - val_loss: 620892.6250 - val_mae: 577.2845\n",
      "Epoch 34/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 620504.7500 - mae: 576.0135 - val_loss: 617211.4375 - val_mae: 574.3082\n",
      "Epoch 35/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 616563.3750 - mae: 573.3572 - val_loss: 613018.0000 - val_mae: 573.3652\n",
      "Epoch 36/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 611806.6875 - mae: 571.4434 - val_loss: 607760.2500 - val_mae: 569.3510\n",
      "Epoch 37/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 606869.2500 - mae: 568.7025 - val_loss: 603022.8125 - val_mae: 566.1375\n",
      "Epoch 38/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 603325.3125 - mae: 567.0156 - val_loss: 599738.0625 - val_mae: 564.6307\n",
      "Epoch 39/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 599855.3750 - mae: 565.2626 - val_loss: 597397.0625 - val_mae: 563.6357\n",
      "Epoch 40/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 598255.8750 - mae: 564.2029 - val_loss: 595627.0625 - val_mae: 562.5104\n",
      "Epoch 41/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 596293.5625 - mae: 563.2410 - val_loss: 594153.7500 - val_mae: 563.7936\n",
      "Epoch 42/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 595082.2500 - mae: 562.6949 - val_loss: 593299.7500 - val_mae: 564.0516\n",
      "Epoch 43/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 593953.1250 - mae: 562.2402 - val_loss: 591443.6875 - val_mae: 561.6872\n",
      "Epoch 44/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 592489.1875 - mae: 561.3471 - val_loss: 591163.1250 - val_mae: 564.1878\n",
      "Epoch 45/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 591710.1250 - mae: 561.3059 - val_loss: 589293.6250 - val_mae: 560.3845\n",
      "Epoch 46/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 590522.1250 - mae: 560.4210 - val_loss: 589100.1875 - val_mae: 562.9288\n",
      "Epoch 47/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 589567.2500 - mae: 560.3779 - val_loss: 587244.2500 - val_mae: 559.7199\n",
      "Epoch 48/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 588431.5000 - mae: 559.2352 - val_loss: 586085.4375 - val_mae: 559.4401\n",
      "Epoch 49/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 587215.4375 - mae: 558.9539 - val_loss: 584871.6875 - val_mae: 557.6472\n",
      "Epoch 50/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 585778.6250 - mae: 558.3171 - val_loss: 584623.9375 - val_mae: 555.2830\n",
      "Epoch 51/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 585153.3750 - mae: 557.1441 - val_loss: 583087.5625 - val_mae: 556.7789\n",
      "Epoch 52/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 584432.8750 - mae: 557.3194 - val_loss: 582497.1250 - val_mae: 555.8447\n",
      "Epoch 53/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582947.7500 - mae: 556.1828 - val_loss: 581087.6875 - val_mae: 554.8157\n",
      "Epoch 54/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 582369.8125 - mae: 555.6105 - val_loss: 580006.3125 - val_mae: 555.2194\n",
      "Epoch 55/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 581072.0000 - mae: 555.1468 - val_loss: 579355.4375 - val_mae: 554.0815\n",
      "Epoch 56/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 580335.3125 - mae: 554.3317 - val_loss: 578217.8125 - val_mae: 554.0439\n",
      "Epoch 57/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 579446.3750 - mae: 553.9286 - val_loss: 577619.5625 - val_mae: 554.3425\n",
      "Epoch 58/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 578770.2500 - mae: 553.5534 - val_loss: 576650.4375 - val_mae: 551.5208\n",
      "Epoch 59/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 577540.5000 - mae: 552.5374 - val_loss: 576266.5625 - val_mae: 554.2762\n",
      "Epoch 60/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 576833.7500 - mae: 552.3478 - val_loss: 574872.1875 - val_mae: 551.7195\n",
      "Epoch 61/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 576217.8125 - mae: 551.5564 - val_loss: 574228.5625 - val_mae: 551.8745\n",
      "Epoch 62/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 575230.8125 - mae: 551.6339 - val_loss: 573381.3750 - val_mae: 549.2463\n",
      "Epoch 63/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 574394.2500 - mae: 550.3939 - val_loss: 572871.7500 - val_mae: 548.8109\n",
      "Epoch 64/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 573991.4375 - mae: 549.9681 - val_loss: 572063.2500 - val_mae: 549.6887\n",
      "Epoch 65/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 573351.3750 - mae: 550.0717 - val_loss: 571288.2500 - val_mae: 549.5055\n",
      "Epoch 66/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 572658.1250 - mae: 549.4327 - val_loss: 570569.7500 - val_mae: 548.0712\n",
      "Epoch 67/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 571533.0000 - mae: 548.9844 - val_loss: 570102.2500 - val_mae: 547.2407\n",
      "Epoch 68/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 571416.8750 - mae: 548.3424 - val_loss: 569233.8750 - val_mae: 547.8616\n",
      "Epoch 69/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 570383.0000 - mae: 547.8561 - val_loss: 568585.3125 - val_mae: 547.8010\n",
      "Epoch 70/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 570155.4375 - mae: 547.9720 - val_loss: 568071.4375 - val_mae: 546.6402\n",
      "Epoch 71/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 569705.2500 - mae: 547.1983 - val_loss: 567565.7500 - val_mae: 545.9480\n",
      "Epoch 72/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 569215.6875 - mae: 546.7205 - val_loss: 567137.6875 - val_mae: 546.5656\n",
      "Epoch 73/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 568476.7500 - mae: 546.9185 - val_loss: 566849.8750 - val_mae: 544.8055\n",
      "Epoch 74/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 568139.1875 - mae: 546.4904 - val_loss: 566550.6875 - val_mae: 544.8147\n",
      "Epoch 75/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 567814.7500 - mae: 546.4091 - val_loss: 565921.2500 - val_mae: 544.6568\n",
      "Epoch 76/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 567319.2500 - mae: 545.6609 - val_loss: 565487.7500 - val_mae: 544.6473\n",
      "Epoch 77/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 566936.1250 - mae: 545.6782 - val_loss: 565077.1250 - val_mae: 545.4070\n",
      "Epoch 78/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 566871.6875 - mae: 545.4298 - val_loss: 564655.8750 - val_mae: 544.8604\n",
      "Epoch 79/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 566366.6250 - mae: 545.5392 - val_loss: 564641.3750 - val_mae: 545.7383\n",
      "Epoch 80/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 565850.0625 - mae: 545.3724 - val_loss: 564224.5000 - val_mae: 545.3538\n",
      "Epoch 81/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 565552.1250 - mae: 544.7487 - val_loss: 564191.6250 - val_mae: 546.3333\n",
      "Epoch 82/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 565279.9375 - mae: 544.9338 - val_loss: 563555.3125 - val_mae: 544.2318\n",
      "Epoch 83/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 564795.4375 - mae: 544.3654 - val_loss: 563575.5625 - val_mae: 545.6035\n",
      "Epoch 84/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 564856.9375 - mae: 544.9449 - val_loss: 562871.1250 - val_mae: 543.7168\n",
      "Epoch 85/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 564565.1875 - mae: 544.4211 - val_loss: 562693.5000 - val_mae: 543.0215\n",
      "Epoch 86/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 564122.8750 - mae: 544.0538 - val_loss: 562909.7500 - val_mae: 545.4402\n",
      "Epoch 87/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 564006.5625 - mae: 544.1924 - val_loss: 562461.0000 - val_mae: 543.5892\n",
      "Epoch 88/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 563876.4375 - mae: 544.3033 - val_loss: 561930.3750 - val_mae: 542.3804\n",
      "Epoch 89/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 563614.6875 - mae: 544.0527 - val_loss: 561764.9375 - val_mae: 542.5286\n",
      "Epoch 90/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 563317.2500 - mae: 543.5189 - val_loss: 561712.9375 - val_mae: 541.9059\n",
      "Epoch 91/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 563208.0625 - mae: 543.6025 - val_loss: 560855.1875 - val_mae: 541.7481\n",
      "Epoch 92/250\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 561826.1250 - mae: 543.1882 - val_loss: 560290.8125 - val_mae: 543.2446\n",
      "Epoch 93/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 561692.1250 - mae: 542.6697 - val_loss: 560215.5000 - val_mae: 544.4560\n",
      "Epoch 94/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 561349.0625 - mae: 543.2529 - val_loss: 559477.1250 - val_mae: 542.0938\n",
      "Epoch 95/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 561049.4375 - mae: 543.1953 - val_loss: 559460.1250 - val_mae: 540.7175\n",
      "Epoch 96/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 560870.1875 - mae: 542.1166 - val_loss: 559031.0000 - val_mae: 543.1389\n",
      "Epoch 97/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 560465.8125 - mae: 543.0887 - val_loss: 558793.8750 - val_mae: 541.1730\n",
      "Epoch 98/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 560230.3125 - mae: 542.2912 - val_loss: 558571.1250 - val_mae: 541.0703\n",
      "Epoch 99/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 559955.9375 - mae: 542.4963 - val_loss: 558303.8125 - val_mae: 542.2735\n",
      "Epoch 100/250\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 559586.9375 - mae: 542.0065 - val_loss: 558053.6875 - val_mae: 540.9149\n",
      "Epoch 101/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 559588.6250 - mae: 542.2667 - val_loss: 557916.1875 - val_mae: 540.5186\n",
      "Epoch 102/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 559233.3125 - mae: 541.8868 - val_loss: 557486.1875 - val_mae: 541.6165\n",
      "Epoch 103/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 559164.1875 - mae: 541.8602 - val_loss: 557300.7500 - val_mae: 541.6174\n",
      "Epoch 104/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 558753.0000 - mae: 542.1696 - val_loss: 557215.6250 - val_mae: 540.1381\n",
      "Epoch 105/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 558399.1875 - mae: 541.1525 - val_loss: 556995.1875 - val_mae: 541.0525\n",
      "Epoch 106/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 558530.5625 - mae: 541.5100 - val_loss: 556670.3125 - val_mae: 541.4380\n",
      "Epoch 107/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 558300.1875 - mae: 541.8824 - val_loss: 556564.1250 - val_mae: 539.8232\n",
      "Epoch 108/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 557791.6250 - mae: 541.2107 - val_loss: 556439.3750 - val_mae: 540.9099\n",
      "Epoch 109/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 557927.4375 - mae: 541.2742 - val_loss: 556383.1250 - val_mae: 542.2532\n",
      "Epoch 110/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 557422.3125 - mae: 541.6270 - val_loss: 556568.1250 - val_mae: 540.0101\n",
      "Epoch 111/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 557563.0000 - mae: 541.2340 - val_loss: 555805.7500 - val_mae: 540.3580\n",
      "Epoch 112/250\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 557515.1250 - mae: 541.4481 - val_loss: 556708.9375 - val_mae: 537.7451\n",
      "Epoch 113/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 557379.7500 - mae: 540.3964 - val_loss: 555554.8125 - val_mae: 541.0673\n",
      "Epoch 114/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 556818.1250 - mae: 541.1063 - val_loss: 555339.2500 - val_mae: 539.4926\n",
      "Epoch 115/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 556420.8125 - mae: 540.2607 - val_loss: 554988.5625 - val_mae: 540.5972\n",
      "Epoch 116/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 556173.8750 - mae: 539.9830 - val_loss: 554980.5000 - val_mae: 541.4364\n",
      "Epoch 117/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 556228.5000 - mae: 540.2328 - val_loss: 554632.5625 - val_mae: 539.9531\n",
      "Epoch 118/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 556004.0000 - mae: 540.1656 - val_loss: 554518.3125 - val_mae: 538.0688\n",
      "Epoch 119/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555713.3750 - mae: 539.8719 - val_loss: 554188.7500 - val_mae: 539.4125\n",
      "Epoch 120/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555463.8125 - mae: 539.7978 - val_loss: 553878.1250 - val_mae: 538.4774\n",
      "Epoch 121/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555523.8125 - mae: 539.4964 - val_loss: 553873.1250 - val_mae: 538.7050\n",
      "Epoch 122/250\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 555107.5625 - mae: 539.7248 - val_loss: 554266.8750 - val_mae: 538.8416\n"
     ]
    }
   ],
   "source": [
    "# MBGD - mse + adam\n",
    "\n",
    "result16_adam_dict = {\n",
    "    'units': [],\n",
    "    'batch_size': [],\n",
    "    'learning_rate': [],\n",
    "    'minimum_mae_error': []\n",
    "}\n",
    "\n",
    "for units in para_dict['hidden_units']:\n",
    "    for b_size in para_dict['batch_size']:\n",
    "        for rate in para_dict['learning_rate'][0]:\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor = 'val_mae',\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "            optimizer = Adam(learning_rate = rate)\n",
    "\n",
    "            model = create_model(columns = x_columns, units = units, loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "            best_model = model.fit(\n",
    "                x_train, y_train,\n",
    "                validation_data = (x_test, y_test),\n",
    "                batch_size = b_size,\n",
    "                epochs = 250,\n",
    "                callbacks = [early_stopping]\n",
    "            )\n",
    "\n",
    "            min_mae = early_stopping.best\n",
    "\n",
    "            result16_adam_dict['units'].append(units)\n",
    "            result16_adam_dict['batch_size'].append(b_size)\n",
    "            result16_adam_dict['learning_rate'].append(rate)\n",
    "            result16_adam_dict['minimum_mae_error'].append(min_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>minimum_mae_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>605.518738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>547.732910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>549.478882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>530.639160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>536.969604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>568.684448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>552.380005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>542.173035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>538.955261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>554.738281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>546.900146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>536.592224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008</td>\n",
       "      <td>535.893250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>535.445923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008</td>\n",
       "      <td>531.749939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>539.809509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008</td>\n",
       "      <td>565.823853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>537.745117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  batch_size  learning_rate  minimum_mae_error\n",
       "0       7          16          0.008         605.518738\n",
       "1       7          16          0.010         547.732910\n",
       "2       7          32          0.008         549.478882\n",
       "3       7          32          0.010         530.639160\n",
       "4       7          64          0.008         536.969604\n",
       "5       7          64          0.010         568.684448\n",
       "6       8          16          0.008         552.380005\n",
       "7       8          16          0.010         542.173035\n",
       "8       8          32          0.008         538.955261\n",
       "9       8          32          0.010         554.738281\n",
       "10      8          64          0.008         546.900146\n",
       "11      8          64          0.010         536.592224\n",
       "12      9          16          0.008         535.893250\n",
       "13      9          16          0.010         535.445923\n",
       "14      9          32          0.008         531.749939\n",
       "15      9          32          0.010         539.809509\n",
       "16      9          64          0.008         565.823853\n",
       "17      9          64          0.010         537.745117"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result16_adam_df = pd.DataFrame(result16_adam_dict)\n",
    "\n",
    "result16_adam_df.to_csv('result16_adam.csv')\n",
    "\n",
    "result16_adam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_154 (Dense)           (None, 8)                 272       \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 281 (1.10 KB)\n",
      "Trainable params: 281 (1.10 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# read data with 33 features\n",
    "train = pd.read_csv('full_hdb_perSqm_train_f34.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "test = pd.read_csv('full_hdb_perSqm_test_f34.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# train set\n",
    "y_train = train['resale_price_per_sqm']\n",
    "x_train = train.drop(['resale_price_per_sqm'], axis = 1)\n",
    "\n",
    "# test set\n",
    "y_test = test['resale_price_per_sqm']\n",
    "x_test = test.drop(['resale_price_per_sqm'], axis = 1).astype(float)\n",
    "\n",
    "# standardization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_columns = list(train.columns)\n",
    "x_columns.remove('resale_price_per_sqm')\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns = x_columns)\n",
    "\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "x_test = pd.DataFrame(x_test, columns = x_columns)\n",
    "\n",
    "'''\n",
    "create best NN models with selected parameters\n",
    "'''\n",
    "def create_best_model(columns = x_columns, units = 8, activation = 'relu', loss = 'mae', metrics = 'mae'):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(units, input_shape = (len(columns), ), activation = activation),\n",
    "        Dense(1, activation = activation)\n",
    "    ])\n",
    "\n",
    "    optimizer = optimizer = SGD(learning_rate = 0.01)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = loss,\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_best_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 6038.3887 - mae: 6038.3887 - val_loss: 5925.5220 - val_mae: 5925.5220\n",
      "Epoch 2/500\n",
      "109/432 [======>.......................] - ETA: 0s - loss: 5651.5283 - mae: 5651.5283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94220\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 1s 2ms/step - loss: 2529.6265 - mae: 2529.6265 - val_loss: 514.4969 - val_mae: 514.4969\n",
      "Epoch 3/500\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 504.8059 - mae: 504.8059 - val_loss: 503.3694 - val_mae: 503.3694\n",
      "Epoch 4/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 496.3177 - mae: 496.3177 - val_loss: 492.8954 - val_mae: 492.8954\n",
      "Epoch 5/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 487.7502 - mae: 487.7502 - val_loss: 490.4588 - val_mae: 490.4588\n",
      "Epoch 6/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 482.4987 - mae: 482.4987 - val_loss: 483.9746 - val_mae: 483.9746\n",
      "Epoch 7/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 473.0598 - mae: 473.0598 - val_loss: 466.4129 - val_mae: 466.4129\n",
      "Epoch 8/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 462.9427 - mae: 462.9427 - val_loss: 463.4135 - val_mae: 463.4135\n",
      "Epoch 9/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 453.5969 - mae: 453.5969 - val_loss: 452.2038 - val_mae: 452.2038\n",
      "Epoch 10/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 447.6769 - mae: 447.6769 - val_loss: 453.4998 - val_mae: 453.4998\n",
      "Epoch 11/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 443.3969 - mae: 443.3969 - val_loss: 447.4207 - val_mae: 447.4207\n",
      "Epoch 12/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 439.0936 - mae: 439.0936 - val_loss: 445.8114 - val_mae: 445.8114\n",
      "Epoch 13/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 436.9099 - mae: 436.9099 - val_loss: 440.9323 - val_mae: 440.9323\n",
      "Epoch 14/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 434.7436 - mae: 434.7436 - val_loss: 439.5726 - val_mae: 439.5726\n",
      "Epoch 15/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 432.3500 - mae: 432.3500 - val_loss: 442.5386 - val_mae: 442.5386\n",
      "Epoch 16/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 431.4470 - mae: 431.4470 - val_loss: 442.5514 - val_mae: 442.5514\n",
      "Epoch 17/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 430.4885 - mae: 430.4885 - val_loss: 445.0448 - val_mae: 445.0448\n",
      "Epoch 18/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 429.9117 - mae: 429.9117 - val_loss: 443.4317 - val_mae: 443.4317\n",
      "Epoch 19/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 426.7973 - mae: 426.7973 - val_loss: 441.6727 - val_mae: 441.6727\n",
      "Epoch 20/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 427.3028 - mae: 427.3028 - val_loss: 432.8000 - val_mae: 432.8000\n",
      "Epoch 21/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 425.4124 - mae: 425.4124 - val_loss: 441.9005 - val_mae: 441.9005\n",
      "Epoch 22/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 423.3005 - mae: 423.3005 - val_loss: 433.6193 - val_mae: 433.6193\n",
      "Epoch 23/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 423.2722 - mae: 423.2722 - val_loss: 428.6967 - val_mae: 428.6967\n",
      "Epoch 24/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 423.3144 - mae: 423.3144 - val_loss: 427.0482 - val_mae: 427.0482\n",
      "Epoch 25/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 421.1941 - mae: 421.1941 - val_loss: 440.2087 - val_mae: 440.2087\n",
      "Epoch 26/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 420.3263 - mae: 420.3263 - val_loss: 428.2027 - val_mae: 428.2027\n",
      "Epoch 27/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 417.9633 - mae: 417.9633 - val_loss: 426.7759 - val_mae: 426.7759\n",
      "Epoch 28/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 416.5664 - mae: 416.5664 - val_loss: 431.7783 - val_mae: 431.7783\n",
      "Epoch 29/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.6465 - mae: 414.6465 - val_loss: 427.3080 - val_mae: 427.3080\n",
      "Epoch 30/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 414.5834 - mae: 414.5834 - val_loss: 417.1338 - val_mae: 417.1338\n",
      "Epoch 31/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 411.2917 - mae: 411.2917 - val_loss: 432.5500 - val_mae: 432.5500\n",
      "Epoch 32/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 410.4108 - mae: 410.4108 - val_loss: 425.4436 - val_mae: 425.4436\n",
      "Epoch 33/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 411.8388 - mae: 411.8388 - val_loss: 421.9959 - val_mae: 421.9959\n",
      "Epoch 34/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.9407 - mae: 409.9407 - val_loss: 416.9784 - val_mae: 416.9784\n",
      "Epoch 35/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.6019 - mae: 409.6019 - val_loss: 418.1094 - val_mae: 418.1094\n",
      "Epoch 36/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 409.5542 - mae: 409.5542 - val_loss: 421.1080 - val_mae: 421.1080\n",
      "Epoch 37/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 407.3669 - mae: 407.3669 - val_loss: 423.3636 - val_mae: 423.3636\n",
      "Epoch 38/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 407.9087 - mae: 407.9087 - val_loss: 417.4731 - val_mae: 417.4731\n",
      "Epoch 39/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 406.9702 - mae: 406.9702 - val_loss: 427.3266 - val_mae: 427.3266\n",
      "Epoch 40/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 406.4003 - mae: 406.4003 - val_loss: 417.3451 - val_mae: 417.3451\n",
      "Epoch 41/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.3813 - mae: 406.3813 - val_loss: 414.8823 - val_mae: 414.8823\n",
      "Epoch 42/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 406.1111 - mae: 406.1111 - val_loss: 415.4242 - val_mae: 415.4242\n",
      "Epoch 43/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.7816 - mae: 404.7816 - val_loss: 417.0095 - val_mae: 417.0095\n",
      "Epoch 44/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.8944 - mae: 404.8944 - val_loss: 413.8614 - val_mae: 413.8614\n",
      "Epoch 45/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 404.2793 - mae: 404.2793 - val_loss: 417.5028 - val_mae: 417.5028\n",
      "Epoch 46/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.7381 - mae: 403.7381 - val_loss: 419.4965 - val_mae: 419.4965\n",
      "Epoch 47/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.6956 - mae: 403.6956 - val_loss: 411.2700 - val_mae: 411.2700\n",
      "Epoch 48/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6404 - mae: 402.6404 - val_loss: 417.3416 - val_mae: 417.3416\n",
      "Epoch 49/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 403.1028 - mae: 403.1028 - val_loss: 410.7794 - val_mae: 410.7794\n",
      "Epoch 50/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.6089 - mae: 402.6089 - val_loss: 412.6219 - val_mae: 412.6219\n",
      "Epoch 51/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.0850 - mae: 401.0850 - val_loss: 416.1501 - val_mae: 416.1501\n",
      "Epoch 52/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.1106 - mae: 402.1106 - val_loss: 420.6208 - val_mae: 420.6208\n",
      "Epoch 53/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 402.0090 - mae: 402.0090 - val_loss: 421.9821 - val_mae: 421.9821\n",
      "Epoch 54/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.2660 - mae: 401.2660 - val_loss: 410.7935 - val_mae: 410.7935\n",
      "Epoch 55/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 401.6267 - mae: 401.6267 - val_loss: 415.9061 - val_mae: 415.9061\n",
      "Epoch 56/500\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 400.4128 - mae: 400.4128 - val_loss: 419.4610 - val_mae: 419.4610\n",
      "Epoch 57/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.7123 - mae: 400.7123 - val_loss: 414.8665 - val_mae: 414.8665\n",
      "Epoch 58/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.8147 - mae: 399.8147 - val_loss: 414.5193 - val_mae: 414.5193\n",
      "Epoch 59/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.4097 - mae: 400.4097 - val_loss: 410.1648 - val_mae: 410.1648\n",
      "Epoch 60/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.9882 - mae: 398.9882 - val_loss: 411.2462 - val_mae: 411.2462\n",
      "Epoch 61/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.9429 - mae: 398.9429 - val_loss: 417.0855 - val_mae: 417.0855\n",
      "Epoch 62/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 400.0350 - mae: 400.0350 - val_loss: 414.9820 - val_mae: 414.9820\n",
      "Epoch 63/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.5887 - mae: 399.5887 - val_loss: 413.9386 - val_mae: 413.9386\n",
      "Epoch 64/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.8618 - mae: 398.8618 - val_loss: 410.3215 - val_mae: 410.3215\n",
      "Epoch 65/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.7966 - mae: 398.7966 - val_loss: 420.6318 - val_mae: 420.6318\n",
      "Epoch 66/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.6141 - mae: 398.6141 - val_loss: 415.3929 - val_mae: 415.3929\n",
      "Epoch 67/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.2543 - mae: 399.2543 - val_loss: 409.1529 - val_mae: 409.1529\n",
      "Epoch 68/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.1960 - mae: 399.1960 - val_loss: 405.1899 - val_mae: 405.1899\n",
      "Epoch 69/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.9956 - mae: 398.9956 - val_loss: 412.7053 - val_mae: 412.7053\n",
      "Epoch 70/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.1231 - mae: 399.1231 - val_loss: 414.5264 - val_mae: 414.5264\n",
      "Epoch 71/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 399.1628 - mae: 399.1628 - val_loss: 412.2788 - val_mae: 412.2788\n",
      "Epoch 72/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.2990 - mae: 398.2990 - val_loss: 411.6949 - val_mae: 411.6949\n",
      "Epoch 73/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.9421 - mae: 397.9421 - val_loss: 407.1928 - val_mae: 407.1928\n",
      "Epoch 74/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.0760 - mae: 398.0760 - val_loss: 411.8477 - val_mae: 411.8477\n",
      "Epoch 75/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.4452 - mae: 397.4452 - val_loss: 419.0954 - val_mae: 419.0954\n",
      "Epoch 76/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.3930 - mae: 397.3930 - val_loss: 409.2380 - val_mae: 409.2380\n",
      "Epoch 77/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.9084 - mae: 397.9084 - val_loss: 410.0765 - val_mae: 410.0765\n",
      "Epoch 78/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.5166 - mae: 398.5166 - val_loss: 411.5268 - val_mae: 411.5268\n",
      "Epoch 79/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 397.9240 - mae: 397.9240 - val_loss: 411.4527 - val_mae: 411.4527\n",
      "Epoch 80/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.0995 - mae: 397.0995 - val_loss: 409.6151 - val_mae: 409.6151\n",
      "Epoch 81/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 398.1650 - mae: 398.1650 - val_loss: 410.0297 - val_mae: 410.0297\n",
      "Epoch 82/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.5702 - mae: 397.5702 - val_loss: 410.3016 - val_mae: 410.3016\n",
      "Epoch 83/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.4381 - mae: 397.4381 - val_loss: 411.0595 - val_mae: 411.0595\n",
      "Epoch 84/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.5000 - mae: 397.5000 - val_loss: 407.0390 - val_mae: 407.0390\n",
      "Epoch 85/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.2420 - mae: 396.2420 - val_loss: 404.7366 - val_mae: 404.7366\n",
      "Epoch 86/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.1132 - mae: 397.1132 - val_loss: 408.1247 - val_mae: 408.1247\n",
      "Epoch 87/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.6291 - mae: 395.6291 - val_loss: 406.7536 - val_mae: 406.7536\n",
      "Epoch 88/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.4243 - mae: 396.4243 - val_loss: 409.4697 - val_mae: 409.4697\n",
      "Epoch 89/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.2215 - mae: 397.2215 - val_loss: 419.6211 - val_mae: 419.6211\n",
      "Epoch 90/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.0538 - mae: 397.0538 - val_loss: 410.5315 - val_mae: 410.5315\n",
      "Epoch 91/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.5146 - mae: 396.5146 - val_loss: 408.9586 - val_mae: 408.9586\n",
      "Epoch 92/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 397.0727 - mae: 397.0727 - val_loss: 406.1752 - val_mae: 406.1752\n",
      "Epoch 93/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 397.4026 - mae: 397.4026 - val_loss: 412.3941 - val_mae: 412.3941\n",
      "Epoch 94/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 397.1255 - mae: 397.1255 - val_loss: 408.6374 - val_mae: 408.6374\n",
      "Epoch 95/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.7271 - mae: 396.7271 - val_loss: 405.1739 - val_mae: 405.1739\n",
      "Epoch 96/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.5742 - mae: 396.5742 - val_loss: 411.5029 - val_mae: 411.5029\n",
      "Epoch 97/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.6140 - mae: 396.6140 - val_loss: 405.2759 - val_mae: 405.2759\n",
      "Epoch 98/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.8930 - mae: 395.8930 - val_loss: 411.5383 - val_mae: 411.5383\n",
      "Epoch 99/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.6499 - mae: 395.6499 - val_loss: 410.2735 - val_mae: 410.2735\n",
      "Epoch 100/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.3563 - mae: 396.3563 - val_loss: 409.9458 - val_mae: 409.9458\n",
      "Epoch 101/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.6710 - mae: 395.6710 - val_loss: 408.7525 - val_mae: 408.7525\n",
      "Epoch 102/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.2668 - mae: 396.2668 - val_loss: 423.9996 - val_mae: 423.9996\n",
      "Epoch 103/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.3191 - mae: 396.3191 - val_loss: 405.6289 - val_mae: 405.6289\n",
      "Epoch 104/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 396.3576 - mae: 396.3576 - val_loss: 409.0023 - val_mae: 409.0023\n",
      "Epoch 105/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.4870 - mae: 395.4870 - val_loss: 416.1109 - val_mae: 416.1109\n",
      "Epoch 106/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.6361 - mae: 395.6361 - val_loss: 411.5938 - val_mae: 411.5938\n",
      "Epoch 107/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.4955 - mae: 395.4955 - val_loss: 408.3195 - val_mae: 408.3195\n",
      "Epoch 108/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.5235 - mae: 395.5235 - val_loss: 408.3225 - val_mae: 408.3225\n",
      "Epoch 109/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.8590 - mae: 395.8590 - val_loss: 413.0769 - val_mae: 413.0769\n",
      "Epoch 110/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.6028 - mae: 394.6028 - val_loss: 407.4935 - val_mae: 407.4935\n",
      "Epoch 111/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.8601 - mae: 393.8601 - val_loss: 407.4370 - val_mae: 407.4370\n",
      "Epoch 112/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.0290 - mae: 395.0290 - val_loss: 415.8722 - val_mae: 415.8722\n",
      "Epoch 113/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.1366 - mae: 395.1366 - val_loss: 405.3250 - val_mae: 405.3250\n",
      "Epoch 114/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.7218 - mae: 394.7218 - val_loss: 413.4782 - val_mae: 413.4782\n",
      "Epoch 115/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.7389 - mae: 395.7389 - val_loss: 415.9104 - val_mae: 415.9104\n",
      "Epoch 116/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.8960 - mae: 394.8960 - val_loss: 410.7796 - val_mae: 410.7796\n",
      "Epoch 117/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.4248 - mae: 395.4248 - val_loss: 403.6688 - val_mae: 403.6688\n",
      "Epoch 118/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.0573 - mae: 394.0573 - val_loss: 404.0348 - val_mae: 404.0348\n",
      "Epoch 119/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.7819 - mae: 394.7819 - val_loss: 406.9997 - val_mae: 406.9997\n",
      "Epoch 120/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.3061 - mae: 394.3061 - val_loss: 403.5685 - val_mae: 403.5685\n",
      "Epoch 121/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.6059 - mae: 394.6059 - val_loss: 404.9401 - val_mae: 404.9401\n",
      "Epoch 122/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 395.1073 - mae: 395.1073 - val_loss: 403.5909 - val_mae: 403.5909\n",
      "Epoch 123/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.1664 - mae: 394.1664 - val_loss: 414.6701 - val_mae: 414.6701\n",
      "Epoch 124/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.5535 - mae: 394.5535 - val_loss: 408.6014 - val_mae: 408.6014\n",
      "Epoch 125/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 394.2206 - mae: 394.2206 - val_loss: 410.3618 - val_mae: 410.3618\n",
      "Epoch 126/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 395.2296 - mae: 395.2296 - val_loss: 405.0932 - val_mae: 405.0932\n",
      "Epoch 127/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 394.7052 - mae: 394.7052 - val_loss: 405.6202 - val_mae: 405.6202\n",
      "Epoch 128/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 394.3063 - mae: 394.3063 - val_loss: 408.2389 - val_mae: 408.2389\n",
      "Epoch 129/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 394.2005 - mae: 394.2005 - val_loss: 406.2191 - val_mae: 406.2191\n",
      "Epoch 130/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 395.7952 - mae: 395.7952 - val_loss: 402.2716 - val_mae: 402.2716\n",
      "Epoch 131/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 394.3992 - mae: 394.3992 - val_loss: 404.2206 - val_mae: 404.2206\n",
      "Epoch 132/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 393.7513 - mae: 393.7513 - val_loss: 411.2255 - val_mae: 411.2255\n",
      "Epoch 133/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.5326 - mae: 393.5326 - val_loss: 410.3297 - val_mae: 410.3297\n",
      "Epoch 134/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.8193 - mae: 394.8193 - val_loss: 408.6762 - val_mae: 408.6762\n",
      "Epoch 135/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 393.1468 - mae: 393.1468 - val_loss: 409.3493 - val_mae: 409.3493\n",
      "Epoch 136/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.0779 - mae: 394.0779 - val_loss: 403.5385 - val_mae: 403.5385\n",
      "Epoch 137/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.5323 - mae: 394.5323 - val_loss: 400.7260 - val_mae: 400.7260\n",
      "Epoch 138/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.3283 - mae: 393.3283 - val_loss: 403.8054 - val_mae: 403.8054\n",
      "Epoch 139/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 394.2484 - mae: 394.2484 - val_loss: 406.0029 - val_mae: 406.0029\n",
      "Epoch 140/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.5747 - mae: 393.5747 - val_loss: 408.5996 - val_mae: 408.5996\n",
      "Epoch 141/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.6873 - mae: 393.6873 - val_loss: 404.5770 - val_mae: 404.5770\n",
      "Epoch 142/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.8840 - mae: 393.8840 - val_loss: 404.3474 - val_mae: 404.3474\n",
      "Epoch 143/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.6287 - mae: 393.6287 - val_loss: 407.8393 - val_mae: 407.8393\n",
      "Epoch 144/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 393.9071 - mae: 393.9071 - val_loss: 404.5298 - val_mae: 404.5298\n",
      "Epoch 145/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.3721 - mae: 393.3721 - val_loss: 404.3141 - val_mae: 404.3141\n",
      "Epoch 146/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.1393 - mae: 393.1393 - val_loss: 408.3547 - val_mae: 408.3547\n",
      "Epoch 147/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.1590 - mae: 393.1590 - val_loss: 406.3839 - val_mae: 406.3839\n",
      "Epoch 148/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.0041 - mae: 393.0041 - val_loss: 405.9343 - val_mae: 405.9343\n",
      "Epoch 149/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.4713 - mae: 393.4713 - val_loss: 406.9720 - val_mae: 406.9720\n",
      "Epoch 150/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392.8611 - mae: 392.8611 - val_loss: 408.9087 - val_mae: 408.9087\n",
      "Epoch 151/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.3302 - mae: 393.3302 - val_loss: 403.8771 - val_mae: 403.8771\n",
      "Epoch 152/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.1359 - mae: 393.1359 - val_loss: 403.6949 - val_mae: 403.6949\n",
      "Epoch 153/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 393.4141 - mae: 393.4141 - val_loss: 402.9601 - val_mae: 402.9601\n",
      "Epoch 154/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 393.0504 - mae: 393.0504 - val_loss: 405.5831 - val_mae: 405.5831\n",
      "Epoch 155/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.7472 - mae: 392.7472 - val_loss: 400.0513 - val_mae: 400.0513\n",
      "Epoch 156/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.5400 - mae: 392.5400 - val_loss: 403.6967 - val_mae: 403.6967\n",
      "Epoch 157/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.6572 - mae: 392.6572 - val_loss: 407.4803 - val_mae: 407.4803\n",
      "Epoch 158/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.5423 - mae: 391.5423 - val_loss: 405.4902 - val_mae: 405.4902\n",
      "Epoch 159/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.2895 - mae: 392.2895 - val_loss: 406.3942 - val_mae: 406.3942\n",
      "Epoch 160/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.9642 - mae: 391.9642 - val_loss: 399.9225 - val_mae: 399.9225\n",
      "Epoch 161/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.9874 - mae: 392.9874 - val_loss: 402.8479 - val_mae: 402.8479\n",
      "Epoch 162/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392.1878 - mae: 392.1878 - val_loss: 405.1398 - val_mae: 405.1398\n",
      "Epoch 163/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.8102 - mae: 391.8102 - val_loss: 401.5306 - val_mae: 401.5306\n",
      "Epoch 164/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.1809 - mae: 392.1809 - val_loss: 406.6069 - val_mae: 406.6069\n",
      "Epoch 165/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.2725 - mae: 392.2725 - val_loss: 402.5947 - val_mae: 402.5947\n",
      "Epoch 166/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.8768 - mae: 391.8768 - val_loss: 407.3849 - val_mae: 407.3849\n",
      "Epoch 167/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.9687 - mae: 391.9687 - val_loss: 404.1989 - val_mae: 404.1989\n",
      "Epoch 168/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.5825 - mae: 391.5825 - val_loss: 404.3008 - val_mae: 404.3008\n",
      "Epoch 169/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.9141 - mae: 391.9141 - val_loss: 402.3173 - val_mae: 402.3173\n",
      "Epoch 170/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.9662 - mae: 391.9662 - val_loss: 401.3815 - val_mae: 401.3815\n",
      "Epoch 171/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.9856 - mae: 391.9856 - val_loss: 401.4445 - val_mae: 401.4445\n",
      "Epoch 172/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.3740 - mae: 391.3740 - val_loss: 407.1395 - val_mae: 407.1395\n",
      "Epoch 173/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392.1748 - mae: 392.1748 - val_loss: 407.4417 - val_mae: 407.4417\n",
      "Epoch 174/500\n",
      "432/432 [==============================] - 2s 3ms/step - loss: 392.2888 - mae: 392.2888 - val_loss: 408.9267 - val_mae: 408.9267\n",
      "Epoch 175/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8211 - mae: 390.8211 - val_loss: 402.8414 - val_mae: 402.8414\n",
      "Epoch 176/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.2007 - mae: 391.2007 - val_loss: 405.1613 - val_mae: 405.1613\n",
      "Epoch 177/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.4829 - mae: 392.4829 - val_loss: 399.0650 - val_mae: 399.0650\n",
      "Epoch 178/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392.4409 - mae: 392.4409 - val_loss: 406.2259 - val_mae: 406.2259\n",
      "Epoch 179/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.7503 - mae: 391.7503 - val_loss: 407.5358 - val_mae: 407.5358\n",
      "Epoch 180/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.5877 - mae: 391.5877 - val_loss: 399.9622 - val_mae: 399.9622\n",
      "Epoch 181/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.7519 - mae: 390.7519 - val_loss: 405.3112 - val_mae: 405.3112\n",
      "Epoch 182/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.6862 - mae: 391.6862 - val_loss: 406.1525 - val_mae: 406.1525\n",
      "Epoch 183/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 392.3389 - mae: 392.3389 - val_loss: 402.7535 - val_mae: 402.7535\n",
      "Epoch 184/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.4689 - mae: 390.4689 - val_loss: 409.9048 - val_mae: 409.9048\n",
      "Epoch 185/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.4648 - mae: 391.4648 - val_loss: 406.8901 - val_mae: 406.8901\n",
      "Epoch 186/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.2561 - mae: 391.2561 - val_loss: 400.3812 - val_mae: 400.3812\n",
      "Epoch 187/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.2475 - mae: 391.2475 - val_loss: 401.2343 - val_mae: 401.2343\n",
      "Epoch 188/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.7495 - mae: 391.7495 - val_loss: 409.9040 - val_mae: 409.9040\n",
      "Epoch 189/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 392.0900 - mae: 392.0900 - val_loss: 398.5732 - val_mae: 398.5732\n",
      "Epoch 190/500\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 390.9080 - mae: 390.9080 - val_loss: 402.6864 - val_mae: 402.6864\n",
      "Epoch 191/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.0538 - mae: 391.0538 - val_loss: 400.7023 - val_mae: 400.7023\n",
      "Epoch 192/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.0001 - mae: 391.0001 - val_loss: 405.8580 - val_mae: 405.8580\n",
      "Epoch 193/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.0160 - mae: 391.0160 - val_loss: 406.6643 - val_mae: 406.6643\n",
      "Epoch 194/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.2314 - mae: 391.2314 - val_loss: 402.4068 - val_mae: 402.4068\n",
      "Epoch 195/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.5076 - mae: 391.5076 - val_loss: 418.6896 - val_mae: 418.6896\n",
      "Epoch 196/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.0102 - mae: 391.0102 - val_loss: 405.4860 - val_mae: 405.4860\n",
      "Epoch 197/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.9702 - mae: 390.9702 - val_loss: 405.9097 - val_mae: 405.9097\n",
      "Epoch 198/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.2037 - mae: 391.2037 - val_loss: 403.7634 - val_mae: 403.7634\n",
      "Epoch 199/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.1609 - mae: 391.1609 - val_loss: 400.1097 - val_mae: 400.1097\n",
      "Epoch 200/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.3455 - mae: 391.3455 - val_loss: 400.2939 - val_mae: 400.2939\n",
      "Epoch 201/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.6729 - mae: 391.6729 - val_loss: 403.8092 - val_mae: 403.8092\n",
      "Epoch 202/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.5085 - mae: 391.5085 - val_loss: 405.4780 - val_mae: 405.4780\n",
      "Epoch 203/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.1459 - mae: 391.1459 - val_loss: 401.8503 - val_mae: 401.8503\n",
      "Epoch 204/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8047 - mae: 390.8047 - val_loss: 399.8508 - val_mae: 399.8508\n",
      "Epoch 205/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.1123 - mae: 391.1123 - val_loss: 403.1774 - val_mae: 403.1774\n",
      "Epoch 206/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8966 - mae: 390.8966 - val_loss: 400.9696 - val_mae: 400.9696\n",
      "Epoch 207/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.8163 - mae: 391.8163 - val_loss: 399.7119 - val_mae: 399.7119\n",
      "Epoch 208/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.9051 - mae: 391.9051 - val_loss: 402.3192 - val_mae: 402.3192\n",
      "Epoch 209/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.1895 - mae: 391.1895 - val_loss: 404.2066 - val_mae: 404.2066\n",
      "Epoch 210/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.7610 - mae: 390.7610 - val_loss: 420.5170 - val_mae: 420.5170\n",
      "Epoch 211/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.5162 - mae: 390.5162 - val_loss: 404.3811 - val_mae: 404.3811\n",
      "Epoch 212/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8943 - mae: 390.8943 - val_loss: 408.4187 - val_mae: 408.4187\n",
      "Epoch 213/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.9217 - mae: 390.9217 - val_loss: 401.2593 - val_mae: 401.2593\n",
      "Epoch 214/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.1996 - mae: 391.1996 - val_loss: 400.1449 - val_mae: 400.1449\n",
      "Epoch 215/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.4098 - mae: 390.4098 - val_loss: 406.2912 - val_mae: 406.2912\n",
      "Epoch 216/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.9374 - mae: 390.9374 - val_loss: 402.9500 - val_mae: 402.9500\n",
      "Epoch 217/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1014 - mae: 390.1014 - val_loss: 405.0024 - val_mae: 405.0024\n",
      "Epoch 218/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.4603 - mae: 390.4603 - val_loss: 399.2961 - val_mae: 399.2961\n",
      "Epoch 219/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.6624 - mae: 390.6624 - val_loss: 408.7719 - val_mae: 408.7719\n",
      "Epoch 220/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.5906 - mae: 390.5906 - val_loss: 398.7720 - val_mae: 398.7720\n",
      "Epoch 221/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.9257 - mae: 390.9257 - val_loss: 404.8557 - val_mae: 404.8557\n",
      "Epoch 222/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8226 - mae: 390.8226 - val_loss: 403.7585 - val_mae: 403.7585\n",
      "Epoch 223/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8609 - mae: 390.8609 - val_loss: 401.6021 - val_mae: 401.6021\n",
      "Epoch 224/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.7174 - mae: 390.7174 - val_loss: 400.7226 - val_mae: 400.7226\n",
      "Epoch 225/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8320 - mae: 390.8320 - val_loss: 405.4707 - val_mae: 405.4707\n",
      "Epoch 226/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.5158 - mae: 390.5158 - val_loss: 402.0499 - val_mae: 402.0499\n",
      "Epoch 227/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.6356 - mae: 390.6356 - val_loss: 402.9788 - val_mae: 402.9788\n",
      "Epoch 228/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0544 - mae: 390.0544 - val_loss: 410.4313 - val_mae: 410.4313\n",
      "Epoch 229/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.2754 - mae: 391.2754 - val_loss: 401.5122 - val_mae: 401.5122\n",
      "Epoch 230/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8045 - mae: 390.8045 - val_loss: 411.6853 - val_mae: 411.6853\n",
      "Epoch 231/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.3789 - mae: 391.3789 - val_loss: 412.1861 - val_mae: 412.1861\n",
      "Epoch 232/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3718 - mae: 390.3718 - val_loss: 404.2140 - val_mae: 404.2140\n",
      "Epoch 233/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.9111 - mae: 390.9111 - val_loss: 399.9800 - val_mae: 399.9800\n",
      "Epoch 234/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.2861 - mae: 391.2861 - val_loss: 402.2626 - val_mae: 402.2626\n",
      "Epoch 235/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8087 - mae: 390.8087 - val_loss: 403.7805 - val_mae: 403.7805\n",
      "Epoch 236/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3362 - mae: 390.3362 - val_loss: 404.7493 - val_mae: 404.7493\n",
      "Epoch 237/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1854 - mae: 390.1854 - val_loss: 403.8524 - val_mae: 403.8524\n",
      "Epoch 238/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3299 - mae: 390.3299 - val_loss: 416.4836 - val_mae: 416.4836\n",
      "Epoch 239/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8535 - mae: 390.8535 - val_loss: 402.5620 - val_mae: 402.5620\n",
      "Epoch 240/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.3647 - mae: 391.3647 - val_loss: 404.6238 - val_mae: 404.6238\n",
      "Epoch 241/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2534 - mae: 390.2534 - val_loss: 398.7172 - val_mae: 398.7172\n",
      "Epoch 242/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.4602 - mae: 390.4602 - val_loss: 399.3314 - val_mae: 399.3314\n",
      "Epoch 243/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.7444 - mae: 389.7444 - val_loss: 402.0410 - val_mae: 402.0410\n",
      "Epoch 244/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9298 - mae: 389.9298 - val_loss: 403.5939 - val_mae: 403.5939\n",
      "Epoch 245/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3294 - mae: 390.3294 - val_loss: 403.2112 - val_mae: 403.2112\n",
      "Epoch 246/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.4589 - mae: 390.4589 - val_loss: 410.7981 - val_mae: 410.7981\n",
      "Epoch 247/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.6521 - mae: 390.6521 - val_loss: 404.3892 - val_mae: 404.3892\n",
      "Epoch 248/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.6353 - mae: 390.6353 - val_loss: 401.6189 - val_mae: 401.6189\n",
      "Epoch 249/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1161 - mae: 390.1161 - val_loss: 413.7378 - val_mae: 413.7378\n",
      "Epoch 250/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2651 - mae: 390.2651 - val_loss: 398.1948 - val_mae: 398.1948\n",
      "Epoch 251/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1913 - mae: 390.1913 - val_loss: 405.6779 - val_mae: 405.6779\n",
      "Epoch 252/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.4841 - mae: 390.4841 - val_loss: 404.5813 - val_mae: 404.5813\n",
      "Epoch 253/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3470 - mae: 390.3470 - val_loss: 406.1923 - val_mae: 406.1923\n",
      "Epoch 254/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.9703 - mae: 390.9703 - val_loss: 404.2943 - val_mae: 404.2943\n",
      "Epoch 255/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8339 - mae: 390.8339 - val_loss: 399.1338 - val_mae: 399.1338\n",
      "Epoch 256/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.1245 - mae: 390.1245 - val_loss: 403.1024 - val_mae: 403.1024\n",
      "Epoch 257/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.9930 - mae: 389.9930 - val_loss: 405.1857 - val_mae: 405.1857\n",
      "Epoch 258/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 391.0290 - mae: 391.0290 - val_loss: 408.0699 - val_mae: 408.0699\n",
      "Epoch 259/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.3296 - mae: 391.3296 - val_loss: 401.5838 - val_mae: 401.5838\n",
      "Epoch 260/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6824 - mae: 389.6824 - val_loss: 405.6382 - val_mae: 405.6382\n",
      "Epoch 261/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0989 - mae: 390.0989 - val_loss: 401.3542 - val_mae: 401.3542\n",
      "Epoch 262/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0160 - mae: 390.0160 - val_loss: 403.4295 - val_mae: 403.4295\n",
      "Epoch 263/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1284 - mae: 390.1284 - val_loss: 405.7997 - val_mae: 405.7997\n",
      "Epoch 264/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.7116 - mae: 389.7116 - val_loss: 400.6396 - val_mae: 400.6396\n",
      "Epoch 265/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.5969 - mae: 390.5969 - val_loss: 402.9791 - val_mae: 402.9791\n",
      "Epoch 266/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.5323 - mae: 390.5323 - val_loss: 400.9189 - val_mae: 400.9189\n",
      "Epoch 267/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0488 - mae: 390.0488 - val_loss: 404.7291 - val_mae: 404.7291\n",
      "Epoch 268/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.7068 - mae: 390.7068 - val_loss: 401.0859 - val_mae: 401.0859\n",
      "Epoch 269/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3288 - mae: 390.3288 - val_loss: 401.7221 - val_mae: 401.7221\n",
      "Epoch 270/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9551 - mae: 389.9551 - val_loss: 401.4814 - val_mae: 401.4814\n",
      "Epoch 271/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.5318 - mae: 390.5318 - val_loss: 401.7869 - val_mae: 401.7869\n",
      "Epoch 272/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.6385 - mae: 390.6385 - val_loss: 397.7155 - val_mae: 397.7155\n",
      "Epoch 273/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9026 - mae: 389.9026 - val_loss: 414.2189 - val_mae: 414.2189\n",
      "Epoch 274/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.6873 - mae: 390.6873 - val_loss: 401.7875 - val_mae: 401.7875\n",
      "Epoch 275/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2947 - mae: 390.2947 - val_loss: 407.8011 - val_mae: 407.8011\n",
      "Epoch 276/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.7060 - mae: 390.7060 - val_loss: 400.1837 - val_mae: 400.1837\n",
      "Epoch 277/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9857 - mae: 389.9857 - val_loss: 405.2512 - val_mae: 405.2512\n",
      "Epoch 278/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3037 - mae: 390.3037 - val_loss: 400.8351 - val_mae: 400.8351\n",
      "Epoch 279/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.9991 - mae: 389.9991 - val_loss: 402.3890 - val_mae: 402.3890\n",
      "Epoch 280/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1700 - mae: 390.1700 - val_loss: 400.8023 - val_mae: 400.8023\n",
      "Epoch 281/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3968 - mae: 390.3968 - val_loss: 400.9651 - val_mae: 400.9651\n",
      "Epoch 282/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6492 - mae: 389.6492 - val_loss: 401.0653 - val_mae: 401.0653\n",
      "Epoch 283/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9968 - mae: 389.9968 - val_loss: 402.9434 - val_mae: 402.9434\n",
      "Epoch 284/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.7046 - mae: 390.7046 - val_loss: 402.0243 - val_mae: 402.0243\n",
      "Epoch 285/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.8152 - mae: 389.8152 - val_loss: 401.0819 - val_mae: 401.0819\n",
      "Epoch 286/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.6312 - mae: 390.6312 - val_loss: 410.9178 - val_mae: 410.9178\n",
      "Epoch 287/500\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 389.7851 - mae: 389.7851 - val_loss: 414.0986 - val_mae: 414.0986\n",
      "Epoch 288/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2534 - mae: 390.2534 - val_loss: 405.3886 - val_mae: 405.3886\n",
      "Epoch 289/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 391.1104 - mae: 391.1104 - val_loss: 401.9745 - val_mae: 401.9745\n",
      "Epoch 290/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5897 - mae: 389.5897 - val_loss: 400.4462 - val_mae: 400.4462\n",
      "Epoch 291/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.5005 - mae: 390.5005 - val_loss: 411.9056 - val_mae: 411.9056\n",
      "Epoch 292/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.2285 - mae: 389.2285 - val_loss: 401.2906 - val_mae: 401.2906\n",
      "Epoch 293/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1374 - mae: 390.1374 - val_loss: 402.1742 - val_mae: 402.1742\n",
      "Epoch 294/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3046 - mae: 390.3046 - val_loss: 410.7284 - val_mae: 410.7284\n",
      "Epoch 295/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.6306 - mae: 390.6306 - val_loss: 405.9965 - val_mae: 405.9965\n",
      "Epoch 296/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7336 - mae: 389.7336 - val_loss: 404.0529 - val_mae: 404.0529\n",
      "Epoch 297/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.8395 - mae: 389.8395 - val_loss: 402.2445 - val_mae: 402.2445\n",
      "Epoch 298/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0511 - mae: 390.0511 - val_loss: 400.8832 - val_mae: 400.8832\n",
      "Epoch 299/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5415 - mae: 389.5415 - val_loss: 399.5282 - val_mae: 399.5282\n",
      "Epoch 300/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.8766 - mae: 389.8766 - val_loss: 404.5797 - val_mae: 404.5797\n",
      "Epoch 301/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.0571 - mae: 389.0571 - val_loss: 404.3265 - val_mae: 404.3265\n",
      "Epoch 302/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.2769 - mae: 389.2769 - val_loss: 400.8371 - val_mae: 400.8371\n",
      "Epoch 303/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0349 - mae: 390.0349 - val_loss: 398.4045 - val_mae: 398.4045\n",
      "Epoch 304/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9714 - mae: 389.9714 - val_loss: 399.7787 - val_mae: 399.7787\n",
      "Epoch 305/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2517 - mae: 390.2517 - val_loss: 404.9990 - val_mae: 404.9990\n",
      "Epoch 306/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0005 - mae: 390.0005 - val_loss: 403.9912 - val_mae: 403.9912\n",
      "Epoch 307/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.8397 - mae: 390.8397 - val_loss: 402.5924 - val_mae: 402.5924\n",
      "Epoch 308/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6302 - mae: 389.6302 - val_loss: 407.6027 - val_mae: 407.6027\n",
      "Epoch 309/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3895 - mae: 390.3895 - val_loss: 400.5551 - val_mae: 400.5551\n",
      "Epoch 310/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4763 - mae: 389.4763 - val_loss: 401.5898 - val_mae: 401.5898\n",
      "Epoch 311/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.8810 - mae: 389.8810 - val_loss: 399.6789 - val_mae: 399.6789\n",
      "Epoch 312/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9571 - mae: 389.9571 - val_loss: 404.3266 - val_mae: 404.3266\n",
      "Epoch 313/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.2922 - mae: 389.2922 - val_loss: 399.9375 - val_mae: 399.9375\n",
      "Epoch 314/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9091 - mae: 389.9091 - val_loss: 402.0905 - val_mae: 402.0905\n",
      "Epoch 315/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3008 - mae: 389.3008 - val_loss: 401.6607 - val_mae: 401.6607\n",
      "Epoch 316/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.9904 - mae: 389.9904 - val_loss: 399.8443 - val_mae: 399.8443\n",
      "Epoch 317/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.3885 - mae: 390.3885 - val_loss: 403.5996 - val_mae: 403.5996\n",
      "Epoch 318/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.8620 - mae: 389.8620 - val_loss: 407.9619 - val_mae: 407.9619\n",
      "Epoch 319/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.3263 - mae: 389.3263 - val_loss: 404.2377 - val_mae: 404.2377\n",
      "Epoch 320/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.9180 - mae: 389.9180 - val_loss: 401.1706 - val_mae: 401.1706\n",
      "Epoch 321/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.7065 - mae: 389.7065 - val_loss: 407.2069 - val_mae: 407.2069\n",
      "Epoch 322/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.2283 - mae: 390.2283 - val_loss: 398.4948 - val_mae: 398.4948\n",
      "Epoch 323/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.5433 - mae: 390.5433 - val_loss: 399.5649 - val_mae: 399.5649\n",
      "Epoch 324/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.4475 - mae: 389.4475 - val_loss: 403.3823 - val_mae: 403.3823\n",
      "Epoch 325/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.4779 - mae: 389.4779 - val_loss: 403.6303 - val_mae: 403.6303\n",
      "Epoch 326/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.2773 - mae: 390.2773 - val_loss: 404.8405 - val_mae: 404.8405\n",
      "Epoch 327/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.2176 - mae: 390.2176 - val_loss: 409.0867 - val_mae: 409.0867\n",
      "Epoch 328/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.2695 - mae: 389.2695 - val_loss: 401.1958 - val_mae: 401.1958\n",
      "Epoch 329/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9918 - mae: 389.9918 - val_loss: 399.3254 - val_mae: 399.3254\n",
      "Epoch 330/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3279 - mae: 389.3279 - val_loss: 399.8827 - val_mae: 399.8827\n",
      "Epoch 331/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9176 - mae: 389.9176 - val_loss: 406.3682 - val_mae: 406.3682\n",
      "Epoch 332/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9432 - mae: 389.9432 - val_loss: 401.9358 - val_mae: 401.9358\n",
      "Epoch 333/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7357 - mae: 389.7357 - val_loss: 403.3523 - val_mae: 403.3523\n",
      "Epoch 334/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.3226 - mae: 389.3226 - val_loss: 402.1152 - val_mae: 402.1152\n",
      "Epoch 335/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.4449 - mae: 390.4449 - val_loss: 400.5695 - val_mae: 400.5695\n",
      "Epoch 336/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.9586 - mae: 389.9586 - val_loss: 401.8445 - val_mae: 401.8445\n",
      "Epoch 337/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.6619 - mae: 389.6619 - val_loss: 404.6129 - val_mae: 404.6129\n",
      "Epoch 338/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.2646 - mae: 389.2646 - val_loss: 411.3918 - val_mae: 411.3918\n",
      "Epoch 339/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9008 - mae: 389.9008 - val_loss: 403.1097 - val_mae: 403.1097\n",
      "Epoch 340/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.1132 - mae: 389.1132 - val_loss: 410.0987 - val_mae: 410.0987\n",
      "Epoch 341/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9729 - mae: 389.9729 - val_loss: 401.1689 - val_mae: 401.1689\n",
      "Epoch 342/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6372 - mae: 389.6372 - val_loss: 398.0672 - val_mae: 398.0672\n",
      "Epoch 343/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4259 - mae: 389.4259 - val_loss: 403.8281 - val_mae: 403.8281\n",
      "Epoch 344/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0055 - mae: 390.0055 - val_loss: 402.4049 - val_mae: 402.4049\n",
      "Epoch 345/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.6985 - mae: 390.6985 - val_loss: 406.2593 - val_mae: 406.2593\n",
      "Epoch 346/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.8564 - mae: 389.8564 - val_loss: 409.6360 - val_mae: 409.6360\n",
      "Epoch 347/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0684 - mae: 390.0684 - val_loss: 403.8975 - val_mae: 403.8975\n",
      "Epoch 348/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9718 - mae: 389.9718 - val_loss: 401.9741 - val_mae: 401.9741\n",
      "Epoch 349/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5031 - mae: 389.5031 - val_loss: 406.8470 - val_mae: 406.8470\n",
      "Epoch 350/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9691 - mae: 389.9691 - val_loss: 402.7345 - val_mae: 402.7345\n",
      "Epoch 351/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7044 - mae: 389.7044 - val_loss: 406.4384 - val_mae: 406.4384\n",
      "Epoch 352/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5812 - mae: 389.5812 - val_loss: 404.0501 - val_mae: 404.0501\n",
      "Epoch 353/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2725 - mae: 390.2725 - val_loss: 401.2722 - val_mae: 401.2722\n",
      "Epoch 354/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7893 - mae: 389.7893 - val_loss: 402.4600 - val_mae: 402.4600\n",
      "Epoch 355/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1173 - mae: 390.1173 - val_loss: 404.3578 - val_mae: 404.3578\n",
      "Epoch 356/500\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 390.3061 - mae: 390.3061 - val_loss: 400.0681 - val_mae: 400.0681\n",
      "Epoch 357/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7542 - mae: 389.7542 - val_loss: 402.1543 - val_mae: 402.1543\n",
      "Epoch 358/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7386 - mae: 389.7386 - val_loss: 404.6827 - val_mae: 404.6827\n",
      "Epoch 359/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1585 - mae: 390.1585 - val_loss: 399.5282 - val_mae: 399.5282\n",
      "Epoch 360/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3156 - mae: 389.3156 - val_loss: 404.8639 - val_mae: 404.8639\n",
      "Epoch 361/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.9740 - mae: 389.9740 - val_loss: 401.0188 - val_mae: 401.0188\n",
      "Epoch 362/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2276 - mae: 390.2276 - val_loss: 403.6216 - val_mae: 403.6216\n",
      "Epoch 363/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4042 - mae: 389.4042 - val_loss: 403.9211 - val_mae: 403.9211\n",
      "Epoch 364/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6068 - mae: 389.6068 - val_loss: 405.6660 - val_mae: 405.6660\n",
      "Epoch 365/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.5254 - mae: 390.5254 - val_loss: 401.4355 - val_mae: 401.4355\n",
      "Epoch 366/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.4473 - mae: 389.4473 - val_loss: 406.4770 - val_mae: 406.4770\n",
      "Epoch 367/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2080 - mae: 390.2080 - val_loss: 406.4185 - val_mae: 406.4185\n",
      "Epoch 368/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7109 - mae: 389.7109 - val_loss: 407.7231 - val_mae: 407.7231\n",
      "Epoch 369/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6077 - mae: 389.6077 - val_loss: 404.4741 - val_mae: 404.4741\n",
      "Epoch 370/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.0549 - mae: 389.0549 - val_loss: 403.1987 - val_mae: 403.1987\n",
      "Epoch 371/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5664 - mae: 389.5664 - val_loss: 398.7879 - val_mae: 398.7879\n",
      "Epoch 372/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3481 - mae: 389.3481 - val_loss: 410.4799 - val_mae: 410.4799\n",
      "Epoch 373/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4047 - mae: 389.4047 - val_loss: 400.1578 - val_mae: 400.1578\n",
      "Epoch 374/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7285 - mae: 389.7285 - val_loss: 402.1385 - val_mae: 402.1385\n",
      "Epoch 375/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1725 - mae: 390.1725 - val_loss: 406.0222 - val_mae: 406.0222\n",
      "Epoch 376/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6476 - mae: 389.6476 - val_loss: 400.1412 - val_mae: 400.1412\n",
      "Epoch 377/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4111 - mae: 389.4111 - val_loss: 404.6295 - val_mae: 404.6295\n",
      "Epoch 378/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5791 - mae: 389.5791 - val_loss: 399.0432 - val_mae: 399.0432\n",
      "Epoch 379/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.8224 - mae: 389.8224 - val_loss: 403.9404 - val_mae: 403.9404\n",
      "Epoch 380/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6088 - mae: 389.6088 - val_loss: 403.6576 - val_mae: 403.6576\n",
      "Epoch 381/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3503 - mae: 389.3503 - val_loss: 410.7746 - val_mae: 410.7746\n",
      "Epoch 382/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6382 - mae: 389.6382 - val_loss: 408.1990 - val_mae: 408.1990\n",
      "Epoch 383/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6033 - mae: 389.6033 - val_loss: 402.2554 - val_mae: 402.2554\n",
      "Epoch 384/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0329 - mae: 390.0329 - val_loss: 404.2090 - val_mae: 404.2090\n",
      "Epoch 385/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0305 - mae: 390.0305 - val_loss: 412.4005 - val_mae: 412.4005\n",
      "Epoch 386/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7881 - mae: 389.7881 - val_loss: 403.4853 - val_mae: 403.4853\n",
      "Epoch 387/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6874 - mae: 389.6874 - val_loss: 404.5226 - val_mae: 404.5226\n",
      "Epoch 388/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.4902 - mae: 389.4902 - val_loss: 401.7713 - val_mae: 401.7713\n",
      "Epoch 389/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.8966 - mae: 389.8966 - val_loss: 406.6161 - val_mae: 406.6161\n",
      "Epoch 390/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.6556 - mae: 389.6556 - val_loss: 400.8478 - val_mae: 400.8478\n",
      "Epoch 391/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.8717 - mae: 389.8717 - val_loss: 399.7411 - val_mae: 399.7411\n",
      "Epoch 392/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5246 - mae: 389.5246 - val_loss: 398.7560 - val_mae: 398.7560\n",
      "Epoch 393/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.1068 - mae: 389.1068 - val_loss: 400.5693 - val_mae: 400.5693\n",
      "Epoch 394/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7684 - mae: 389.7684 - val_loss: 400.8806 - val_mae: 400.8806\n",
      "Epoch 395/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4474 - mae: 389.4474 - val_loss: 409.5537 - val_mae: 409.5537\n",
      "Epoch 396/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9070 - mae: 389.9070 - val_loss: 400.1567 - val_mae: 400.1567\n",
      "Epoch 397/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388.8437 - mae: 388.8437 - val_loss: 402.8915 - val_mae: 402.8915\n",
      "Epoch 398/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.0797 - mae: 389.0797 - val_loss: 398.9590 - val_mae: 398.9590\n",
      "Epoch 399/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4116 - mae: 389.4116 - val_loss: 409.4574 - val_mae: 409.4574\n",
      "Epoch 400/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2603 - mae: 390.2603 - val_loss: 407.1289 - val_mae: 407.1289\n",
      "Epoch 401/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3846 - mae: 389.3846 - val_loss: 409.3924 - val_mae: 409.3924\n",
      "Epoch 402/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.8562 - mae: 389.8562 - val_loss: 401.2472 - val_mae: 401.2472\n",
      "Epoch 403/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.4415 - mae: 389.4415 - val_loss: 401.9263 - val_mae: 401.9263\n",
      "Epoch 404/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0952 - mae: 390.0952 - val_loss: 404.5864 - val_mae: 404.5864\n",
      "Epoch 405/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7928 - mae: 389.7928 - val_loss: 402.3235 - val_mae: 402.3235\n",
      "Epoch 406/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0398 - mae: 390.0398 - val_loss: 402.9040 - val_mae: 402.9040\n",
      "Epoch 407/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7880 - mae: 389.7880 - val_loss: 401.3804 - val_mae: 401.3804\n",
      "Epoch 408/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.0883 - mae: 389.0883 - val_loss: 404.5440 - val_mae: 404.5440\n",
      "Epoch 409/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0541 - mae: 390.0541 - val_loss: 408.4711 - val_mae: 408.4711\n",
      "Epoch 410/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9759 - mae: 389.9759 - val_loss: 400.1388 - val_mae: 400.1388\n",
      "Epoch 411/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.7811 - mae: 389.7811 - val_loss: 400.3711 - val_mae: 400.3711\n",
      "Epoch 412/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5142 - mae: 389.5142 - val_loss: 407.6318 - val_mae: 407.6318\n",
      "Epoch 413/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5773 - mae: 389.5773 - val_loss: 401.0232 - val_mae: 401.0232\n",
      "Epoch 414/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5486 - mae: 389.5486 - val_loss: 405.4430 - val_mae: 405.4430\n",
      "Epoch 415/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.3655 - mae: 390.3655 - val_loss: 402.1364 - val_mae: 402.1364\n",
      "Epoch 416/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0688 - mae: 390.0688 - val_loss: 400.2601 - val_mae: 400.2601\n",
      "Epoch 417/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.0815 - mae: 389.0815 - val_loss: 399.4856 - val_mae: 399.4856\n",
      "Epoch 418/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.8649 - mae: 389.8649 - val_loss: 401.7323 - val_mae: 401.7323\n",
      "Epoch 419/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4875 - mae: 389.4875 - val_loss: 401.4695 - val_mae: 401.4695\n",
      "Epoch 420/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3226 - mae: 389.3226 - val_loss: 399.8499 - val_mae: 399.8499\n",
      "Epoch 421/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.6493 - mae: 389.6493 - val_loss: 405.7292 - val_mae: 405.7292\n",
      "Epoch 422/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7856 - mae: 389.7856 - val_loss: 399.0820 - val_mae: 399.0820\n",
      "Epoch 423/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.7939 - mae: 389.7939 - val_loss: 412.3235 - val_mae: 412.3235\n",
      "Epoch 424/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4796 - mae: 389.4796 - val_loss: 399.1354 - val_mae: 399.1354\n",
      "Epoch 425/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6964 - mae: 389.6964 - val_loss: 398.2244 - val_mae: 398.2244\n",
      "Epoch 426/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.7391 - mae: 389.7391 - val_loss: 401.0694 - val_mae: 401.0694\n",
      "Epoch 427/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.2577 - mae: 389.2577 - val_loss: 402.3773 - val_mae: 402.3773\n",
      "Epoch 428/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.0681 - mae: 389.0681 - val_loss: 402.4973 - val_mae: 402.4973\n",
      "Epoch 429/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388.9319 - mae: 388.9319 - val_loss: 401.7869 - val_mae: 401.7869\n",
      "Epoch 430/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5412 - mae: 389.5412 - val_loss: 407.7411 - val_mae: 407.7411\n",
      "Epoch 431/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3091 - mae: 389.3091 - val_loss: 402.7187 - val_mae: 402.7187\n",
      "Epoch 432/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.4799 - mae: 389.4799 - val_loss: 402.3028 - val_mae: 402.3028\n",
      "Epoch 433/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.0503 - mae: 389.0503 - val_loss: 403.0049 - val_mae: 403.0049\n",
      "Epoch 434/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.2006 - mae: 390.2006 - val_loss: 403.2031 - val_mae: 403.2031\n",
      "Epoch 435/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7380 - mae: 389.7380 - val_loss: 403.8515 - val_mae: 403.8515\n",
      "Epoch 436/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9316 - mae: 389.9316 - val_loss: 401.4213 - val_mae: 401.4213\n",
      "Epoch 437/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3245 - mae: 389.3245 - val_loss: 399.2398 - val_mae: 399.2398\n",
      "Epoch 438/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0727 - mae: 390.0727 - val_loss: 399.6787 - val_mae: 399.6787\n",
      "Epoch 439/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388.8300 - mae: 388.8300 - val_loss: 404.1160 - val_mae: 404.1160\n",
      "Epoch 440/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3157 - mae: 389.3157 - val_loss: 404.2410 - val_mae: 404.2410\n",
      "Epoch 441/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.4890 - mae: 389.4890 - val_loss: 405.4484 - val_mae: 405.4484\n",
      "Epoch 442/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.1003 - mae: 389.1003 - val_loss: 401.1240 - val_mae: 401.1240\n",
      "Epoch 443/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.6690 - mae: 389.6690 - val_loss: 400.4559 - val_mae: 400.4559\n",
      "Epoch 444/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.1120 - mae: 389.1120 - val_loss: 402.4252 - val_mae: 402.4252\n",
      "Epoch 445/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7000 - mae: 389.7000 - val_loss: 399.0811 - val_mae: 399.0811\n",
      "Epoch 446/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5546 - mae: 389.5546 - val_loss: 404.0904 - val_mae: 404.0904\n",
      "Epoch 447/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9095 - mae: 389.9095 - val_loss: 406.0644 - val_mae: 406.0644\n",
      "Epoch 448/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388.9403 - mae: 388.9403 - val_loss: 401.5335 - val_mae: 401.5335\n",
      "Epoch 449/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3812 - mae: 389.3812 - val_loss: 399.8644 - val_mae: 399.8644\n",
      "Epoch 450/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388.9690 - mae: 388.9690 - val_loss: 401.3311 - val_mae: 401.3311\n",
      "Epoch 451/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5459 - mae: 389.5459 - val_loss: 401.9321 - val_mae: 401.9321\n",
      "Epoch 452/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9913 - mae: 389.9913 - val_loss: 399.5191 - val_mae: 399.5191\n",
      "Epoch 453/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.2241 - mae: 389.2241 - val_loss: 408.8355 - val_mae: 408.8355\n",
      "Epoch 454/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.2662 - mae: 389.2662 - val_loss: 406.8161 - val_mae: 406.8161\n",
      "Epoch 455/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1943 - mae: 390.1943 - val_loss: 401.0011 - val_mae: 401.0011\n",
      "Epoch 456/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.1775 - mae: 389.1775 - val_loss: 411.1706 - val_mae: 411.1706\n",
      "Epoch 457/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7381 - mae: 389.7381 - val_loss: 406.3980 - val_mae: 406.3980\n",
      "Epoch 458/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7806 - mae: 389.7806 - val_loss: 401.1975 - val_mae: 401.1975\n",
      "Epoch 459/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0031 - mae: 390.0031 - val_loss: 399.7073 - val_mae: 399.7073\n",
      "Epoch 460/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.1071 - mae: 389.1071 - val_loss: 400.3527 - val_mae: 400.3527\n",
      "Epoch 461/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388.8789 - mae: 388.8789 - val_loss: 402.2272 - val_mae: 402.2272\n",
      "Epoch 462/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5562 - mae: 389.5562 - val_loss: 397.3492 - val_mae: 397.3492\n",
      "Epoch 463/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7031 - mae: 389.7031 - val_loss: 402.1365 - val_mae: 402.1365\n",
      "Epoch 464/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5183 - mae: 389.5183 - val_loss: 399.7895 - val_mae: 399.7895\n",
      "Epoch 465/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 388.9754 - mae: 388.9754 - val_loss: 403.6427 - val_mae: 403.6427\n",
      "Epoch 466/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5002 - mae: 389.5002 - val_loss: 403.8967 - val_mae: 403.8967\n",
      "Epoch 467/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3770 - mae: 389.3770 - val_loss: 397.6156 - val_mae: 397.6156\n",
      "Epoch 468/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.0358 - mae: 389.0358 - val_loss: 403.5401 - val_mae: 403.5401\n",
      "Epoch 469/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1234 - mae: 390.1234 - val_loss: 408.8418 - val_mae: 408.8418\n",
      "Epoch 470/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0938 - mae: 390.0938 - val_loss: 400.8454 - val_mae: 400.8454\n",
      "Epoch 471/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.1990 - mae: 389.1990 - val_loss: 409.4638 - val_mae: 409.4638\n",
      "Epoch 472/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7834 - mae: 389.7834 - val_loss: 402.2212 - val_mae: 402.2212\n",
      "Epoch 473/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5628 - mae: 389.5628 - val_loss: 406.0157 - val_mae: 406.0157\n",
      "Epoch 474/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.6703 - mae: 389.6703 - val_loss: 417.0876 - val_mae: 417.0876\n",
      "Epoch 475/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.1039 - mae: 390.1039 - val_loss: 408.7554 - val_mae: 408.7554\n",
      "Epoch 476/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.2295 - mae: 390.2295 - val_loss: 402.3420 - val_mae: 402.3420\n",
      "Epoch 477/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5140 - mae: 389.5140 - val_loss: 401.4656 - val_mae: 401.4656\n",
      "Epoch 478/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7329 - mae: 389.7329 - val_loss: 402.1237 - val_mae: 402.1237\n",
      "Epoch 479/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 388.5185 - mae: 388.5185 - val_loss: 403.9415 - val_mae: 403.9415\n",
      "Epoch 480/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.0550 - mae: 389.0550 - val_loss: 404.2988 - val_mae: 404.2988\n",
      "Epoch 481/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 390.1364 - mae: 390.1364 - val_loss: 398.0434 - val_mae: 398.0434\n",
      "Epoch 482/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5195 - mae: 389.5195 - val_loss: 401.6192 - val_mae: 401.6192\n",
      "Epoch 483/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6107 - mae: 389.6107 - val_loss: 400.6138 - val_mae: 400.6138\n",
      "Epoch 484/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5306 - mae: 389.5306 - val_loss: 407.7181 - val_mae: 407.7181\n",
      "Epoch 485/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.3433 - mae: 389.3433 - val_loss: 399.7794 - val_mae: 399.7794\n",
      "Epoch 486/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0822 - mae: 390.0822 - val_loss: 400.4587 - val_mae: 400.4587\n",
      "Epoch 487/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 390.0352 - mae: 390.0352 - val_loss: 404.1841 - val_mae: 404.1841\n",
      "Epoch 488/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.5241 - mae: 389.5241 - val_loss: 400.4978 - val_mae: 400.4978\n",
      "Epoch 489/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 388.5692 - mae: 388.5692 - val_loss: 402.8295 - val_mae: 402.8295\n",
      "Epoch 490/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.9369 - mae: 389.9369 - val_loss: 400.1463 - val_mae: 400.1463\n",
      "Epoch 491/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5230 - mae: 389.5230 - val_loss: 408.7729 - val_mae: 408.7729\n",
      "Epoch 492/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.6729 - mae: 389.6729 - val_loss: 399.4805 - val_mae: 399.4805\n",
      "Epoch 493/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 388.7508 - mae: 388.7508 - val_loss: 400.4399 - val_mae: 400.4399\n",
      "Epoch 494/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.5722 - mae: 389.5722 - val_loss: 402.5253 - val_mae: 402.5253\n",
      "Epoch 495/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.3328 - mae: 389.3328 - val_loss: 403.4969 - val_mae: 403.4969\n",
      "Epoch 496/500\n",
      "432/432 [==============================] - 1s 2ms/step - loss: 389.7036 - mae: 389.7036 - val_loss: 414.3617 - val_mae: 414.3617\n",
      "Epoch 497/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.8327 - mae: 389.8327 - val_loss: 406.0375 - val_mae: 406.0375\n",
      "Epoch 498/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 388.5652 - mae: 388.5652 - val_loss: 402.6682 - val_mae: 402.6682\n",
      "Epoch 499/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.3249 - mae: 389.3249 - val_loss: 403.3254 - val_mae: 403.3254\n",
      "Epoch 500/500\n",
      "432/432 [==============================] - 1s 1ms/step - loss: 389.2966 - mae: 389.2966 - val_loss: 409.4968 - val_mae: 409.4968\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only = True)\n",
    "\n",
    "model = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data = (x_test, y_test),\n",
    "    batch_size = 32,\n",
    "    epochs = 500,\n",
    "    callbacks = [checkpoint]\n",
    ")\n",
    "\n",
    "best_model = load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 2ms/step\n",
      "RÂ²:  0.8243354549813238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"RÂ²: \", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
